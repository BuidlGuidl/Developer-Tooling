{
  "mcpdotdirect/evm-mcp-server": {
    "fetchedAt": "2025-11-12T22:35:24.676Z",
    "content": "# EVM MCP Server\n\n![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)\n![EVM Networks](https://img.shields.io/badge/Networks-30+-green)\n![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6)\n![Viem](https://img.shields.io/badge/Viem-1.0+-green)\n\nA comprehensive Model Context Protocol (MCP) server that provides blockchain services across multiple EVM-compatible networks. This server enables AI agents to interact with Ethereum, Optimism, Arbitrum, Base, Polygon, and many other EVM chains with a unified interface.\n\n## üìã Contents\n\n- [Overview](#overview)\n- [Features](#features)\n- [Supported Networks](#supported-networks)\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Server Configuration](#server-configuration)\n- [Usage](#usage)\n- [API Reference](#api-reference)\n  - [Tools](#tools)\n  - [Resources](#resources)\n- [Security Considerations](#security-considerations)\n- [Project Structure](#project-structure)\n- [Development](#development)\n- [License](#license)\n\n## üî≠ Overview\n\nThe MCP EVM Server leverages the Model Context Protocol to provide blockchain services to AI agents. It supports a wide range of services including:\n\n- Reading blockchain state (balances, transactions, blocks, etc.)\n- Interacting with smart contracts\n- Transferring tokens (native, ERC20, ERC721, ERC1155)\n- Querying token metadata and balances\n- Chain-specific services across 30+ EVM networks\n- **ENS name resolution** for all address parameters (use human-readable names like 'vitalik.eth' instead of addresses)\n\nAll services are exposed through a consistent interface of MCP tools and resources, making it easy for AI agents to discover and use blockchain functionality. **Every tool that accepts Ethereum addresses also supports ENS names**, automatically resolving them to addresses behind the scenes.\n\n## ‚ú® Features\n\n### Blockchain Data Access\n\n- **Multi-chain support** for 30+ EVM-compatible networks\n- **Chain information** including blockNumber, chainId, and RPCs\n- **Block data** access by number, hash, or latest\n- **Transaction details** and receipts with decoded logs\n- **Address balances** for native tokens and all token standards\n- **ENS resolution** for human-readable Ethereum addresses (use 'vitalik.eth' instead of '0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045')\n\n### Token services\n\n- **ERC20 Tokens**\n  - Get token metadata (name, symbol, decimals, supply)\n  - Check token balances\n  - Transfer tokens between addresses\n  - Approve spending allowances\n\n- **NFTs (ERC721)**\n  - Get collection and token metadata\n  - Verify token ownership\n  - Transfer NFTs between addresses\n  - Retrieve token URIs and count holdings\n\n- **Multi-tokens (ERC1155)**\n  - Get token balances and metadata\n  - Transfer tokens with quantity\n  - Access token URIs\n\n### Smart Contract Interactions\n\n- **Read contract state** through view/pure functions\n- **Write services** with private key signing\n- **Contract verification** to distinguish from EOAs\n- **Event logs** retrieval and filtering\n\n### Comprehensive Transaction Support\n\n- **Native token transfers** across all supported networks\n- **Gas estimation** for transaction planning\n- **Transaction status** and receipt information\n- **Error handling** with descriptive messages\n\n## üåê Supported Networks\n\n### Mainnets\n- Ethereum (ETH)\n- Optimism (OP)\n- Arbitrum (ARB)\n- Arbitrum Nova\n- Base\n- Polygon (MATIC)\n- Polygon zkEVM\n- Avalanche (AVAX)\n- Binance Smart Chain (BSC)\n- zkSync Era\n- Linea\n- Celo\n- Gnosis (xDai)\n- Fantom (FTM)\n- Filecoin (FIL)\n- Moonbeam\n- Moonriver\n- Cronos\n- Scroll\n- Mantle\n- Manta\n- Blast\n- Fraxtal\n- Mode\n- Metis\n- Kroma\n- Zora\n- Aurora\n- Canto\n- Flow\n- Lumia\n\n### Testnets\n- Sepolia\n- Optimism Sepolia\n- Arbitrum Sepolia\n- Base Sepolia\n- Polygon Amoy\n- Avalanche Fuji\n- BSC Testnet\n- zkSync Sepolia\n- Linea Sepolia\n- Scroll Sepolia\n- Mantle Sepolia\n- Manta Sepolia\n- Blast Sepolia\n- Fraxtal Testnet\n- Mode Testnet\n- Metis Sepolia\n- Kroma Sepolia\n- Zora Sepolia\n- Celo Alfajores\n- Goerli\n- Holesky\n- Flow Testnet\n- Filecoin Calibration\n- Lumia Testnet\n\n## üõ†Ô∏è Prerequisites\n\n- [Bun](https://bun.sh/) 1.0.0 or higher\n- Node.js 18.0.0 or higher (if not using Bun)\n\n## üì¶ Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/mcpdotdirect/mcp-evm-server.git\ncd mcp-evm-server\n\n# Install dependencies with Bun\nbun install\n\n# Or with npm\nnpm install\n```\n\n## ‚öôÔ∏è Server Configuration\n\nThe server uses the following default configuration:\n\n- **Default Chain ID**: 1 (Ethereum Mainnet)\n- **Server Port**: 3001\n- **Server Host**: 0.0.0.0 (accessible from any network interface)\n\nThese values are hardcoded in the application. If you need to modify them, you can edit the following files:\n\n- For chain configuration: `src/core/chains.ts`\n- For server configuration: `src/server/http-server.ts`\n\n## üöÄ Usage\n\n### Using npx (No Installation Required)\n\nYou can run the MCP EVM Server directly without installation using npx:\n\n```bash\n# Run the server in stdio mode (for CLI tools)\nnpx @mcpdotdirect/evm-mcp-server\n\n# Run the server in HTTP mode (for web applications)\nnpx @mcpdotdirect/evm-mcp-server --http\n```\n\n### Running the Server Locally\n\nStart the server using stdio (for embedding in CLI tools):\n\n```bash\n# Start the stdio server\nbun start\n\n# Development mode with auto-reload\nbun dev\n```\n\nOr start the HTTP server with SSE for web applications:\n\n```bash\n# Start the HTTP server\nbun start:http\n\n# Development mode with auto-reload\nbun dev:http\n```\n\n### Connecting to the Server\n\nConnect to this MCP server using any MCP-compatible client. For testing and debugging, you can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\n\n### Connecting from Cursor\n\nTo connect to the MCP server from Cursor:\n\n1. Open Cursor and go to Settings (gear icon in the bottom left)\n2. Click on \"Features\" in the left sidebar\n3. Scroll down to \"MCP Servers\" section\n4. Click \"Add new MCP server\"\n5. Enter the following details:\n   - Server name: `evm-mcp-server`\n   - Type: `command`\n   - Command: `npx @mcpdotdirect/evm-mcp-server`\n\n6. Click \"Save\"\n\nOnce connected, you can use the MCP server's capabilities directly within Cursor. The server will appear in the MCP Servers list and can be enabled/disabled as needed.\n\n### Using mcp.json with Cursor\n\nFor a more portable configuration that you can share with your team or use across projects, you can create an `.cursor/mcp.json` file in your project's root directory:\n\n```json\n{\n  \"mcpServers\": {\n    \"evm-mcp-server\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@mcpdotdirect/evm-mcp-server\"\n      ]\n    },\n    \"evm-mcp-http\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\", \n        \"@mcpdotdirect/evm-mcp-server\", \n        \"--http\"\n      ]\n    }\n  }\n}\n```\n\nPlace this file in your project's `.cursor` directory (create it if it doesn't exist), and Cursor will automatically detect and use these MCP server configurations when working in that project. This approach makes it easy to:\n\n1. Share MCP configurations with your team\n2. Version control your MCP setup\n3. Use different server configurations for different projects\n\n### Example: HTTP Mode with SSE\n\nIf you're developing a web application and want to connect to the HTTP server with Server-Sent Events (SSE), you can use this configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"evm-mcp-sse\": {\n      \"url\": \"http://localhost:3001/sse\"\n    }\n  }\n}\n```\n\nThis connects directly to the HTTP server's SSE endpoint, which is useful for:\n- Web applications that need to connect to the MCP server from the browser\n- Environments where running local commands isn't ideal\n- Sharing a single MCP server instance among multiple users or applications\n\nTo use this configuration:\n1. Create a `.cursor` directory in your project root if it doesn't exist\n2. Save the above JSON as `mcp.json` in the `.cursor` directory\n3. Restart Cursor or open your project\n4. Cursor will detect the configuration and offer to enable the server(s)\n\n### Example: Using\n\n[... truncated ...]"
  },
  "mhw0/libethc": {
    "fetchedAt": "2025-11-12T22:35:33.228Z",
    "content": "# libethc <img width=\"38\" height=\"38\" alt=\"optimism-ethereum-op-logo\" src=\"https://github.com/user-attachments/assets/201e9eec-2d1e-4cb9-9e46-c2fa72c4f14b\" align=\"right\" /> <img width=\"38\" height=\"38\" alt=\"polygon-matic-logo\" src=\"https://github.com/user-attachments/assets/e01171dc-aa84-486d-80aa-8ad9f772a7f7\" align=\"right\" /> <img width=\"38\" height=\"38\" alt=\"arbitrum-arb-logo\" src=\"https://github.com/user-attachments/assets/a24c27a3-3d33-4ddd-bb64-2e9a661ce252\" align=\"right\" /> <img width=\"38\" height=\"38\" alt=\"ethereum-eth-logo\" src=\"https://github.com/user-attachments/assets/cf6c3c48-9a47-4969-a45d-095f555937f6\" align=\"right\" />\n\n[![ci-unix](https://github.com/mhw0/libethc/actions/workflows/ci-unix.yaml/badge.svg)](https://github.com/mhw0/libethc/actions/workflows/ci-unix.yaml)\n[![ci-docs](https://github.com/mhw0/libethc/actions/workflows/ci-docs.yaml/badge.svg)](https://github.com/mhw0/libethc/actions/workflows/ci-docs.yaml)\n[![GitHub release](https://img.shields.io/github/v/release/mhw0/libethc?include_prereleases)](https://GitHub.com/mhw0/libethc/releases/)\n\nlibethc is an open-source Ethereum library for C and C++. It comes with numerous utility functions that will help when interacting with EVM based networks.\n\n## Motivation\n\nMost Ethereum libraries are made for high-level languages like JavaScript, Python or others, but those aren‚Äôt a good fit for low-level environments. C and C++ are fast, lightweight, and widely used in embedded development, firmware, and performance-critical software. With libethc, it becomes possible to use blockchain features on devices that don‚Äôt have the resources for big runtimes or dynamic memory. This includes things like hardware wallets, IoT devices, and payment terminals ‚Äî places where there‚Äôs a need to sign transactions or perform actions on Ethereum network, directly on the device. Right now, most tools simply aren‚Äôt built for that. libethc fills that gap and makes Ethereum integration possible in environments that have been left out.\n\n\n## Features\n\n| ABI                | RLP                | ACCOUNT                    | ADDRESS                   | HEXADECIMAL          | ECDSA                  | KECCAK256        | UNIT               | BLOOM FILTER           |\n|--------------------|--------------------|----------------------------|---------------------------|----------------------|------------------------|------------------|--------------------| -----------------------|\n| `eth_abi_bool `    | `eth_rlp_uint8`    | `eth_account_create`       | `eth_is_address`          | `eth_is_hex`         | `eth_ecdsa_pubkey_get` | `eth_keccak256`  | `eth_unit_convert` | `eth_bloom_from_bytes` |\n| `eth_abi_uint8`    | `eth_rlp_uint16`   | `eth_account_from_privkey` | `eth_is_checksum_address` | `eth_hex_pad_left`   | `eth_ecdsa_sign`       | `eth_keccak256p` |                    | `eth_bloom_and`        |\n| `eth_abi_uint16`   | `eth_rlp_uint32`   | `eth_account_address_get`  | `eth_to_checksum_address` | `eth_hex_pad_right`  |                        |                  |                    | `eth_bloom_or`         |\n| `eth_abi_uint32`   | `eth_rlp_uint64`   | `eth_account_pubkey_get`   | `eth_hex_from_bytes`      |\n| `eth_abi_uint64`   | `eth_rlp_uint`     | `eth_account_sign`         | `eth_hex_to_bytes`        |\n| `eth_abi_int8`     | `eth_rlp_address`  |\n| `eth_abi_int16`    | `eth_rlp_array`    |\n| `eth_abi_int32`    | `eth_rlp_bytes`    |\n| `eth_abi_int64`    | `eth_rlp_hex`      |\n| `eth_abi_mpint`    | `eth_rlp_len`      |\n| `eth_abi_bytes8`   | `eth_rlp_to_hex`   |\n| `eth_abi_bytes16`  | `eth_rlp_to_bytes` |\n| `eth_abi_bytes32`  | `eth_rlp_from_hex` |\n| `eth_abi_bytes`    |\n| `eth_abi_address`  |\n| `eth_abi_string`   |\n| `eth_abi_call`     |\n| `eth_abi_array`    | \n| `eth_abi_from_hex` |\n| `eth_abi_to_hex`   |\n\n\n## Documentation\nDocumentation can be found here: https://mhw0.github.io/libethc\n"
  },
  "polareth/evmstate": {
    "fetchedAt": "2025-11-12T22:35:41.627Z",
    "content": "# @polareth/evmstate\n\nA TypeScript library for tracing, and visualizing EVM state changes with detailed human-readable labeling.\n\n## Overview\n\nThe library traces all state changes after a transaction has been executed in a local VM, or by watching transactions in incoming blocks. It then labels them with semantic insights and a detailed diff of all the changes.\n\nIt can be seen as an alternative to using event logs for evm interfaces, as it captures and labels every state change with precise semantic information, including variable names, mapping keys, array indices, decoded values and path tracing.\n\nPowered by [Tevm](https://github.com/evmts/tevm-monorepo) and [whatsabi](https://github.com/shazow/whatsabi).\n\n## Features\n\n- **Complete state change tracing**: Track the state of every account touched during the transaction\n- **Human-readable labeling**: Retrieve the storage layout of each account if it's available for contracts, to label storage slots with variable names, decode values and provide a detailed path of access from the base slot to the final value\n- **Intelligent key detection**: Extract and match mapping keys from transaction data\n- **Type-aware decoding**: Convert raw storage values to appropriate JavaScript types; the state trace is fully typed if a storage layout is provided\n\n## Installation\n\n```bash\nnpm install @polareth/evmstate\n# or\npnpm add @polareth/evmstate\n# or\nyarn add @polareth/evmstate\n```\n\n## Quickstart\n\n```typescript\nimport { traceState } from \"@polareth/evmstate\";\n\n// Trace a transaction\nconst trace = await traceState({\n  rpcUrl: \"https://1.rpc.thirdweb.com\",\n  from: \"0xYourAddress\",\n  to: \"0xContractAddress\",\n  data: \"0xEncodedCalldata\",\n  value: 0n,\n});\n\n// Watch an account's state\nconst unsubscribe = await watchState({\n  rpcUrl: \"https://1.rpc.thirdweb.com\",\n  address: \"0xContractAddress\",\n  storageLayout: contractStorageLayout as const,\n  abi: contractAbi,\n  onStateChange: (stateChange) => {\n    console.log(stateChange);\n  },\n  onError: (error) => {\n    console.error(error);\n  },\n});\n```\n\n## Core functionality\n\n### 1. `traceState` - Analyze transaction state\n\nThe `traceState` function is the primary way to analyze how a transaction affects state. It can be used in several ways:\n\n#### Basic usage with RPC URL and transaction parameters\n\n```typescript\nimport { traceState } from \"@polareth/evmstate\";\n\n// Trace a simulated transaction\nconst trace = await traceState({\n  rpcUrl: \"https://1.rpc.thirdweb.com\",\n  from: \"0xYourAddress\",\n  to: \"0xContractAddress\",\n  data: \"0xEncodedCalldata\",\n  value: 0n,\n});\n```\n\n#### Using contract ABI for better readability\n\n```typescript\nimport { traceState } from \"@polareth/evmstate\";\n\n// Trace with typed contract call (similar to viem)\nconst trace = await traceState({\n  rpcUrl: \"https://1.rpc.thirdweb.com\",\n  from: \"0xYourAddress\",\n  to: \"0xContractAddress\",\n  abi: contractAbi,\n  functionName: \"transfer\",\n  args: [\"0xRecipient\", \"1000000000000000000\"], // address, amount\n});\n```\n\n#### Tracing an existing transaction\n\n```typescript\nimport { traceState } from \"@polareth/evmstate\";\n\n// Trace an existing transaction by hash\nconst trace = await traceState({\n  rpcUrl: \"https://1.rpc.thirdweb.com\",\n  txHash: \"0xTransactionHash\",\n});\n```\n\n#### Using a custom Tevm client for more control\n\n```typescript\nimport { createMemoryClient, http } from \"tevm\";\nimport { mainnet } from \"tevm/common\";\nimport { traceState } from \"@polareth/evmstate\";\n\n// Initialize client\nconst client = createMemoryClient({\n  common: mainnet,\n  fork: {\n    transport: http(\"https://1.rpc.thirdweb.com\"),\n    blockTag: \"latest\",\n  },\n});\n\n// Trace with custom client\nconst trace = await traceState({\n  client,\n  from: \"0xYourAddress\",\n  to: \"0xContractAddress\",\n  data: \"0xEncodedCalldata\",\n});\n```\n\n### 2. `Tracer` - Create reusable tracing instances\n\nThe `Tracer` class provides an object-oriented interface for reusing client instances and configuration:\n\n```typescript\nimport { createMemoryClient, http } from \"tevm\";\nimport { mainnet } from \"tevm/common\";\nimport { Tracer } from \"@polareth/evmstate\";\n\n// Initialize client\nconst client = createMemoryClient({\n  common: mainnet,\n  fork: {\n    transport: http(\"https://1.rpc.thirdweb.com\"),\n    blockTag: \"latest\",\n  },\n});\n\n// Create a reusable tracer\nconst tracer = new Tracer({ client });\n\n// Trace multiple transactions with the same client\nconst trace1 = await tracer.traceState({\n  from: \"0xYourAddress\",\n  to: \"0xContractAddress\",\n  data: \"0xEncodedCalldata1\",\n});\n\nconst trace2 = await tracer.traceState({\n  from: \"0xYourAddress\",\n  to: \"0xContractAddress\",\n  data: \"0xEncodedCalldata2\",\n});\n```\n\n### 3. `watchState` - Monitor account state\n\nThe `watchState` function allows continuous monitoring of state access for a specific contract or EOA:\n\n```typescript\nimport { watchState } from \"@polareth/evmstate\";\n\n// Start watching state\nconst unsubscribe = await watchState({\n  rpcUrl: \"https://1.rpc.thirdweb.com\",\n  address: \"0xContractAddress\",\n  // Optional storage layout (improves labeling) - needs to be imported 'as const' similar to the ABI\n  storageLayout: contractStorageLayout,\n  // Optional ABI (improves decoding)\n  abi: contractAbi,\n  // Callback for state change/access\n  onStateChange: (stateChange) => {\n    console.log(\"State change detected:\", stateChange);\n    // Use the state\n  },\n  // Callback on error\n  onError: (error) => {\n    console.error(\"Watch error:\", error);\n  },\n  // Optional polling interval (default: 1000ms)\n  pollingInterval: 2000,\n});\n\n// Later, stop watching\nunsubscribe();\n```\n\n## Understanding the output\n\nThe `traceState` and `watchState` functions return detailed information about state changes. The output follows this structure (`watchState` directly emits the object for the account address):\n\n```typescript\n{\n  \"0xContractAddress\": {\n    // Intrinsic state (balance, nonce, code)\n    \"balance\": {\n      \"current\": 1000000000000000000n, // Current value (bigint)\n      \"modified\": true, // Whether it was modified\n      \"next\": 2000000000000000000n // New value after the transaction\n    },\n    \"nonce\": {\n      \"current\": 5,\n      \"modified\": true,\n      \"next\": 6\n    },\n    \"code\": { \"current\": \"0x...\", \"modified\": false },\n\n    // Storage changes, labeled by variable name\n    \"storage\": {\n      // Primitive types\n      \"counter\": {\n        \"kind\": \"primitive\",\n        \"name\": \"counter\",\n        \"type\": \"uint256\",\n        \"trace\": [\n          {\n            \"current\": { \"hex\": \"0x05\", \"decoded\": 5n },\n            \"modified\": true,\n            \"next\": { \"hex\": \"0x06\", \"decoded\": 6n },\n            \"path\": [],\n            \"fullExpression\": \"counter\",\n            \"slots\": [\"0x0000000000000000000000000000000000000000000000000000000000000000\"]\n          }\n        ]\n      },\n\n      // Mappings with keys\n      \"balances\": {\n        \"kind\": \"mapping\",\n        \"name\": \"balances\",\n        \"type\": \"mapping(address => uint256)\",\n        \"trace\": [\n          {\n            \"current\": { \"hex\": \"0x2386f26fc10000\", \"decoded\": 10000000000000000n },\n            \"modified\": true,\n            \"next\": { \"hex\": \"0x2386f26fc10001\", \"decoded\": 20000000000000000n },\n            \"path\": [\n              {\n                \"kind\": \"mapping_key\",\n                \"key\": \"0x1234567890123456789012345678901234567890\",\n                \"keyType\": \"address\"\n              }\n            ],\n            \"fullExpression\": \"balances[0x1234567890123456789012345678901234567890]\",\n            \"slots\": [\"0x8e9c0c9f9fb928592f2fb0a9314450706c27839d034893b88d8ed2f54cf1bd5e\"]\n          }\n        ]\n      },\n\n      // Arrays with indices\n      \"numbers\": {\n        \"kind\": \"dynamic_array\",\n        \"name\": \"numbers\",\n        \"type\": \"uint256[]\",\n        \"trace\": [\n          {\n            \"current\": { \"hex\": \"0x03\", \"decoded\": 3n },\n            \"modified\": false,\n            \"path\": [\n              { \"kind\": \"array_length\", \"name\": \"_length\" }\n            ],\n            \"fullExpression\": \"numbers._length\",\n            \"slots\": [\n\n[... truncated ...]"
  },
  "ngmisl/etherml": {
    "fetchedAt": "2025-11-12T22:35:49.484Z",
    "content": "# üîí Quantum-Resistant Ethereum Wallet\n\n[![CodeQL](https://github.com/ngmisl/etherml/actions/workflows/github-code-scanning/codeql/badge.svg)](https://github.com/ngmisl/etherml/actions/workflows/github-code-scanning/codeql) [![Go](https://github.com/ngmisl/etherml/actions/workflows/go.yml/badge.svg)](https://github.com/ngmisl/etherml/actions/workflows/go.yml)\n\nA **quantum-resistant** Ethereum wallet manager with post-quantum **ML-KEM-1024** encryption and an elegant terminal user interface. Built with Go 1.24.4 and designed for the post-quantum era.\n\n## üåü Features\n\n- üõ°Ô∏è **Post-Quantum Security**\n  - **ML-KEM-1024** (NIST-standardized post-quantum encryption)\n  - Hybrid encryption: ML-KEM-1024 + AES-256-GCM  \n  - Future-proof against quantum computer attacks\n  - No legacy encryption fallbacks - pure post-quantum always\n\n- üîê **Advanced Cryptography**\n  - **Deniable Encryption**: ($5 wrench protection) - plausible deniability with dual-mode key derivation\n  - Argon2id key derivation with secure parameters\n  - Secure memory handling with automatic key zeroing\n  - Password re-authentication for private key access\n  - Cryptographically secure random number generation\n\n- üíª **Elegant Terminal Interface**\n  - Beautiful TUI with professional styling and colors\n  - Real-time search and filtering\n  - Inline wallet label editing\n  - One-click address copying to clipboard\n  - Modal dialogs for secure operations\n  - Responsive design with proper scrolling\n\n- üöÄ **Modern Go Implementation**\n  - Built with Go 1.24.4 (uses crypto/mlkem standard library)\n  - **Modular Architecture**: Refactored into `pkg/quantum/` and `pkg/tui/` packages\n  - Type-safe design with comprehensive error handling\n  - Cross-platform clipboard support\n  - Efficient memory management\n\n## üöÄ Installation\n\n### Prerequisites\n- Go 1.24.4 or higher (required for crypto/mlkem)\n- Git\n- System dependencies (for clipboard support):\n  - Linux: `libx11-dev` \n  - macOS: Xcode command line tools\n  - Windows: No additional deps needed\n\n### Quick Start\n```bash\n# Clone the repository\ngit clone https://github.com/ngmisl/etherml.git\ncd etherml\n\n# Build the wallet\ngo build -o wallet\n\n# Run the wallet\n./wallet\n```\n\n### System Dependencies (Linux)\n```bash\n# Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install -y libx11-dev\n\n# RHEL/CentOS/Fedora  \nsudo dnf install libX11-devel\n```\n\n## üõ†Ô∏è Usage\n\n### Interactive Terminal Interface\n```bash\n# Launch the wallet TUI\n./wallet\n```\n\nWhen prompted, enter your master password to unlock the encrypted wallet storage.\n\n### TUI Controls\n- **`n`** - Create new wallet with optional label\n- **`‚èé`** - Edit wallet label (hover and press Enter)\n- **`c`** - Copy selected wallet address to clipboard  \n- **`e`** - Export private key (requires password re-authentication)\n- **`d`** - Delete wallet (with confirmation)\n- **`/`** - Search wallets by label or address\n- **`‚Üë/‚Üì`** - Navigate wallet list\n- **`q`** - Quit application\n\n### First Run\n1. Run `./wallet` \n2. Create a strong master password (this encrypts all wallet data)\n3. Press `n` to create your first wallet\n4. Optionally add a label for easy identification\n5. Your wallet address and encrypted private key are now securely stored\n\n### Security Notes\n- All private keys are encrypted with ML-KEM-1024 post-quantum encryption\n- Master password is required to decrypt wallet data\n- Private keys are only decrypted in memory when explicitly requested\n- Memory is automatically zeroed after private key operations\n\n## üîê Security Architecture\n\n### Post-Quantum Encryption\nThis wallet uses **ML-KEM-1024** (Module-Lattice-Based Key Encapsulation Mechanism), a NIST-standardized post-quantum cryptographic algorithm that remains secure even against quantum computer attacks.\n\n### Storage Format\n```json\n{\n  \"version\": \"1.0\",\n  \"algorithm\": \"mlkem1024-aes256gcm\",\n  \"kdf\": {\n    \"function\": \"argon2id\",\n    \"memory\": 65536,\n    \"iterations\": 3,\n    \"parallelism\": 4,\n    \"salt\": \"base64_encoded_salt\",\n    \"key_len\": 32\n  },\n  \"mlkem_public_key\": \"base64_encoded_public_key\",\n  \"mlkem_private_key_enc\": \"base64_encoded_encrypted_private_key\",\n  \"mlkem_private_key_nonce\": \"base64_encoded_nonce\", \n  \"wallets\": [\n    {\n      \"address\": \"hex_encoded_address\",\n      \"encrypted_key\": \"base64_mlkem_encrypted_private_key\",\n      \"nonce\": \"base64_encoded_nonce\",\n      \"created_at\": \"2025-01-01T00:00:00Z\",\n      \"label\": \"optional_label\"\n    }\n  ]\n}\n```\n\n### Security Features\n- **Quantum Resistance**: ML-KEM-1024 provides 256-bit post-quantum security\n- **Hybrid Encryption**: ML-KEM-1024 + AES-256-GCM for optimal performance\n- **Memory Safety**: Automatic zeroing of sensitive data after use\n- **Secure Key Derivation**: Argon2id with high memory requirements\n- **File Permissions**: Storage files created with 0600 permissions\n- **No Legacy Crypto**: Pure post-quantum encryption, no fallbacks\n\n## üìö Technical Details\n\n### Architecture\nModular design with separated concerns for enhanced maintainability and testing:\n\n- **main.go** - Application entry point and CLI handling\n- **pkg/quantum/** - Post-quantum cryptography module\n  - `mlkem.go` - ML-KEM-1024 key generation\n  - `hybrid.go` - Hybrid encryption (ML-KEM + AES-256-GCM)\n  - `security.go` - Memory safety, key derivation, deniable encryption\n  - `types.go` - Cryptographic type definitions\n- **pkg/tui/** - Terminal user interface module\n- **test/quantum/** - Comprehensive test suite with unit, benchmark, and fuzz tests\n- **wallets.enc** - Encrypted storage file (created on first run)\n\n### Key Components\n- **ML-KEM Integration**: Uses Go 1.24.4's `crypto/mlkem` standard library\n- **TUI Framework**: Built with Charm's Bubble Tea for professional interface\n- **Ethereum Crypto**: Compatible with standard Ethereum private key format\n- **Clipboard Support**: Cross-platform address copying with `golang.design/x/clipboard`\n\n### Building from Source\n```bash\n# Clone and build\ngit clone https://github.com/ngmisl/etherml.git\ncd etherml\ngo build -o wallet\n\n# Run comprehensive tests\ngo test ./test/...\n\n# Run performance benchmarks\ngo test -bench=. ./test/quantum/\n\n# Run fuzzing tests (optional)\ngo test -fuzz=. ./test/quantum/ -fuzztime=30s\n\n# Run the wallet\n./wallet\n```\n\n### Testing and Validation\nThe wallet includes comprehensive testing with security-first validation:\n\n```bash\n# Run all tests (unit, integration, security)\ngo test ./test/...\n\n# Performance benchmarks (actual results)\ngo test -bench=. ./test/quantum/\n# Results: ~109ms key generation, 1.4GB/s encryption throughput\n\n# Fuzzing tests for robustness\ngo test -fuzz=. ./test/quantum/ -fuzztime=30s\n```\n\n**Security Test Coverage**:\n- ML-KEM-1024 keypair generation and validation\n- Hybrid encryption/decryption round-trip integrity\n- Deniable encryption dual-mode verification\n- Memory safety and secure data clearing\n- Constant-time operation validation\n- Concurrent operation thread safety\n\n## üõ£Ô∏è Roadmap\n\n- [x] **Modular Architecture** - Refactored into separate packages for maintainability\n- [x] **Deniable Encryption** - Plausible deniability protection against coercion\n- [x] **Comprehensive Testing** - Unit, benchmark, and fuzz tests for security validation\n- [ ] **Hardware Wallet Integration** - Ledger/Trezor support with post-quantum verification\n- [ ] **Multi-Signature Wallets** - ML-KEM-based threshold signatures\n- [ ] **Network Integration** - Direct Ethereum RPC interaction for balance/transactions\n- [ ] **Import/Export** - Support for standard wallet formats with PQ re-encryption\n- [ ] **Mobile App** - React Native app with Go mobile bindings\n\n## ü§ù Contributing\n\nContributions welcome! This project prioritizes:\n- **Security first** - All crypto changes require thorough review\n- **Post-quantum only** - No legacy crypto additions\n- **Simple architecture** - Keep the single-file design for auditability\n- **Comprehensive testing** - 100% coverage for cryptographic functions with unit, benchmark, and fuzz tests\n\n## üî¨ Research & References\n\n- [NIST PQC Standardizatio\n\n[... truncated ...]"
  },
  "evmts/tevm-monorepo": {
    "fetchedAt": "2025-11-12T22:35:57.407Z",
    "content": "<p align=\"center\">\n  <a href=\"https://node.tevm.sh\">\n    <img src=\"https://github.com/user-attachments/assets/880d8f54-8063-4018-8777-98ba383433ee\" width=\"400\" alt=\"Tevm Logo\" />\n  </a>\n</p>\n\n<h1 align=\"center\">Tevm</h1>\n\n<p align=\"center\">\n  <b>JavaScript-Native Ethereum Virtual Machine</b>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/evmts/tevm-monorepo/actions/workflows/ci.yml\">\n    <img src=\"https://github.com/evmts/tevm-monorepo/actions/workflows/ci.yml/badge.svg\" alt=\"CI Status\" />\n  </a>\n  <a href=\"https://www.npmjs.com/package/tevm\">\n    <img src=\"https://img.shields.io/npm/v/tevm\" alt=\"NPM Version\" />\n  </a>\n  <a href=\"https://www.npmjs.com/package/tevm\">\n    <img src=\"https://img.shields.io/npm/dm/tevm.svg\" alt=\"Tevm Downloads\" />\n  </a>\n  <a href=\"https://bundlephobia.com/package/tevm@latest\">\n    <img src=\"https://badgen.net/bundlephobia/minzip/tevm\" alt=\"Minzipped Size\" />\n  </a>\n  <a href=\"https://t.me/+ANThR9bHDLAwMjUx\">\n    <img alt=\"Telegram\" src=\"https://img.shields.io/badge/chat-telegram-blue.svg\">\n  </a>\n  <a href=\"https://deepwiki.com/evmts/tevm-monorepo\">\n    <img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\">\n  </a>\n</p>\n\n---\n\n## Note: we are near the end of a large rewrite to zig. It is expected we get a new stable version of Tevm in November\n\n## üöÄ The EVM for TypeScript, JavaScript, and the Modern Web\n\nTevm puts an Ethereum node anywhere JavaScript runs‚ÄîNode, browser, serverless, edge, or desktop. Instantly fork mainnet, simulate complex contracts, and run full-stack devnets, all with TypeScript-first safety and blazing speed.\n\nIf you use **viem**, **wagmi**, **0x**, or build modern Ethereum apps, Tevm is the engine that powers next-level shipping, testing, and UX.\n\n---\n\n## ‚ú® Why Tevm?\n\n- **‚ö° Ship at Lightspeed**: Instant feedback. Test and deploy with no wait, no Docker, no slow subprocesses. Build and iterate like the Rust and Go elite‚Äînow in JS.\n- **üö´ Goodbye, Loading Spinners**: Deliver real optimistic UI. Run every contract locally for true instant dapp experiences‚Äîno more waiting on RPCs.\n- **üîí TypeScript-Native Confidence**: End-to-end type safety and autocompletion. Import Solidity, call contracts, and simulate transactions with zero guesswork.\n- **üåê Mainnet-Grade Simulation**: Fork any EVM chain‚Äîmainnet, L2, L3‚Äîand manipulate state locally with full fidelity.\n- **üß™ Unmatched Testing Power**: Write robust integration tests, simulate reorgs, verify gas, and check UX edge cases, all in one toolkit.\n- **üíª True Local-First**: Full EVM in Node, browser, or edge‚Äîoffline or online, always in your control.\n- **üéØ The Fastest Path from Idea to User**: Tevm Compiler brings Solidity into your codebase with real types, letting you ship faster and safer than ever before.\n- **‚ö° Optimistic Updates, Advanced Gas Modeling**: Build dapps that feel like Web2 and simulate costs with precision, in JS/TS.\n\n---\n\n## üõ†Ô∏è The Tevm Ecosystem\n\nEverything you need to build, simulate, and ship at the speed of your ideas.\n\n### 1. Tevm Node: Instant, In-Memory Ethereum\n\nRun an EVM devnet anywhere‚ÄîNode, browser, edge, or serverless. One line, zero dependencies.\n\n```typescript\nimport { createMemoryClient } from \"tevm\";\nconst client = createMemoryClient();\n```\n\n### 2. Tevm Bundler: Solidity‚ÄîTyped, Bundled, Native\n\nImport Solidity right into TypeScript and call it with full type safety:\n\n```typescript\nimport { ERC20 } from '@openzeppelin/contracts/token/ERC20.sol';\nimport { createMemoryClient } from 'tevm';\nconst client = createMemoryClient();\n\nconst token = ERC20.withAddress(\"0x123...\");\nconst balance = await client.readContract(token.read.balanceOf(\"0x456...\"));\n```\n\nWrite contracts inline with `sol` template literals (coming soon):\n\n```typescript\nimport { sol } from 'tevm';\nconst { MyContract } = sol`\n  contract MyContract {\n    function greet() public pure returns (string memory) {\n      return \"hello\";\n    }\n  }\n`;\n```\n\n[See Bundler Quickstart ‚Üí](https://node.tevm.sh/getting-started/bundler)\n\n\n### 4. Tevm Engine (Preview): Optimistic UX for viem/wagmi\n\nNext-gen plugin for instant optimistic updates, auto-caching, and devnet magic in your frontend.\n\n---\n\n## üí° What Can You Do With Tevm?\n\n- **üîÑ Test Against Mainnet or Any Chain**: Fork and simulate mainnet, L2s, L3s, and custom rollups with a single call.\n- **ü§ñ Prototype Next-Gen Apps**: From L2 fraud proofs to LLM/EVM wallets and AI agents‚Äîin the browser or edge.\n- **‚ú® Deliver Seamless UX**: Eliminate spinners. Build apps that always feel instant.\n- **‚õΩ Model Gas & Simulate Fees**: Run \"what if\" gas scenarios and advanced fee logic, locally and reproducibly.\n- **üîç Debug, Profile, and Introspect**: Step through opcodes and inspect contract state in real time.\n\n---\n\n## üìä Devnet Comparison\n\n| Feature | Tevm | Anvil | Hardhat | Ganache | Tenderly |\n|---------|------|-------|---------|---------|----------|\n| **Language** | JS/Wasm | Rust | JS/Rust | JS | Go |\n| **Browser Support** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ (SaaS) |\n| **Minimal Dependencies** | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ (SaaS) |\n| **Viem Integration** | Native | Yes (RPC) | Minimal | Minimal | None |\n| **Forking (L1, Rollups)** | ‚úÖ | ‚úÖ | ‚úÖ | Some | ‚úÖ |\n| **Rebase/Fork Updates** | Soon | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |\n| **Solidity Tests** | Some | Yes | Yes | No | No |\n| **Fuzzing** | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |\n| **Open Source** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |\n\n---\n\n## üèÜ Backed by the Ethereum Foundation\n\nTevm is funded by an Ethereum Foundation grant. Our roadmap:\n\n- ‚úÖ **Tevm 1.0.0 Release**\n- üîÑ **Test Library**\n- üéÆ **MUD Integration** for onchain games\n\n---\n\n## ‚ö° Quick Start\n\n```bash\nnpm install tevm viem@latest\n```\n\n```typescript\nimport { createMemoryClient, http } from \"tevm\";\nimport { optimism } from \"tevm/chains\";\nimport { parseAbi } from \"viem\";\n\n// Fork Optimism mainnet\nconst client = createMemoryClient({\n  common: optimism,\n  fork: { transport: http(\"https://mainnet.optimism.io\") },\n});\nawait client.tevmReady();\n\nconst account = \"0x\" + \"baD60A7\".padStart(40, \"0\");\nawait client.setBalance({ address: account, value: 10_000_000_000_000_000_000n });\n\nconst greeterAbi = parseAbi([\n  \"function greet() view returns (string)\",\n  \"function setGreeting(string memory _greeting) public\",\n]);\nconst greeterAddress = \"0x10ed0b176048c34d69ffc0712de06CbE95730748\";\n\n// Read from contract\nconst greeting = await client.readContract({\n  address: greeterAddress,\n  abi: greeterAbi,\n  functionName: \"greet\",\n});\n\n// Write to contract\nawait client.writeContract({\n  account,\n  address: greeterAddress,\n  abi: greeterAbi,\n  functionName: \"setGreeting\",\n  args: [\"Hello from Tevm!\"],\n});\n\nawait client.mine({ blocks: 1 });\n\nconst newGreeting = await client.readContract({\n  address: greeterAddress,\n  abi: greeterAbi,\n  functionName: \"greet\",\n});\n```\n\n---\n\n## üìö Learn More\n\n- üìñ [Getting Started](https://node.tevm.sh/getting-started/overview)\n- üîó [Viem Integration](https://node.tevm.sh/getting-started/viem)\n- üì¶ [Ethers Integration](https://node.tevm.sh/getting-started/ethers)\n- üõ†Ô∏è [Bundler Quickstart](https://node.tevm.sh/getting-started/bundler)\n- üìö [API Reference](https://node.tevm.sh/api/packages)\n- üí° [Examples](https://github.com/evmts/tevm-monorepo/tree/main/examples)\n\n---\n\n## üë• Community\n\n- üí¨ [Join Telegram](https://t.me/+ANThR9bHDLAwMjUx)\n- üó£Ô∏è [GitHub Discussions](https://github.com/evmts/tevm-monorepo/discussions)\n\n---\n\n## ü§ù Contributing\n\nWe're always looking for passionate builders‚Äîespecially if you love TypeScript, L2/L3s, or pushing the limits of EVM tooling. See [CONTRIBUTING.md](./CONTRIBUTING.md) to get started.\n\n---\n\n## üìÑ License\n\nTevm is fully open source under the MIT license. See [LICENSE](./LICENSE) for details.\n\n---\n\n## üö¶ Who Should Use Tevm?\n\nTevm is for you if you're:\n\n- üîß Building with **viem**, **wagmi**, **0x**, or TypeScript-first Ethereum apps\n- ‚ö° Shipping UIs that need instant feedback (no spinners)\n- üöÄ Creating next-gen dapps, rollups, wallets, or LLM/EVM integrations\n- üò§ Tired of slow, fragile, or heavyweight devnets\n\n---\n\n<p align=\"center\">\n  <b>‚ù§\n\n[... truncated ...]"
  },
  "open-rpc/server-js": {
    "fetchedAt": "2025-11-12T22:36:12.396Z",
    "content": "# OpenRPC Server JS\n\n<center>\n  <span>\n    <img alt=\"CircleCI branch\" src=\"https://img.shields.io/circleci/project/github/open-rpc/server-js/master.svg\">\n    <img src=\"https://codecov.io/gh/open-rpc/server-js/branch/master/graph/badge.svg\" />\n    <img alt=\"Dependabot status\" src=\"https://api.dependabot.com/badges/status?host=github&repo=open-rpc/server-js\" />\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@open-rpc/server-js.svg\" />\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/open-rpc/server-js.svg\" />\n    <img alt=\"GitHub commits since latest release\" src=\"https://img.shields.io/github/commits-since/open-rpc/server-js/latest.svg\" />\n  </span>\n</center>\n\nJSON-RPC 2.0 + OpenRPC Server implementation that supports multiple transport protocols. Built to run with node 10+.\n\nNeed help or have a question? Join us on [Discord](https://discord.gg/gREUKuF)!\n\n## Features\n\n - [x] Multiple Transports\n   - [x] HTTP\n   - [x] HTTPS1/2\n   - [x] WebSockets\n   - [x] IPC\n     - [x] UDP\n     - [x] TCP\n - [x] Automatically Validate JSON Schemas for [ContentDescriptor#schemas](https://spec.open-rpc.org/#content-descriptor-schema) [MethodObject#params](https://spec.open-rpc.org/#method-result).\n - [x] CLI to start a server by configuration\n\n## How to Use\n\ninstall server, and optionally schema-utils-js if you want to dereference/validate the open-rpc document before running.\n```bash\nnpm install --save @open-rpc/server-js @open-rpc/schema-utils-js\n```\n\nWrite an open-rpc document describing your service\n`./src/openrpc.json`\nsee: https://raw.githubusercontent.com/open-rpc/examples/master/service-descriptions/simple-math-openrpc.json\nor write your own in [playground](https://playground.open-rpc.org/).\n\n\nFor each of the methods, create a function that has the same name\n`src/method-mapping`\n```typescript\nimport { MethodMapping } from \"@open-rpc/server-js/build/router\";\nexport const methodMapping: MethodMapping = {\n  addition: (a: number, b: number) => a + b,\n  subtraction: (a: number, b: number) => a - b\n};\nexport default methodMapping;\n```\n\nCreate a server with the methods and the document, serve it over http and websocket\n`src/server.ts`\n```typescript\nimport { Server, ServerOptions } from \"@open-rpc/server-js\";\nimport { HTTPServerTransportOptions } from \"@open-rpc/server-js/build/transports/http\";\nimport { WebSocketServerTransportOptions } from \"@open-rpc/server-js/build/transports/websocket\";\nimport { OpenrpcDocument } from \"@open-rpc/meta-schema\";\nimport { parseOpenRPCDocument } from \"@open-rpc/schema-utils-js\";\nimport methodMapping from \"./method-mapping\";\nimport doc from \"./openrpc.json\";\n\nexport async function start() {\n  const serverOptions: ServerOptions = {\n    openrpcDocument: await parseOpenRPCDocument(doc as OpenrpcDocument),\n    transportConfigs: [\n      {\n        type: \"HTTPTransport\",\n        options: {\n          port: 3330,\n          middleware: [],\n        } as HTTPServerTransportOptions,\n      },\n      {\n        type: \"WebSocketTransport\",\n        options: {\n          port: 3331,\n          middleware: [],\n        } as WebSocketServerTransportOptions,\n      },\n    ],\n    methodMapping,\n  };\n\n  console.log(\"Starting Server\"); // tslint:disable-line\n  const s = new Server(serverOptions);\n\n  s.start();\n}\n```\n\n#### Lower Level Bits\n\n##### Creating Routers\n\n###### using method mapping and OpenRPC document\n\n```typescript\nimport { types } from \"@open-rpc/meta-schema\";\nimport { Router } from \"@open-rpc/server-js\";\n\nconst openrpcDocument = {\n  openrpc: \"1.0.0\",\n  info: {\n    title: \"node-json-rpc-server example\",\n    version: \"1.0.0\"\n  },\n  methods: [\n    {\n      name: \"addition\",\n      params: [\n        { name: \"a\", schema: { type: \"integer\" } },\n        { name: \"b\", schema: { type: \"integer\" } }\n      ],\n      result: {\n        { name: \"c\", schema: { type: \"integer\" } }\n      }\n    }\n  ]\n} as types.OpenRPC;\n\nconst methodHandlerMapping = {\n  addition: (a: number, b: number) => Promise.resolve(a + b)\n};\n\nconst router = new Router(openrpcDocument, methodHandlerMapping);\n```\n\n###### mock mode\n\n```typescript\nconst router = new Router(openrpcDocument, { mockMode: true });\n```\n\n##### Creating Transports\n\n###### IPC\n\n```typescript\nimport { TCPIPCServerTranport, UDPIPCServerTranport } from \"@open-rpc/server-js\";\n\nconst ipcOptions = { maxConnetions: 20 }; // https://www.npmjs.com/package/node-ipc#ipc-config\nconst TCPIPCOptions = { ...ipcOptions, networkPort: 4343 };\nconst UDPIPCOptions = { ...ipcOptions, networkPort: 4343, udp: true };\n\nconst tcpIpcTransport = new IPCServerTranport(TCPIPCTransportOptions);\nconst UdpIpcTransport = new IPCServerTranport(UDPIPCTransportOptions);\n```\n\n###### HTTP/S\n\n```\nimport { HTTPServerTransport, HTTPSServerTransport } from \"@open-rpc/server-js\";\nimport express from \"express\";\n\nconst existingApp = express();\n\nconst httpOptions = {\n  middleware: [ cors({ origin: \"*\" }) ],\n  port: 4345,\n  app: existingApp, // optional existing express/connect app\n};\nconst httpsOptions = { // extends https://nodejs.org/api/https.html#https_https_createserver_options_requestlistener\n  middleware: [ cors({ origin: \"*\" }) ],\n  port: 4346,\n  key: await fs.readFile(\"test/fixtures/keys/agent2-key.pem\"),\n  cert: await fs.readFile(\"test/fixtures/keys/agent2-cert.pem\"),\n  ca: fs.readFileSync(\"ssl/ca.crt\")\n};\n\nconst httpTransport = new HTTPServerTransport(httpOptions);\nconst httpsTransport = new HTTPSServerTransport(httpsOptions); // Defaults to using HTTP2, allows HTTP1.\n```\n\n###### WebSockets\n\n```\nimport { WebSocketServerTransport } from \"@open-rpc/server-js\";\n\nconst webSocketFromHttpsOptions = { // extends https://github.com/websockets/ws/blob/master/doc/ws.md#new-websocketserveroptions-callback\n  server: httpsTransport.server\n};\n\nconst webSocketOptions = { // extends https://github.com/websockets/ws/blob/master/doc/ws.md#new-websocketserveroptions-callback\n  port: 4347\n};\nconst wsFromHttpsTransport = new WebSocketServerTransport(webSocketFromHttpsOptions); // Accepts http transport as well.\nconst wsTransport = new WebSocketServerTransport(webSocketOptions); // Accepts http transport as well.\n```\n\n###### Add components as you go\n```\nconst server = new Server();\nserver.start();\n\nserver.addTransport(httpsTransport); // will be started immediately\nserver.setRouter(router);\nserver.addTransports([ wsTransport, wsFromHttpsTransport, httpsTransport ]); // will be started immediately.\n```\n\n### Contributing\n\nHow to contribute, build and release are outlined in [CONTRIBUTING.md](CONTRIBUTING.md), [BUILDING.md](BUILDING.md) and [RELEASING.md](RELEASING.md) respectively. Commits in this repository follow the [CONVENTIONAL_COMMITS.md](CONVENTIONAL_COMMITS.md) specification.\n"
  },
  "open-rpc/spec": {
    "fetchedAt": "2025-11-12T22:36:12.785Z",
    "content": "# The OpenRPC Specification Repository\n\n<p align=\"center\">\n  <img alt=\"open-rpc logo\" src=\"https://github.com/open-rpc/design/blob/master/png/open-rpc-logo-320x320.png?raw=true\" />\n</p>\n\n<p align=\"center\">\n  Join us on <a href=\"https://discord.gg/gREUKuF\">Discord</a>!\n</p>\n\n## Purpose of this Repository\n\nThis is a repository that contains the OpenRPC specification, and the tooling to build, maintain, and release the specification.\n\n## Latest OpenRPC Specification\n\nThe latest version of the specification may be found [here](https://spec.open-rpc.org/).\n\n## Previous Versions of the Specification\n\nAll versions of the specification can be found on [the Github releases page](https://github.com/open-rpc/spec/releases).\n\nYou may also access specific versions of the spec by appending the version to the spec url as follows:\n\n`https://spec.open-rpc.org/1.0.0`\n\n## Contributing\n\nHow to contribute, build and release are outlined in [CONTRIBUTING.md](CONTRIBUTING.md), [BUILDING.md](BUILDING.md) and [RELEASING.md](RELEASING.md) respectively. Commits in this repository follow the [CONVENTIONAL_COMMITS.md](CONVENTIONAL_COMMITS.md) specification.\n\n## Contact\n\nNeed help or have a question? Join us on [Discord](https://discord.gg/gREUKuF)!\n"
  },
  "open-rpc/schema-utils-js": {
    "fetchedAt": "2025-11-12T22:36:13.142Z",
    "content": "# OpenRPC Utils For Javascript\n\n<center>\n  <span>\n    <img alt=\"CircleCI branch\" src=\"https://img.shields.io/circleci/project/github/open-rpc/schema-utils-js/master.svg\">\n    <img src=\"https://codecov.io/gh/open-rpc/schema-utils-js/branch/master/graph/badge.svg\" />\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@open-rpc/schema-utils-js.svg\" />\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/open-rpc/schema-utils-js.svg\" />\n    <img alt=\"GitHub commits since latest release\" src=\"https://img.shields.io/github/commits-since/open-rpc/schema-utils-js/latest.svg\" />\n  </span>\n</center>\n\nSee developer documentation here: https://open-rpc.github.io/schema-utils-js/\n\nNeed help or have a question? Join us on [Discord](https://discord.gg/gREUKuF)!\n\n### Contributing\n\nHow to contribute, build and release are outlined in [CONTRIBUTING.md](CONTRIBUTING.md), [BUILDING.md](BUILDING.md) and [RELEASING.md](RELEASING.md) respectively. Commits in this repository follow the [CONVENTIONAL_COMMITS.md](CONVENTIONAL_COMMITS.md) specification.\n"
  },
  "open-rpc/client-js": {
    "fetchedAt": "2025-11-12T22:36:13.452Z",
    "content": "# OpenRPC Client JS\n\n<center>\n  <span>\n    <img alt=\"CircleCI branch\" src=\"https://img.shields.io/circleci/project/github/open-rpc/client-js/master.svg\">\n    <img src=\"https://codecov.io/gh/open-rpc/client-js/branch/master/graph/badge.svg\" />\n    <img alt=\"Dependabot status\" src=\"https://api.dependabot.com/badges/status?host=github&repo=open-rpc/client-js\" />\n    <img alt=\"Chat on Discord\" src=\"https://img.shields.io/badge/chat-on%20discord-7289da.svg\" />\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@open-rpc/client-js.svg\" />\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/open-rpc/client-js.svg\" />\n    <img alt=\"GitHub commits since latest release\" src=\"https://img.shields.io/github/commits-since/open-rpc/client-js/latest.svg\" />\n  </span>\n</center>\n\nA browser-compatible JSON-RPC client with multiple transports:\n\n- EventEmitter\n- HTTP/HTTPS\n- WebSocket\n- PostMessageWindow\n- PostMessageIframe\n\n```javascript\nimport { RequestManager, HTTPTransport, Client } from \"@open-rpc/client-js\";\nconst transport = new HTTPTransport(\"http://localhost:8545\");\nconst client = new Client(new RequestManager([transport]));\nconst result = await client.request({ method: \"addition\", params: [2, 2] });\n// => { jsonrpc: '2.0', id: 1, result: 4 }\n```\n\n#### Examples\n\n<details>\n  <summary>EventEmitter</summary>\n\n```javascript\nimport { EventEmitter } from \"events\";\nimport {\n  RequestManager,\n  EventEmitterTransport,\n  Client,\n} from \"@open-rpc/client-js\";\n\nconst chan1 = \"chan1\";\nconst chan2 = \"chan2\";\n\nconst emitter = new EventEmitter();\nconst transport = new EventEmitterTransport(emitter, chan1, chan2);\nconst requestManager = new RequestManager([transport]);\nconst client = new Client(requestManager);\n\n// event emitter server code\nemitter.on(chan1, (jsonrpcRequest) => {\n  const res = {\n    jsonrpc: \"2.0\",\n    result: \"potato\",\n    id: jsonrpcRequest.id,\n  };\n  emitter.emit(chan2, JSON.stringify(res));\n});\n\nconst main = async () => {\n  const result = await client.request({ method: \"addition\", params: [2, 2] });\n  console.log(result);\n};\n\nmain().then(() => {\n  console.log(\"DONE\");\n});\n```\n\n</details>\n\n<details>\n  <summary>HTTP</summary>\n\n```javascript\nimport { RequestManager, Client, HTTPTransport } from \"@open-rpc/client-js\";\n\nconst transport = new HTTPTransport(\"http://localhost:3333\");\nconst requestManager = new RequestManager([transport]);\nconst client = new Client(requestManager);\n\nconst main = async () => {\n  const result = await client.request({ method: \"addition\", params: [2, 2] });\n  console.log(result);\n};\n\nmain().then(() => {\n  console.log(\"DONE\");\n});\n```\n\n</details>\n\n<details>\n  <summary>WebSocket</summary>\n\n```javascript\nimport {\n  RequestManager,\n  Client,\n  WebSocketTransport,\n} from \"@open-rpc/client-js\";\n\nconst transport = new WebSocketTransport(\"ws://localhost:3333\");\nconst requestManager = new RequestManager([transport]);\nconst client = new Client(requestManager);\n\nconst main = async () => {\n  const result = await client.request({ method: \"addition\", params: [2, 2] });\n  console.log(result);\n};\n\nmain().then(() => {\n  console.log(\"DONE\");\n  client.close();\n});\n```\n\n</details>\n\n### Building\n\n```sh\n# Install bun\ncurl -fsSL https://bun.sh/install | bash\n\n# Build the repo\nbun install\nbun run build\n```\n\n### Contributing\n\nHow to contribute, build and release are outlined in [CONTRIBUTING.md](CONTRIBUTING.md), [BUILDING.md](BUILDING.md) and [RELEASING.md](RELEASING.md) respectively. Commits in this repository follow the [CONVENTIONAL_COMMITS.md](CONVENTIONAL_COMMITS.md) specification.\n"
  },
  "open-rpc/tools": {
    "fetchedAt": "2025-11-12T22:36:13.851Z",
    "content": "# OpenRPC Tools\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/open-rpc/design/master/icons/open-rpc-logo-noText/open-rpc-logo-noText%20(PNG)/256x256.png\" alt=\"OpenRPC Logo\" width=\"150\" />\n</p>\n\nA collection of developer tools for the [OpenRPC](https://open-rpc.org) ecosystem.\n\n[![Conventional Commits](https://img.shields.io/badge/Conventional%20Commits-1.0.0-yellow.svg)](https://conventionalcommits.org)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Packages](#packages)\n- [Installation](#installation)\n- [Development](#development)\n  - [Building Packages](#building-packages)\n- [Version Management](#version-management)\n- [Contributing](#contributing)\n- [Changelog](#changelog)\n- [License](#license)\n- [Resources](#resources)\n\n## Overview\n\nOpenRPC Tools is a monorepo containing various tools and utilities for working with the OpenRPC specification. These tools help developers create, validate, document, and interact with JSON-RPC APIs using the OpenRPC standard.\n\nThe OpenRPC specification provides a way to describe JSON-RPC 2.0 APIs in a machine-readable format, similar to how OpenAPI/Swagger works for REST APIs. This repository contains React components, utilities, and applications that make working with OpenRPC documents easier.\n\n## Packages\n\n| Package                                                                     | Description                                            | Link                                                     |\n| --------------------------------------------------------------------------- | ------------------------------------------------------ | -------------------------------------------------------- |\n| [@open-rpc/inspector](./packages/inspector)                                 | A tool to create, modify and execute JSON-RPC requests | [README](./packages/inspector/README.md)                 |\n| [@open-rpc/docs-react](./packages/docs-react)                               | React component for rendering OpenRPC documentation    | [README](./packages/docs-react/README.md)                |\n| [@open-rpc/extensions](./packages/extensions)                               | Collection of OpenRPC Specification Extensions         | [README](./packages/extensions/README.md)                |\n| [@open-rpc/playground](./packages/playground)                               | Editor and live-preview for OpenRPC documents          | [README](./packages/playground/README.md)                |\n| [@open-rpc/logs-react](./packages/logs-react)                               | React component for displaying JSON-RPC logs           | [README](./packages/logs-react/README.md)                |\n| [@open-rpc/json-schema-to-react-tree](./packages/json-schema-to-react-tree) | React component to visually display JSON Schemas       | [README](./packages/json-schema-to-react-tree/README.md) |\n| [@open-rpc/monaco-editor-react](./packages/monaco-editor-react)             | Monaco editor with OpenRPC support                     | [README](./packages/monaco-editor-react/README.md)       |\n\n## Installation\n\nThis project requires Node.js version 20.11.1 or higher.\n\nTo install all dependencies and build all packages:\n\n```sh\nnpm install\nnpm run build\n```\n\n## Development\n\nThis repository is structured as a monorepo using npm workspaces. To work on a specific package:\n\n```sh\ncd packages/<package-name>\nnpm install\nnpm start\n```\n\nFor testing:\n\n```sh\n# Run tests for all packages\nnpm test\n\n# Run tests for a specific package\ncd packages/<package-name>\nnpm test\n```\n\n### Building Packages\n\nTo build an individual package, navigate to the package directory and run the build:package script:\n\n```sh\n# Navigate to the package directory\ncd packages/<package-name>\n\n# Build the package\nnpm run build:package\n```\n\nThe build process respects dependencies between packages, so if you build a package that depends on another package, the dependency will be built first.\n\n## Version Management\n\nThis project uses [Changesets](https://github.com/changesets/changesets) to manage versions and generate changelogs.\n\n### Creating a Changeset\n\nWhen making changes that should result in a version bump, create a changeset using the npm script:\n\n```sh\nnpm run changeset\n```\n\nThis will prompt you to:\n\n1. Select the packages that have changed\n2. Choose the semver increment (major, minor, patch)\n3. Provide a description of the changes\n\nThe changeset will be added to the `.changeset` directory and should be committed with your changes.\n\nIf your PR doesn't require a version change, you can create an empty changeset:\n\n```sh\nnpm run changeset -- --empty\n```\n\nThis creates a special changeset that satisfies the PR validation check without triggering a version bump.\n\n### Automated Versioning and Publishing\n\nThe versioning and publishing process is handled automatically by GitHub Actions:\n\n1. When a PR is opened, the CI checks for the presence of a changeset\n2. When a PR is merged to main, the changesets/action:\n   - Updates package versions based on the changesets\n   - Generates changelog entries\n   - Publishes packages to npm\n\nFor more details on the CI/CD process, see the workflow files in the [.github/workflows](./.github/workflows) directory.\n\n## Contributing\n\nWe welcome contributions to any of the packages in this repository! Please read the following documents before contributing:\n\n- [CONTRIBUTING.md](CONTRIBUTING.md) - How to contribute to this project\n- [BUILDING.md](BUILDING.md) - How to build the project\n- [RELEASING.md](RELEASING.md) - How to release new versions\n- [CONVENTIONAL_COMMITS.md](CONVENTIONAL_COMMITS.md) - Commit message format\n\nWhen contributing code changes, please also include a changeset describing your changes as described in the [Version Management](#version-management) section.\n\n## Changelog\n\nThis project uses a semantic-release style changelog generator. For more information on how changelogs are generated and maintained, see [CHANGELOG_GUIDE.md](CHANGELOG_GUIDE.md).\n\n## License\n\n[Apache 2.0](LICENSE)\n\n## Resources\n\n- [OpenRPC Specification](https://spec.open-rpc.org/)\n- [OpenRPC Website](https://open-rpc.org/)\n- [Discord Community](https://discord.gg/gREUKuF)\n- [OpenRPC GitHub Organization](https://github.com/open-rpc)\n"
  },
  "open-rpc/meta-schema": {
    "fetchedAt": "2025-11-12T22:36:14.218Z",
    "content": "# OpenRPC Meta JSON Schema\n\n<center>\n  <span>\n    <img alt=\"CircleCI branch\" src=\"https://img.shields.io/circleci/project/github/open-rpc/meta-schema/master.svg\">\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@open-rpc/meta-schema.svg\" />\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/open-rpc/meta-schema.svg\" />\n    <img alt=\"GitHub commits since latest release\" src=\"https://img.shields.io/github/commits-since/open-rpc/meta-schema/latest.svg\" />\n  </span>\n</center>\n\nThis is the JSON Schema file for the [OpenRPC Specification](https://spec.open-rpc.org/). You may use it to validate your open rpc documents.\n\nThis repo also contains the code which takes the schema, and generates typings for various languages. Currently supported languages:\n\n- Typescript\n- Rust\n- Go\n- Python\n\nNeed help or have a question? Join us on [Discord](https://discord.gg/gREUKuF)!\n\n## License\n\nApache-2.0\n\n### Contributing\n\nHow to contribute, build and release are outlined in [CONTRIBUTING.md](CONTRIBUTING.md), [BUILDING.md](BUILDING.md) and [RELEASING.md](RELEASING.md) respectively. Commits in this repository follow the [CONVENTIONAL_COMMITS.md](CONVENTIONAL_COMMITS.md) specification.\n"
  },
  "open-rpc/generator": {
    "fetchedAt": "2025-11-12T22:36:14.567Z",
    "content": "# OpenRPC Generator\n\n<center>\n  <span>\n    <img alt=\"CircleCI branch\" src=\"https://img.shields.io/circleci/project/github/open-rpc/generator/master.svg\">\n    <img src=\"https://codecov.io/gh/open-rpc/generator/branch/master/graph/badge.svg\" />\n    <img alt=\"npm\" src=\"https://img.shields.io/npm/dt/@open-rpc/generator.svg\" />\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/open-rpc/generator.svg\" />\n    <img alt=\"GitHub commits since latest release\" src=\"https://img.shields.io/github/commits-since/open-rpc/generator/latest.svg\" />\n  </span>\n</center>\n\nA Generator tool for [open-rpc](https://github.com/open-rpc/spec) APIs.\n\nNeed help or have a question? Join us on [Discord](https://discord.gg/gREUKuF)!\n\n## Features:\n\n- Built in components for:\n  - Clients\n  - Server\n  - Documentation\n- Easy to create new components\n\n\n## Usage\n\nThe generator CLI has a generate command which takes a config to run. The config specifies what components you want to make, as well as the configuration for each component.\n\nUsing the CLI's `init` command, you can walk though an interactive config builder.\n\n### Quick start\n\n```sh\nnpm install -g @open-rpc/generator\n\nopen-rpc-generator init\nopen-rpc-generator generate -c open-rpc-generator-config.json\n```\n\n### Generating an individual component\n\n```shell\nopen-rpc-generator generate \\\n  -t client \\\n  -l typescript \\\n  -n petstoreClientTs \\\n  -d https://raw.githubusercontent.com/open-rpc/examples/master/service-descriptions/petstore-openrpc.json \\\n  -o ./generated\n```\n### Custom Component Generation Configuration\nHere for customComponent we specify the module that exports as\ndefault the type IComponentModule see custom-test-component.js as an example. It is easy to also refer to an npm package as well as a plain js file. customType is can be anything , it is not restricted to client | server | doc naming.\n```\n{\n  \"openrpcDocument\": \"./src/awesome-custom-client_openrpc.json\",\n  \"outDir\": \"generated-client\",\n  \"components\": [\n      {\n          \"type\": \"custom\",\n          \"name\": \"awesome-custom-client\",\n          \"language\": \"typescript\",\n          \"customComponent\": \"./src/custom-test-component.js\",\n          \"customType\": \"client\"\n      }\n  ]\n}\n```\n## Resources\n\n- [@open-rpc/generator package](https://www.npmjs.com/package/@open-rpc/generator)\n- [example open-rpc documents](https://github.com/open-rpc/examples/tree/master/service-descriptions)\n"
  },
  "LZeroAnalytics/layerzero-package": {
    "fetchedAt": "2025-11-12T22:36:23.853Z",
    "content": "# LayerZero Kurtosis package\n\nThis is a LayerZero package developed by [Bloctopus](https://www.bloctopus.io) that facilitates cross-chain message execution and verification using LayerZero V2. The package includes both on-chain and off-chain components for message verification and execution.\n\nThis package does the following:\n\n1. Deploy simple DVN and Executor contracts into the specified networks\n2. Spin up a DVN off-chain component for each specified connection\n3. Spin up an Executor off-chain component for each specified connection\n\n## Get started\n\n### Prerequisites\n\n1. [Install Docker & start the Docker Daemon if you haven't done so already][docker-installation]\n2. [Install the Kurtosis CLI, or upgrade it to the latest version if it's already installed][kurtosis-cli-installation]\n3. Deploy at least two LayerZero compatible forked networks with funded accounts on each chain and reliable RPC access. These networks need to be remote networks and cannot be running on localhost. (See [Coming Soon](#coming-soon) section)\n\n### Configuration\n\nThis package is parameterizable using a YAML or JSON configuration file.\nBelow is an example which connects two networks that were created through the [Bloctopus](https://www.bloctopus.io) platform:\n\n\n```yaml\nnetworks:\n  - name: ethereum\n    chain_id: \"3151908\"\n    rpc: https://769aebebe72d4b069840e92ce9b06fad-rpc.dev.lzeroanalytics.com\n    endpoint: 0x1a44076050125825900e736c501f859c50fE728c\n    trusted_send_lib: 0xbB2Ea70C9E858123480642Cf96acbcCE1372dCe1\n    trusted_receive_lib: 0xc02Ab410f0734EFa3F14628780e6e695156024C2\n    eid: \"30101\"\n    private_key: 0xbcdf20249abf0ed6d944c0288fad489e33f66b3960d9e6229c1cd214ed3bbe31\n  - name: arbitrum\n    chain_id: \"3151910\"\n    rpc: https://ebc3f5fcc4ce423ba43b837872b43941-rpc.dev.lzeroanalytics.com\n    endpoint: 0x1a44076050125825900e736c501f859c50fE728c\n    trusted_send_lib: 0x975bcD720be66659e3EB3C0e4F1866a3020E493A\n    trusted_receive_lib: 0x7B9E184e07a6EE1aC23eAe0fe8D6Be2f663f05e6\n    eid: \"30110\"\n    private_key: 0xbcdf20249abf0ed6d944c0288fad489e33f66b3960d9e6229c1cd214ed3bbe31\nconnections:\n  - from: ethereum\n    to: arbitrum\n    exec_fee: \"10000000000000000\" # in wei\n    dvn_fee: \"0\" # in wei\n```\n\nFor simplicity, you can also specify a `type` for each network which will automatically use known values for \n`endpoint`, `trusted_send_lib`, `trusted_receive_lib`, `chain_id` and `eid`.\nMake sure you still specify `name`, `rpc`, and `private_key`. Below are the supported known networks:\n\n```text\nethereum_mainnet\nethereum_sepolia\nethereum_holesky\narbitrum_mainnet\narbitrum_sepolia\noptimism_mainnet\noptimism_sepolia\nbase_mainnet\nbase_sepolia\n```\n\n### Running the package\nTo run the package, use the command below.\nYou can use [network_remote.yaml](network_remote.yaml) or [network_custom.yaml](network_custom.yaml) as sample files.\n```bash\nkurtosis run --enclave <enclave-name> github.com/0xBloctopus/layerzero-package --args-file <config file>\n```\n\nTo shut down the enclave, you can run:\n\n```bash\nkurtosis enclave rm -f <enclave-name>\n```\n\nTo retrieve logs from any service, you can run:\n```bash\nkurtosis service logs <enclave-name> <service-name>\n```\n\n## Coming Soon\n1. Running fully local deployments including all the required forked networks\n2. Support for chains that LayerZero doesn't currently support (automatic cdeployment of Endpoint and MessageLib)\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Contact & Support\n\nFor issues, feature requests, or contributions, please open an issue or submit a pull request on GitHub.\n\n[docker-installation]: https://docs.docker.com/get-docker/\n[kurtosis-cli-installation]: https://docs.kurtosis.com/install\n[kurtosis-repo]: https://github.com/kurtosis-tech/kurtosis\n[package-reference]: https://docs.kurtosis.com/advanced-concepts/packages\n"
  },
  "LZeroAnalytics/chainlink-node-package": {
    "fetchedAt": "2025-11-12T22:36:24.451Z",
    "content": "# üîó Chainlink Node Package for Kurtosis üöÄ\n\n> *Easily deploy and setup Chainlink Node infrastructure in isolated test environments with one command.*\n\n## üåê Overview\n\nThis package allows you to deploy and configure Chainlink Nodes in isolated, reproducible environments using [Kurtosis](https://kurtosis.com/).\n\n## üöÄ Key Capabilities\n\n- üõ†Ô∏è **Node Deployment & Management**:\n  - Deploy multiple Chainlink nodes in parallel with one command\n  - Manage cryptographic keys (ETH, VRF, P2P, OCR) securely\n  - Configure node resources and PostgreSQL databases automatically\n\n- ‚ö° **Oracle Services & Jobs**:\n  - üé≤ VRF: Verifiable randomness for gaming, NFTs and fair selection\n  - üìä OCR: Scalable, cost-efficient price feeds and data delivery\n  - üîÑ Automation: Condition-based smart contract maintenance\n  - üìà Direct Request: Custom on-demand data fetching from any API\n  - üåâ DKG: Distributed Key Generation for threshold cryptography\n\n- üèóÔ∏è **Advanced Off-chain/On-chain Workflows/Automations**:\n  - Architect powerful data pipelines bridging external systems to smart contracts\n  - Orchestrate precise time-based and event-driven contract executions\n  - Process and transform data through custom validation logic\n  - Deploy sophisticated off-chain computation with on-chain verification\n  - Connect seamlessly with external APIs and proprietary data sources\n\n- üåê **Cross-Chain Operations** (Coming soon):\n  - CCIP: Securely transfer tokens and data between blockchains\n  - Multi-chain oracle network coordination\n  - Cross-chain messaging and verification services\n\n## ‚ú® Features\n\n- **Multi-Node Support**: Deploy multiple Chainlink nodes with different configurations\n- **PostgreSQL Database**: Each node comes with its own PostgreSQL database\n- **Blockchain Integration**: Connect to any EVM-compatible blockchain\n- **Job Templates**: Pre-configured job templates for OCR2, BHS/BHF, and VRF functionalities\n- **Comprehensive Toolkit**: Rich set of functions for key management, job deployment, network configuration, and node orchestration\n- **Configurable Resources**: Fine-tune CPU and memory allocation\n\n## üìã Prerequisites\n\n| Requirement | Version |\n|-------------|---------|\n| [Kurtosis](https://docs.kurtosis.com/)    | >= 0.47.0 | \n| Docker/Kubernetes      | >= 20.10.0 |\n| Disk Space  | >= 5GB |\n\n## üèÉ Quick Start\n\n<div style=\"display: flex; align-items: flex-start;\">\n<div style=\"flex: 1;\">\n\n1Ô∏è‚É£ Create a `config.yaml` file:\n\n```yaml\nnetwork:\n  rpc: http://host.docker.internal:8545\n  ws: ws://host.docker.internal:8546\n  chain_id: \"1337\"\n\nchainlink_nodes:\n  - node_name: \"chainlink-1\"\n    image: \"smartcontract/chainlink:latest\"\n    keystore_pw: \"AtLeast16Characters!\"\n    api_user: \"admin@chain.link\"\n    api_password: \"StrongPassword123!\"\n```\n\n2Ô∏è‚É£ Run the package:\n\n```bash\nkurtosis run github.com/your-org/chainlink-node-package --args-file config.yaml\n```\n3Ô∏è‚É£ Access your node(s) Operator UI:\n\n| Node Name   | Web UI               |\n|-------------|----------------------|\n| chainlink-1 | http://localhost:6688 |\n\n</div>\n<div style=\"flex: 0 0 50%; padding-left: 5%; padding-top: 8px;\">\n<img src=\"./assets/operator-ui-screenshot.webp\" alt=\"Chainlink Operator UI Screenshot\" style=\"max-width: 650px; width: 100%;\" />\n</div>\n</div>\n\n## ‚öôÔ∏è Configuration Reference (Args)\n\nThe package provides a powerful input parser that auto-fills most parameters. You only need to specify the network configuration and node names to determine how many nodes to deploy.\n\n### üåê Network Configs (required)\n\n| Parameter | Required | Description |\n|-----------|----------|-------------|\n| `rpc`     | ‚úÖ Yes   | HTTP RPC endpoint URL |\n| `ws`      | ‚úÖ Yes   | WebSocket endpoint URL |\n| `chain_id`| ‚úÖ Yes   | Chain ID as string |\n\n### üîó Chainlink Node Configuration\n\n| Parameter     | Required | Default | Description |\n|---------------|----------|---------|-------------|\n| `node_name`   | ‚úÖ Yes   | - | Unique name for the node |\n| `image` | ‚ùå No  | `smartcontract/chainlink:latest` | Chainlink image version |\n| `keystore_pw` | ‚ùå No  | - | Node keystore password (min 16 chars) |\n| `api_user`    | ‚ùå No   | - | API/GUI username |\n| `api_password`| ‚ùå No   | - | API/GUI password |\n\n### üóÑÔ∏è PostgreSQL Configuration\n\n| Parameter   | Required | Default | Description |\n|-------------|----------|---------|-------------|\n| `user`      | ‚ùå No    | `postgres` | Database username |\n| `password`  | ‚úÖ Yes   | - | Database password |\n| `min_cpu`   | ‚ùå No    | 10 | Minimum CPU allocation |\n| `max_cpu`   | ‚ùå No    | 1000 | Maximum CPU allocation |\n| `min_memory`| ‚ùå No    | 32 | Minimum memory in MB |\n| `max_memory`| ‚ùå No    | 1024 | Maximum memory in MB |\n\n## üîÑ Advanced Usage\n\n### üñ•Ô∏è Multi-Node Setup\n\n```yaml\nchainlink_nodes:\n  - node_name: \"vrf-primary\"\n    # Primary node config...\n    \n  - node_name: \"vrf-backup\"\n    # Backup node config...\n    \n  - node_name: \"monitoring\"\n    # Monitoring node config...\n```\n\n### üìù Custom Job Templates\n\nThe package includes several pre-configured job templates that get preloaded in the node to be used to create jobs on demand:\n- `ocr2vrf-job-template.toml`: OCR2 VRF job configuration\n- `bhs-or-bhf-job-template.toml`: Block header service/feeder jobs\n- `dkg-bootstrap-job-template.toml`: DKG bootstrapping job\n- `dkg-job-template.toml`: DKG participant job\n- `vrf2plus-job-template.toml`: VRF v2 Plus jobs\n\n## üõ†Ô∏è Functions & API\n\nThis package provides Starlark functions for Chainlink Nodes setup and infrastructure management. **Note that only the `run` function is directly callable from the command line.** The other functions are internal to the package and used can be used only within Starlark scripts.\n\n### üöÄ Main Function\n\n| Function | Description | How to Use |\n|----------|-------------|------------|\n| `run` | Main entrypoint that deploys all nodes in parallel | Directly with `kurtosis run github.com/your-org/vrf-package --args-file config.yaml` |\n\n### üß© Internal Starlark Functions\n\nThe following functions are used internally within the package's Starlark scripts. If you want to use these functions, you'll need to create custom Starlark scripts that import this package.\n\n#### üèóÔ∏è Infrastructure Setup\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `create_node_database` | Creates a PostgreSQL database for a node | `plan`, `postgres_configs`, `node_name` |\n| `create_node_config` | Creates a ServiceConfig for a node | `plan`, `chainlink_configs`, `postgres_output`, `chain_configs` |\n\n#### üîë Key Management\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `create_vrf_keys` | Creates VRF keys on a node | `plan`, `node_name` |\n| `get_eth_key` | Gets first Ethereum key address | `plan`, `node_name` |\n| `get_p2p_peer_id` | Gets P2P key and PeerID | `plan`, `node_name` |\n| `get_ocr_key_bundle_id` | Gets OCR key bundle ID | `plan`, `node_name` |\n| `get_ocr_key` | Gets OCR key details | `plan`, `node_name` |\n\n#### üìã Job Management\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `create_bootstrap_job` | Creates a DKG bootstrap job | `plan`, `dkg_contract_address`, `chain_id`, `node_name` |\n| `create_bhs_or_bhf_job` | Creates a BHS or BHF job | Various parameters for job configuration |\n| `create_vrfv2plus_job` | Creates a VRF v2 Plus job | Various parameters for VRF configuration |\n| `create_dkg_job` | Creates a DKG job (v2.14 only) | Various parameters for DKG setup |\n| `create_ocr2vrf_job` | Creates an OCR2 VRF job (v2.14 only) | Various parameters for OCR2 VRF setup |\n\n#### üåâ DKG Specific (v2.14 Only)\n\n| Function | Description | Parameters |\n|----------|-------------|------------|\n| `create_dkg_encr_key` | Creates a DKG encryption key | `plan`, `node_name` |\n| `create_dkg_sign_key` | Creates a DKG signing key | `plan`, `node_name` |\n\n### üìù Creating Custom Scripts\n\nTo leverage these internal functions, you'd need to create your own Starlark script:\n\n```starlark\n# Example custom script: setup_vrf_node.star\n\n[... truncated ...]"
  },
  "LZeroAnalytics/lzero-reth": {
    "fetchedAt": "2025-11-12T22:36:25.415Z",
    "content": "# Bloctopus reth\n\n[![CI status](https://github.com/paradigmxyz/reth/workflows/unit/badge.svg)][gh-ci]\n[![cargo-deny status](https://github.com/paradigmxyz/reth/workflows/deny/badge.svg)][gh-deny]\n[![Telegram Chat][tg-badge]][tg-url]\n\n**Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol**\n\n**[Install](https://paradigmxyz.github.io/reth/installation/installation.html)**\n| [User Book](https://reth.rs)\n| [Developer Docs](./docs)\n| [Crate Docs](https://reth.rs/docs)\n\n[gh-ci]: https://github.com/paradigmxyz/reth/actions/workflows/unit.yml\n[gh-deny]: https://github.com/paradigmxyz/reth/actions/workflows/deny.yml\n[tg-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fparadigm%5Freth\n\n## What is Bloctopus Reth?\n\nBloctopus Reth is a fork of the official Reth implementation. It adds forking capabilities so that users can create networks that \nhave full access to mainnet data. It also supports Chainlink data feeds. It's intended to be used with this [ethereum kurtosis package](https://github.com/0xBloctopus/ethereum-package).\n\n### How to use it\n1. Build your own docker image which will use the custom example under examples/lzero-custom-reth.\n2. Define FORKING_RPC_URL (e.g. Alchemy RPC) and optionally FORKING_BLOCK_HEIGHT and PRICE_FEEDS (e.g. [Chainlink price feeds](https://docs.chain.link/data-feeds/price-feeds/addresses?network=ethereum&page=1) formatted as json with an address field) as environment variables\n3. Run the generated executable at /usr/local/bin/lzero-custom-reth\n\n## What is Reth?\n\nReth (short for Rust Ethereum, [pronunciation](https://twitter.com/kelvinfichter/status/1597653609411268608)) is a new Ethereum full node implementation that is focused on being user-friendly, highly modular, as well as being fast and efficient. Reth is an Execution Layer (EL) and is compatible with all Ethereum Consensus Layer (CL) implementations that support the [Engine API](https://github.com/ethereum/execution-apis/tree/a0d03086564ab1838b462befbc083f873dcf0c0f/src/engine). It is originally built and driven forward by [Paradigm](https://paradigm.xyz/), and is licensed under the Apache and MIT licenses.\n\n## Goals\n\nAs a full Ethereum node, Reth allows users to connect to the Ethereum network and interact with the Ethereum blockchain. This includes sending and receiving transactions/logs/traces, as well as accessing and interacting with smart contracts. Building a successful Ethereum node requires creating a high-quality implementation that is both secure and efficient, as well as being easy to use on consumer hardware. It also requires building a strong community of contributors who can help support and improve the software.\n\nMore concretely, our goals are:\n\n1. **Modularity**: Every component of Reth is built to be used as a library: well-tested, heavily documented and benchmarked. We envision that developers will import the node's crates, mix and match, and innovate on top of them. Examples of such usage include but are not limited to spinning up standalone P2P networks, talking directly to a node's database, or \"unbundling\" the node into the components you need. To achieve that, we are licensing Reth under the Apache/MIT permissive license. You can learn more about the project's components [here](./docs/repo/layout.md).\n2. **Performance**: Reth aims to be fast, so we used Rust and the [Erigon staged-sync](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) node architecture. We also use our Ethereum libraries (including [Alloy](https://github.com/alloy-rs/alloy/) and [revm](https://github.com/bluealloy/revm/)) which we‚Äôve battle-tested and optimized via [Foundry](https://github.com/foundry-rs/foundry/).\n3. **Free for anyone to use any way they want**: Reth is free open source software, built for the community, by the community. By licensing the software under the Apache/MIT license, we want developers to use it without being bound by business licenses, or having to think about the implications of GPL-like licenses.\n4. **Client Diversity**: The Ethereum protocol becomes more antifragile when no node implementation dominates. This ensures that if there's a software bug, the network does not finalize a bad block. By building a new client, we hope to contribute to Ethereum's antifragility.\n5. **Support as many EVM chains as possible**: We aspire that Reth can full-sync not only Ethereum, but also other chains like Optimism, Polygon, BNB Smart Chain, and more. If you're working on any of these projects, please reach out.\n6. **Configurability**: We want to solve for node operators that care about fast historical queries, but also for hobbyists who cannot operate on large hardware. We also want to support teams and individuals who want both sync from genesis and via \"fast sync\". We envision that Reth will be configurable enough and provide configurable \"profiles\" for the tradeoffs that each team faces.\n\n## Status\n\nReth is production ready, and suitable for usage in mission-critical environments such as staking or high-uptime services. We also actively recommend professional node operators to switch to Reth in production for performance and cost reasons in use cases where high performance with great margins is required such as RPC, MEV, Indexing, Simulations, and P2P activities.\n\nMore historical context below:\n* We released 1.0 \"production-ready\" stable Reth in June 2024.\n    * Reth completed an audit with [Sigma Prime](https://sigmaprime.io/), the developers of [Lighthouse](https://github.com/sigp/lighthouse), the Rust Consensus Layer implementation. Find it [here](./audit/sigma_prime_audit_v2.pdf).\n    * Revm (the EVM used in Reth) underwent an audit with [Guido Vranken](https://twitter.com/guidovranken) (#1 [Ethereum Bug Bounty](https://ethereum.org/en/bug-bounty)). We will publish the results soon.\n* We released multiple iterative beta versions, up to [beta.9](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.9) on Monday June 3rd 2024 the last beta release.\n* We released [beta](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) on Monday March 4th 2024, our first breaking change to the database model, providing faster query speed, smaller database footprint, and allowing \"history\" to be mounted on separate drives.\n* We shipped iterative improvements until the last alpha release on February 28th 2024, [0.1.0-alpha.21](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.21).\n* We [initially announced](https://www.paradigm.xyz/2023/06/reth-alpha) [0.1.0-alpha.1](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.1) in June 20th 2023.\n\n### Database compatibility\n\nWe do not have any breaking database changes since beta.1, and do not plan any in the near future.\n\nReth [v0.2.0-beta.1](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) includes\na [set of breaking database changes](https://github.com/paradigmxyz/reth/pull/5191) that makes it impossible to use database files produced by earlier versions.\n\nIf you had a database produced by alpha versions of Reth, you need to drop it with `reth db drop`\n(using the same arguments such as `--config` or `--datadir` that you passed to `reth node`), and resync using the same `reth node` command you've used before.\n\n## For Users\n\nSee the [Reth Book](https://paradigmxyz.github.io/reth) for instructions on how to install and run Reth.\n\n## For Developers\n\n### Using reth as a library\n\nYou can use individual crates of reth in your project.\n\nThe crate docs can be found [here](https://paradigmxyz.github.io/reth/docs).\n\nFor a general overview of the crates, see [Project Layout](./docs/repo/layout.md).\n\n### Contributing\n\nIf you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/paradigm_reth) to chat with us about the development of Reth!\n\n- Our contributor guidelines can be found in [`CONTRIBUTING.md`](./CONTR\n\n[... truncated ...]"
  },
  "LZeroAnalytics/ethereum-package": {
    "fetchedAt": "2025-11-12T22:36:26.146Z",
    "content": "# Bloctopus Ethereum Package\n\nThis project is a fork of the ethpandaops [Ethereum Package](https://github.com/ethpandaops/ethereum-package).\n\nIt is fully synced with the original ethereum package and provides the same capabilities. Additionally, this package adds additional features. Specifically, it enables:\n\n- Fork any public EVM-based network (using a custom Reth client)\n- A faucet for ETH and USDC (refer to the [docs](https://github.com/0xBloctopus/ethereum-faucet))\n- A fully functional Uniswap interface (requires forking, only available in cloud environments)\n- Blockscout explorer (only available in cloud environments)\n\n## Quickstart\n\n1. [Install Docker & start the Docker Daemon if you haven't done so already][docker-installation]\n2. [Install the Kurtosis CLI, or upgrade it to the latest version if it's already installed][kurtosis-cli-installation]\n3. Run the package with default configurations from the command line:\n\n   ```bash\n   kurtosis run --enclave my-testnet github.com/0xBloctopus/ethereum-package\n   ```\n\n#### Run with your own configuration\n\nKurtosis packages are parameterizable, meaning you can customize your network and its behavior to suit your needs by storing parameters in a file that you can pass in at runtime like so:\n\n```bash\nkurtosis run --enclave my-testnet github.com/0xBloctopus/ethereum-package --args-file network_params.yaml\n```\n\nWhere `network_params.yaml` contains the parameters for your network in your home directory.\n\n\n#### Tear down\n\nThe testnet will reside in an [enclave][enclave] - an isolated, ephemeral environment. The enclave and its contents (e.g. running containers, files artifacts, etc) will persist until torn down. You can remove an enclave and its contents with:\n\n```bash\nkurtosis enclave rm -f my-testnet\n```\n\n## Management\n\nThe [Kurtosis CLI](https://docs.kurtosis.com/cli) can be used to inspect and interact with the network.\n\nFor example, if you need shell access, simply run:\n\n```bash\nkurtosis service shell my-testnet $SERVICE_NAME\n```\n\nAnd if you need the logs for a service, simply run:\n\n```bash\nkurtosis service logs my-testnet $SERVICE_NAME\n```\n\nCheck out the full list of CLI commands [here](https://docs.kurtosis.com/cli)\n\n## Debugging\n\nTo grab the genesis files for the network, simply run:\n\n```bash\nkurtosis files download my-testnet $FILE_NAME $OUTPUT_DIRECTORY\n```\n\nFor example, to retrieve the Execution Layer (EL) genesis data, run:\n\n```bash\nkurtosis files download my-testnet el-genesis-data ~/Downloads\n```\n\n## Configuration\n\nTo configure the package behaviour, you can modify your `network_params.yaml` file. Below is an example of a\nconfiguration that uses the additional features available in this package:\n\n```yaml\nparticipants:\n  - el_type: reth\n    el_image: tiljordan/reth-forking:1.0.0\n    el_extra_env_vars:\n      FORKING_RPC_URL: <FORKING URL> # e.g. Alchemy endpoint\n      FORKING_BLOCK_HEIGHT: \"latest\" # Specify any previous block height\n    cl_type: lighthouse\nnetwork_params:\n  prefunded_accounts: '{\"0xe1A74e1FCB254CB1e5eb1245eaAe034A4D7dD538\": {\"balance\": \"1000000000ETH\"}}'\nfaucet_params:\n  private_key: 1cdf65ac75f477650040ebe272ddaffb6735dcf55bd651869963ada71944e6db # Needs to be a prefunded account\nblockscout_params:\n  backend_url: <BLOCKSCOUT BACKEND URL> # URL at which the blockscout backend will be available\n  frontend_url: <BLOCKSCOUT FRONTEND URL> # URL at which the blockscout frontend will be available\nuniswap_params:\n  backend_url: <UNISWAP BACKEND URL> # URL at which the backend service will be available\n\nadditional_services:\n  - faucet\n  - blockscout\n  - uniswap\n\n```\n\nThe full YAML schema that can be passed in is as follows with the defaults provided:\n\n```yaml\n# Specification of the participants in the network\nparticipants:\n  # EL(Execution Layer) Specific flags\n    # The type of EL client that should be started\n    # Valid values are geth, nethermind, erigon, besu, ethereumjs, reth, nimbus-eth1\n  - el_type: geth\n\n    # The Docker image that should be used for the EL client; leave blank to use the default for the client type\n    # Defaults by client:\n    # - geth: ethereum/client-go:latest\n    # - erigon: ethpandaops/erigon:main\n    # - nethermind: nethermind/nethermind:latest\n    # - besu: hyperledger/besu:develop\n    # - reth: ghcr.io/paradigmxyz/reth\n    # - ethereumjs: ethpandaops/ethereumjs:master\n    # - nimbus-eth1: ethpandaops/nimbus-eth1:master\n    # If you want to use forking capabilities use:\n    # - tiljordan/reth-forking:1.0.0\n    el_image: \"\"\n\n    # The log level string that this participant's EL client should log at\n    # If this is emptystring then the global `logLevel` parameter's value will be translated into a string appropriate for the client (e.g. if\n    # global `logLevel` = `info` then Geth would receive `3`, Besu would receive `INFO`, etc.)\n    # If this is not emptystring, then this value will override the global `logLevel` setting to allow for fine-grained control\n    # over a specific participant's logging\n    el_log_level: \"\"\n\n    # A list of optional extra env_vars the el container should spin up with\n    el_extra_env_vars: {}\n\n    # A list of optional extra labels the el container should spin up with\n    # Example; el_extra_labels: {\"ethereum-package.partition\": \"1\"}\n    el_extra_labels: {}\n\n    # A list of optional extra params that will be passed to the EL client container for modifying its behaviour\n    el_extra_params: []\n\n    # A list of tolerations that will be passed to the EL client container\n    # Only works with Kubernetes\n    # Example: el_tolerations:\n    # - key: \"key\"\n    #   operator: \"Equal\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule\"\n    #   toleration_seconds: 3600\n    # Defaults to empty\n    el_tolerations: []\n\n    # Persistent storage size for the EL client container (in MB)\n    # Defaults to 0, which means that the default size for the client will be used\n    # Default values can be found in /src/package_io/constants.star VOLUME_SIZE\n    el_volume_size: 0\n\n    # Resource management for el containers\n    # CPU is milicores\n    # RAM is in MB\n    # Defaults to 0, which results in no resource limits\n    el_min_cpu: 0\n    el_max_cpu: 0\n    el_min_mem: 0\n    el_max_mem: 0\n\n  # CL(Consensus Layer) Specific flags\n    # The type of CL client that should be started\n    # Valid values are nimbus, lighthouse, lodestar, teku, prysm, and grandine\n    cl_type: lighthouse\n\n    # The Docker image that should be used for the CL client; leave blank to use the default for the client type\n    # Defaults by client:\n    # - lighthouse: sigp/lighthouse:latest\n    # - teku: consensys/teku:latest\n    # - nimbus: statusim/nimbus-eth2:multiarch-latest\n    # - prysm: gcr.io/prysmaticlabs/prysm/beacon-chain:latest\n    # - lodestar: chainsafe/lodestar:next\n    # - grandine: sifrai/grandine:stable\n    cl_image: \"\"\n\n    # The log level string that this participant's CL client should log at\n    # If this is emptystring then the global `logLevel` parameter's value will be translated into a string appropriate for the client (e.g. if\n    # global `logLevel` = `info` then Teku would receive `INFO`, Prysm would receive `info`, etc.)\n    # If this is not emptystring, then this value will override the global `logLevel` setting to allow for fine-grained control\n    # over a specific participant's logging\n    cl_log_level: \"\"\n\n    # A list of optional extra env_vars the cl container should spin up with\n    cl_extra_env_vars: {}\n\n    # A list of optional extra labels that will be passed to the CL client Beacon container.\n    # Example; cl_extra_labels: {\"ethereum-package.partition\": \"1\"}\n    cl_extra_labels: {}\n\n    # A list of optional extra params that will be passed to the CL client Beacon container for modifying its behaviour\n    # If the client combines the Beacon & validator nodes (e.g. Teku, Nimbus), then this list will be passed to the combined Beacon-validator node\n    cl_extra_params: []\n\n    # A list of tolerations that will be passed to the CL client contain\n\n[... truncated ...]"
  },
  "alloy-rs/alloy": {
    "fetchedAt": "2025-11-12T22:36:34.462Z",
    "content": "# Alloy\n\nAlloy connects applications to blockchains.\n\nAlloy is a rewrite of [`ethers-rs`] from the ground up, with exciting new\nfeatures, high performance, and excellent [docs](https://docs.rs/alloy).\n\nWe also have a [book](https://alloy.rs/) on all things Alloy and many [examples](https://github.com/alloy-rs/examples) to help you get started.\n\n[![Telegram chat][telegram-badge]][telegram-url]\n\n[`ethers-rs`]: https://github.com/gakonst/ethers-rs\n[telegram-badge]: https://img.shields.io/endpoint?color=neon&style=for-the-badge&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fethers_rs\n[telegram-url]: https://t.me/ethers_rs\n\n## Installation\n\nAlloy consists of a number of crates that provide a range of functionality essential for interfacing with any Ethereum-based blockchain.\n\nThe easiest way to get started is to add the `alloy` crate with the `full` feature flag from the command-line using Cargo:\n\n```sh\ncargo add alloy --features full\n```\n\nAlternatively, you can add the following to your `Cargo.toml` file:\n\n```toml\nalloy = { version = \"1\", features = [\"full\"] }\n```\n\nFor a more fine-grained control over the features you wish to include, you can add the individual crates to your `Cargo.toml` file, or use the `alloy` crate with the features you need.\n\nA comprehensive list of available features can be found on [docs.rs](https://docs.rs/crate/alloy/latest/features) or in the [`alloy` crate's `Cargo.toml`](https://github.com/alloy-rs/alloy/blob/main/crates/alloy/Cargo.toml).\n\n## Overview\n\nThis repository contains the following crates:\n\n- [`alloy`]: Meta-crate for the entire project, including [`alloy-core`]\n- [`alloy-consensus`] - Ethereum consensus interface\n  - [`alloy-consensus-any`] - Catch-all consensus interface for multiple networks\n- [`alloy-contract`] - Interact with on-chain contracts\n- [`alloy-eips`] - Ethereum Improvement Proposal (EIP) implementations\n- [`alloy-genesis`] - Ethereum genesis file definitions\n- [`alloy-json-rpc`] - Core data types for JSON-RPC 2.0 clients\n- [`alloy-ens`] - Ethereum Name Service (ENS) utilities\n- [`alloy-network`] - Network abstraction for RPC types\n  - [`alloy-network-primitives`] - Primitive types for the network abstraction\n- [`alloy-node-bindings`] - Ethereum execution-layer client bindings\n- [`alloy-provider`] - Interface with an Ethereum blockchain\n- [`alloy-pubsub`] - Ethereum JSON-RPC [publish-subscribe] tower service and type definitions\n- [`alloy-rpc-client`] - Low-level Ethereum JSON-RPC client implementation\n- [`alloy-rpc-types`] - Meta-crate for all Ethereum JSON-RPC types\n  - [`alloy-rpc-types-admin`] - Types for the `admin` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-anvil`] - Types for the [Anvil] development node's Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-any`] - Types for JSON-RPC namespaces across multiple networks\n  - [`alloy-rpc-types-beacon`] - Types for the [Ethereum Beacon Node API][beacon-apis]\n  - [`alloy-rpc-types-debug`] - Types for the `debug` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-engine`] - Types for the `engine` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-eth`] - Types for the `eth` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-mev`] - Types for the MEV bundle JSON-RPC namespace\n  - [`alloy-rpc-types-trace`] - Types for the `trace` Ethereum JSON-RPC namespace\n  - [`alloy-rpc-types-txpool`] - Types for the `txpool` Ethereum JSON-RPC namespace\n- [`alloy-serde`] - [Serde]-related utilities\n- [`alloy-signer`] - Ethereum signer abstraction\n  - [`alloy-signer-aws`] - [AWS KMS] signer implementation\n  - [`alloy-signer-gcp`] - [GCP KMS] signer implementation\n  - [`alloy-signer-ledger`] - [Ledger] signer implementation\n  - [`alloy-signer-local`] - Local (private key, keystore, mnemonic, YubiHSM) signer implementations\n  - [`alloy-signer-trezor`] - [Trezor] signer implementation\n- [`alloy-transport`] - Low-level Ethereum JSON-RPC transport abstraction\n  - [`alloy-transport-http`] - HTTP transport implementation\n  - [`alloy-transport-ipc`] - IPC transport implementation\n  - [`alloy-transport-ws`] - WS transport implementation\n\n[`alloy`]: https://github.com/alloy-rs/alloy/tree/main/crates/alloy\n[`alloy-core`]: https://docs.rs/alloy-core\n[`alloy-consensus`]: https://github.com/alloy-rs/alloy/tree/main/crates/consensus\n[`alloy-consensus-any`]: https://github.com/alloy-rs/alloy/tree/main/crates/consensus-any\n[`alloy-contract`]: https://github.com/alloy-rs/alloy/tree/main/crates/contract\n[`alloy-eips`]: https://github.com/alloy-rs/alloy/tree/main/crates/eips\n[`alloy-genesis`]: https://github.com/alloy-rs/alloy/tree/main/crates/genesis\n[`alloy-json-rpc`]: https://github.com/alloy-rs/alloy/tree/main/crates/json-rpc\n[`alloy-network`]: https://github.com/alloy-rs/alloy/tree/main/crates/network\n[`alloy-network-primitives`]: https://github.com/alloy-rs/alloy/tree/main/crates/network-primitives\n[`alloy-node-bindings`]: https://github.com/alloy-rs/alloy/tree/main/crates/node-bindings\n[`alloy-provider`]: https://github.com/alloy-rs/alloy/tree/main/crates/provider\n[`alloy-pubsub`]: https://github.com/alloy-rs/alloy/tree/main/crates/pubsub\n[`alloy-rpc-client`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-client\n[`alloy-rpc-types`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types\n[`alloy-rpc-types-admin`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-admin\n[`alloy-rpc-types-anvil`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-anvil\n[`alloy-rpc-types-any`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-any\n[`alloy-rpc-types-beacon`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-beacon\n[`alloy-rpc-types-debug`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-debug\n[`alloy-rpc-types-engine`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-engine\n[`alloy-rpc-types-eth`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-eth\n[`alloy-rpc-types-mev`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-mev\n[`alloy-rpc-types-trace`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-trace\n[`alloy-rpc-types-txpool`]: https://github.com/alloy-rs/alloy/tree/main/crates/rpc-types-txpool\n[`alloy-serde`]: https://github.com/alloy-rs/alloy/tree/main/crates/serde\n[`alloy-signer`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer\n[`alloy-signer-aws`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-aws\n[`alloy-signer-gcp`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-gcp\n[`alloy-signer-ledger`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-ledger\n[`alloy-signer-local`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-local\n[`alloy-signer-trezor`]: https://github.com/alloy-rs/alloy/tree/main/crates/signer-trezor\n[`alloy-transport`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport\n[`alloy-transport-http`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport-http\n[`alloy-transport-ipc`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport-ipc\n[`alloy-transport-ws`]: https://github.com/alloy-rs/alloy/tree/main/crates/transport-ws\n[`alloy-ens`]: https://github.com/alloy-rs/alloy/tree/main/crates/ens\n[publish-subscribe]: https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern\n[AWS KMS]: https://aws.amazon.com/kms\n[GCP KMS]: https://cloud.google.com/kms\n[Ledger]: https://www.ledger.com\n[Trezor]: https://trezor.io\n[Serde]: https://serde.rs\n[beacon-apis]: https://ethereum.github.io/beacon-APIs\n[Anvil]: https://github.com/foundry-rs/foundry\n\n## Supported Rust Versions (MSRV)\n\n<!--\nWhen updating this, also update:\n- clippy.toml\n- Cargo.toml\n- .github/workflows/ci.yml\n-->\n\nThe current MSRV (minimum supported rust version) is 1.88.\n\nAlloy will keep a rolling MSRV policy of **at least** two versions behind the\nlatest stable release (so if the latest stable release is 1.58, we would\nsupport 1.56).\n\nNote that the MSRV is not increased automatically, and only as part of a patc\n\n[... truncated ...]"
  },
  "alloy-rs/op-alloy": {
    "fetchedAt": "2025-11-12T22:36:34.847Z",
    "content": "# op-alloy\n\n<a href=\"https://github.com/alloy-rs/op-alloy/actions/workflows/ci.yml\"><img src=\"https://github.com/alloy-rs/op-alloy/actions/workflows/ci.yml/badge.svg?label=ci\" alt=\"CI\"></a>\n<a href=\"https://github.com/alloy-rs/op-alloy/blob/main/LICENSE-APACHE\"><img src=\"https://img.shields.io/badge/License-APACHE-d1d1f6.svg?label=license&labelColor=2a2f35\" alt=\"License\"></a>\n<a href=\"https://github.com/alloy-rs/op-alloy/blob/main/LICENSE-MIT\"><img src=\"https://img.shields.io/badge/License-MIT-d1d1f6.svg?label=license&labelColor=2a2f35\" alt=\"License\"></a>\n<a href=\"https://github.com/alloy-rs/op-alloy/blob/main/SNAPPY-LICENSE\"><img src=\"https://img.shields.io/badge/License-SNAPPY-d1d1f6.svg?label=license&labelColor=2a2f35\" alt=\"License\"></a>\n<a href=\"https://alloy-rs.github.io/op-alloy\"><img src=\"https://img.shields.io/badge/Book-854a15?logo=mdBook&labelColor=2a2f35\" alt=\"Book\"></a>\n\nBuilt on [Alloy][alloy], op-alloy aggregates the OP stack's unique primitives from [Maili][maili], \nto the subset of L1 types used by Optimistic rollups.\n\n\n## Usage\n\nThe following crates are provided by `op-alloy`:\n\n| Crate Name  | Description / Purpose                   | Version |\n|-------------|-----------------------------------------|---------|\n| [op-alloy-consensus](https://crates.io/crates/op-alloy-consensus) | Handles consensus-related logic         | [![version](https://img.shields.io/crates/v/op-alloy-consensus)](https://crates.io/crates/op-alloy-consensus) |\n| [op-alloy-network](https://crates.io/crates/op-alloy-network) | Manages networking functionality        | [![version](https://img.shields.io/crates/v/op-alloy-network)](https://crates.io/crates/op-alloy-network) |\n| [op-alloy-rpc-jsonrpsee](https://crates.io/crates/op-alloy-rpc-jsonrpsee) | RPC implementation using `jsonrpsee`    | [![version](https://img.shields.io/crates/v/op-alloy-rpc-jsonrpsee)](https://crates.io/crates/op-alloy-rpc-jsonrpsee) |\n| [op-alloy-rpc-types-engine](https://crates.io/crates/op-alloy-rpc-types-engine) | Type definitions specific to RPC engine | [![version](https://img.shields.io/crates/v/op-alloy-rpc-types-engine)](https://crates.io/crates/op-alloy-rpc-types-engine) |\n| [op-alloy-rpc-types](https://crates.io/crates/op-alloy-rpc-types) | Shared types used across RPC components | [![version](https://img.shields.io/crates/v/op-alloy-rpc-types)](https://crates.io/crates/op-alloy-rpc-types) |\n\n\n\n## Development Status\n\n`op-alloy` is currently in active development, and is not yet ready for use in production.\n\n\n## Supported Rust Versions (MSRV)\n\nThe current MSRV (minimum supported rust version) is 1.86.\n\nUnlike Alloy, op-alloy may use the latest stable release,\nto benefit from the latest features.\n\nThe MSRV is not increased automatically, and will be updated\nonly as part of a patch (pre-1.0) or minor (post-1.0) release.\n\n\n## Contributing\n\nop-alloy is built by open source contributors like you, thank you for improving the project!\n\nA [contributing guide][contributing] is available that sets guidelines for contributing.\n\nPull requests will not be merged unless CI passes, so please ensure that your contribution follows the\nlinting rules and passes clippy.\n\n\n## `no_std`\n\nop-alloy is intended to be `no_std` compatible, initially for use in [kona][kona].\n\nThe following crates support `no_std`.\nNotice, provider crates do not support `no_std` compatibility.\n\n\n| Crate Name                                               | Description / Purpose                   | Version |\n|----------------------------------------------------------|-----------------------------------------|---------|\n| [`op-alloy-consensus`]                 | Handles consensus-related logic         | [![version](https://img.shields.io/crates/v/op-alloy-consensus)](https://crates.io/crates/op-alloy-consensus) |\n| [`op-alloy-rpc-types`]                 | Shared types used across RPC components | [![version](https://img.shields.io/crates/v/op-alloy-rpc-types)](https://crates.io/crates/op-alloy-rpc-types) |\n| [`op-alloy-rpc-types-engine`]   | RPC types specific to the engine API    | [![version](https://img.shields.io/crates/v/op-alloy-rpc-types-engine)](https://crates.io/crates/op-alloy-rpc-types-engine) |\n\n\nIf you would like to add no_std support to a crate,\nplease make sure to update [scripts/check_no_std.sh][check-no-std].\n\n\n## Credits\n\nop-alloy is inspired by the work of several teams and projects, most notably [the Alloy project][alloy].\n\nThis would not be possible without the hard work from open source contributors. Thank you.\n\n\n## License\n\nLicensed under either of <a href=\"LICENSE-APACHE\">Apache License, Version\n2.0</a> or <a href=\"LICENSE-MIT\">MIT license</a> at your option.\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in these crates by you, as defined in the Apache-2.0 license,\nshall be dual licensed as above, without any additional terms or conditions.\n\n\n<!-- Hyperlinks -->\n\n[check-no-std]: ./scripts/check_no_std.sh\n\n[maili]: https://github.com/op-rs/maili\n[kona]: https://github.com/op-rs/kona\n[alloy]: https://github.com/alloy-rs/alloy\n[contributing]: https://alloy-rs.github.io/op-alloy\n\n[`op-alloy-consensus`]: https://crates.io/crates/op-alloy-consensus  \n[`op-alloy-network`]: https://crates.io/crates/op-alloy-network  \n[`op-alloy-rpc-jsonrpsee`]: https://crates.io/crates/op-alloy-rpc-jsonrpsee  \n[`op-alloy-rpc-types-engine`]: https://crates.io/crates/op-alloy-rpc-types-engine  \n[`op-alloy-rpc-types`]: https://crates.io/crates/op-alloy-rpc-types\n\n"
  },
  "runtimeverification/ercx-tests": {
    "fetchedAt": "2025-11-12T22:36:42.743Z",
    "content": "# ERCx Token Test Library\n\nERCx library is a reusable collection of Foundry tests for several ERC token standards. \nThe following tables summarize the number of tests in every category (for Light and Heavy versions of the test suites), for each ERC/EIP standard:\n\n#### Light \n\n| **ERC/EIP standard** | Standard | Security | Features | **Total** |\n| - | - | - | - | - |\n| **20** | 25 | 90 | 14 | **129** |\n| **721** | 141 | 38 | 21 | **200** |\n| **1155** | 37 | 14 | 10 | **61** |\n| **4626** | 40 | 44 | 32 | **116** |\n\n#### Heavy \n\n| **ERC/EIP standard** | Standard | Security | Features | **Total** | Remark |\n| - | - | - | - | - | - |\n| **20** | 21 | - | - | **21** | Full Heavy version for Standard only |\n| **721** | 143 | 36 | 21 | **200** | Semi-Heavy version as fixed dummy user addresses are still used |\n| **1155** | - | - | - | **-** |  |\n| **4626** | 41 | 44 | 106 | **187** | Light version + more tests on Features level |\n\n#### Brief descriptions of each test set are as follows: \n\n**Standard:** contains tests that check properties extracted from the standard, which include properties that contain the key words *MUST* and *SHOULD* and, more generally, properties that can be extracted from the respective EIP specification.\n\n**Security:** contains security properties, including desirable properties for the sane functioning of the token and properties of add-on functions commonly created and used by developers.\n\n**Features:** contains tests that check properties which reflect implementation choices, rather than correctness or incorrectness.\n\n#### Additional information about the test suites:\n\n- A test is skipped if its result is inconclusive as certain conditions are not met while testing the said property test. \nSome reasons for a test to be skipped include to setup issues, such as not failure to deal tokens to dummy users beforehand, or failing to invoke prerequisite functions before checking a property ‚Äî particularly when large input values are involved.\nNote that skipped tests from non-ABI levels are still important property tests that a token should satisfy.  Please exercise caution when interpreting the results for these tests.\n\n- For each standard, there are two versions, \"Light\" and \"Heavy\", of the test suites which you can run. \nThe \"Light\" version runs with fixed dummy user addresses, i.e., the set of users, `alice`, `bob`, and `carol`, is fixed and used for all tests in each test suite. On the other hand, the \"Heavy\" version involves fuzzed user addresses, i.e., the addresses of users `alice`, `bob`, and `carol` change.\n  > **NOTE:** Currently, the repository only has the \"HEAVY\" version for the ERC20 test suite, and it only contains MANDATORY checks. If not indicated, it is assumed that the \"Light\" version of the test suite is used. \n\n- The ERC4626 test suite contains several tests that use the phrase \"up to `delta`-approximation\" in their descriptions. These tests involve calling functions such as `deposit`, `withdraw`, etc., where conversion of shares to assets, and vice-versa, take place.\nAs all math operations in Solidity use integer arithmetic, rounding errors may occur and cause vulnerabilities if the contract does not follow the rounding rules outlined in [EIP-4626](https://eips.ethereum.org/EIPS/eip-4626).\nIn the test suite, we use a global `uint256` variable `delta` in the test that for the user to define a desired leeway for such rounding errors.\nThe value of `delta` represents the maximum approximation error size (an absolute value given in the smallest unit such as Wei) whenever the assertion check is performed.\nFor example, `x - y <= delta` is being checked whenever there is a check for `x == y`. It is important to note that `delta` should only be set to a reasonably small value so that the adversarial profit of exploiting such rounding errors stays relatively small compared to the gas cost. The default value of `delta` is set to 0 as all tests are supposed to pass demonstrating that no rounding issues occur if the contract follows the required rounding rules.\n\n## Table of Contents\n\n* [Installation](#installation)\n* [Usage](#usage)\n    * [Do I need to set up anything before running the ERCx tests?](#do-i-need-to-set-up-anything-before-running-the-ERCx-tests)\n    * [I have a token-address. How can I run the ERCx tests on it?](#i-have-a-token-address-how-can-i-run-the-ERCx-tests-on-it)\n    * [How can I run the ERCx tests on my source code?](#how-can-i-run-the-tests-on-my-source-code)\n* [FAQ](#faq)\n    * [Why do I need an RPC-endpoint?](#why-do-i-need-an-rpc-endpoint)\n    * [What are golden tests?](#what-are-golden-tests)\n\n## Installation\n\nThe ERCx token library requires [Foundry](https://book.getfoundry.sh/getting-started/installation).\nIf you have Foundry installed, you can install the library by running the following command:\n\n~~~sh\nforge install runtimeverification/ercx-tests\n~~~\n\n## Usage\n\nThis section assumes that you already have Foundry and ERCx library installed. There are two ways to execute the test suite.\n\n1. Post-deployment: Run the test suite on any ERC token for which you have the deployment address.\n2. Pre-deployment: Run the test suite on the Solidity source code of an ERC token.\n\n### Do I need to set up anything before running the ERCx tests?\n\nDepending on the test suite you wish to run, there might be some setting up to do before running it, as described below.\n\n#### ERC20 test suite (Optional)\n\nThe test suite will try to deal tokens to dummy users before running the tests. \nIt does so by reading and rewriting the storage slot of functions/variables such as `totalSupply()`\nand `balanceOf(user)`.\nFor most contracts, this should not pose an issue, however, there are some (e.g., deployed contracts such as USDC, stETH) \nthat will cause issues while retrieving and reading these storage slots.\nAs a result, some of the tests may fail due to errors such as `stdStorage find(StdStorage): Slot(s) not found.`.\nWe have set up the ERC20 test suite such that we can resolve this issue by, first, assigning a top token holder, \nfollowed by using this account to transfer some tokens to the dummy users for testing. \n\nThus, if you wish to address all failures caused by the to `stdStorage` issue, here is what you need to do:\n\n1. Retrieve the top token holder (or some account that holds tokens) of the contract that you want to test.\n    > You can retrieve it under the \"Holders\" tab of the contract's [Etherscan](https://etherscan.io/) token page or by calling some API endpoint such as the one provided by [Chainbase](https://docs.chainbase.com/reference/gettoptokenholders).\n\n2. Assign the `address` variable `topTokenHolder` in line 111 of `src/ERCAbstract.sol` to the address that you have retrieved, \ne.g., `address topTokenHolder = 0x...;`.\n\nNow the test suite is ready to be run and the `stdStorage` issue will be resolved.\n\n**NOTE:** The above instructions are optional as it is not needed if \n(a) you are running the test suite on the source code of the contract, or\n(b) you did not encounter any `stdStorage` issue during your run of the test suite.\n\n#### ERC4626 test suite (Optional)\n\nSimilar to the ERC20 test suite, the ERC4626 test suite deals assets, shares, or both to dummy users before running the tests.\nAs a result, you may encounter the same `stdStorage` issue when running the ERC4626 test suite.\n\nThus, you can address this issue similarly to the ERC20 test suite. Here is what you can do:\n\n1. Retrieve the `asset` address of the ERC4626 contract that you are working with.\n    > You can retrieve it by calling an query on the `asset()` function through the contract's [Etherscan](https://etherscan.io/) token page \n    or some API endpoint.\n\n2. Retrieve the top **asset** holder (or some account that holds assets) of the asset contract that you retrieved in the previous step.\n    > You can retrieve it under the \"Holders\" tab of the asset contract's [Etherscan](https://etherscan.io/) token page or by calling some API endpoint such as the \n\n[... truncated ...]"
  },
  "EnsoBuild/sdk-ts": {
    "fetchedAt": "2025-11-12T22:36:52.743Z",
    "content": "<div align=\"center\">\n\n[![NPM Version](https://img.shields.io/npm/v/%40ensofinance%2Fsdk)](https://www.npmjs.com/package/@ensofinance/sdk)\n[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/EnsoBuild)](https://x.com/EnsoBuild)\n\n</div>\n\n# Enso SDK\n\nThe Enso SDK provides a set of tools and methods to interact with the Enso shortcuts. It includes functionalities for automated swap routing, multichain routing, token approvals, quoting, and balance checking.\n\n## Introduction\n\nThe Enso API offers two powerful routing components:\n\n1. **Route API**: Finds the optimal execution path across multiple DeFi protocols including liquidity pools, lending platforms, automated market makers, yield optimizers, and more. It automatically determines the best path between two tokens or positions.\n\n2. **Bundle API**: Enables building custom route creators for complex multi-step DeFi operations by composing sequences of actions. This is perfect for advanced use cases like yield farming, leveraged positions, and portfolio rebalancing.\n\n## Installation\n\n```bash\nnpm install @ensofinance/sdk\n```\n\nor\n\n```bash\nyarn add @ensofinance/sdk\n```\n\n## Quick Start\n\n```typescript\nimport { EnsoClient } from \"@ensofinance/sdk\";\n\n// Initialize the client with your API key\nconst ensoClient = new EnsoClient({\n  apiKey: \"YOUR_API_KEY\",\n});\n\n// Get the best route from one token to another\nconst routeData = await ensoClient.getRouteData({\n  fromAddress: \"0xYourAddress\",\n  chainId: 1,\n  amountIn: [\"1000000000000000000\"],\n  tokenIn: [\"0xTokenInAddress\"],\n  tokenOut: [\"0xTokenOutAddress\"],\n  routingStrategy: \"router\",\n});\n\n// Execute the transaction with your web3 provider\n// const tx = await web3.eth.sendTransaction(routeData.tx);\n```\n\n## Routing Strategies\n\nThere are 3 routing strategies available depending on your use case:\n\n- `router` - Uses a single contract which acts as a universal router\n- `delegate` - Returns calldata in the form of delegateCalls for smart accounts\n- `ensowallet` - Returns calldata for deploying an Enso smart account, and executing all the logic inside of the smart account in the same transaction\n\n## Core Features\n\n### Token Approvals\n\nGet approval data to allow token spending when using `router` as `routingStrategy` (not needed when using `delegate`):\n\n```typescript\n// Example: Approving USDC for spending\nconst approvalData = await ensoClient.getApprovalData({\n  fromAddress: \"0xYourAddress\",\n  tokenAddress: \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\", // USDC\n  chainId: 1,\n  amount: \"1000000000\", // 1000 USDC (6 decimals)\n  routingStrategy: \"router\",\n});\n```\n\n### Automated Routing\n\nGet the optimal execution data for a route between tokens:\n\n```typescript\nconst routeData = await ensoClient.getRouteData({\n  fromAddress: \"0xYourAddress\",\n  receiver: \"0xReceiverAddress\", // Optional, defaults to fromAddress\n  chainId: 1,\n  amountIn: [\"1000000000000000000\"],\n  tokenIn: [\"0xTokenInAddress\"],\n  tokenOut: [\"0xTokenOutAddress\"],\n  slippage: \"50\", // 0.5%\n  routingStrategy: \"router\",\n});\n```\n\n### Wallet Balances\n\nGet token balances for a wallet:\n\n```typescript\n// Example: Get all token balances for an Ethereum address\nconst balances = await ensoClient.getBalances({\n  eoaAddress: \"0xYourAddress\",\n  chainId: 1, // Ethereum mainnet\n  useEoa: true, // Default is true - get balances for the EOA, not the Enso wallet\n});\n```\n\n### Bundled Transactions\n\nBundle multiple DeFi actions into a single transaction and use results between transactions.\n\n```typescript\n// Example: Convert ETH to USDC then deposit into Aave V3\nconst bundleData = await ensoClient.getBundleData(\n  {\n    fromAddress: \"0xYourAddress\",\n    chainId: 1,\n    routingStrategy: \"router\",\n  },\n  [\n    {\n      protocol: \"enso\",\n      action: \"route\",\n      args: {\n        tokenIn: \"0xeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\", // ETH\n        tokenOut: \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\", // USDC\n        amountIn: \"1000000000000000000\", // 1 ETH\n        slippage: \"100\", // 1%\n      },\n    },\n    {\n      protocol: \"aave-v3\",\n      action: \"deposit\",\n      args: {\n        tokenIn: \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\", // USDC\n        tokenOut: \"0xbcca60bb61934080951369a648fb03df4f96263c\", // aUSDC v3\n        amountIn: {\n          useOutputOfCallAt: 0, // Use output from the first action\n        },\n        primaryAddress: \"0x87870Bca3F3fD6335C3F4ce8392D69350B4fA4E2\", // Aave V3 pool\n      },\n    },\n  ],\n);\n```\n\n### Bridging Pool Address\n\nUse `getLayerZeroPool` to get the correct pool information, and use it as `primaryAddress` for the [`bridge` action](https://docs.enso.build/pages/build/reference/actions#bridge).\n\n```ts\nconst poolInfo = await client.getLayerZeroPool({\n  chainId: 42161, // Arbitrum\n  destinationChainId: 999, // Zora  \n  token: '0xFd086bC7CD5C481DCC9C85ebE478A1C0b69FCbb9' // USDT\n});\n```\n\n### Non-Tokenized Positions\n\nRoute to a non-tokenized position:\n\n```typescript\n// Example: Routing to a Morpho Blue USDC vault position\nconst nonTokenizedRoute = await ensoClient.getRouteNonTokenized({\n  fromAddress: \"0xYourAddress\",\n  chainId: 1,\n  tokenIn: [\"0xeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\"], // ETH\n  positionOut: \"0xBEeFFF209270748ddd194831b3fa287a5386f5bC\", // Morpho USDC vault\n  amountIn: [\"1000000000000000000\"], // 1 ETH\n  receiver: \"0xYourAddress\",\n  slippage: \"300\", // 3%\n  routingStrategy: \"delegate\",\n});\n```\n\n\n### Token Data\n\nGet paginated information about tokens:\n\n```typescript\n// Example: Get details about wstETH including metadata\nconst tokenData = await ensoClient.getTokenData({\n  chainId: 1,\n  address: \"0x7f39c581f595b53c5cb19bd0b3f8da6c935e2ca0\", // wstETH\n  includeMetadata: true,\n  type: \"defi\", // Filter by token type - can be \"defi\" or \"base\"\n});\n```\n\n### Token Pricing\n\nGet token price data:\n\n```typescript\n// Example: Get current price of WETH\nconst priceData = await ensoClient.getPriceData({\n  chainId: 1,\n  address: \"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\", // WETH\n});\n\n// Example: Get prices for multiple tokens\nconst multiPriceData = await ensoClient.getMultiplePriceData({\n  chainId: 1,\n  addresses: [\n    \"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\", // WETH\n    \"0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48\", // USDC\n  ],\n});\n```\n\n### Protocol Support\n\nGet information about supported protocols:\n\n```typescript\n// Get all protocols\nconst protocols = await ensoClient.getProtocolData();\n\n// Get protocols for a specific chain\nconst ethereumProtocols = await ensoClient.getProtocolData({ chainId: 1 });\n\n// Get a specific protocol\nconst aaveProtocol = await ensoClient.getProtocolData({ slug: \"aave-v3\" });\n```\n\n## Handling Large Numbers\n\nThe SDK properly handles large numbers common in blockchain transactions:\n\n```typescript\n// Using string representation for large numbers (recommended)\nconst largeAmount = \"1000000000000000000000000\"; // 1 million tokens with 18 decimals\n\n// You can also use JavaScript numbers for smaller values\nconst smallAmount = 1000000; // 1 USDC with 6 decimals\n```\n\n## Supported Actions\n\nThe Bundle API supports a variety of [actions for interacting with DeFi protocols](https://docs.enso.build/pages/build/reference/actions).\n\nFor an up-to-date reference of all available actions and their parameters, you can call:\n\n```typescript\n// Get all available actions\nconst actions = await ensoClient.getActions();\n\n// Get actions for a specific protocol\nconst aaveActions = await ensoClient.getActionsBySlug(\"aave-v3\");\n```\n\n## Supported Networks\n\nTo get information about [supported networks](https://docs.enso.build/pages/build/reference/supported-networks):\n\n```typescript\n// Get all supported networks\nconst networks = await ensoClient.getNetworks();\n\n// Get a specific network\nconst ethereumNetwork = await ensoClient.getNetworks({\n  chainId: \"1\",\n  name: \"Ethereum\",\n});\n```\n\n## API Reference\n\nFor detailed information about all available methods and parameters, see our [API Reference Documentation](https://docs.enso.build/pages/api-reference/overview).\n\n### Main Client\n\n[... truncated ...]"
  },
  "EnsoBuild/shortcuts-widget": {
    "fetchedAt": "2025-11-12T22:36:53.092Z",
    "content": "<div align=\"center\">\n\n# Cross-chain Shortcuts Widget\n\n[![NPM Version](https://img.shields.io/npm/v/%40ensofinance%2Fshortcuts-widget)](https://www.npmjs.com/package/%40ensofinance%2Fshortcuts-widget)\n[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/EnsoBuild)](https://twitter.com/EnsoBuild)\n\n</div>\n\n## Overview\n\nThe Enso Shortcuts Widget is a React component that provides a seamless interface for cross-chain DeFi operations. Powered by the Enso API, it enables users to perform complex DeFi actions through a simple, intuitive UI without leaving your application.\n\n## Features\n\n- **Token Swaps** - Swap any token to any other token across supported chains\n- **Cross-chain Bridging** - Bridge tokens between different blockchain networks\n- **DeFi Protocol Integration** - Deposit to and withdraw from various DeFi protocols\n- **Zap-in Operations** - Enter complex DeFi positions in a single transaction\n- **Token Information** - Display comprehensive token details including balance and USD value\n- **Slippage Controls** - Set and manage slippage tolerance for transactions\n- **DeFi Composition** - Execute multiple DeFi operations in a single transaction using Enso API\n\n## Installation\n\nTo install the widget in your project:\n\n```bash\nnpm install @ensofinance/shortcuts-widget\n```\n\n> **Note:** This package requires `wagmi` and `viem` as peer dependencies. Please ensure these are installed in your project.\n\n## Getting Started\n\n### API Key\n\nTo use the widget, you'll need an Enso API key. Visit [https://developers.enso.build](https://developers.enso.build) to get your API key.\n\n### Basic Implementation\n\n```tsx\nimport React from \"react\";\nimport SwapWidget from \"@ensofinance/shortcuts-widget\";\n\nconst App = () => {\n    return (\n        <div className=\"app-container\">\n            <SwapWidget\n                apiKey=\"YOUR_API_KEY\"\n                // Optional configuration\n                enableShare={true}\n                adaptive={true}\n            />\n        </div>\n    );\n};\n\nexport default App;\n```\n\n### Advanced Implementation\n\n```tsx\nimport React, { useState } from \"react\";\nimport SwapWidget from \"@ensofinance/shortcuts-widget\";\n\nconst App = () => {\n    const [selectedTokens, setSelectedTokens] = useState(null);\n\n    const handleChange = (data) => {\n        setSelectedTokens(data);\n        console.log(\"Widget selection changed:\", data);\n    };\n\n    return (\n        <div className=\"app-container\">\n            <SwapWidget\n                apiKey=\"YOUR_API_KEY\"\n                tokenIn=\"0x1234...\" // Specify input token address\n                chainId={1} // Ethereum mainnet\n                tokenOut=\"0xabcd...\" // Specify output token address\n                outChainId={137} // Polygon\n                onChange={handleChange}\n                enableShare={true}\n                indicateRoute={true}\n            />\n        </div>\n    );\n};\n\nexport default App;\n```\n\n## Configuration\n\n### Props\n\nThe `SwapWidget` component accepts the following props:\n\n#### Required\n\n- `apiKey` (string): Enso API key\n\n#### Token Selection\n\n- `tokenIn` (string): Token address for the input token\n- `tokenOut` (string): Token address for the output token\n- `chainId` (number): Chain ID for the input token's blockchain network\n- `outChainId` (number): Chain ID for the output token's blockchain network\n- `outProject` (string): Limit output token selection to a specific project\n- `outProjects` (object): Object containing projects to limit input projects options\n- `inProjects` (object): Object containing projects to limit input projects options\n- `outTokens` (object): Object containing tokens to limit output token options\n- `inTokens` (object): Object containing tokens to limit input token options\n- `referralCode` (string): 16 bytes string that enables onchain request tracking\n\n#### UI Configuration\n\n- `themeConfig` (SystemConfig): Customize the widget's appearance\n- `enableShare` (boolean): Enable route sharing functionality (copy with button)\n- `obligateSelection` (boolean): Force users to select tokens\n- `rotateObligated` (boolean | 0 | 1): Display arrow to rotate obligated token selection\n- `indicateRoute` (boolean): Show routing information in the UI\n- `adaptive` (boolean): Enable adaptive UI behavior based on container size\n- `notificationPlacement` (string): Control the placement of notification toasts\n\n#### Event Handlers\n\n- `onChange` (function): Callback triggered when token selections or route change\n- `onSuccess` (function): Callback called with amount argument once user perfoms swap action\n\n## Customization\n\nThe widget can be customized using the `themeConfig` prop which accepts a `SystemConfig` object from Chakra UI. This allows you to match the widget's appearance to your application's design system.\n\n## License\n\nThis project is licensed under the MIT License. See the `LICENSE` file for more details.\n\n## Contributing\n\nContributions are welcome! Please open an issue or submit a pull request on GitHub.\n\n## Support\n\nFor any questions or support, please contact the Enso Finance team:\n\n- [Telegram](https://t.me/Enso_shortcuts)\n- [Twitter](https://twitter.com/EnsoBuild)\n- [Website](https://enso.finance)\n"
  },
  "EnsoBuild/shortcuts-client-contracts": {
    "fetchedAt": "2025-11-12T22:36:53.538Z",
    "content": "# Enso Shortcuts Client Contracts\n\nClient contracts for running Enso Shortcuts.\n\n## Install\n\nRequires [Foundry](https://getfoundry.sh/).\n\n```bash\n$ forge install\n$ pnpm install\n$ pnpm foundry:update\n$ forge build\n```\n\n---\n\n## Tests\n\n```bash\n$ forge test\n```\n\n### Unit & Integration Testing - Write BTTs with Bulloak\n\n_Bulloak_ is a Solidity test generator based on the **Branching Tree Technique\n(BTT)**. See the [Bulloak repo](https://github.com/alexfertel/bulloak) for full\ndocumentation, examples, and advanced usage.\n\n#### **Requirements**\n\n- [Bulloak](https://github.com/alexfertel/bulloak) (install with\n  `cargo install bulloak`)\n- (Optional)\n  [VSCode Ascii Tree Generator extension](https://marketplace.visualstudio.com/items?itemName=aprilandjan.ascii-tree-generator)\n  for easier tree editing\n\n#### **How to Write and Scaffold BTT Trees**\n\n1. **Create a Tree File**\n\n   Create a `<ContractName>.tree` file (e.g., `ERC4337CloneFactory.tree`). Each\n   tree describes the branching logic of a function or contract using ASCII art.\n\n   **Example:**\n\n   ```\n   ERC4337CloneFactory_DelegateDeploy\n   # when EnsoReceiver does not exist\n   ## it should emit CloneDeployed event\n   ## it should deploy clone\n   ## it should initialize clone\n   # when EnsoReceiver already exists\n   ## it should revert\n   ```\n\n2. **Convert to Tree Structure**\n\n   Use ASCII tree tools or an LLM to convert your outline to a tree with `‚îú`,\n   `‚îî`, and `‚îÇ` characters. You can group multiple trees in a single file, but\n   only one can be scaffolded at a time (comment out others).\n\n   **Example:**\n\n   ```tree\n   // ERC4337CloneFactory_Deploy\n   // ‚îú‚îÄ‚îÄ when EnsoReceiver does not exist\n   // ‚îÇ   ‚îú‚îÄ‚îÄ it should emit CloneDeployed event\n   // ‚îÇ   ‚îú‚îÄ‚îÄ it should deploy clone\n   // ‚îÇ   ‚îî‚îÄ‚îÄ it should initialize clone\n   // ‚îî‚îÄ‚îÄ when EnsoReceiver already exists\n   //     ‚îî‚îÄ‚îÄ it should revert\n\n   ERC4337CloneFactory_DelegateDeploy\n   ‚îú‚îÄ‚îÄ when EnsoReceiver does not exist\n   ‚îÇ   ‚îú‚îÄ‚îÄ it should emit CloneDeployed event\n   ‚îÇ   ‚îú‚îÄ‚îÄ it should deploy clone\n   ‚îÇ   ‚îî‚îÄ‚îÄ it should initialize clone\n   ‚îî‚îÄ‚îÄ when EnsoReceiver already exists\n       ‚îî‚îÄ‚îÄ it should revert\n   ```\n\n3. **Scaffold the Solidity Test**\n\n   Run:\n\n   ```sh\n   bulloak scaffold path/to/YourContract.tree\n   ```\n\n   This generates a `.t.sol` test file with the contract and test stubs.\n\n4. **Review and Finalize**\n   - Set the correct SPDX license and pragma.\n   - Add necessary imports.\n   - Update the contract name and inheritance as needed.\n   - **Naming pattern suggestion:**\n     `<ContractName>_<Method>[_When<Condition>][_As<Role>][_Unit|Int|Fork][_Concrete|Fuzz]_Test`\n\n### Mutation Testing\n\nMutation testing helps you measure the effectiveness of your test suite by\nintroducing small changes (\"mutants\") to your code and checking if your tests\ncatch them.\n\n#### **Requirements**\n\n- [Certora Gambit](https://github.com/Certora/gambit) (for mutation generation)\n- Node.js (for running the mutation test script)\n- A working `gambit.config.json` (see below)\n\n#### **Setup**\n\n1. **Create or update your Gambit config**\n\n   Make sure you have a `gambit.config.json` in your project root. See\n   [Certora Gambit docs](https://github.com/Certora/gambit) for config options.\n\n2. **Generate Mutations**\n\n   ```sh\n   gambit mutate --json gambit.config.json\n   ```\n\n   This will create mutated versions of your contracts in `gambit_out/mutants/`.\n\n3. **Run Mutation Tests**\n\n   You can run mutation tests using the provided script:\n\n   ```sh\n   node ./mutationTest.mjs --matchContract 'EnsoReceiver_.*_Unit_Concrete_Test'\n   ```\n\n   - Use the `--matchContract` flag with a regex to select which test contracts\n     to run against each mutant.\n   - You can also use `--matchMutant` to filter which mutants to test (by\n     contract name or pattern).\n\n   **Example:**\n\n   ```sh\n   node ./mutationTest.mjs --matchContract 'EnsoReceiver_.*_Unit_Concrete_Test' --matchMutant EnsoReceiver\n   ```\n\n   This will run all test contracts matching the pattern against all mutants of\n   `EnsoReceiver`.\n\n   > **Tip:** You can use more complex regexes to match multiple contracts, e.g.\n   > `--matchContract 'EnsoReceiver_.*_(Unit|Fork)_Concrete_Test'`\n\n4. **(Optional) Automate with a Script**\n\n   For more complex or repeated runs, you can create a JS script in `scripts/`,\n   e.g.\n   [`scripts/runEnsoCheckoutMutationTests.mjs`](./scripts/runEnsoCheckoutMutationTests.mjs).\n\n#### **Script Options and Advanced Usage**\n\nThe `mutationTest.mjs` script is based on\n[ibourn/gambit-mutation-testing](https://github.com/ibourn/gambit-mutation-testing?tab=readme-ov-file#script-options-to-refine-test-execution).\n**For a full list of available options and advanced usage, see the\n[original script documentation](https://github.com/ibourn/gambit-mutation-testing?tab=readme-ov-file#script-options-to-refine-test-execution).**\n\nSome useful options include:\n\n- `--matchContract \"<pattern>\"` ‚Äì Only run tests for contracts matching the\n  regex.\n- `--noMatchContract \"<pattern>\"` ‚Äì Exclude contracts matching the regex.\n- `--matchTest \"<pattern>\"` ‚Äì Only run test functions matching the regex.\n- `--noMatchTest \"<pattern>\"` ‚Äì Exclude test functions matching the regex.\n- `--matchMutant \"<pattern>\"` ‚Äì Only test mutants for source files matching the\n  pattern.\n- `--verbose true` ‚Äì Show detailed output in the console.\n- `--debug true` ‚Äì Save detailed logs to the `testLogs` folder.\n\n#### **How It Works**\n\n- The script will:\n  - Backup the original contract file (in `src/`)\n  - Replace it with each mutant, one at a time\n  - Run your Foundry tests with the specified contract filter\n  - Restore the original file after each mutant\n  - Log results and mutation score\n\n#### **Best Practices & Troubleshooting**\n\n- **Do not stage or commit mutated files during or after an interrupted test\n  run**. Always ensure the original contract files are restored before\n  committing.\n- **Always use a regex for `--matchContract`** if you want to match multiple\n  contracts. Example: `--matchContract 'EnsoReceiver_.*_Unit_Concrete_Test'`\n- **Do not stage or commit files in `gambit_out/` or `tempBackup/`**‚Äîthese are\n  generated and temporary.\n- If you see errors about missing files (e.g.,\n  `ENOENT: no such file or directory, lstat 'delegate/EnsoReceiver.sol'`), make\n  sure your source files are in `src/` and the script is up to date (see\n  [#Path Issues](#path-issues) below).\n- **Check your test coverage**: Surviving mutants indicate untested or weakly\n  tested code paths.\n- If you reorganize or rename your contracts, ensure the mutation config and\n  script is updated accordingly.\n\n---\n\n**For more details and advanced script options, see the\n[gambit-mutation-testing script documentation](https://github.com/ibourn/gambit-mutation-testing?tab=readme-ov-file#script-options-to-refine-test-execution).**\n\n## Deployment\n\nCopy `.env.example` to `.env`, fill out required values.\n\n```bash\n$ forge script Deployer --broadcast --fork-url <network>\n```\n\n---\n\n## Verification\n\nExample of how manually verifying a contract with constructor args after\ndeployment:\n\n```sh\nforge verify-contract \\\n--watch \\\n--chain polygon \\\n0xDb5b96dC4CE3E0E44d30279583F926363eFaE29f \\\nsrc/helpers/FeeSplitter.sol:FeeSplitter \\\n--verifier etherscan \\\n--etherscan-api-key <string:etherscan-api-key> \\\n--constructor-args $(cast abi-encode \"constructor(address,address[],uint16[])\" \"0x6AA68C46eD86161eB318b1396F7b79E386e88676\" \"[0xBfC330020E3267Cea008718f1712f1dA7F0d32A9,0x6AA68C46eD86161eB318b1396F7b79E386e88676]\" \"[1,1]\")\n```\n"
  },
  "EnsoBuild/Uniswap-migrator": {
    "fetchedAt": "2025-11-12T22:36:53.911Z",
    "content": "<div align=\"center\">\n\n[![NPM Version](https://img.shields.io/npm/v/%40ensofinance%2Funiswap-migrator)](https://www.npmjs.com/package/%40ensofinance%2Funiswap-migrator)\n[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/EnsoBuild)](https://twitter.com/EnsoBuild)\n\n</div>\n\n# Uniswap Migrator\n\nThe Uniswap Migrator is a tool that helps users easily migrate their existing Uniswap v3 position or deposit any token into Uniswap v4 pool. This widget provides a seamless experience for users to transfer their liquidity between different Uniswap versions while maintaining control over their positions.\n\n## Workspace Structure\n\n- `app/`: Main application that uses the widget\n- `widget/`: Reusable Uniswap migrator widget\n\n## Installation\n\nTo install the widget in your project using npm:\n\n```bash\nnpm install @ensofinance/uniswap-migrator\n```\n\n## Usage\n\nGet your key at [Enso Dashboard](https://developers.enso.build)\n\nHere's a basic example of how to use the widget in your React application:\n\n```jsx\nimport { WidgetWrapper } from \"@ensofinance/uniswap-migrator\";\n\n/*\n * for next Next.js projects we need to use dynamic import instead\nimport dynamic from \"next/dynamic\";\nconst WidgetWrapper= dynamic(() => import(\"@ensofinance/uniswap-migrator\").then(mod => mod.WidgetWrapper), {\n    ssr: false,\n}); \n*/\n\nfunction App() {\n  return (\n    <div>\n      <h1>My DeFi App</h1>\n      <WidgetWrapper apiKey=\"YOUR_ENSO_API_KEY\" />\n    </div>\n  );\n}\n\nexport default App;\n```\n\n### Advanced Configuration\n\nYou can customize the widget behavior with additional props:\n\n```jsx\nimport { WidgetWrapper } from \"@ensofinance/uniswap-migrator\";\n\nfunction App() {\n  return (\n    <div>\n      <h1>My DeFi App</h1>\n      <WidgetWrapper\n        apiKey=\"YOUR_ENSO_API_KEY\"\n        outTokens={[\n          \"0xeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\", // Native token (ETH)\n          \"0x0b2c639c533813f4aa9d7837caf62653d097ff85\", // Example token address\n        ]}\n        poolFeeGrade={500}\n        outChainId={10} // Optimism\n        ticks={[-200050, -195990]}\n      />\n    </div>\n  );\n}\n\nexport default App;\n```\n\n## Configuration Options\n\n| Property       | Type       | Description                                |\n| -------------- | ---------- | ------------------------------------------ |\n| `apiKey`       | `string`   | Your Enso API key (required)               |\n| `outTokens`    | `string[]` | Array of token addresses to use for output |\n| `poolFeeGrade` | `number`   | Fee tier for the pool (e.g., 500 = 0.05%)  |\n| `outChainId`   | `number`   | Target chain ID for migration              |\n| `ticks`        | `number[]` | Price tick range for the position          |\n\n## Development\n\n- To work on the widget: `pnpm --filter widget build --watch`\n- To run the app: `pnpm dev`\n"
  },
  "peterferguson/react-native-passkeys": {
    "fetchedAt": "2025-11-12T22:37:02.400Z",
    "content": "# React Native Passkeys\n\nThis is an Expo module to help you create and authenticate with passkeys on iOS, Android & web with the same api. The library aims to stay close to the standard [`navigator.credentials`](https://w3c.github.io/webappsec-credential-management/#framework-credential-management). More specifically, we provide an api for `get` & `create` functions (since these are the functions available cross-platform).\n\nThe adaptations we make are simple niceties like providing automatic conversion of base64-url encoded strings to buffer. This is also done to make it easier to pass the values to the native side.\n\nFurther niceties include some flag functions that indicate support for certain features.\n\n## Installation\n\n```sh\nnpx expo install react-native-passkeys\n```\n\n## iOS Setup\n\n#### 1. Host an Apple App Site Association (AASA) file\n\nFor Passkeys to work on iOS, you'll need to host an AASA file on your domain. This file is used to verify that your app is allowed to handle the domain you are trying to authenticate with. This must be hosted on a site with a valid SSL certificate.\n\nThe file should be hosted at:\n\n```\nhttps://<your_domain>/.well-known/apple-app-site-association\n```\n\nNote there is no `.json` extension for this file but the format is json. The contents of the file should look something like this:\n\n```json\n{\n  \"webcredentials\": {\n    \"apps\": [\"<teamID>.<bundleID>\"]\n  }\n}\n```\n\nReplace `<teamID>` with your Apple Team ID and `<bundleID>` with your app's bundle identifier.\n\n#### 2. Add Associated Domains\n\nAdd the following to your `app.json`:\n\n```json\n{\n  \"expo\": {\n    \"ios\": {\n      \"associatedDomains\": [\"webcredentials:<your_domain>\"]\n    }\n  }\n}\n```\n\nReplace `<your_domain>` with the domain you are hosting the AASA file on. For example, if you are hosting the AASA file on `https://example.com/.well-known/apple-app-site-association`, you would add `example.com` to the `associatedDomains` array.\n\n#### 3. Add minimum deployment target\n\nAdd the following to your `app.json`:\n\n```json\n{\n  \"expo\": {\n    \"plugins\": [\n      [\n        \"expo-build-properties\",\n        {\n          \"ios\": {\n            \"deploymentTarget\": \"15.0\"\n          }\n        }\n      ]\n    ]\n  }\n}\n```\n\n#### 4. Prebuild and run your app\n\n```sh\nnpx expo prebuild -p ios\nnpx expo run:ios # or build in the cloud with EAS\n```\n\n## Android Setup\n\n#### 1. Host an `assetlinks.json` File\n\nFor Passkeys to work on Android, you'll need to host an `assetlinks.json` file on your domain. This file is used to verify that your app is allowed to handle the domain you are trying to authenticate with. This must be hosted on a site with a valid SSL certificate.\n\nThe file should be hosted at:\n\n```\nhttps://<your_domain>/.well-known/assetlinks.json\n```\n\nand should look something like this (you can generate this file using the [Android Asset Links Assistant](https://developers.google.com/digital-asset-links/tools/generator)):\n\n```json\n[\n  {\n    \"relation\": [\"delegate_permission/common.handle_all_urls\"],\n    \"target\": {\n      \"namespace\": \"android_app\",\n      \"package_name\": \"<package_name>\",\n      \"sha256_cert_fingerprints\": [\"<sha256_cert_fingerprint>\"]\n    }\n  }\n]\n```\n\nReplace `<package_name>` with your app's package name and `<sha256_cert_fingerprint>` with your app's SHA256 certificate fingerprint.\n\n#### 2. Modify Expo Build Properties\n\nNext, you'll need to modify the `compileSdkVersion` in your `app.json` to be at least 34.\n\n```json\n{\n  \"expo\": {\n    \"plugins\": [\n      [\n        \"expo-build-properties\",\n        {\n          \"android\": {\n            \"compileSdkVersion\": 34\n          }\n        }\n      ]\n    ]\n  }\n}\n```\n\n#### 3. Prebuild and run your app\n\n```sh\nnpx expo prebuild -p android\nnpx expo run:android # or build in the cloud with EAS\n```\n"
  },
  "RevokeCash/revoke.cash": {
    "fetchedAt": "2025-11-12T22:37:11.336Z",
    "content": "<p align=\"center\">\n  <img width=\"400\" src=\"public/assets/images/revoke-wordmark-black.svg\">\n</p>\n\n> _Do you want to swap 10 DAI for ETH? Sure thing, we'll just need your approval to spend a BAJILLION DOLLARS!_\n\nDo you ever feel worried about the different apps that have access to the tokens in your wallet? [revoke.cash](https://revoke.cash) allows you to inspect all the contracts you've approved to spend money on your behalf, and revoke their access for the ones you no longer need. If you don't want to completely revoke access, it's also possible to update the amount they are allowed to spend instead.\n\nIf you want to learn more about (unlimited) token approvals, I wrote an article on my blog: [Unlimited ERC20 allowances considered harmful](https://kalis.me/unlimited-erc20-allowances/).\n\n## Running locally\n\n```\ngit clone git@github.com:RevokeCash/revoke.cash.git\ncd revoke.cash\nyarn\nyarn dev\n```\n\n### Environment variables\n\nAn `.example.env` file is provided that needs to be copied into a `.env` file and filled out.\n\nSome of these variables are integral to the functioning of Revoke.cash:\n\n- `NEXT_PUBLIC_INFURA_API_KEY` is used for reading data from Ethereum + Testnets.\n- `NEXT_PUBLIC_ALCHEMY_API_KEY` is used for reading data from Polygon, Optimism and Arbitrum + Testnets\n  - Alchemy is also used for ENS and UNS name resolutions - if omitted those resolutions will not work.\n- `COVALENT_API_KEY` and `COVALENT_RATE_LIMIT` is used for certain chains such as Harmony.\n- `ETHERSCAN_API_KEYS` and `ETHERSCAN_RATE_LIMITS` are used for many of the other chains such as BNB Chain or Avalanche.\n- `NEXT_PUBLIC_NODE_URLS` is used to override any RPC URLs on the frontend - e.g. if you want to use Alchemy instead of Infura.\n- `NEXT_PUBLIC_WALLETCONNECT_PROJECT_ID` is used for WalletConnect - if omitted, WalletConnect will not work.\n\nIf you omit any of these variables, Revoke.cash will not work for the chains you omitted.\n\nThen there are a few less essential variables:\n\n- `IRON_SESSION_PASSWORD` is used for encrypting session cookies and can be filled with any random 32-character string - if omitted many chains will not work.\n- `NEXT_PUBLIC_MIXPANEL_API_KEY` is used for Analytics - if omitted, no Analytics are collected.\n- `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` are used for queueing third-party API calls - these are only necessary when hosting in a serverless environment such as Vercel.\n- `RESERVOIR_API_KEY` is used for fetching NFT prices - if omitted, NFT prices will not be shown.\n- `NODE_URLS` is currently unused, but can be used for certain networks in the future.\n- `LOCALAZY_API_KEY` is used for generating \"Help Us Translate This Page\" links - if omitted, those links will not work.\n\n## Contributing\n\n### Adding a new network\n\nAdding a new network is relatively straightforward as you only need to change three files: `lib/utils/chains.ts`, `cypress/e2e/chains.cy.ts` and `locales/en/networks.json`.\n\n#### Prerequisites\n\nTo add a new network, **one** of the following needs to be available:\n\n- A (public or private) RPC endpoint that supports `eth_getLogs` requests for the entire history of the network.\n- Or: Support in [GoldRush](https://goldrush.dev/) for the network.\n- Or: A block explorer with an exposed API that is compatible with Etherscan's API (such as Blockscout).\n- Or: A [HyperSync](https://docs.envio.dev/docs/HyperSync/overview) instance with at least a Bronze tier.\n\nAlso make sure that your network is listed in [ethereum-lists/chains](https://github.com/ethereum-lists/chains) (and that it has subsequently been included in [@revoke.cash/chains](https://github.com/RevokeCash/chains)). Besides the earlier requirements, we also require a publicly available RPC endpoint with rate limits that are not too restrictive. It is also helpful if your network is listed (with TVL and volume stats) on DeFiLlama, but this is not required.\n\n#### Adding the network\n\nIn `lib/utils/chains.ts`:\n\n- Add a network configuration for the network to the `CHAINS` mapping. A network configuration can include the following properties, and need to be filled out accordingly. `name`, `infoUrl`, `nativeToken`, `explorerUrl` and `rpc` only need to be added if the data in `ethereum-lists/chains` is different than what should be used by Revoke.cash\n  - `type`: The type of support, can be `SupportType.PROVIDER` for networks with a public RPC endpoint, `SupportType.COVALENT` for networks supported by CovalentHQ, or `SupportType.ETHERSCAN_COMPATIBLE` for networks with a block explorer API.\n  - `chainId`: The chain ID of the network.\n  - `name`: The name of the network.\n  - `logoUrl`: The URL of the network's logo. Add a logo file (preferably svg) to `public/assets/images/vendor/chains` and add the path here.\n  - `infoUrl` (Optional): The URL of the network's website.\n  - `nativeToken` (Optional): The symbol of the network's native token.\n  - `nativeTokenCoingeckoId` (Optional): The Coingecko ID of the network's native token.\n  - `explorerUrl` (Optional): The URL of the network's block explorer.\n  - `etherscanCompatibleApiUrl` (Only for `SupportType.ETHERSCAN_COMPATIBLE`): The URL of the network's block explorer API.\n  - `rpc.main` (Optional): The URL of the network's RPC endpoint.\n  - `rpc.logs` (Optional): The URL of the network's RPC endpoint for fetching logs (if different from `main`).\n  - `rpc.free` (Optional): The URL of the network's free RPC endpoint (will be used when adding the network to a wallet).\n  - `deployedContracts` (Optional): If multicall3 is deployed to the network, set this to `{ ...MULTICALL }` (check on https://www.multicall3.com/).\n  - `priceStrategy` (Optional): If a price source (Uniswap v2 or Uniswap v3 fork), add a corresponding `PriceStrategy` to enable token pricing.\n  - `backendPriceStrategy` (Optional): If Reservoir has an API endpoint for the network, add a corresponding `ReservoirPriceStrategy` to enable NFT pricing.\n  - `isTestnet` (Optional): Whether the network is a testnet.\n  - `isCanary` (Optional): Whether the network is a canary network.\n  - `correspondingMainnetChainId` (Optional): The chain ID of the corresponding mainnet network (only for testnets or canary networks).\n- Add the network to `CHAIN_SELECT_MAINNETS` or `CHAIN_SELECT_TESTNETS` depending on whether it is a mainnet or testnet. You can subsequently run `yarn tsx scripts/get-chain-order.ts` to determine its rough position in the network selection dropdown.\n\nIn `cypress/support/chain-fixtures.ts`:\n\n- Find a wallet that has active approvals and add it to `TEST_ADDRESSES`.\n\nIn `locales/en/networks.json`:\n\n- Add a one-paragraph description for the network in the `\"networks\"` object under the correct slug.\n- An admin will then need to run `yarn translations:update` to make sure this description gets forwarded to translators.\n\n## Credits\n\nWebsite created by Rosco Kalis after discussing the idea with Paul Berg at Devcon 5 in Osaka. Uses [viem](https://github.com/wagmi-dev/viem) and [wagmi](https://github.com/wagmi-dev/wagmi) for all Ethereum-related operations and [Etherscan](https://etherscan.io), [CovalentHQ](https://www.covalenthq.com/), [Infura](https://infura.io/) & [Alchemy](https://www.alchemy.com/) for extended multichain support. Built with Next.js, Tailwind and TypeScript. Uses Upstash for queueing.\n"
  },
  "RevokeCash/browser-extension": {
    "fetchedAt": "2025-11-12T22:37:11.744Z",
    "content": "# Revoke.cash Browser Extension\n\nIn many cases, phishing websites try to make you sign a token allowance while they pretend to be an NFT mint or other legitimate use cases. When these phishing scams happen, it is recommended to use the Revoke.cash website to mitigate the damage, but it is even better to prevent the scam in the first place.\n\nThis is where the Revoke.cash Browser Extension comes in. The extension pops up whenever you are about to sign an allowance and will inform you of the allowance details. This can help prevent signing malicious allowances.\n\nThe extension also informs you when you are about to list an item for sale on popular marketplaces such as OpenSea and LooksRare, or when you are about to sign a hash. These hashes are used by certain marketplaces like X2Y2 for listing NFTs.\n\nA common scam is to try to trick you into signing one of these gasless signatures on a phishing website, allowing the scammers to steal your NFTs. The official websites of OpenSea, LooksRare, X2Y2, Genie, and Gem are allowlisted for these actions, so that the Revoke.cash browser extension does not interrupt your normal flow.\n\nThe different categories of warnings can be turned on and off in the extension settings.\n\nThe Revoke.cash browser extension works with every EVM-based chain including Ethereum, Polygon, and Avalanche.\n\n## Development\n\n### Prerequisites\n\nContributing to the Revoke.cash extension requires Node.js v16+ and Yarn.\n\n### Running locally\n\nTo continuously build the application using webpack you can run `yarn dev:chrome` or `yarn dev:firefox`. This will make sure that the `dist/` directory is always up to date. From there you can import the generated directory into your browser (e.g. through `chrome://extensions`).\n\n### Building for publication\n\nTo build and package the extension for publication you can run `yarn build && yarn zip`. This will generate zip files for every supported platform that can be submitted to their respective extension stores.\n\n## Credits\n\nThe Revoke.cash browser extension was created by Rosco Kalis after discussing the idea with Merwane Drai and Dries Steenberghe while working on Chaingrep in 2022.\n"
  },
  "ethernautdao/ethernaut-cli": {
    "fetchedAt": "2025-11-12T22:37:18.089Z",
    "content": "![Colored ASCII Art](demos/banner.png)\n\n[![Dynamic JSON Badge](https://img.shields.io/npm/v/ethernaut-cli.svg)](https://www.npmjs.com/package/ethernaut-cli)\n[![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/theethernaut/ethernaut-cli/ci.yml)](https://github.com/theethernaut/ethernaut-cli/actions/workflows/ci.yml)\n[![Coverage Status](https://coveralls.io/repos/github/theethernaut/ethernaut-cli/badge.svg)](https://coveralls.io/github/theethernaut/ethernaut-cli)\n\n## What is it?\n\nA universal Ethereum swiss army knife with an AI duck taped onto it.\n\nA CLI for non-technical users, trying to bridge the gap between graphical UIs and CLIs.\n\nA framework for rapid tool building; integrate a new tool in a matter of hours.\n\nAn extensible framework composed of [hardhat](https://github.com/NomicFoundation/hardhat) plugins.\n\nExample usages:\n\n`ethernaut what is the total supply of USDC`\n\nor\n\n`ethernaut complete level 2 of the ethernaut challenges`\n\nIt can also be used as a regular cli:\n\n`ethernaut util unit 5 --from ether --to wei`\n\nAnd also features an interactive mode that allows easy navigation of tasks and collection of task arguments.\n\n### Prerequisites:\n\nNode.js\n\n`curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -`\n\n`sudo apt install nodejs`\n\nAnvil\n\n`curl -L https://foundry.paradigm.xyz | bash`\n\n`foundryup`\n\nxClip (on Debian/Ubuntu systems)\n\n`sudo apt install xclip`\n\n## Development\n\nThis is a monorepo built with [lerna](https://lerna.js.org/), composed of [hardhat](https://github.com/NomicFoundation/hardhat) plugins. The global nodejs application entry point is in `packages/ethernaut-cli/ethernaut`. All code is vanilla javascript.\n\n### Setup\n\nClone the repo.\n\nInstalls all monorepo dependencies.\n\n`npm install`\n\nBootstraps lerna and runs build scripts for all packages.\n\n`npm run build`\n\nCompiles any contracts in the monorepo's packages.\n\n`npm run compile`\n\n### Running\n\nUse the global `ethernaut` binary to run the CLI.\n\n`./packages/ethernaut-cli/ethernaut <command> <args>`\n\nYou may want to add this binary to your PATH in your .zshrc or .bashrc, so that you can run it with an abbreviation such as 'eth'.\n\n`eth <command> <args>`\n\nThis would allow you to have an `eth` develpment version as well as an `ethernaut` official version installed on your system as a global npm package.\n\nTo run the CLI with verbose output, run:\n\n`DEBUG=* eth <command> <args>` // All packages\n\n`DEBUG=*hardhat* eth <command> <args>` // Hardhat packages\n\n`DEBUG=*ethernaut* eth <command> <args>` // ethernaut packages\n\n`DEBUG=*ethernaut:ui* eth <command> <args>` // ethernaut-ui packages\n\n### Testing\n\nSome tests require a network to be running. You can start one with:\n\n`npm run chain`\n\nTests all packages in the monorepo.\n\n`npm run test`\n\nTo test a single package, run:\n\n`cd packages/ethernaut-ai && npm test`\n\nTo run tests with verbose output, run:\n\n`DEBUG=* npm test` // All packages\n\n`DEBUG=*hardhat* npm test` // Hardhat packages\n\n`DEBUG=*ethernaut* npm test` // ethernaut packages\n\n`DEBUG=*ethernaut:ui* npm test` // ethernaut-ui packages\n\n## Tutorials and articles\n\n- [Announcing the ethernaut-cli](https://mirror.xyz/theethernaut.eth/0HP3L4mWzb4isXYERfsncBQgzT1T99uQTH8tvJvICmE)\n\n## Features\n\n### Intuitive navigation\n\nNo more man pages. No more --help.\n\nJust type `ethernaut` and jump straight into an enquirer based navigation mode. Select a scope, select a task, and boom.\n\n<details>\n  <summary>Navigation demo</summary>\n  <img src=\"demos/nav.gif\" alt=\"Enquirer navigation\">\n</details>\n\n## Smart interactive mode\n\nOnce in a task, interactive mode kicks in, and parameters are collected through enquirer prompts.\n\n<details>\n  <summary>Enquirer param collection</summary>\n  <img src=\"demos/interactive.gif\" alt=\"Enquirer param collection\">\n</details>\n\n### Normal CLI interaction\n\nThis is still a regular CLI app, so commands can be called without all the fancy ui or ai stuff:\n\n<details>\n  <summary>Normal CLI mode</summary>\n  <img src=\"demos/normal.gif\" alt=\"Normal CLI mode\">\n</details>\n\n## Ui extensions\n\nPlugins of plugins? Why not.\n\nPlugins that enhance parameter collection prompts in other plugins with even cooler prompts, smart suggestions, etc.\n\nFor example, the ui extension of the interact plugin can fetch the abi from Etherscan if you didn't provide an abi:\n\n<details>\n  <summary>Custom ABI Prompt</summary>\n  <img src=\"demos/custom.gif\" alt=\"Etherscan custom ABI prompt\">\n</details>\n\nBut after you've interacted with the contract, it already has the abi, so the abi is instead suggested:\n\n<details>\n  <summary>Abi suggestion</summary>\n  <img src=\"demos/custom1.gif\" alt=\"Abi suggestion\">\n</details>\n\nAnother example is the extension for the model param in `ethernaut ai config --model`, which queries the openai API and presents a list of available models.\n\n### Natural language to cli commands\n\nIf that wasn't easy enough, just type whatever you want and AI will kick in to try to make sense of what you typed, and the right command or sequence of commands will be executed.\n\n<details>\n  <summary>Ai natural language interpretation</summary>\n  <img src=\"demos/interpret.gif\" alt=\"Ai natural language interpretation\">\n</details>\n\nYou want the AI to also teach you how the commands work? Sure.\n\n<details>\n  <summary>Ai command explanation</summary>\n  <img src=\"demos/explain.gif\" alt=\"Ai command explanation\">\n</details>\n\nYou want the AI to also teach you about Ethereum. Also sure.\n\n<details>\n  <summary>Complete level 1</summary>\n  <img src=\"demos/teach.gif\" alt=\"Complete level 1\">\n</details>\n\n### Extensibility through hardhat plugins\n\nYou don't have to use this entire plethora of features tho. You can use a single feature in your regular hardhat project with exactly what you need. This is because the ethernaut-cli is completely built with hardhat plugins.\n\nYou just want task navigation and interactive mode in your project: use the `ethernaut-ui` plugin.\n\nOr the ai stuff: use `ethernaut-ai` plugin.\n\nAll the plugins combined conform the ethernaut-cli.\n\n<details>\n\n<summary>List of packages</summary>\n\n| Title                                                             | Description                                                                                            |\n| ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n| [ethernaut-ai](packages/ethernaut-ai/README.md)                   | AI assistant that interprets user input and executes hardhat tasks and talks to Optimism documentation |\n| [ethernaut-ai-ui](packages/ethernaut-ai-ui/README.md)             | Ui extensions for the ethernaut-ai package                                                             |\n| [ethernaut-cli](packages/ethernaut-cli/README.md)                 | Main hardhat project                                                                                   |\n| [ethernaut-challenges](packages/ethernaut-challenges/README.md)   | Tasks for playing the Open Zeppelin Ethernaut challenges from the CLI                                  |\n| [ethernaut-common](packages/ethernaut-common/README.md)           | Common utils used by several ethernaut-cli plugins                                                     |\n| [ethernaut-interact](packages/ethernaut-interact/README.md)       | Tasks for sending transactions and interacting with contracts                                          |\n| [ethernaut-interact-ui](packages/ethernaut-interact-ui/README.md) | Ui extensions for the ethernaut-interact package                                                       |\n| [ethernaut-network](packages/ethernaut-network/README.md)         | Tasks for interacting with different networks                                                          |\n| [ethernaut-network-ui](packages/ethernaut-network-ui/README.md)   | Ui extensions for the ethernaut-network package                                              \n\n[... truncated ...]"
  },
  "eth-brownie/brownie": {
    "fetchedAt": "2025-11-12T22:37:26.180Z",
    "content": "# Brownie\n\n[![Pypi Status](https://img.shields.io/pypi/v/eth-brownie.svg)](https://pypi.org/project/eth-brownie/) [![Docs Status](https://readthedocs.org/projects/eth-brownie/badge/?version=latest)](https://eth-brownie.readthedocs.io/en/stable/)\n\nBrownie is a Python-based development and testing framework for smart contracts targeting the [Ethereum Virtual Machine](https://solidity.readthedocs.io/en/v0.6.0/introduction-to-smart-contracts.html#the-ethereum-virtual-machine).\n\n**Brownie is no longer actively maintained**. Future releases may come sporadically - or never at all. Check out [Ape Framework](https://github.com/ApeWorX/ape) for all your python Ethereum development needs.\n\n## Features\n\n* Full support for [Solidity](https://github.com/ethereum/solidity) (`>=0.4.22`) and [Vyper](https://github.com/vyperlang/vyper) (`>=0.1.0-beta.16`)\n* Contract testing via [`pytest`](https://github.com/pytest-dev/pytest), including trace-based coverage evaluation\n* Property-based and stateful testing via [`hypothesis`](https://github.com/HypothesisWorks/hypothesis/tree/master/hypothesis-python)\n* Powerful debugging tools, including python-style tracebacks and custom error strings\n* Built-in console for quick project interaction\n\n## Dependencies\n\n* [python3](https://www.python.org/downloads/release/python-3910/) version 3.10 or greater, python3-dev\n* [hardhat](https://github.com/NomicFoundation/hardhat) or [ganache](https://github.com/trufflesuite/ganache)\n\nTested with ganache version [7.9.2](https://github.com/trufflesuite/ganache/releases/tag/v7.0.2), however it is generally recommended to use hardhat because ganache has been sunsetted.\n\n## Installation\n\n### via `pipx`\n\nThe recommended way to install Brownie is via [`pipx`](https://github.com/pipxproject/pipx). pipx installs Brownie into a virtual environment and makes it available directly from the commandline. Once installed, you will never have to activate a virtual environment prior to using Brownie.\n\nTo install `pipx`:\n\n```bash\npython3 -m pip install --user pipx\npython3 -m pipx ensurepath\n```\n\nTo install Brownie using `pipx`:\n\n```bash\npipx install eth-brownie\n```\n\nTo upgrade to the latest version:\n\n```bash\npipx upgrade eth-brownie\n```\n\nTo use latest master or another branch as version:\n```bash\npipx install git+https://github.com/eth-brownie/brownie.git@master\n```\n\n### via `pip`\n\nYou can install the latest release via [`pip`](https://pypi.org/project/pip/):\n\n```bash\npip install eth-brownie\n```\n\n### via `setuptools`\n\nYou can clone the repository and use [`setuptools`](https://github.com/pypa/setuptools) for the most up-to-date version:\n\n```bash\ngit clone https://github.com/eth-brownie/brownie.git\ncd brownie\npython3 setup.py install\n```\n\n### as a library\n\nIf you want to install brownie inside your own project (rather than as a standalone cli tool):\n\n```bash\nexport BROWNIE_LIB=1\npip install eth-brownie\n```\n\nThis loosens the pins on all dependencies. You'll want to make sure you have your own `requirements.txt` to make sure upgrades upstream don't surprise anyone.\n\n### for development\n\nThere are extra tools that are helpful when developing:\n\n```bash\ngit clone https://github.com/eth-brownie/brownie.git\ncd brownie\npython3 -m venv venv\n./venv/bin/pip install wheel\n./venv/bin/pip install -e . -r requirements-dev.txt\n```\n\nUpgrading the pinned versions of dependencies is easy:\n```\n./venv/bin/pip-compile --upgrade\n./venv/bin/pip-compile --upgrade requirements-dev.in\n./venv/bin/pip-compile --upgrade requirements-windows.in\n```\n\nEven small upgrades of patch versions have broken things in the past, so be sure to run all tests after upgrading things!\n\n## Quick Usage\n\nTo initialize a new Brownie project, start by creating a new folder. From within that folder, type:\n\n```bash\nbrownie init\n```\n\nNext, type `brownie --help` for basic usage information.\n\n## Documentation and Support\n\nBrownie documentation is hosted at [Read the Docs](https://eth-brownie.readthedocs.io/en/latest/).\n\nIf you have any questions about how to use Brownie, feel free to ask on [Ethereum StackExchange](https://ethereum.stackexchange.com/) or join us on [Gitter](https://gitter.im/eth-brownie/community).\n\n## Testing\n\nTo run the tests, first install the developer dependencies:\n\n```bash\npip install -e . -r requirements-dev.txt\n```\n\nThen use [`tox`](https://github.com/tox-dev/tox) to run the complete suite against the full set of build targets, or [`pytest`](https://github.com/pytest-dev/pytest) to run tests against a specific version of Python. If you are using [`pytest`](https://github.com/pytest-dev/pytest) you must include the `-p no:pytest-brownie` flag to prevent it from loading the Brownie plugin.\n\n### Using Docker\n\nYou can use a sandbox container provided in the [`docker-compose.yml`](docker-compose.yml) file for testing inside a Docker environment.\n\nThis container provides everything you need to test using a Python 3.6 interpreter.\n\nStart the test environment:\n\n```bash\ndocker-compose up -d\n```\n\nTo open a session to the container:\n\n```bash\ndocker-compose exec sandbox bash\n```\n\nTo run arbitrary commands, use the `bash -c` prefix.\n\n```bash\ndocker-compose exec sandbox bash -c ''\n```\n\nFor example, to run the tests in `brownie/tests/test_format_input.py`:\n\n```bash\ndocker-compose exec sandbox bash -c 'python -m pytest tests/convert/test_format_input.py'\n```\n\n#### Attaching to dockerized RPC clients\n\nYou can also attach to a RPC client already running inside a docker container.\n\nFor example for running ganache-cli you could just startup the official ganache-cli docker image:\n\n```bash\ndocker run -p 8545:8545 trufflesuite/ganache-cli\n```\n\nThen in another terminal on your host you could connect to it:\n\n```bash\nbrownie console\n```\n\nIf you have your RPC client bound to a specific hostname e.g. `ganache` you could create a separate brownie network for it:\n\n```bash\nbrownie networks add Development dev cmd=ganache-cli host=http://ganache:8545\n```\n\nThen connect to it with:\n\n```bash\nbrownie console --network dev\n```\n\n## Contributing\n\nHelp is always appreciated! Feel free to open an issue if you find a problem, or a pull request if you've solved an issue.\n\nPlease check out our [Contribution Guide](CONTRIBUTING.md) prior to opening a pull request, and join the Brownie [Gitter channel](https://gitter.im/eth-brownie/community) if you have any questions.\n\n## License\n\nThis project is licensed under the [MIT license](LICENSE).\n"
  },
  "daimo-eth/pay": {
    "fetchedAt": "2025-11-12T22:37:33.686Z",
    "content": "<a href=\"https://paydocs.daimo.com\">\n  <img src=\"https://pbs.twimg.com/profile_banners/1666972322828541954/1733698695/1500x500\">\n</a>\n\n# Daimo Pay\n\nDaimo Pay enables seamless crypto payments for your app.\n\nOnboard users from any chain, any coin into your app with one click and maximize your conversion.\n\n## Features\n\n- üå± Instant cross-chain payments ‚Äî Accept payment from 1000+ tokens on multiple chains. Payments complete in less than 5 seconds. We handle the swapping\n  and bridging so that your customers don't have to.\n- üí° Pay with a single transaction - No more wallet round-trips to make approval, swap, or bridging transactions. Your customers pay with a single transfer transaction.\n- ‚ö°Ô∏è Fully permissionless - Daimo never custodies funds and funds can never be stuck in a contract. Payments can be permissionlessly completed by anyone.\n- üí± Support for all major wallets and exchanges - Daimo Pay supports payments from browser wallets like MetaMask and Rabby, as well as exchanges like Coinbase and Binance.\n- üí® Integrate within minutes - Get up and running with Daimo Pay in as little as 10 minutes with little to no code.\n\nand much more...\n\n## Documentation\n\nYou can find the full Daimo Pay documentation [here](https://paydocs.daimo.com).\n\n## Examples\n\nCheck out https://github.com/daimo-eth/daimo-pay-demo\n\n### Try in CodeSandbox\n\nComing soon.\n\n### Local Development\n\nClone the repository and build the SDK in `dev` mode:\n\n```sh\ngit clone https://github.com/daimo-eth/pay.git\ncd pay/packages/connectkit\nnpm i\nnpm run dev\n```\n\nThe rollup bundler will now watch file changes in the background. Try using one of the examples for testing:\n\n```sh\ncd examples/nextjs\nnpm i\nnpm run dev\n```\n\nAny changes will be reflected on the Pay button in the example app.\n\n## Contracts\n\nDaimo Pay is noncustodial and runs on open-source, audited contracts. See `/packages/contract`.\n\nAudits:\n\n- [Nethermind, 2025 Aug](https://github.com/user-attachments/files/22227674/NM-0585-Daimo.pdf)\n- [Nethermind, 2025 Apr](https://github.com/user-attachments/files/20544714/NM-0500-Daimo-Pay-final-report.pdf)\n\n## Support\n\n[Contact us](mailto:support@daimo.com) if you'd like to integrate Daimo Pay.\n\n## License\n\nSee [LICENSE](https://github.com/daimo-eth/pay/blob/master/packages/connectkit/LICENSE) for more information.\n\n## Credits\n\nDaimo Pay SDK uses a fork of [ConnectKit](https://github.com/family/connectkit), developed by [Family](https://family.co). We're grateful to them for making ConnectKit open-source.\n"
  },
  "nftscan-official/nftscan-api-js-sdk": {
    "fetchedAt": "2025-11-12T22:37:41.223Z",
    "content": "# NFTScan API SDK (JavaScript / TypeScript)\nThe NFTScan API SDK is a `JavaScript` / `TypeScript` library which provides convenience and quick access to the [NFTScan's APIs](https://docs.nftscan.com/), it helps developers build new experiences retrieving NFTs and data analysis. We provide a set of endpoints that enable you to fetch ERC721 and ERC1155 NFT assets as well as transactions, collections, marketplace statistics and more.\n\nTo use our APIs, You need to register an account on NFTScan open platform [OpenAPI Platform](https://developer.nftscan.com) and get your `API-KEY` for making calls to API services.\n\nThe SDK currently supports the following chains:\n\n| Blockchain   | Domain name             | Short name |\n| ------------ | ----------------------- | ---------- |\n| Ethereum     | restapi.nftscan.com     | eth        |\n| BNB chain    | bnbapi.nftscan.com      | bnb        |\n| Polygon      | polygonapi.nftscan.com  | polygon    |\n| OP Mainnet   | optimismapi.nftscan.com | optimism   |\n| Mint         | mintapi.nftscan.com     | mint       |\n| Mantle       | mantleapi.nftscan.com   | mantle     |\n| Base         | baseapi.nftscan.com     | base       |\n| Sei          | seiapi.nftscan.com      | sei        |\n| Gravity      | gravityapi.nftscan.com  | gravity    |\n| Berachain    | beraapi.nftscan.com     | bera       |\n| Viction      | victionapi.nftscan.com  | viction    |\n| Solana       | solanaapi.nftscan.com   | solana     |\n\n*The value of **Short name** is used in the SDK as an initialization configuration parameter.*\n\n## Getting started\n\nvia `npm`:\n\n```shell\nnpm install nftscan-api\n```\n\nor `yarn`:\n\n```shell\nyarn add nftscan-api\n```\n\nThen you can import and use the SDK:\n\n```ts\nimport { ErcType, EvmChain, NftscanEvm } from \"nftscan-api\";\n\nconst config = {\n  apiKey: \"<YOUR_API_KEY>\", // Replace with your NFTScan API key.\n  chain: EvmChain.ETH, // Replace with your chain.\n};\n\nconst evm = new NftscanEvm(config);\n```\nor\n```ts\nimport { ErcType, NftscanEvm } from \"nftscan-api\";\n\nconst config = {\n  apiKey: \"<YOUR_API_KEY>\", // Replace with your NFTScan API key.\n  baseUrl: \"<HTTPS_URL>\" + \"/api\", // Or replace with a valid https URL.\n};\n\nconst evm = new NftscanEvm(config);\n```\n\nThe `new NftscanEvm()` returns an object that can query the EVM-like chain, for here it is `EvmChain.ETH`, which stand for the Ethereum blockchain. It must be ensured that one of the `chain` or `baseUrl` attribute is valid. A valid `baseUrl` supported by NFTSCAN can be found here: [EVM chains](https://docs.nftscan.com/guides/Overview/1#evm_chains).\n\nThe complete enumeration value of `EvmChain` includes the following:\n```ts\nexport enum EvmChain {\n  ETH = 'eth',\n  BNB = 'bnb',\n  POLYGON = 'polygon',\n  OPTIMISM = 'optimism',\n  MINT = 'mint',\n  MANTLE = 'mantle',\n  BASE = 'base',\n  SEI = 'sei',\n  GRAVITY = 'gravity',\n  BERA = 'bera',\n  VICTION = 'viction',\n}\n```\n\nAnd then you can use the object `evm` to access to the NFTScan API, form example `getAssetsByAccount`, which can retrieve the assets owned by an account.\n\n```ts\nconst accountAddress = \"<ACCOUNT_ADDRESS>\"; // Replace with the account address you want to query.\n// Access asset-related APIs\nevm.asset\n  // Retrieve assets owned by an account.\n  .getAssetsByAccount(accountAddress, {\n    erc_type: ErcType.ERC_721, // Can be erc721 or erc1155\n  })\n  .then((res) => console.log(res));\n\n// Access transaction-related APIs \nevm.transaction\n  // Retrieve transactions by an account\n  .getTransactionsByAccount(accountAddress)\n  .then((res) => console.log(res));\n```\nNot only `asset` and `transaction`, but the `NftscanEvm` also provides several other objects, for example `collection` \\ `statistic` \\ `other`, these objects provide different types of APIs.\n\nTo query the other EVM-like chain's asset, for example 'Arbitrum', changing the config param `chain` to `EvmChain.ARBITRUM`:\n```ts\nconst evm = new NftscanEvm({\n  apiKey: \"<YOUR_API_KEY>\",\n  chain: EvmChain.ARBITRUM, \n});\n```\n\nWe also support the Solana blockchain, to access the API, you just need to use `new NftscanSolana()` to get an object.\n\n```ts\nconst sol = new NftscanSolana({ apiKey: \"<YOUR_API_KEY>\" });\nsol.asset\n  .getAssetsByAccount(\"<ACCOUNT_ADDRESS>\")\n  .then((res) => console.log(res));\n```\n\n### Pagination\nIn general, NFTScan's API that supports pagination will uses the query params `cursor` as the paging parameter, The return data of the API call will contain the attribute `next`, you can pass in the `next` value to the next call.\n\nFor example:\n```ts\nlet nextCursor = \"\";\nconst { content, next } = await evm.asset.getAccountMinted(\"<ACCOUNT_ADDRESS>\", {\n  cursor: nextCursor, // A cursor to retrieve the next page\n  limit: 20, // Page size\n});\n// update the nextCursor\nnextCursor = next;\n```\n\n## API\nThe SDK currently supports all of the [NFTScan API](https://developer.nftscan.com/) endpoints, The distribution of the API is consistent with the [NFTScan API](https://developer.nftscan.com/). \n\nAs follows:\n\n- #### NFTScan API of EVM\n  - ##### Retrieve Assets (`new NftscanEvm().asset.*`)\n    - `getAssetsByAccount()`: [Get NFTs by account](https://docs.nftscan.com/reference/evm/get-nfts-by-account)\n    - `getAllAssets()`: [Get all NFTs by account](https://docs.nftscan.com/reference/evm/get-all-nfts-by-account)\n    - `getAccountMinted()`: [Get minted NFTs by account](https://docs.nftscan.com/reference/evm/get-minted-nfts-by-account)\n    - `getAssetsByContract()`: [Get NFTs by contract](https://docs.nftscan.com/reference/evm/get-nfts-by-contract)\n    - `getAssetsByContractAndTokenId()`: [Get single NFT](https://docs.nftscan.com/reference/evm/get-single-nft)\n    - `queryAssetsInBatches`: [Get multiple NFTs](https://docs.nftscan.com/reference/evm/get-multiple-nfts)\n    - `queryAssetsByFilters()`: [Search NFTs](https://docs.nftscan.com/reference/evm/search-nfts).\n    - `queryAssetsByAttributes()`: [Get NFTs by attributes](https://docs.nftscan.com/reference/evm/get-nfts-by-attributes)\n    - `getMultiChainAssets()`: [Get all multi-chain NFTs by account](https://docs.nftscan.com/reference/evm/get-all-multi-chain-nfts-by-account)\n  - ##### Retrieve Transactions (`new NftscanEvm().transaction.*`)\n    - `getTransactionsByAccount()`: [Get transactions by account](https://docs.nftscan.com/reference/evm/get-transactions-by-account)\n    - `getTransactionsByContract()`: [Get transactions by contract](https://docs.nftscan.com/reference/evm/get-transactions-by-contract)\n    - `getTransactionsByContractAndTokenId()`: [Get transactions by NFT](https://docs.nftscan.com/reference/evm/get-transactions-by-nft)\n    - `queryTransactionsByFilters()`: [Search transactions](https://docs.nftscan.com/reference/evm/search-transactions)\n    - `getTransactionsByToAddress()`: [Get transactions by to address](https://docs.nftscan.com/reference/evm/get-transactions-by-to-address)\n    - `queryTransactionsByTxHashList()`: [Get transactions by hash](https://docs.nftscan.com/reference/evm/get-transactions-by-hash)\n  - ##### Retrieve Collections (`new NftscanEvm().collection.*`)\n    - `getCollectionsByContract()`: [Get an NFT collection](https://docs.nftscan.com/reference/evm/get-an-nft-collection)\n    - `queryCollectionsByFilters()`: [Search NFT collections](https://docs.nftscan.com/reference/evm/search-nft-collections)\n    - `queryCollectionsByAccountAddress()`: [Get NFT collections by account](https://docs.nftscan.com/reference/evm/get-nft-collections-by-account)\n    - `getCollectionsByRanking()`: [Get NFT collections by ranking](https://docs.nftscan.com/reference/evm/get-nft-collections-by-ranking)\n  - ##### Statistics (`new NftscanEvm().statistic.*`)\n    - `getTradeRanking()`: [Trade ranking](https://docs.nftscan.com/reference/evm/trade-ranking)\n    - `getMintRanking()`: [mint ranking](https://docs.nftscan.com/reference/evm/mint-ranking)\n    - `getMintAmount()`: [Mint amount](https://docs.nftscan.com/reference/evm/mint-amount)\n    - `getTradersRanking()`: [Traders ranking](https://docs.nftscan.com/reference/evm/traders-ranking)\n\n[... truncated ...]"
  },
  "runtimeverification/evm-semantics": {
    "fetchedAt": "2025-11-12T22:37:49.194Z",
    "content": "KEVM: Semantics of EVM in K\n===========================\n\nIn this repository, we provide a model of the EVM in K.\n\nFast Installation\n-----------------\n\n-   `bash <(curl https://kframework.org/install)`: install [kup package manager].\n-   `kup install kevm`: install KEVM.\n-   `kup list kevm`: list available KEVM versions.\n-   `kup update kevm`: update to latest KEVM version.\n\n**NOTE**: The first run will take longer to fetch all the libraries and compile sources. (30m to 1h)\n\nDocumentation/Support\n---------------------\n\nThese may be useful for learning KEVM and K (newest to oldest):\n\n-   [K, KEVM and Foundry Integration overview](https://www.youtube.com/watch?v=9PLnQStkiUo)\n-   [Jello Paper], a nice presentation of this repository.\n-   [20 minute tour of the semantics](https://www.youtube.com/watch?v=tIq_xECoicQNov) at [2017 Devcon3].\n-   [KEVM 1.0 technical report](http://hdl.handle.net/2142/97207), especially sections 3 and 5.\n-   [KEVM Paper at CSF'18/FLoC](https://fsl.cs.illinois.edu/publications/hildenbrandt-saxena-zhu-rodrigues-daian-guth-moore-zhang-park-rosu-2018-csf).\n\nTo get support for KEVM, please join our [Discord Channel](https://discord.com/invite/CurfmXNtbN).\n\nIf you want to start proving with KEVM, refer to [tests/specs/examples/README.md].\n\nRepository Structure\n--------------------\n\nThe following files constitute the KEVM semantics:\n\n-   [network.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/network.md) provides the status codes reported to an Ethereum client on execution exceptions.\n-   [json-rpc.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/json-rpc.md) is an implementation of JSON RPC in K.\n-   [evm-types.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/evm-types.md) provides the (functional) data of EVM (256-bit words, wordstacks, etc...).\n-   [serialization.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/serialization.md) provides helpers for parsing and unparsing data (hex strings, recursive-length prefix, Merkle trees, etc.).\n-   [evm.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/evm.md) is the main KEVM semantics, containing EVM‚Äôs configuration and transition rules.\n-   [gas.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/gas.md) contains all information relevant to gas.\n-   [schedule.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/schedule.md) contains all information relevant to EVM schedules.\n\nThese additional files extend the semantics to make the repository more useful:\n\n-   [buf.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/buf.md) defines the `#buf` byte-buffer abstraction for use during symbolic execution.\n-   [abi.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/abi.md) defines the [Contract ABI Specification](https://docs.soliditylang.org/en/v0.8.22/abi-spec.html) for use in proofs and easy contract/function specification.\n-   [hashed-locations.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/hashed-locations.md) defines the `#hashedLocation` abstraction used to specify Solidity-generated storage layouts.\n-   [edsl.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/edsl.md) combines the previous three abstractions for ease-of-use.\n\nThese files are used for testing the semantics itself:\n\n-   [state-utils.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/state-utils.md) provides functionality for EVM initialization, setup, and querying.\n-   [driver.md](kevm-pyk/src/kevm_pyk/kproj/evm-semantics/driver.md) is an execution harness for KEVM, providing a simple language for describing tests/programs.\n\nBuilding from source\n--------------------\n\nThere are two backends of K available: LLVM for concrete execution and Haskell for symbolic execution.\nThis repository generates the build-products for each backend in `$XDG_CACHE_HOME/evm-semantics-<digest>`.\n\n### System Dependencies\n\nRun `install-build-deps` to install the required OS-supplied dependencies.\n\nThere are some additional notes for specific systems:\n\nUbuntu:\n- The script works for ‚â• 22.04.\n- On Ubuntu < 18.04, you'll need to skip `libsecp256k1-dev` and instead\n  build it from source (via our `Makefile`) using `make libsecp256k1`.\n\nArch:\n- No issues known.\n\nMacOS:\n- After installing the Command Line Tools, [Homebrew](https://brew.sh/),\n  and getting the [blockchain plugin](#blockchain-plugin), run:\n- **NOTE**: It is recommended to use the homebrew version of `flex` and\n  XCode.\n- If you are building on an Apple Silicon machine, ensure that your `PATH`\n  is set up correctly before running `make deps` or `make k-deps`. You can\n  do so using [`direnv`](https://direnv.net/) by copying `macos-envrc` to\n  `.envrc`, then running `direnv allow`.\n- If the build on macOS still fails, you can also try adding the following\n  lines to the top of your `Makefile` under `UNAME_S`:\n\n      ifeq ($(UNAME_S), Darwin)\n      SHELL := /usr/local/bin/bash\n      PATH := $(pwd)/.build/usr/bin:$(PATH)\n      endif\n\n#### Haskell Stack (all platforms)\n\n-   [Haskell Stack](https://docs.haskellstack.org/en/stable/install_and_upgrade/#installupgrade).\n    Note that the version of the `stack` tool provided by your package manager might not be recent enough.\n    Please follow installation instructions from the Haskell Stack website linked above.\n\nTo upgrade `stack` (if needed):\n\n```sh\nstack upgrade\nexport PATH=$HOME/.local/bin:$PATH\n```\n\n### Build Dependencies\n\n#### K Framework\n\nYou need to install the [K Framework] on your system, see the instructions there.\nThe fastest way is via the [kup package manager], with which you can do to get the correct version of K:\n\n```sh\nkup install k.openssl --version v$(cat deps/k_release)\n```\n\nYou can also drop into a single development shell with the correct version of K on path by doing:\n\n```sh\nkup shell k.openssl --version v$(cat deps/k_release)\n```\n\n### Building\n\nMake sure Python (`>=3.10`) and [`uv`](https://docs.astral.sh/uv/) are installed on your system.\nYou can check your setup by running `make`.\n\n#### Blockchain Plugin\n\nYou also need to get the blockchain plugin submodule and install it.\n\n```sh\ngit submodule update --init --recursive\nuv --project kevm-pyk run -- kdist --verbose build evm-semantics.plugin\n```\n\nTo change the default compiler:\n\n```sh\nCXX=clang++-15 uv --project kevm-pyk run -- kdist --verbose build evm-semantics.plugin\n```\n\nOn Apple silicon:\n\n```sh\nAPPLE_SILICON=true uv --project kevm-pyk run -- kdist --verbose build evm-semantics.plugin\n```\n\n#### K Definitions\n\nFinally, you can build the semantics.\n\n```sh\nuv --project kevm-pyk run -- kdist --verbose build -j6\n```\n\nYou can build specific targets using options `evm-semantics.{llvm,kllvm,kllvm-runtime,haskell,haskell-standalone,plugin}`, e.g.:\n\n```sh\nuv --project kevm-pyk run -- kdist build -j2 evm-semantics.llvm evm-semantics.haskell\n```\n\nTargets can be cleaned with\n\n```sh\nuv --project kevm-pyk run -- kdist clean\n```\n\nFor more information, refer to `kdist --help` and the [dist.py](kevm-pyk/src/kevm_pyk/dist.py) module.\n\nRunning Tests\n-------------\n\nTo execute tests from the [Ethereum Test Set], the submodule needs to be fetched first.\n\n```sh\ngit submodule update --init --recursive  -- tests/ethereum-tests\n```\n\nThe tests are run using the supplied `Makefile`.\n\nThe following subsume all other tests:\n\n-   `make test`: All of the quick tests.\n-   `make test-all`: All of the quick and slow tests.\n\nThese are the individual test-suites (all of these can be suffixed with `-all` to also run slow tests):\n\n-   `make test-vm`: VMTests from the [Ethereum Test Set].\n-   `make test-bchain`: Subset of BlockchainTests from the [Ethereum Test Set].\n-   `make test-proof`: Proofs from the [Verified Smart Contracts].\n-   `make test-interactive`: Tests of the `kevm` command.\n\nAll these targets call `pytest` under the hood. You can pass additional arguments to the call by appending them to variable `PYTEST_ARGS`. E.g. run\n\n```\nmake test-vm PYTEST_ARGS+=-vv\n```\n\nto execute VMTests with increased verbosity, and\n\n```\nmake test-vm PYTEST_ARGS+=-n0\n```\n\nto execute them on a single worker.\n\nFiles produced by test runs, e.g. kompiled definition and l\n\n[... truncated ...]"
  },
  "foundry-rs/foundry": {
    "fetchedAt": "2025-11-12T22:37:57.228Z",
    "content": "<div align=\"center\">\n  <img src=\".github/assets/banner.png\" alt=\"Foundry banner\" />\n\n&nbsp;\n\n[![Github Actions][gha-badge]][gha-url] [![Telegram Chat][tg-badge]][tg-url] [![Telegram Support][tg-support-badge]][tg-support-url]\n![Foundry](https://img.shields.io/badge/Foundry-grey?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAElElEQVR4nH1VUUhUaRg9984YdzBpkqR0Z210rIESIXSabEbcHgydrpNRRj00kWaztj0U1MOW0MOIbD300IvLMqBpMTGYxdoqyoRNDUESBDWwUuPugCSSsTM7u0Oj1/+efdiMcmnP2/fDd77D4f/OB6xCa2urQZbllVICYGtqanK1tLS4AdgAyAAgyzJaW1sNq/ulT4twOGw4fPiwAGDp7Ow8VV1d7bVarRWxWCw/k8mgsbExm0wmZ+Lx+M/Xr1//CcAsSVmSJH01McLhsAEAnE5nx+Tk5B/xeJxOp5N9fX2sqqqixWLhnTt36HA4GIvFGI1GU3V1df5Pe/9D1t7eHkgkEuzo6GBPT49WWloq7Ha7fujQITocDu7atUs3m83i6tWr2okTJ/jixQuePn265zPScDhskGUZe/fubXv8+DFv3rypbdiwQaxbt46RSIT79u3j0NAQb926RVVVOT4+TqvVyvz8fD0YDC5NTk6ysbHxlCRJ/5KSlAAURyKRTFNTkwAg7t69S5/Px76+Pq7GyMgI9+/fz9HRUQIQO3bsEKOjo38DsJCUJADw+/0BVVW7otHo8ps3b4yvXr3CxMQETCYTTCYTNE0DAOTl5SGXy0FRFOzZswdmsxkVFRXLNTU1xmg0+kNvb+/3AGAcGBiI7969Wwcg6urq+OTJE967d49btmzh9PT0R3WJRIKBQIDBYJBTU1NsaGggAGGz2fTe3t5fAeQZAWwuLi4uP3nypOT1emEwGFBeXo7a2losLCygoaEB/f39MJlMCIVCkCQJBw8ehNVqhcfjQXNzs1RSUiKtX7++DEAZqqqq3KFQiABYUFDAM2fOkCQXFxdJkvfv32dhYSG9Xi+vXbvG2dnZj4oDgQCLioqoKAqHhobodDq/Mc7NzUklJSUIBoOw2WzYtm0blpeXsWbNGkxMTODp06doa2vD4OAgNm7cCIvFApLQdR3nzp3Dzp078fLlSxQVFeHdu3cAgIpHjx69/zBUX5k+MDBAt9vNY8eOsbu7m6lUigcOHKDL5WImkyHJz9TGYrEcALsMIPn69esZTdMIgM+ePUNXVxdu376NsrIyuN1uXLp0CWazGcPDw3C5XFBVFWfPnkVNTQ18Pp+ezWY5MzPzO4DfAABHjhzpJslUKqVdvHiR4+PjbG9vZy6XI0kuLS0xmUxSCEGS9Pv9LC0tpdFoZGVlpSaEoM/nuwIAKx/7q5GRkb9CoZBQVVWcP3+ez58/J0mm02kODg7ywoULjMViTKfTtNvtXLt2LTdt2qTncrnlsbGxLICvSUqfrl5HJBLh1NTUkhBCJ8mFhQX29/dTVVUWFBTwwYMH1HWdly9fpqIoeiKRWJqfn2d1dXWnLMuf7zMAHD16tGd+fn7FZy2bzYrKykodAAFQVVV9cXFRkNTevn3Lubk5trS0XPnfxHE4HN8ODw+nV/yanp6mx+Ohx+P5aIMQgmNjY3/W1tZ+t5rsSwG7+fjx4/76+vrm7du32woLC00AkE6n38fj8ZmHDx/+cuPGjR8BJL8YsCtYdQIMALYqilKvKEo9APuHty+egH8A3GfFDJXmxmMAAAAASUVORK5CYII%3D&link=https%3A%2F%2Fbook.getfoundry.sh%2F)\n\n[gha-badge]: https://img.shields.io/github/actions/workflow/status/foundry-rs/foundry/test.yml?branch=master\n[gha-url]: https://github.com/foundry-rs/foundry/actions\n[tg-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&style=flat-square&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_rs\n[tg-url]: https://t.me/foundry_rs\n[tg-support-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=support&style=flat-square&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_support\n[tg-support-url]: https://t.me/foundry_support\n\n**[Install](https://getfoundry.sh/getting-started/installation)**\n| [Docs][foundry-docs]\n| [Developer Guidelines](./docs/dev/README.md)\n| [Contributing](./CONTRIBUTING.md)\n| [Crate Docs](https://foundry-rs.github.io/foundry)\n\n</div>\n\n---\n\n### Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.\n\nFoundry consists of:\n\n- [**Forge**](#forge): Build, test, fuzz, debug and deploy [Solidity][solidity] contracts, like Hardhat, Brownie, Ape.\n- [**Cast**](#cast): A Swiss Army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n- [**Anvil**](#anvil): Fast local Ethereum development node, akin to Hardhat Network, Tenderly.\n- [**Chisel**](#chisel): Fast, utilitarian, and verbose Solidity REPL.\n\n**Need help getting started with Foundry? Read the [üìñ Foundry Docs][foundry-docs]!**\n\n![Demo](.github/assets/demo.gif)\n\n## Features\n\n- **High-Performance Compilation**\n\n  - **Fast and Flexible**: Automatically detects and installs the required Solidity compiler version.\n  - **Solidity and Vyper Support**: Fully supports both Solidity and Vyper out-of-the-box.\n  - **Incremental Compilation**: Re-compiles only changed files, saving time.\n  - **Parallelized Pipeline**: Leverages multi-core systems for ultra-fast builds.\n  - **Broad Compatibility**: Supports non-standard directory structures, including [Hardhat repos](https://twitter.com/gakonst/status/1461289225337421829).\n\n- **Advanced Testing**\n\n  - **No Context Switching**: Write tests directly in Solidity.\n  - **Fuzz Testing**: Quickly identify edge cases with input shrinking and counter-example generation.\n  - **Invariant Testing**: Ensure complex system properties hold across a wide range of inputs.\n  - **Debugging Made Easy**: Use [forge-std](https://github.com/foundry-rs/forge-std)'s `console.sol` for flexible debug logging.\n  - **Interactive Debugger**: Step through your Solidity code with Foundry's interactive debugger, making it easy to pinpoint issues.\n\n- **Powerful Runtime Features**\n\n  - **RPC Forking**: Fast and efficient remote RPC forking backed by [Alloy][alloy].\n  - **Lightweight & Portable**: No dependency on Nix or other package managers for installation.\n\n- **Streamlined CI/CD**\n\n  - **Optimized CI**: Accelerate builds, run tests and execute scripts using [Foundry's GitHub action][foundry-gha].\n\n## Installation\n\nGetting started is very easy:\n\nInstall `foundryup`:\n\n```\ncurl -L https://foundry.paradigm.xyz | bash\n```\n\nNext, run `foundryup`.\n\nIt will automatically install the latest version of the precompiled binaries: [`forge`](#forge), [`cast`](#cast), [`anvil`](#anvil), and [`chisel`](#chisel).\n\n```\nfoundryup\n```\n\n**Done!**\n\nFor additional details see the [installation guide](https://getfoundry.sh/getting-started/installation) in the [Foundry Docs][foundry-docs].\n\nIf you're experiencing any issues while installing, check out [Getting Help](#getting-help) and the [FAQ](https://getfoundry.sh/faq).\n\n## How Fast?\n\nForge is quite fast at both compiling (leveraging `solc` with [foundry-compilers]) and testing.\n\nSee the benchmarks below. Older benchmarks against [DappTools][dapptools] can be found in the [v0.2.0 announcement post][benchmark-post] and in the [Convex Shutdown Simulation][convex] repository.\n\n### Testing Benchmarks\n\n| Project                                       | Type                 | [Forge 1.0][foundry-1.0] | [Forge 0.2][foundry-0.2] | DappTools | Speedup        |\n| --------------------------------------------- | -------------------- | ------------------------ | ------------------------ | --------- | -------------- |\n| [vectorized/solady][solady]                   | Unit / Fuzz          | 0.9s                     | 2.3s                     | -         | 2.6x           |\n| [morpho-org/morpho-blue][morpho-blue]         | Invariant            | 0.7s                     | 1m43s                    | -         | 147.1x         |\n| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cold)   | 6.1s                     | 6.3s                     | -         | 1.04x          |\n| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cached) | 0.6s                     | 0.9s                     | -         | 1.50x          |\n| [transmissions11/solmate][solmate]            | Unit / Fuzz          | 2.7s                     | 2.8s                     | 6m34s     | 1.03x / 140.0x |\n| [reflexer-labs/geb][geb]                      | Unit / Fuzz          | 0.2s                     | 0.4s                     | 23s       | 2.0x / 57.5x   |\n\n_In the above benchmarks, compilation was always skipped_\n\n**Takeaway: Forge dramatically outperforms the competition, delivering blazing-fast execution speeds while continuously expanding its robust feature set.**\n\n### Compilation Benchmarks\n\n<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\".github/assets/build_benchmark_solady_dark.png\" width=\"600px\">\n    <img src=\".github/assets/build_benchmark_solady_light.png\" width=\"600px\">\n  </picture>\n\n<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\".github/assets/build_benchmark_openzeppelin_dark.png\" width=\"600px\">\n    <img src=\".github/assets/build_benchmark_openzeppelin_light.png\" width=\"600px\">\n  </picture>\n\n&nbsp;\n\n</div>\n\n**Takeaway: Forge compilation is consistently faster than Hardhat by a factor of `2.1x` to `5.2x`, depending on\n\n[... truncated ...]"
  },
  "kurtosis-tech/kurtosis": {
    "fetchedAt": "2025-11-12T22:38:04.188Z",
    "content": "\n<img src=\"./readme-static-files/logo.png\" width=\"1200\">\n\n[![Follow us on X, formerly Twitter](https://img.shields.io/twitter/follow/KurtosisTech?style=social)](https://twitter.com/Kurtosistech)\n[![Number of GitHub stars](https://img.shields.io/github/stars/kurtosis-tech/kurtosis)](https://github.com/kurtosis-tech/kurtosis/stargazers)\n\n----\n\nWhat is Kurtosis?\n=================\n\nHave you ever tried to build on top of a colleague's work, or contribute to an open source project, just to get stuck on the first steps of spinning up a stack to play with? [Kurtosis](https://www.kurtosis.com) handles the complexity of spinning up ephemeral dev or test stacks so you can focus on developing, not configuring.\n\nKurtosis is formed of:\n- A packaging system for distributing backend stack definitions, which can run on docker or on kubernetes\n- A runtime with a per-stack file management system for reproducibly initializing the state of your stack\n- A set of tools to enable devs to interact with their stacks, like they do on docker or k8s\n\nWhy use Kurtosis?\n=========================\n\nKurtosis is best for:\n\n- Reusing the logic in your stack definitions for all of: local dev, scheduled testing in CI, and ad-hoc larger-scale testing on k8s clusters\n- Giving other devs a way to spin up your application, and commonly used variations of it, with one-liners, via Kurtosis' packaging and parameterization systems\n- Handling complex setup logic in your backend stack, like passing arbitrary data between services as they start up, and enforcing arbitrary wait conditions\n\nHow is Kurtosis different than Docker Compose or Helm?\n==========================\n\nKurtosis operates at a level higher than Docker Compose or Helm, and produces stacks running on either of the underlying engines (the Docker engine, or Kubernetes).\nBecause of this additional layer of abstraction, we are able to introduce several features to improve the experience of spinning up ephemeral stacks:\n\n- A per-stack file management system that enables portable state initialization for dev or test stacks\n- Stack-level parameterizability; users have a powerful and flexible way (beyond messing with env vars) to affect modifications in their stacks\n- First-class plug-and-play composability; it's expected for users to import stack definitions into larger stacks, and this experience is optimized\n- The ability to get all of the above, but running over _either_ the docker engine or k8s, at your election\n\n`NOTE: we do NOT recommend using Kurtosis to deploy long term production environments at this moment. Any issues/Discords related to production usage will be closed.`\n\nHow do I get going?\n===================\nTo see Kurtosis in action, first install it using the instructions [here](https://docs.kurtosis.com/install).\n\nThen, run the [Redis voting app Kurtosis package](https://github.com/kurtosis-tech/awesome-kurtosis/tree/main/redis-voting-app):\n\n```bash\nkurtosis run github.com/kurtosis-tech/awesome-kurtosis/redis-voting-app\n```\n\n<img src=\"./readme-static-files/redis-voting-app-run-output.png\">\n\nFinally, open the `http` link printed in the last line in your browser.\n\nIf you have an issue or feature request, we'd love to hear about it through one of the following:\n- Post your question on our [Github Discussions Forum](https://github.com/kurtosis-tech/kurtosis/discussions/new?category=q-a)\n- [Asking for help on our Discord server][discord]\n- Filing an issue on our [Github](https://github.com/kurtosis-tech/kurtosis/issues/new/choose) (which can also be done via `kurtosis feedback --bug` or `kurtosis feedback --feature`)\n- [Messaging us on Twitter][twitter]\n\n### Going further\n\nTo try more Kurtosis packages just like this one, check out the [`awesome-kurtosis` repo][awesome-kurtosis]! \n\nTo learn about how to write Kurtosis packages, check out our [quickstart][quickstart-reference].\n\nTo read about how Kurtosis works, see [our documentation][docs].\n\nTo see where we're going with the product, check out the roadmap [here](https://github.com/kurtosis-tech/kurtosis/wiki/Short%E2%80%90term-Roadmap).\n\nGot more questions? Drop them in our [Github Discussions](https://github.com/kurtosis-tech/kurtosis/discussions/new?category=q-a) where we, or other community members, can help answer.\n\nContributing to Kurtosis\n========================\n\n<details>\n<summary>Expand to see contribution info</summary>\n\nSee our [CONTRIBUTING](./CONTRIBUTING.md) file.\n\nRepository Structure\n--------------------\n\nThis repository is structured as a monorepo, containing the following projects:\n- `container-engine-lib`: Library used to abstract away container engine being used by the [enclave][enclave].\n- `core`: Container launched inside an [enclave][enclave] to coordinate its state\n- `engine`: Container launched to coordinate [enclaves][enclave]\n- `api`: Defines the API of the Kurtosis platform (`engine` and `core`)\n- `cli`: Produces CLI binary, allowing interaction with the Kurtosis system\n- `docs`: Documentation that is published to [docs.kurtosis.com](docs)\n- `internal_testsuites`: End to end tests\n\nDev Dependencies (Nix)\n----------------\n\nInstall the [Nix package manager](https://nixos.org/download).\n```bash\nsh <(curl -L https://nixos.org/nix/install)\n```\n\nAnd enable some Nix flags (alternatively you can add `--extra-experimental-features 'nix-command flakes'` every time calling the `nix` command):\n```bash\nmkdir -p ~/.config/nix\necho \"experimental-features = nix-command flakes\" >> ~/.config/nix/nix.conf\n```\n\nAnd to bring the environment up, just open a new shell terminal, go to the root folder of the repo and run:\n```bash\nnix  develop\n```\n\nThis will download all dev deps and setup the environment accordingly.\n\nYou can also use the [`direnv`](https://direnv.net/) to automatically load the environment when entering the main folder or using a plugin in your preferred IDE:\n- `vscode`: [mkhl.direnv](https://github.com/direnv/direnv-vscode)\n- `jet brains`: [Direnv integration](https://plugins.jetbrains.com/plugin/15285-direnv-integration)\n\nDirenv can also be easily installed with Nix (or [HomeBrew](https://formulae.brew.sh/formula/direnv) if you prefer):\n```bash\nnix-env -f '<nixpkgs>' -iA direnv\n```\n\nNow you just to add the direnv hook to your shell:\n```bash\necho 'eval \"$(direnv hook bash)\"' >> ~/.bashrc\n# or for ZSH\necho 'eval \"$(direnv hook zsh)\"' >> ~/.zshrc\n```\n\nNow next time you open a new shell terminal and go to repo's folder you environment will update and load automatically.\n\nDev Dependencies (Manual install)\n----------------\n\nThe commands below assume that the env variable BREW_PREFIX contains the brew prefix.\n```bash\nBREW_PREFIX=\"$(brew --prefix)\"\n```\n\n#### Bash (5 or above)\n\nOn MacOS:\n```bash\n# Install modern version of bash, the one that ships on MacOS is too old\nbrew install bash\n# Allow bash as shell\necho \"${BREW_PREFIX}/bin/bash\" | sudo tee -a /etc/shells\n# Optional: make bash your default shell\nchsh -s \"${BREW_PREFIX}/bin/bash\"\n```\n\n#### Git\n\nOn MacOS:\n```bash\n# Install modern version of git, the one that ships on MacOS can be too old\nbrew install git\n```\n\n#### Docker\n\nOn MacOS:\n```bash\nbrew install docker\n```\n\n#### Go (1.23 or above)\n\nOn MacOS:\n```bash\nbrew install go@1.23\n# Add the Go binary dir to your PATH\nPATH=\"${BREW_PREFIX}/opt/go@1.23/bin:$PATH\"\n# Add the GOPATH bin dir to your PATH\nPATH=\"${HOME}/go/bin:$PATH\"\n```\n\nOn Ubuntu:\n```bash\nwget https://go.dev/dl/go1.23.7.linux-amd64.tar.gz\ntar -C /usr/local -zxf go1.23.7.linux-amd64.tar.gz\n# Add the following to your bashrc or equivalent.\nexport PATH=$PATH:/usr/local/go/bin\n```\n\n#### Goreleaser\n\nOn MacOS:\n```bash\nbrew install goreleaser/tap/goreleaser\n```\n\nOn Ubuntu:\n```bash\necho 'deb [trusted=yes] https://repo.goreleaser.com/apt/ /' | sudo tee /etc/apt/sources.list.d/goreleaser.list\nsudo apt update\nsudo apt install goreleaser\n```\n\n#### Node (20.* or above) and Yarn\n\nOn MacOS, using `NVM`:\n```bash\nbrew install nvm\nmkdir ~/.nvm\nnvm install 20.11.0\nnpm install -g yarn\n```\n\nOn Ubuntu, using `NVM`:\n```bash\nc\n\n[... truncated ...]"
  },
  "etherspot/skandha": {
    "fetchedAt": "2025-11-12T22:38:15.067Z",
    "content": "<div align=\"center\">\n  <h1 align=\"center\">Skandha</h1>\n</div>\n\n<!-- PROJECT LOGO -->\n\n<div align=\"center\">\n  <img src=\"https://public.etherspot.io/assets/etherspot.gif\" width=\"200\" height=\"200\">\n  <p>\n    <b>\n      A modular, developer-friendly Typescript Bundler for Ethereum EIP-4337 Account Abstraction\n    </b>\n   </p>\n</div>\n\n<div align=\"center\">\n  <p>\n    <b>\n       Warning! This repo/software is under active development\n    </b>\n   </p>\n</div>\n\n> [!IMPORTANT]\n> **Skandha v1** - supports EntryPoint 0.6.0 and can be found on [releases/v0.6](https://github.com/etherspot/skandha/tree/releases/v0.6)\n> \n> **Skandha v2** - supports EntryPoint 0.7.0 and can be found on [releases/v0.7](https://github.com/etherspot/skandha/tree/releases/v0.7)\n> \n> **Skandha v3** - supports EntryPoint 0.8.0 and can be found on [master](https://github.com/etherspot/skandha/tree/master)\n\n## Important links\n\n**[Install Skandha](https://etherspot.fyi/skandha/installation)**\n| [Chains supported](https://etherspot.fyi/prime-sdk/chains-supported)\n| [UserOp Fee history](https://etherspot.fyi/skandha/feehistory)\n\n## ‚öôÔ∏è How to run (from Source code)\n\nRun with one-liner:\n\n```sh\ncurl -fsSL https://skandha.run | bash\n```\nOr follow the steps below:\n\n1. install all dependencies by running `bun install`\n2. patch for bcrypto `cd ./node_modules/bcrypto && bun install`\n3. build `bun build`\n4. `cp config.json.default config.json`\n5. edit `config.json`\n6. (optional) run local geth-node from `test/geth-dev`\n7. run `./skandha standalone`\n8. The bundler will be available on `http://localhost:14337/rpc/`\n\n## üê≥ How to run (a Docker image)\n\n1. `cp config.json.default config.json`\n2. edit `config.json`\n3. `docker build -t etherspot/skandha .`\n4. `docker run --mount type=bind,source=\"$(pwd)\"/config.json,target=/usr/app/config.json,readonly -dp 14337:14337 etherspot/skandha standalone`\n\n\n## üìú Additional features\n- [x] Unsafe mode - bypass opcode & stake validation\n- [x] Redirect RPC - Redirect ETH rpc calls to the underlying execution client. This is needed if you use UserOp.js\n\n### ‚ö°Ô∏è CLI Options\n- `--unsafeMode` - enables unsafeMode\n- `--redirectRpc` - enables redirecting eth rpc calls\n- `--executor.bundlingMode manual|auto` - sets bundling mode to `manual` or `auto` on start. Default value is `auto`\n- `--metrics.enable false|true` - enable Prometheus metrics (default - `false`)\n- `--metrics.host` - metrics host (default - `127.0.0.1`)\n- `--metrics.port` - metrics port (default - `8008`)\n\n## üîë Relayer Configuration\n\n#### Simplest config.json\n```yaml\n{\n  \"entryPoints\": [\n    \"0x0000000071727De22E5E9d8BAf0edAc6f37da032\"\n  ],\n  \"relayers\": [\n    \"0x{RELAYER-PRIVATE-KEY}\"\n  ],\n  \"rpcEndpoint\": \"https://polygon-mumbai.blockpi.network/v1/rpc/public\"\n}\n```\n\n#### config.json with a default value of each config parameter\n\n```yaml\n{\n  \"entryPoints\": [ # supported entry points\n    \"0x0000000071727De22E5E9d8BAf0edAc6f37da032\"\n  ],\n  \"relayers\": [\n    \"0x0101010101010101010101010101010101010101010101010101010101010101\",\n    \"test test test test test test test test test test test junk\"\n  ], # relayers private keys, can access from here or via environment variables (SKANDHA_MUMBAI_RELAYERS | SKANDHA_DEV_RELAYERS | etc.)\n  \"beneficiary\": \"0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266\", # optional, fee collector, avaiable via env var (SKANDHA_MUMBAI_BENEFICIARY | etc) - if not set, relayer will be used\n  \"rpcEndpoint\": \"http://localhost:8545\", # rpc provider, also available via env variable (SKANDHA_MUMBAI_RPC | etc)\n  \"minInclusionDenominator\": 10, # optional, see EIP-4337\n  \"throttlingSlack\": 10, # optional, see EIP-4337\n  \"banSlack\": 50 # optional, see EIP-4337\n  \"minStake\": 10000000000, # optional, min stake of an entity (in wei)\n  \"minUnstakeDelay\": 0, # optional, min unstake delay of an entity\n  \"minSignerBalance\": 1, # optional, default is 0.1 ETH. If the relayer's balance drops lower than this, it will be selected as a fee collector\n  \"multicall\": \"0xcA11bde05977b3631167028862bE2a173976CA11\", # optional, multicall3 contract (see https://github.com/mds1/multicall#multicall3-contract-addresses)\n  \"estimationStaticBuffer\": 21000, # optional,adds certain amount of gas to callGasLimit on estimation\n  \"validationGasLimit\": 10e6, # optional,gas limit during simulateHandleOps and simulateValidation calls\n  \"receiptLookupRange\": 1024, # optional,limits the block range of getUserOperationByHash and getUserOperationReceipt\n  \"etherscanApiKey\": \"\", # optional,etherscan api is used to fetch gas prices\n  \"conditionalTransactions\": false, # optional,enable conditional transactions\n  \"rpcEndpointSubmit\": \"\", # optional,rpc endpoint that is used only during submission of a bundle\n  \"gasPriceMarkup\": 0, # optional,adds % markup on reported gas price via skandha_getGasPrice, 10000 = 100.00%, 500 = 5%\n  \"enforceGasPrice\": false, # optional,do not bundle userops with low gas prices\n  \"enforceGasPriceThreshold\": 1000, # optional,gas price threshold in bps. If set to 500, userops' gas price is allowed to be 5% lower than the network's gas price\n  \"eip2930\": false, # optional, enables eip-2930\n  \"useropsTTL\": 300, # optional, Userops time to live (in seconds)\n  \"whitelistedEntities\": { # optional, Entities that bypass stake and opcode validation (array of addresses)\n    \"factory\": [],\n    \"paymaster\": [],\n    \"account\": []\n  },\n  \"bundleGasLimitMarkup\": 25000, # optional, adds some amount of additional gas to a bundle tx\n  \"relayingMode\": \"classic\"; # optional, \"flashbots\" for Flashbots Builder API, \"merkle\" for Merkle.io\n  \"bundleInterval\": 10000, # bundle creation interval\n  \"bundleSize\": 4, # optional, max size of a bundle, 4 userops by default\n  \"pvgMarkup\": 0 # optional, adds some gas on top of estimated PVG\n}\n```\n## üí¨ Contact\n\nIf you have any questions or feedback about the ERC-4337 Bundler project, please feel free to reach out to us.\n\n- [Follow on Twitter](https://twitter.com/etherspot)\n- [Join our discord](https://discord.etherspot.io/)\n\n## üìÑ License\n\nLicensed under the [MIT License](https://github.com/etherspot/skandha/blob/master/LICENSE).\n\n## ü§ù Shared Mempool (P2P)\n\n> [!WARNING]  \n> This version of the bundler only supports Entry Point v7, which does not have the p2p mempool yet.\n\n\n## üî¢ Statistics\n![Alt](https://repobeats.axiom.co/api/embed/4d7ec3ece88b2461c5b1757574321f4f6540cdd5.svg \"Skandha analytics image\")\n\n## üôè Acknowledgements\n\n- [eth-infinitism](https://github.com/eth-infinitism)\n- [lodestar](https://github.com/ChainSafe/lodestar) \n"
  },
  "erpc/erpc": {
    "fetchedAt": "2025-11-12T22:38:22.156Z",
    "content": "<p align=\"center\">\n  <img src=\"https://i.imgur.com/sa4MhlS.png\" alt=\"eRPC Hero\" />\n</p>\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/erpc/erpc/release.yml?branch=main&style=flat&colorA=000000&colorB=000000)](https://github.com/erpc/erpc/actions/workflows/release.yml)\n[![Docs](https://img.shields.io/badge/docs-get%20started-brightgreen?style=flat&colorA=000000&colorB=000000)](https://docs.erpc.cloud/)\n[![License](https://img.shields.io/github/license/erpc/erpc?style=flat&colorA=000000&colorB=000000)](https://github.com/erpc/erpc/blob/main/LICENSE)\n[![Contributors](https://img.shields.io/github/contributors/erpc/erpc?style=flat&colorA=000000&colorB=000000)](https://github.com/erpc/erpc/graphs/contributors)\n[![Telegram](https://img.shields.io/endpoint?logo=telegram&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ferpc_cloud&style=flat&colorA=000000&colorB=000000&label=telegram)](https://t.me/erpc_cloud)\n\neRPC is a fault-tolerant EVM RPC proxy and **re-org aware permanent caching solution**. It is built with read-heavy use-cases in mind, such as data indexing and high-load frontend usage.\n\n<img src=\"./assets/hla-diagram.svg\" alt=\"Architecture Diagram\" width=\"70%\" />\n\n---\n\n### Quick Start\n\nWith the below setup, you get immediate access to 2,000+ chains and 4,000+ public free EVM RPC endpoints.\n\n#### Run an eRPC instance:\n\nUsing `npx`:\n\n```bash\nnpx start-erpc\n```\n\nOr, using `Docker`:\n\n```bash\ndocker run -p 4000:4000 ghcr.io/erpc/erpc\n```\n\nOr, using `Railway`:\n\n[![Deploy on Railway](https://railway.app/button.svg)](https://railway.com/template/10iW1q?referralCode=PpPFJd)\n\n#### Send a request to your eRPC instance:\n\n```bash\ncurl 'http://localhost:4000/main/evm/42161' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"method\": \"eth_getBlockByNumber\",\n    \"params\": [\"latest\", false],\n    \"id\": 9199,\n    \"jsonrpc\": \"2.0\"\n}'\n```\n\n#### Next Steps:\nThis setup is ideal for development and testing purposes. For production environments, we recommend extending your configuration with dedicated premium providers and advanced failover settings. See our [Configuration Guide](https://docs.erpc.cloud/config/example) for more details.\n\n---\n\n### Key Features\n\n- **Retries, circuit breakers, failovers, and hedged requests**: Ensures the fastest, most reliable upstream is always used  \n- **Configurable rate limits**: Set hourly or daily [rate limits](https://docs.erpc.cloud/config/rate-limiters) per upstream to control usage and costs  \n- **Local re-org aware cache**: Avoid redundant upstream calls and maintain data consistency when blockchain reorgs occur  \n- **Automatic method routing**: No need to worry which provider supports which `eth_*` method  \n- **Unified error handling**: Consistent error codes and detailed messages across multiple providers  \n- **Single dashboard**: Observe throughput (RPS), errors, and average latency across all providers  \n- **Flexible authentication**: Supports [basic auth, secrets, JWT, SIWE](https://docs.erpc.cloud/config/auth) and more  \n- **Smart batching**: [Aggregate multiple RPC or contract calls into one](https://docs.erpc.cloud/operation/batch)\n- **Selection policy**: Allows you to influence how upstreams are selected to serve traffic (or not) w/ [selection policies](https://docs.erpc.cloud/config/projects/selection-policies).\n- **Data integrity**: Ensures accurate, up-to-date responses by levering several [data integrity mechanisms](https://docs.erpc.cloud/config/failsafe/integrity).\n- **Consensus policy**: Compares results from multiple upstreams and punishes nodes that consistently disagree.\n\n---\n\n### Case Studies\n\n- üîµ [Moonwell: How eRPC slashed RPC calls by 67%](https://erpc.cloud/case-studies/moonwell)  \n- üü¢ [Chronicle: How eRPC reduced RPC cost by 45%](https://erpc.cloud/case-studies/chronicle)\n\n---\n\n### Local Development\n\n1. **Clone this repository:**\n\n```bash\ngit clone https://github.com/erpc/erpc.git\n```\n\n2. **Install Go dependencies:**\n\n```bash\nmake setup\n```\n\n3. **Create a configuration file:**\n\n```bash\ncp erpc.dist.yaml erpc.yaml\nvi erpc.yaml\n```\n\n4. **Run the eRPC server:**\n\n```bash\nmake run\n```\n\n---\n\n### Contributors\n\n<a href=\"https://github.com/erpc/erpc/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=erpc/erpc&max=50&columns=10&anon=1\" alt=\"Contributors\" />\n</a>\n\n<p>\n  By contributing to this project, you agree that your contributions may be used in both the open-source and enterprise versions of the software. Please review our \n  <a href=\"./CONTRIBUTING.md\">Contributing Guidelines</a> and \n  <a href=\"./CLA.md\">Contributor License Agreement</a> before submitting your contributions.\n</p>\n\n---\n\n### License\n\nApache 2.0 \n"
  },
  "miguelmota/go-ethereum-hdwallet": {
    "fetchedAt": "2025-11-12T22:38:30.268Z",
    "content": "<h3 align=\"center\">\n  <br />\n  <img src=\"https://github.com/miguelmota/go-ethereum-hdwallet/assets/168240/20a63a4b-cb97-4e23-8f59-e89d0fd91882\" alt=\"logo\" width=\"600\" />\n  <br />\n  <br />\n  <br />\n</h3>\n\n# go-ethereum-hdwallet\n\n> Ethereum HD Wallet derivations from [mnemonic] seed in Go (golang). Implements the [go-ethereum](https://github.com/ethereum/go-ethereum) [`accounts.Wallet`](https://github.com/ethereum/go-ethereum/blob/master/accounts/accounts.go) interface.\n\n[![License](http://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/miguelmota/go-ethereum-hdwallet/master/LICENSE)\n[![Build Status](https://travis-ci.org/miguelmota/go-ethereum-hdwallet.svg?branch=master)](https://travis-ci.org/miguelmota/go-ethereum-hdwallet)\n[![Go Report Card](https://goreportcard.com/badge/github.com/miguelmota/go-ethereum-hdwallet?)](https://goreportcard.com/report/github.com/miguelmota/go-ethereum-hdwallet)\n[![GoDoc](https://godoc.org/github.com/miguelmota/go-ethereum-hdwallet?status.svg)](https://godoc.org/github.com/miguelmota/go-ethereum-hdwallet)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](#contributing)\n\n## Install\n\n```bash\ngo get -u github.com/miguelmota/go-ethereum-hdwallet\n```\n\n## Documenation\n\n[https://godoc.org/github.com/miguelmota/go-ethereum-hdwallet](https://godoc.org/github.com/miguelmota/go-ethereum-hdwallet)\n\n## Getting started\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\n\t\"github.com/miguelmota/go-ethereum-hdwallet\"\n)\n\nfunc main() {\n\tmnemonic := \"tag volcano eight thank tide danger coast health above argue embrace heavy\"\n\twallet, err := hdwallet.NewFromMnemonic(mnemonic)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tpath := hdwallet.MustParseDerivationPath(\"m/44'/60'/0'/0/0\")\n\taccount, err := wallet.Derive(path, false)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Println(account.Address.Hex()) // 0xC49926C4124cEe1cbA0Ea94Ea31a6c12318df947\n\n\tpath = hdwallet.MustParseDerivationPath(\"m/44'/60'/0'/0/1\")\n\taccount, err = wallet.Derive(path, false)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfmt.Println(account.Address.Hex()) // 0x8230645aC28A4EdD1b0B53E7Cd8019744E9dD559\n}\n```\n\n### Signing transaction\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\t\"math/big\"\n\n\t\"github.com/davecgh/go-spew/spew\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/miguelmota/go-ethereum-hdwallet\"\n)\n\nfunc main() {\n\tmnemonic := \"tag volcano eight thank tide danger coast health above argue embrace heavy\"\n\twallet, err := hdwallet.NewFromMnemonic(mnemonic)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tpath := hdwallet.MustParseDerivationPath(\"m/44'/60'/0'/0/0\")\n\taccount, err := wallet.Derive(path, true)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tnonce := uint64(0)\n\tvalue := big.NewInt(1000000000000000000)\n\ttoAddress := common.HexToAddress(\"0x0\")\n\tgasLimit := uint64(21000)\n\tgasPrice := big.NewInt(21000000000)\n\tvar data []byte\n\n\ttx := types.NewTransaction(nonce, toAddress, value, gasLimit, gasPrice, data)\n\tsignedTx, err := wallet.SignTx(account, tx, nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tspew.Dump(signedTx)\n}\n```\n\n## CLI\n\n```bash\ngo install github.com/miguelmota/go-ethereum-hdwallet/cmd/geth-hdwallet@latest\n```\n\n```bash\n$ geth-hdwallet -mnemonic \"tag volcano eight thank tide danger coast health above argue embrace heavy\" -path \"m/44'/60'/0'/0/0\"\n\npublic address: 0xC49926C4124cEe1cbA0Ea94Ea31a6c12318df947\nprivate key: 63e21d10fd50155dbba0e7d3f7431a400b84b4c2ac1ee38872f82448fe3ecfb9\n```\n\n## Development\n\nBuild CLI:\n\n```bash\nmake build\n```\n\nFormat code:\n\n```bash\nmake format\n```\n\n### Test\n\nRun tests:\n\n```bash\nmake test\n```\n\n### Release\n\nGit tag after committing latest changes:\n\n```bash\ngit tag v0.1.x\n```\n\nCreate a release with [goreleaser](https://github.com/goreleaser/goreleaser):\n\n```bash\nmake release\n```\n\n## Contributing\n\nPull requests are welcome!\n\nFor contributions please create a new branch and submit a pull request for review.\n\n## License\n\nReleased under the [MIT](./LICENSE) license.\n\n¬© [Miguel Mota](https://github.com/miguelmota)\n"
  },
  "PraneshASP/foundry-mcp-server": {
    "fetchedAt": "2025-11-12T22:38:37.200Z",
    "content": "# Foundry MCP Server\n\nA simple, lightweight and fast MCP (Model Context Protocol) server that provides Solidity development capabilities using the Foundry toolchain (Forge, Cast, and Anvil).\n\n![Foundry MCP Demo](./assets/analysis_gif.gif)\n\n## Overview\n\nThis server connects LLM assistants to the Foundry ecosystem, enabling them to:\n\n- Interact with nodes (local Anvil instances or remote RPC endpoints)\n- Analyze smart contracts and blockchain data\n- Perform common EVM operations using Cast\n- Manage, deploy, and execute Solidity code and scripts\n- Work with a persistent Forge workspace\n\n## Features\n\n### Network Interaction\n\n- Start and manage local Anvil instances\n- Connect to any remote network (just specify the RPC)\n- Get network/chain information\n\n### Contract Interaction\n\n- Call contract functions (read-only)\n- Send transactions to contracts (if `PRIVATE_KEY` is configured)\n- Get transaction receipts\n- Read contract storage\n- Analyze transaction traces\n- Retrieve contract ABIs and sources from block explorers\n\n### Solidity Development\n\n- Maintain a dedicated Forge workspace\n- Create and edit Solidity files\n- Install dependencies\n- Run Forge scripts\n- Deploy contracts\n\n### Utility Functions\n\n- Calculate contract addresses\n- Check contract bytecode size\n- Estimate gas costs\n- Convert between units (hex to decimals, etc.,)\n- Generate wallets\n- Get event logs\n- Lookup function and event signatures\n\n### Smart Contract Analysis (Heimdall)\n\n- Disassemble EVM bytecode into human-readable opcodes\n- Decode raw calldata without requiring ABI\n- Decompile EVM bytecode to Solidity source code and ABI\n- Generate visual control flow graphs for EVM bytecode\n- Detailed transaction inspection with calldata decoding and trace analysis\n\n## Usage\n\nThe server is designed to be used as an MCP tool provider for MCP Clients. When connected to a client, it enables the clients(claude desktop, cursor, client, etc.,) to perform Solidity and onchain operations directly.\n\n\n#### Requirements\n\n- [Node.js v18+](https://nodejs.org)\n- [Foundry toolchain](https://book.getfoundry.sh/) (Forge, Cast, Anvil)\n- [Heimdall-rs](https://github.com/Jon-Becker/heimdall-rs) (for smart contract analysis)\n  \n### Manual Setup\n\n1. Ensure Foundry tools (Forge, Cast, Anvil) are installed on your system:\n   ```\n   curl -L https://foundry.paradigm.xyz | bash\n   foundryup\n   ```\n2. Clone and build the server.\n\n    ```sh\n    bun i && bun build ./src/index.ts --outdir ./dist --target node\n   \n3. Update your client config (eg: Claude desktop):\n\n```json\n \"mcpServers\": {\n    \"foundry\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"path/to/foundry-mcp-server/dist/index.js\"\n      ],\n      \"env\" :{\n        \"PRIVATE_KEY\": \"0x1234\",\n      }\n    }\n }\n```\n\n> [!NOTE]\n> `PRIVATE_KEY` is optional \n\n\n### Setup using NPM Package\n\nYou can now install and run the server directly using npm:\n\n#### Global Installation\n```bash\nnpm install -g @pranesh.asp/foundry-mcp-server\n```\n\n#### Direct Usage with npx\n```bash\nnpx @pranesh.asp/foundry-mcp-server\n```\n\n#### MCP Client Configuration\n\n**Claude Code**\n\n```bash\n claude mcp add-json foundry-mcp-server '{\"type\":\"stdio\",\"command\":\"npx\",\"args\":[\"@pranesh.asp/foundry-mcp-server\"],\"env\":{\"RPC_URL\": \"\", \"\"PRIVATE_KEY\":\"\"}}'   \n```\n\n**Other MCP Clients (Cursor, Claude, Windsurf)**\n\nAdd to your MCP settings:\n\n```json\n{\n  \"mcpServers\": {\n    \"foundry\": {\n      \"command\": \"npx\",\n      \"args\": [\"@pranesh.asp/foundry-mcp-server\"],\n      \"env\": {\n        \"RPC_URL\": \"http://localhost:8545\",\n        \"PRIVATE_KEY\": \"0x...\"\n      }\n    }\n  }\n}\n```\n\n\n#### Configuration\n\nThe server supports the following environment variables:\n\n- `RPC_URL`: Default RPC URL to use when none is specified (optional)\n- `PRIVATE_KEY`: Private key to use for transactions (optional)\n\n> [!CAUTION]\n> Do not add keys with mainnet funds. Even though the code uses it safely, LLMs can hallicunate and send malicious transactions. \n> Use it only for testing/development purposes. DO NOT trust the LLM!!\n\n### Workspace\n\nThe server maintains a persistent Forge workspace at `~/.mcp-foundry-workspace` for all Solidity files, scripts, and dependencies.\n\n## Tools\n\n### Anvil \n\n- `anvil_start`: Start a new Anvil instance\n- `anvil_stop`: Stop a running Anvil instance\n- `anvil_status`: Check if Anvil is running and get its status\n\n### Cast  \n\n- `cast_call`: Call a contract function (read-only)\n- `cast_send`: Send a transaction to a contract function\n- `cast_balance`: Check the ETH balance of an address\n- `cast_receipt`: Get the transaction receipt\n- `cast_storage`: Read contract storage at a specific slot\n- `cast_run`: Run a published transaction in a local environment\n- `cast_logs`: Get logs by signature or topic\n- `cast_sig`: Get the selector for a function or event signature\n- `cast_4byte`: Lookup function or event signature from the 4byte directory\n- `cast_chain`: Get information about the current chain\n\n### Forge\n\n- `forge_script`: Run a Forge script from the workspace\n- `install_dependency`: Install a dependency for the Forge workspace\n\n### File Management\n\n- `create_solidity_file`: Create or update a Solidity file in the workspace\n- `read_file`: Read the content of a file from the workspace\n- `list_files`: List files in the workspace\n\n### Utilities\n\n- `convert_eth_units`: Convert between EVM units (wei, gwei, hex)\n- `compute_address`: Compute the address of a contract that would be deployed\n- `contract_size`: Get the bytecode size of a deployed contract\n- `estimate_gas`: Estimate the gas cost of a transaction\n\n### Heimdall Analysis\n\n- `heimdall_disassemble`: Disassemble EVM bytecode into human-readable opcodes\n- `heimdall_decode`: Decode raw calldata without requiring ABI\n- `heimdall_decompile`: Decompile EVM bytecode to Solidity source code and ABI\n- `heimdall_cfg`: Generate visual control flow graph for EVM bytecode\n- `heimdall_inspect`: Detailed inspection of Ethereum transactions\n\n## Usage in Claude Desktop App üéØ\n\nOnce the installation is complete, and the Claude desktop app is configured, you must completely close and re-open the Claude desktop app to see the tavily-mcp server. You should see a hammer icon in the bottom left of the app, indicating available MCP tools, you can click on the hammer icon to see more details on the available tools.\n\n![Alt text](./assets/tools.png)\n\nNow claude will have complete access to the foundry-mcp server. If you insert the below examples into the Claude desktop app, you should see the foundry-mcp server tools in action.\n\n### Examples\n\n1. **Transaction analysis**:\n```\nCan you analyze the transaction and explain what it does? \nhttps://etherscan.io/tx/0xcb73ad3116f19358e2e649d4dc801b7ae0590a47b8bb2e57a8e98b6daa5fb14b\n```\n\n2. **Querying Balances**:\n```\nQuery the mainnet ETH and USDT balances for the wallet 0x195F46025a6926968a1b3275822096eB12D97E70.\n```\n3.  **Sending transactions**:\n```\nTransfer 0.5 USDC to 0x195F46025a6926968a1b3275822096eB12D97E70 on Mainnet. \n```\n\n4. **Deploying contracts/Running scripts**:\n```\nDeploy a mock ERC20 contract to a local anvil instance and name it \"Fire Coin\".\n```\n\n\n## Acknowledgments ‚ú®\n\n- [Model Context Protocol](https://modelcontextprotocol.io) for the MCP specification\n- [Anthropic](https://anthropic.com) for Claude Desktop\n\n## Disclaimer\n\n_The software is being provided as is. No guarantee, representation or warranty is being made, express or implied, as to the safety or correctness of the software. They have not been audited and as such there can be no assurance they will work as intended, and users may experience delays, failures, errors, omissions, loss of transmitted information or loss of funds. The creators are not liable for any of the foregoing. Users should proceed with caution and use at their own risk._"
  },
  "builders-garden/miniapp-next-template": {
    "fetchedAt": "2025-11-12T22:38:45.052Z",
    "content": "## This template provides a minimal setup to get Next.js working with MiniKit and Frames.js\n\n## Setup\n\n```bash\ncp .env.example .env\nyarn \nyarn dev\n\n```\n\nTo run as a mini app choose a production app in the dev portal and use NGROK to tunnel. Set the `NEXTAUTH_URL` and the redirect url if using sign in with worldcoin to that ngrok url\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nTo use the application, you'll need to:\n\n## Frames.js\n\n- **Generate the account credentials**\n  1. Run `yarn frames`\n  2. Select `Frames v2`\n  3. Sign in with Farcaster (you have to pay 10 warps on Warpcast)\n  4. Now you can associate your domain with the account\n     - Click `Generate` on Domain Account Association\n     - Insert the domain you are using (default to `http://localhost:3000/`)\n     - Then you will be asked to sign with your wallet to generate the signature\n     - Copy the JSON object and paste it in the `account` object in the file `public/.well-known/farcaster.json`\n        ```json\n        {\n          \"account\": { // paste it here\n            \"header\": \"...\",\n            \"payload\": \"...\",\n            \"signature\": \"...\"\n          },\n          \"frame\": {\n            ...\n          }\n        }\n        ```\n     - Now you can debug your frame locally\n\n\n## WorldCoin\n\n1. **Get World ID Credentials**\n   From the [World ID Developer Portal](https://developer.worldcoin.org/):\n\n   - Create a new app to get your `APP_ID`\n   - Get `DEV_PORTAL_API_KEY` from the API Keys section\n   - Navigate to \"Sign in with World ID\" page to get:\n     - `WLD_CLIENT_ID`\n     - `WLD_CLIENT_SECRET`\n\n2. **Configure Action**\n   - In the Developer Portal, create an action in the \"Incognito Actions\" section\n   - Use the same action name in `components/Verify/index.tsx`\n\nView docs: [Docs](https://docs.world.org/)\n\n[Developer Portal](https://developer.worldcoin.org/)\n\n\n## Deploy\n\nRemember to update your env variables accordingly, especially \n```bash\nNEXT_PUBLIC_URL=\"https://your-domain.com\"\nNEXT_PUBLIC_APP_ENV=\"production\" # Eruda provider\n```"
  },
  "builders-garden/frames-v2-starter": {
    "fetchedAt": "2025-11-12T22:38:45.586Z",
    "content": "# Frames v2 Starter Kit\n\nA full-featured starter kit for building Farcaster Frames v2 applications with Next.js. This project provides a robust foundation with authentication, notifications, and essential tooling pre-configured.\n\n## Features\n\n- üîê **Authentication** - Built-in Farcaster authentication using Frame SDK\n- üì® **Notifications** - Ready-to-use Frame notifications system\n- üîÑ **State Management** - TanStack Query for efficient server state management\n- üé® **Styling** - Tailwind CSS for rapid UI development\n- üìä **Analytics** - PostHog integration for tracking user interactions\n- üêõ **Error Tracking** - Sentry integration for monitoring errors\n- üîç **Type Safety** - Full TypeScript support\n- üöÄ **API Routes** - Pre-configured API endpoints for user management\n- üíæ **Database** - Redis integration for data persistence\n- ‚ö° **Background Jobs** - QStash integration for handling async tasks\n\n## Prerequisites\n\n- Node.js 18+\n- Redis database (Upstash recommended)\n- Neynar API key\n- PostHog account (optional)\n- Sentry account (optional)\n\n## Getting Started\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/builders-garden/frames-v2-starter\ncd frames-v2-starter\n````\n\n2. Install dependencies:\n\n```bash\nnpm install\n# or\nyarn install\n# or\npnpm install\n```\n\n3. Create a `.env` file based on `.env.sample`:\n\n```env\nNEXT_PUBLIC_URL=http://localhost:3000\nJWT_SECRET=your-secret-key\nNEYNAR_API_KEY=your-neynar-api-key\nKV_API_URL=your-redis-url\nKV_API_TOKEN=your-redis-token\nQSTASH_TOKEN=your-qstash-token\nQSTASH_CURRENT_SIGNING_KEY=your-qstash-signing-key\nNEXT_PUBLIC_POSTHOG_KEY=your-posthog-key\nNEXT_PUBLIC_POSTHOG_HOST=your-posthog-host\n```\n\n4. Run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n```\n\n5. Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\n## Testing Your Frame\n1. Run yarn frames\n2. Generate domain account association for http://localhost:3000\n3. Paste it in your manifest (farcaster.json)\n4. Debug and Test interactions from the debugger\n\n## Project Structure\n\n```\n‚îú‚îÄ‚îÄ app/                # Next.js app router pages and API routes\n‚îú‚îÄ‚îÄ components/         # React components\n‚îú‚îÄ‚îÄ hooks/             # Custom React hooks\n‚îú‚îÄ‚îÄ lib/               # Utility functions and configurations\n‚îú‚îÄ‚îÄ public/            # Static assets\n‚îî‚îÄ‚îÄ types/             # TypeScript type definitions\n```\n\n## Key Components\n\n- `components/Demo.tsx` - Example component showing Frame authentication\n- `hooks/use-sign-in.ts` - Hook for handling Farcaster authentication\n- `lib/notifications.ts` - Frame notifications implementation\n- `lib/db/index.ts` - Database operations\n- `middleware.ts` - API route authentication\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## License\n\nMIT License - feel free to use this starter kit for any project.\n\n## Support\n\nIf you have any questions or need help, please open an issue in the repository.\n"
  },
  "builders-garden/base-minikit-starter": {
    "fetchedAt": "2025-11-12T22:38:45.899Z",
    "content": "# Farcaster Mini App Template w/ Base MiniKit\n\nThis is a [Next.js](https://nextjs.org) starter kit bootstrapped from [Mini App Next Template](https://github.com/builders-garden/miniapp-next-template)\n\n- [MiniKit](https://docs.base.org/builderkits/minikit/overview)\n- [Farcaster Mini Apps](https://miniapps.xyz)\n- [OnchainKit Documentation](https://docs.base.org/builderkits/onchainkit/getting-started)\n- [Tailwind CSS](https://tailwindcss.com)\n- [Next.js](https://nextjs.org/docs)\n- [Neynar](https://neynar.com)\n\n## Getting Started\n\n1. Install dependencies:\n\n```bash\nnpm install\n# or\nyarn install\n# or\npnpm install\n# or\nbun install\n```\n\n2. Verify environment variables:\n\nThe environment variables enable the following features:\n\n- Frame metadata - Sets up the Frame Embed that will be shown when you cast your frame\n- Account assocation - Allows users to add your frame to their account, enables notifications\n- Redis API keys - Enable Webhooks and background notifications for your application by storing users notification details\n\n```bash\n# Required for Frame metadata\nNEXT_PUBLIC_URL=\nNEXT_PUBLIC_MINIKIT_PROJECT_ID=\n\n# Required to allow users to add your frame\nNEXT_PUBLIC_FARCASTER_HEADER=\nNEXT_PUBLIC_FARCASTER_PAYLOAD=\nNEXT_PUBLIC_FARCASTER_SIGNATURE=\n\n# Required for user authentication\nNEYNAR_API_KEY=\nJWT_SECRET=\n\n# Required for webhooks and background notifications\nREDIS_URL=\nREDIS_TOKEN=\n```\n\n3. Start the development server:\n\n```bash\nnpm run dev\n```\n\n4. Run a local tunneling server\n\n- [NGROK](https://ngrok.com)\n- [Local Tunnel](https://theboroer.github.io/localtunnel-www/)\n\n5. Generate your Farcaster Manifest variables\n\n- Follow these [instructions](https://miniapps.farcaster.xyz/docs/guides/publishing)\n- Visit [Manifest Tool](https://warpcast.com/~/developers/mini-apps/manifest)\n- Paste your tunnel domain\n\n## Template Features\n\n### Frame Configuration\n\n- `.well-known/farcaster.json` endpoint configured for Frame metadata and account association\n- Frame metadata automatically added to page headers in `layout.tsx`\n\n### Background Notifications\n\n- Redis-backed notification system using Upstash\n- Ready-to-use notification endpoints in `api/notify` and `api/webhook`\n- Notification client utilities in `lib/notification-client.ts`\n\n### MiniKit Provider\n\nThe app is wrapped with `MiniKitProvider` in `providers.tsx`, configured with:\n\n- OnchainKit integration\n- Access to Frames context\n- Sets up Wagmi Connectors\n- Sets up Frame SDK listeners\n- Applies Safe Area Insets\n\n### Dynamic Preview Images\n\n- `dynamic-image-example/[id]/page.tsx` show how to create a Mini App URL resolving to a custom preview image\n- `api/og/example/[id]/route.ts` shows how to generate a custom preview image\n\n## Learn More\n\n- [MiniKit Documentation](https://docs.base.org/builderkits/minikit/overview)\n- [OnchainKit Documentation](https://docs.base.org/builderkits/onchainkit/getting-started)\n- [Farcaster Mini Apps](https://miniapps.xyz)\n- [Next.js Documentation](https://nextjs.org/docs)\n- [Tailwind CSS Documentation](https://tailwindcss.com/docs)\n- [Neynar](https://neynar.com)\n"
  },
  "builders-garden/farcaster-miniapp-starter": {
    "fetchedAt": "2025-11-12T22:38:46.250Z",
    "content": "# Farcaster Mini App Template\n\nThis is a [Next.js](https://nextjs.org) starter kit to boostrap your Farcaster Mini App\n\n- [Farcaster Mini Apps](https://miniapps.xyz)\n- [Tailwind CSS](https://tailwindcss.com)\n- [Next.js](https://nextjs.org/docs)\n- [Neynar](https://neynar.com)\n\n## Getting Started\n\n1. Install dependencies:\n\n```bash\nnpm install\n# or\nyarn install\n# or\npnpm install\n# or\nbun install\n```\n\n2. Verify environment variables:\n\nThe environment variables enable the following features:\n\n- Frame metadata - Sets up the Frame Embed that will be shown when you cast your frame\n- Account assocation - Allows users to add your frame to their account, enables notifications\n- Redis API keys - Enable Webhooks and background notifications for your application by storing users notification details\n\n```bash\n# Required for Frame metadata\nNEXT_PUBLIC_URL=\n\n# Required to allow users to add your frame\nNEXT_PUBLIC_FARCASTER_HEADER=\nNEXT_PUBLIC_FARCASTER_PAYLOAD=\nNEXT_PUBLIC_FARCASTER_SIGNATURE=\n\n# Required for user authentication\nNEYNAR_API_KEY=\nJWT_SECRET=\n\n# Required for webhooks and background notifications\nREDIS_URL=\nREDIS_TOKEN=\n```\n\n3. Start the development server:\n\n```bash\nnpm run dev\n```\n\n4. Run a local tunneling server\n\n- [NGROK](https://ngrok.com)\n- [Local Tunnel](https://theboroer.github.io/localtunnel-www/)\n\n5. Generate your Farcaster Manifest variables\n\n- Follow these [instructions](https://miniapps.farcaster.xyz/docs/guides/publishing)\n- Visit [Manifest Tool](https://warpcast.com/~/developers/mini-apps/manifest)\n- Paste your tunnel domain\n\n## Template Features\n\n### Frame Configuration\n\n- `.well-known/farcaster.json` endpoint configured for Frame metadata and account association\n- Frame metadata automatically added to page headers in `layout.tsx`\n\n### Background Notifications\n\n- Redis-backed notification system using Upstash\n- Ready-to-use notification endpoints in `api/notify` and `api/webhook`\n- Notification client utilities in `lib/notification-client.ts`\n\n### MiniApp Provider\n\nThe app is wrapped with `MiniAppProvider` in `providers.tsx`, configured with:\n\n- Access to Mini App context\n- Sets up Wagmi Connectors\n- Sets up Mini App SDK listeners\n- Applies Safe Area Insets\n\n### Dynamic Preview Images\n\n- `dynamic-image-example/[id]/page.tsx` show how to create a Mini App URL resolving to a custom preview image\n- `api/og/example/[id]/route.ts` shows how to generate a custom preview image\n\n## Learn More\n\n- [Farcaster Mini Apps](https://miniapps.xyz)\n- [Next.js Documentation](https://nextjs.org/docs)\n- [Tailwind CSS Documentation](https://tailwindcss.com/docs)\n- [Neynar](https://neynar.com)\n"
  },
  "prettier-solidity/prettier-plugin-solidity": {
    "fetchedAt": "2025-11-12T22:38:54.389Z",
    "content": "# prettier-plugin-solidity\n\n[![CI](https://github.com/prettier-solidity/prettier-plugin-solidity/actions/workflows/CI.yml/badge.svg)](https://github.com/prettier-solidity/prettier-plugin-solidity/actions)\n[![Telegram](/assets/telegram-badge.svg)](https://t.me/+kgTgkFgIwJkwMjcx)\n[![Twitter Follow](https://img.shields.io/twitter/follow/PrettierSol.svg?style=social)](https://x.com/PrettierSol)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/prettier-solidity/prettier-plugin-solidity/badge)](https://www.gitpoap.io/gh/prettier-solidity/prettier-plugin-solidity)\n\n<p align=\"center\">\n  <img width=\"375\" height=\"375\" src=\"https://user-images.githubusercontent.com/1022054/59317198-f1149b80-8d15-11e9-9b0f-0c5e7d4b8b81.png\">\n</p>\n\n> ‚ÑπÔ∏è This README is for the new major version of Prettier Plugin Solidity.\n>\n> The differences from v1 are minimal, but there are some breaking changes.\n>\n> To migrate from v1, follow the [migration guide](#migrating-from-v1).\n>\n> If you're looking for the previous version, check out the [v1 branch](https://github.com/prettier-solidity/prettier-plugin-solidity/tree/v1).\n\nA [Prettier](https://prettier.io/) plugin for automatically formatting your [Solidity](https://docs.soliditylang.org/en/latest/) code.\n\n## Installation and usage\n\n### Using in NodeJS\n\nInstall both `prettier` and `prettier-plugin-solidity`:\n\n```Bash\nnpm install --save-dev prettier prettier-plugin-solidity\n```\n\nRun prettier on your contracts:\n\n```Bash\nnpx prettier --write --plugin=prettier-plugin-solidity 'contracts/**/*.sol'\n```\n\nYou can add an npm script to run prettier on all your contracts:\n\n```\n\"prettier\": \"prettier --write --plugin=prettier-plugin-solidity 'contracts/**/*.sol'\"\n```\n\nOr you can use it as part of your linting to check that all your code is prettified:\n\n```\n\"lint\": \"prettier --list-different --plugin=prettier-plugin-solidity 'contracts/**/*.sol'\"\n```\n\n> Prettier Solidity only works with valid code. If there is a syntax error, nothing will be done and a parser error will be thrown.\n\n### Using in the Browser\n\nTo use this package in the browser, you need to load Prettier's standalone bundle before loading the build provided in this package.\n\nPrettier's unpkg field points to `https://unpkg.com/prettier/standalone.js`, in a similar way this plugin points to `https://unpkg.com/prettier-plugin-solidity/dist/standalone.js`.\n\nOnce the scripts are loaded you will have access to the globals `prettier` and `prettierPlugins`.\n\nWe follow Prettier's strategy for populating their plugins in the object `prettierPlugins`, you can load other plugins like `https://unpkg.com/prettier@2.8.0/parser-markdown.js` and Prettier will have access to multiple parsers.\n\n```html\n<script type=\"module\">\n  const prettier = await import(\n    'https://unpkg.com/prettier-plugin-solidity@latest'\n  );\n  const prettierSolidity = await import(\n    'https://unpkg.com/prettier-plugin-solidity@next'\n  );\n\n  async function format(code) {\n    return await prettier.format(code, {\n      parser: 'slang',\n      plugins: [solidityPlugin]\n    });\n  }\n\n  const originalCode = 'contract Foo {}';\n  const formattedCode = format(originalCode);\n</script>\n```\n\nFor more details, have a look at [Prettier's documentation](https://prettier.io/docs/en/browser.html).\n\n### Creating a package for the Browser\n\nIf you are creating your own package to be run in a browser, you might want to import the standalone files directly.\n\n```Javascript\nimport prettier from \"prettier/standalone\";\nimport solidityPlugin from \"prettier-plugin-solidity/standalone\";\n\nasync function format(code) {\n  return await prettier.format(code, {\n    parser: \"slang\",\n    plugins: [solidityPlugin],\n  });\n}\n\nconst originalCode = \"contract Foo {}\";\nconst formattedCode = format(originalCode);\n```\n\n## Configuration File\n\nPrettier provides a flexible system to configure the formatting rules of a project. For more information please refer to the [documentation](https://prettier.io/docs/en/configuration.html).\nThe following is the default configuration internally used by this plugin.\n\n```JSON\n{\n  \"plugins\": [\"prettier-plugin-solidity\"],\n  \"overrides\": [\n    {\n      \"files\": \"*.sol\",\n      \"options\": {\n        \"parser\": \"slang\",\n        \"printWidth\": 80,\n        \"tabWidth\": 4,\n        \"useTabs\": false,\n        \"singleQuote\": false,\n        \"bracketSpacing\": false,\n      }\n    }\n  ]\n}\n```\n\nNote the use of the [overrides property](https://prettier.io/docs/en/configuration.html#configuration-overrides) which allows for multiple configurations in case there are other languages in the project (i.e. JavaScript, JSON, Markdown).\n\nSince Prettier v3.0.0, the plugin search feature has been removed so we encourage adding our plugin to the configuration file.\n\nMost options are described in Prettier's [documentation](https://prettier.io/docs/en/options.html).\n\n### Compiler\n\nMany versions of the Solidity compiler have changes that affect how the code should be formatted. This plugin, by default, tries to format the code in the most compatible way that is possible, but you can use the `compiler` option to nudge it in the right direction.\n\nOne example of this is import directives. Before `0.7.4`, the compiler didn't accept multi-line import statements, so we always format them in a single line. But if you use the `compiler` option to indicate that you are using a version greater or equal than `0.7.4`, the plugin will use multi-line imports when it makes sense.\n\nThe Solidity versions taken into consideration during formatting are:\n\n- `v0.7.4`: Versions prior `0.7.4` had a bug that would not interpret correctly imports unless they are formatted in a single line.\n\n  ```Solidity\n  // Input\n  import { Foo as Bar, Baz as Qux } from \"/an/extremely/long/location\";\n\n  // \"compiler\": undefined, parser: \"antlr\"\n  import { Foo as Bar, Baz as Qux } from \"/an/extremely/long/location\";\n\n  // \"compiler\": \"0.7.3\" (or lesser)\n  import { Foo as Bar, Baz as Qux } from \"/an/extremely/long/location\";\n\n  // \"compiler\": \"0.7.4\" (or greater)\n  import {\n      Foo as Bar,\n      Baz as Qux\n  } from \"/an/extremely/long/location\";\n  ```\n\n- `v0.8.0`: Introduced these [changes](https://docs.soliditylang.org/en/v0.8.0/080-breaking-changes.html)\n  - The type `byte` has been removed. It was an alias of `bytes1`.\n  - Exponentiation is right associative, i.e., the expression `a**b**c` is parsed as `a**(b**c)`. Before 0.8.0, it was parsed as `(a**b)**c`.\n\n  ```Solidity\n  // Input\n  bytes1 public a;\n  byte public b;\n\n  uint public c = 1 ** 2 ** 3;\n\n  // \"compiler\": undefined\n  bytes1 public a;\n  byte public b;\n\n  uint public c = 1**2**3;\n\n  // \"compiler\": \"0.7.6\" (or lesser)\n  bytes1 public a;\n  byte public b;\n\n  uint public c = (1**2)**3;\n\n  // \"compiler\": \"0.8.0\" (or greater)\n  bytes1 public a;\n  bytes1 public b;\n\n  uint public c = 1**(2**3);\n  ```\n\nYou might have a multi-version project, where different files are compiled with different compilers. If that's the case, you can use [overrides](https://prettier.io/docs/en/configuration.html#configuration-overrides) to have a more granular configuration:\n\n```JSON\n{\n  \"overrides\": [\n    {\n      \"files\": \"contracts/v1/**/*.sol\",\n      \"options\": {\n        \"compiler\": \"0.6.3\"\n      }\n    },\n    {\n      \"files\": \"contracts/v2/**/*.sol\",\n      \"options\": {\n        \"compiler\": \"0.8.4\"\n      }\n    }\n  ]\n}\n```\n\n| Default                                                                                       | CLI Override          | API Override           |\n| --------------------------------------------------------------------------------------------- | --------------------- | ---------------------- |\n| Inferred from pragma statements when using parser `slang`<br/> None when using parser `antlr` | `--compiler <string>` | `compiler: \"<string>\"` |\n\n### Parser\n\nYou can configure the parser used by Prettier Solidity. Two Solidity parsers are supported:\n\n- [Slang](https://nomicfoundation.github.io/slang) (the default), a more powerful and correct parser that results in b\n\n[... truncated ...]"
  },
  "crytic/properties": {
    "fetchedAt": "2025-11-12T22:39:01.813Z",
    "content": "# Table of contents\n\n- [Table of contents](#table-of-contents)\n- [Properties](#properties)\n  - [Testing the properties with fuzzing](#testing-the-properties-with-fuzzing)\n    - [ERC20 tests](#erc20-tests)\n    - [ERC721 Tests](#erc721-tests)\n    - [ERC4626 Tests](#erc4626-tests)\n    - [ABDKMath64x64 tests](#abdkmath64x64-tests)\n  - [Additional resources](#additional-resources)\n- [Helper functions](#helper-functions)\n  - [Usage examples](#usage-examples)\n    - [Logging](#logging)\n    - [Assertions](#assertions)\n    - [Clamping](#clamping)\n- [HEVM cheat codes support](#hevm-cheat-codes-support)\n  - [Usage example](#usage-example)\n- [Trophies](#trophies)\n- [How to contribute to this repo?](#how-to-contribute-to-this-repo)\n\n# Properties\n\nThis repository contains 168 code properties for:\n\n- [ERC20](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/) token: mintable, burnable, pausable and transferable invariants ([25 properties](PROPERTIES.md#erc20)).\n- [ERC721](https://ethereum.org/en/developers/docs/standards/tokens/erc-721/) token: mintable, burnable, and transferable invariants ([19 properties](PROPERTIES.md#erc721)).\n- [ERC4626](https://ethereum.org/en/developers/docs/standards/tokens/erc-4626/) vaults: strict specification and additional security invariants ([37 properties](PROPERTIES.md#erc4626)).\n- [ABDKMath64x64](https://github.com/abdk-consulting/abdk-libraries-solidity/blob/master/ABDKMath64x64.md) fixed-point library invariants ([106 properties](PROPERTIES.md#abdkmath64x64)).\n\nThe goals of these properties are to:\n\n- Detect vulnerabilities\n- Ensure adherence to relevant standards\n- Provide educational guidance for writing invariants\n\nThe properties can be used through unit tests or through fuzzing with [Echidna](https://github.com/crytic/echidna) or [Medusa](https://github.com/crytic/medusa).\n\n## Testing the properties with fuzzing\n\n1. Install [Echidna](https://github.com/crytic/echidna#installation) or [Medusa](https://github.com/crytic/medusa/blob/master/docs/src/getting_started/installation.md#installation).\n2. Import the properties into to your project:\n\n   - In case of using Hardhat, use: `npm install https://github.com/crytic/properties.git` or `yarn add https://github.com/crytic/properties.git`\n   - In case of using Foundry, use: `forge install crytic/properties`\n\n3. According to tests required, go the the specific sections:\n   - [ERC20 tests](#erc20-tests)\n   - [ERC4626 test](#erc4626-tests)\n   - [ABDKMath64x64 tests](#abdkmath64x64-tests)\n\n### ERC20 tests\n\nTo test an ERC20 token, follow these steps:\n\n1. [Integration](#integration)\n2. [Configuration](#configuration)\n3. [Run](#run)\n\nYou can see the output for a [compliant token](#example-output-for-a-compliant-token), and [non compliant token](#example-output-for-a-non-compliant-token).\n\n\n#### Integration\n\nDecide if you want to do internal or external testing. Both approaches have advantages and disadvantages, you can check more information about them [here](https://secure-contracts.com/program-analysis/echidna/basic/common-testing-approaches.html). \n\nFor internal testing, create a new Solidity file containing the `CryticERC20InternalHarness` contract. `USER1`, `USER2` and `USER3` constants are initialized by default in `PropertiesConstants` contract to be the addresses from where echidna sends transactions, and `INITIAL_BALANCE` is by default `1000e18`:\n\n```Solidity\npragma solidity ^0.8.0;\nimport \"@crytic/properties/contracts/ERC20/internal/properties/ERC20BasicProperties.sol\";\nimport \"./MyToken.sol\";\ncontract CryticERC20InternalHarness is MyToken, CryticERC20BasicProperties {\n\n    constructor() {\n        // Setup balances for USER1, USER2 and USER3:\n        _mint(USER1, INITIAL_BALANCE);\n        _mint(USER2, INITIAL_BALANCE);\n        _mint(USER3, INITIAL_BALANCE);\n        // Setup total supply:\n        initialSupply = totalSupply();\n    }\n}\n```\n\nFor external testing, create two contracts: the `CryticERC20ExternalHarness` and the `TokenMock` as shown below.\nIn the `CryticERC20ExternalHarness` contract you can specify which properties to test, via inheritance. In the `TokenMock` contract, you will need to modify the `isMintableOrBurnable` variable if your contract is able to mint or burn tokens.\n\n```Solidity\npragma solidity ^0.8.0;\nimport \"./MyToken.sol\";\nimport {ITokenMock} from \"@crytic/properties/contracts/ERC20/external/util/ITokenMock.sol\";\nimport {CryticERC20ExternalBasicProperties} from \"@crytic/properties/contracts/ERC20/external/properties/ERC20ExternalBasicProperties.sol\";\nimport {PropertiesConstants} from \"@crytic/properties/contracts/util/PropertiesConstants.sol\";\n\n\ncontract CryticERC20ExternalHarness is CryticERC20ExternalBasicProperties {\n    constructor() {\n        // Deploy ERC20\n        token = ITokenMock(address(new CryticTokenMock()));\n    }\n}\n\ncontract CryticTokenMock is MyToken, PropertiesConstants {\n\n    bool public isMintableOrBurnable;\n    uint256 public initialSupply;\n    constructor () {\n        _mint(USER1, INITIAL_BALANCE);\n        _mint(USER2, INITIAL_BALANCE);\n        _mint(USER3, INITIAL_BALANCE);\n        _mint(msg.sender, INITIAL_BALANCE);\n\n        initialSupply = totalSupply();\n        isMintableOrBurnable = true;\n    }\n}\n```\n\n#### Configuration\n\n**Echidna**\n\nCreate the following Echidna config file\n\n```yaml\ncorpusDir: \"tests/crytic/erc20/echidna-corpus-internal\"\ntestMode: assertion\ntestLimit: 100000\ndeployer: \"0x10000\"\nsender: [\"0x10000\", \"0x20000\", \"0x30000\"]\n# Uncomment the following line for external testing\n#allContracts: true\n```\n\n**Medusa** \n\nCreate the following Medusa config file:\n\n```json\n{\n\t\"fuzzing\": {\n    \"testLimit\": 100000,\n\t\t\"corpusDirectory\": \"tests/medusa-corpus\",\n\t\t\"deployerAddress\": \"0x10000\",\n\t\t\"senderAddresses\": [\n\t\t\t\"0x10000\",\n\t\t\t\"0x20000\",\n\t\t\t\"0x30000\"\n\t\t],\n\t\t\"assertionTesting\": {\n\t\t\t\"enabled\": true\n\t\t},\n\t\t\"propertyTesting\": {\n\t\t\t\"enabled\": false\n\t\t},\n    \"optimizationTesting\": {\n\t\t\t\t\"enabled\": false,\n\t\t},\n\t},\n// Uncomment the following lines for external testing\n//\t\t\"testing\": {\n//\t\t\t\"testAllContracts\": true\n//    },\n\t\"compilation\": {\n\t\t\"platform\": \"crytic-compile\",\n\t\t\"platformConfig\": {\n\t\t\t\"target\": \".\",\n\t\t\t\"solcVersion\": \"\",\n\t\t\t\"exportDirectory\": \"\",\n\t\t\t\"args\": [\"--foundry-compile-all\"]\n\t\t}\n\t}\n}\n```\n\nTo perform more than one test, save the files with a descriptive path, to identify what test each file or corpus belongs to. For instace, for these examples, we use `tests/crytic/erc20/echidna-internal.yaml` and `tests/crytic/erc20/echidna-external.yaml` for the Echidna tests for ERC20. We recommended to modify the corpus directory config opction for external tests accordingly.\n\nThe above configuration will start Echidna or Medusa in assertion mode. The target contract(s) will be deployed from address `0x10000`, and transactions will be sent from the owner as well as two different users (`0x20000` and `0x30000`). There is an initial limit of `100000` tests, but depending on the token code complexity, this can be increased. Finally, once our fuzzing tools finish the fuzzing campaign, corpus and coverage results will be available in the specified corpus directory.\n\n#### Run\n\n**Echidna**\n\n- For internal testing: `echidna . --contract CryticERC20InternalHarness --config tests/crytic/erc20/echidna-internal.yaml`\n- For external testing: `echidna . --contract CryticERC20ExternalHarness --config tests/crytic/erc20/echidna-external.yaml`\n\n**Medusa**\n\n- Go to the directory `cd tests/crytic/erc20`\n- For internal testing: `medusa fuzz --target-contracts CryticERC20InternalHarness --config medusa-internal.yaml`\n- For external testing: `medusa fuzz --target-contracts CryticERC20ExternalHarness --config medusa-external.yaml`\n\n#### Example: Output for a compliant token\n\nIf the token under test is compliant and no properties will fail during fuzzing, the Echidna output should be similar to the screen below:\n\n```\n$ echidna . --contract CryticERC20InternalHarness --config tests/echidna.config.yaml\nLoaded total of 23 transactions from c\n\n[... truncated ...]"
  },
  "crytic/solc-select": {
    "fetchedAt": "2025-11-12T22:39:10.018Z",
    "content": "# solc-select\n\nA tool to quickly switch between Solidity compiler versions.\n\nThe tool is split into two CLI utilities:\n\n- `solc-select`: manages installing and setting different `solc` compiler versions\n- `solc`: wrapper around `solc` which picks the right version according to what was set via `solc-select`\n\nThe `solc` binaries are downloaded from https://binaries.soliditylang.org/ which contains\nofficial artifacts for many historial and modern `solc` versions for Linux and macOS.\n\nThe versioned binaries are stored in `~/.solc-select/artifacts/`.\n\n## Installation\n\n### Using pip\n\n```bash\npip3 install solc-select\n```\n\n### Using uv (recommended for development)\n\n```bash\nuv tool install solc-select\n```\n\nTo automatically install and use a version, run `solc-select use <version> --always-install`.\n\n### Running on ARM (Mac M1/M2)\n\n`solc-select` provides native ARM64 support for versions 0.8.5-0.8.23, and universal binary support for 0.8.24+. For versions older than 0.8.5, Rosetta is required. See the FAQ on [how to install Rosetta](#oserror-errno-86-bad-cpu-type-in-executable).\n\n## Usage\n\n### Quick Start\n\n```bash\n# Install and set a specific Solidity version\nsolc-select use 0.8.19 --always-install\n\n# Check the current version\nsolc --version\n```\n\n### Managing Versions\n\nThe global version of `solc` will automatically be set to the latest version. You can change this with the `solc-select use <version>` command:\n\n```shell\n$ solc --version\nsolc, the solidity compiler commandline interface\nVersion: 0.5.2+commit.1df8f40c.Linux.g++\n$ solc-select use 0.4.24\nSwitched global version to 0.4.24\n$ solc --version\nsolc, the solidity compiler commandline interface\nVersion: 0.4.24+commit.e67f0147.Linux.g++\n```\n\nUse `SOLC_VERSION` environment variable to override the global version:\n\n```shell\n$ solc --version\nsolc, the solidity compiler commandline interface\nVersion: 0.4.24+commit.e67f0147.Linux.g++\n$ SOLC_VERSION=0.5.2 solc --version\nsolc, the solidity compiler commandline interface\nVersion: 0.5.2+commit.1df8f40c.Linux.g++\n```\n\nBy default, solc-select will halt if you try to use a version that you do not have installed already. Use the `--always-install` flags to bypass this.\n\n```shell\n$ solc-select use 0.8.1 --always-install\nInstalling '0.8.1'...\nVersion '0.8.1' installed.\n```\n\n### Available Commands\n\n```shell\n# List all available versions\nsolc-select install\n\n# Install a specific version\nsolc-select install 0.8.19\n\n# Switch to an installed version\nsolc-select use 0.8.19\n\n# List installed versions\nsolc-select versions\n\n# Install and switch to a version in one command\nsolc-select use 0.8.19 --always-install\n```\n\n## Getting Help\n\nFeel free to stop by our [Slack channel](https://empirehacking.slack.com/) for help on using or extending `solc-select`.\n\n## FAQ\n\n### OSError: [Errno 86] Bad CPU type in executable\n\nOn newer `solc-select` versions, this might show as `solc binaries for macOS are\nIntel-only. Please install Rosetta on your Mac to continue.` or `solc binaries\nprevious to 0.8.5 for macOS are Intel-only. Please install Rosetta on your Mac\nto continue.`\n\n`solc` releases earlier than 0.8.5 require Rosetta to be installed. Versions 0.8.5-0.8.23 run natively on ARM64, and 0.8.24+ use universal binaries. To see\nwhether you have Rosetta installed on your Mac, run\n\n```bash\npgrep -q oahd && echo Rosetta is installed || echo Rosetta is NOT installed\n```\n\nIf it is not installed, it can be installed with the command\n\n```bash\n/usr/sbin/softwareupdate --install-rosetta --agree-to-license\n```\n\n### solc-version not changing after running `solc-select use [version]` or setting `SOLC_VERSION`\n\nUninstall other installations of solc on your machine. `solc-select` re-installs solc binaries for your operating system and acts as a wrapper for solc. With duplicate solc installations, this may result in your `solc` version not being up to date.\n\n### \"Unsupported Platform\" on Windows\n\nYou might be using an old version of `solc-select` or Python if you are seeing this error message. The current stable release supports Windows; try upgrading your `solc-select` installation with the following command.\n\n```bash\npip install --upgrade solc-select\n```\n\n## Known Issues\n\n### `SSL: CERTIFICATE_VERIFY_FAILED` on running `solc-select` commands [investigation ongoing]\n\n**OS X**: Python distributions on OS X has no certificates and cannot validate SSL connections, a breaking change introduced in Python 3.6. See [StackOverflow](https://stackoverflow.com/a/42334357) post for additional details.\n\nThe following commands may resolve the issue; adjust the Python version to the one installed on your system:\n\n```bash\npip3 install certifi\n/Applications/Python\\ 3.8/Install\\ Certificates.command\n```\n\n### `Connection refused` [investigation ongoing]\n\nOur `0.2.1` version of `solc-select` pulls older Linux binaries from [crytic/solc](https://github.com/crytic/solc) which seems to have introduced unexpected behavior in certain instances. Apparently, [certain ISPs such as Jio](https://github.com/crytic/solc-select/issues/205#issuecomment-1825171056) may be blocking access to certain GitHub domains. If possible, try using a different Internet provider to see if it resolves the problem.\n\nAlternatively, try downgrading to `solc-select version 0.2.0`.\n\n```bash\npip3 uninstall solc-select\npip3 install solc-select==0.2.0\nsolc-select install\n```\n\n### `solc-select` version changes, but `solc --version does not match`\n\nUsers seem to be experiencing situations in which the following command is successful:\n\n```bash\nsolc-select use <version>\n```\n\nHowever, when running the following command, it points to an older version of Solidity.\n\n```bash\nsolc --version\n```\n\n`solc-select` is intended to work with custom binaries. This means that Solidity installed through other means (i.e: `brew install solidity`) will _not_ work!.\n\nUninstall other versions Solidity from your computer.\n\n## License\n\n`solc-select` is licensed and distributed under the [AGPLv3](LICENSE) license. [Contact us](mailto:opensource@trailofbits.com) if you‚Äôre looking for an exception to the terms.\n"
  },
  "crytic/medusa": {
    "fetchedAt": "2025-11-12T22:39:17.338Z",
    "content": "# medusa\n\n`medusa` is a cross-platform [go-ethereum](https://github.com/ethereum/go-ethereum/)-based smart contract fuzzer inspired by [Echidna](https://github.com/crytic/echidna).\nIt provides parallelized fuzz testing of smart contracts through CLI, or its Go API that allows custom user-extended testing methodology.\n\n**Disclaimer**: The Go-level testing API is still **under development** and is subject to breaking changes.\n\n## Features\n\n`medusa` provides support for:\n\n- ‚úîÔ∏è**Parallel fuzzing and testing** methodologies across multiple workers (threads)\n- ‚úîÔ∏è**Assertion and property testing**: built-in support for writing basic Solidity property tests and assertion tests\n- ‚úîÔ∏è**Mutational value generation**: fed by compilation and runtime values.\n- ‚úîÔ∏è**Coverage collecting**: Coverage increasing call sequences are stored in the corpus\n- ‚úîÔ∏è**Coverage guided fuzzing**: Coverage increasing call sequences from the corpus are mutated to further guide the fuzzing campaign\n- ‚úîÔ∏è**Extensible low-level testing API** through events and hooks provided throughout the fuzzer, workers, and test chains.\n- ‚ùå **Extensible high-level testing API** allowing for the addition of per-contract or global post call/event property tests with minimal effort.\n\n## Documentation\n\nTo learn more about how to install and use `medusa`, please refer to our [documentation](./docs/src/SUMMARY.md).\n\nFor a better viewing experience, we recommend you install [mdbook](https://rust-lang.github.io/mdBook/guide/installation.html)\nand then running the following steps from medusa's source directory:\n\n```bash\ncd docs\nmdbook serve\n```\n\n## Install\n\nRun the following command to install the latest version of `medusa`:\n\n```shell\n\ngo install github.com/crytic/medusa@latest\n```\n\nFor more information on building from source, using package managers, or obtaining binaries for Windows and Linux,\nplease refer to the [installation guide](./docs/src/getting_started/installation.md).\n\n## Contributing\n\nFor information about how to contribute to this project, check out the [CONTRIBUTING](./CONTRIBUTING.md) guidelines.\n\n## License\n\n`medusa` is licensed and distributed under the [AGPLv3](./LICENSE).\n"
  },
  "crytic/slither": {
    "fetchedAt": "2025-11-12T22:39:24.925Z",
    "content": "# [Slither, the smart contract static analyzer](https://crytic.github.io/slither/slither.html)\n\n<img src=\"https://raw.githubusercontent.com/crytic/slither/master/logo.png\" alt=\"Slither Static Analysis Framework Logo\" width=\"500\" />\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/crytic/slither/ci.yml?branch=master)](https://github.com/crytic/slither/actions?query=workflow%3ACI)\n![PyPI](https://img.shields.io/pypi/v/slither-analyzer?logo=python&logoColor=white&label=slither-analyzer)\n[![Slither - Read the Docs](https://img.shields.io/badge/Slither-Read_the_Docs-2ea44f)](https://crytic.github.io/slither/slither.html)\n[![Slither - Wiki](https://img.shields.io/badge/Slither-Wiki-2ea44f)](https://github.com/crytic/slither/wiki/SlithIR)\n\n> Join the Empire Hacking Slack\n>\n> [![Slack Status](https://slack.empirehacking.nyc/badge.svg)](https://slack.empirehacking.nyc/)\n> > <sub><i>- Discussions and Support </i></sub>\n\n**Slither** is a Solidity & Vyper static analysis framework written in Python3. It runs a suite of vulnerability detectors, prints visual information about contract details, and provides an API to easily write custom analyses. Slither enables developers to find vulnerabilities, enhance their code comprehension, and quickly prototype custom analyses.\n\n* [Features](#features)\n* [Usage](#usage)\n* [How to install](#how-to-install)\n  * [Using Pip](#using-pip)\n  * [Using Git](#using-git)\n  * [Using Docker](#using-docker)\n  * [Integration](#integration)\n* [Detectors](#detectors)\n* [Printers](#printers)\n  * [Quick Review Printers](#quick-review-printers)\n  * [In-Depth Review Printers](#in-depth-review-printers)\n* [Tools](#tools)\n* [API Documentation](#api-documentation)\n* [Getting Help](#getting-help)\n* [FAQ](#faq)\n* [License](#license)\n* [Publications](#publications)\n  * [Trail of Bits publication](#trail-of-bits-publication)\n  * [External publications](#external-publications)\n\n## Features\n\n* Detects vulnerable Solidity code with low false positives (see the list of [trophies](./trophies.md))\n* Identifies where the error condition occurs in the source code\n* Easily integrates into continuous integration and Hardhat/Foundry builds\n* Built-in 'printers' quickly report crucial contract information\n* Detector API to write custom analyses in Python\n* Ability to analyze contracts written with Solidity >= 0.4\n* Intermediate representation ([SlithIR](https://github.com/crytic/slither/wiki/SlithIR)) enables simple, high-precision analyses\n* Correctly parses 99.9% of all public Solidity code\n* Average execution time of less than 1 second per contract\n* Integrates with Github's code scanning in [CI](https://github.com/marketplace/actions/slither-action)\n* Support for Vyper smart contracts\n\n## Usage\n\nRun Slither on a Hardhat/Foundry/Dapp/Brownie application:\n\n```console\nslither .\n```\n\nThis is the preferred option if your project has dependencies as Slither relies on the underlying compilation framework to compile source code.\n\nHowever, you can run Slither on a single file that does not import dependencies:\n\n```console\nslither tests/uninitialized.sol\n```\n\n## How to install\n\n> **Note** <br />\n> Slither requires Python 3.8+.\nIf you're **not** going to use one of the [supported compilation frameworks](https://github.com/crytic/crytic-compile), you need [solc](https://github.com/ethereum/solidity/), the Solidity compiler; we recommend using [solc-select](https://github.com/crytic/solc-select) to conveniently switch between solc versions.\n\n### Using Pip\n\n```console\npython3 -m pip install slither-analyzer\n```\n\n#### How to upgrade\n\n```console\npython3 -m pip install --upgrade slither-analyzer\n```\n\n### Using Brew\n\n```console\nbrew install slither-analyzer\n```\n\n### Using Git\n\n```bash\ngit clone https://github.com/crytic/slither.git && cd slither\npython3 -m pip install .\n```\n\nWe recommend using a Python virtual environment, as detailed in the [Developer Installation Instructions](https://github.com/crytic/slither/wiki/Developer-installation), if you prefer to install Slither via git.\n\n### Using Docker\n\nUse the [`eth-security-toolbox`](https://github.com/crytic/eth-security-toolbox/) docker image. It includes all of our security tools and every major version of Solidity in a single image. `/home/share` will be mounted to `/share` in the container.\n\n```bash\ndocker pull trailofbits/eth-security-toolbox\n```\n\nTo share a directory in the container:\n\n```bash\ndocker run -it -v /home/share:/share trailofbits/eth-security-toolbox\n```\n\n### Integration\n\n* For GitHub action integration, use [slither-action](https://github.com/marketplace/actions/slither-action).\n* For pre-commit integration, use (replace `$GIT_TAG` with real tag)\n  ```YAML\n  - repo: https://github.com/crytic/slither\n    rev: $GIT_TAG\n    hooks:\n      - id: slither\n  ```\n* To generate a Markdown report, use `slither [target] --checklist`.\n* To generate a Markdown with GitHub source code highlighting, use `slither [target] --checklist --markdown-root https://github.com/ORG/REPO/blob/COMMIT/` (replace `ORG`, `REPO`, `COMMIT`)\n\n## Detectors\n\nNum | Detector | What it Detects | Impact | Confidence\n--- | --- | --- | --- | ---\n1 | `abiencoderv2-array` | [Storage abiencoderv2 array](https://github.com/crytic/slither/wiki/Detector-Documentation#storage-abiencoderv2-array) | High | High\n2 | `arbitrary-send-erc20` | [transferFrom uses arbitrary `from`](https://github.com/crytic/slither/wiki/Detector-Documentation#arbitrary-from-in-transferfrom) | High | High\n3 | `array-by-reference` | [Modifying storage array by value](https://github.com/crytic/slither/wiki/Detector-Documentation#modifying-storage-array-by-value) | High | High\n4 | `encode-packed-collision` | [ABI encodePacked Collision](https://github.com/crytic/slither/wiki/Detector-Documentation#abi-encodePacked-collision) | High | High\n5 | `incorrect-shift` | [The order of parameters in a shift instruction is incorrect.](https://github.com/crytic/slither/wiki/Detector-Documentation#incorrect-shift-in-assembly) | High | High\n6 | `multiple-constructors` | [Multiple constructor schemes](https://github.com/crytic/slither/wiki/Detector-Documentation#multiple-constructor-schemes) | High | High\n7 | `name-reused` | [Contract's name reused](https://github.com/crytic/slither/wiki/Detector-Documentation#name-reused) | High | High\n8 | `protected-vars` | [Detected unprotected variables](https://github.com/crytic/slither/wiki/Detector-Documentation#protected-variables) | High | High\n9 | `public-mappings-nested` | [Public mappings with nested variables](https://github.com/crytic/slither/wiki/Detector-Documentation#public-mappings-with-nested-variables) | High | High\n10 | `rtlo` | [Right-To-Left-Override control character is used](https://github.com/crytic/slither/wiki/Detector-Documentation#right-to-left-override-character) | High | High\n11 | `shadowing-state` | [State variables shadowing](https://github.com/crytic/slither/wiki/Detector-Documentation#state-variable-shadowing) | High | High\n12 | `suicidal` | [Functions allowing anyone to destruct the contract](https://github.com/crytic/slither/wiki/Detector-Documentation#suicidal) | High | High\n13 | `uninitialized-state` | [Uninitialized state variables](https://github.com/crytic/slither/wiki/Detector-Documentation#uninitialized-state-variables) | High | High\n14 | `uninitialized-storage` | [Uninitialized storage variables](https://github.com/crytic/slither/wiki/Detector-Documentation#uninitialized-storage-variables) | High | High\n15 | `unprotected-upgrade` | [Unprotected upgradeable contract](https://github.com/crytic/slither/wiki/Detector-Documentation#unprotected-upgradeable-contract) | High | High\n16 | `codex` | [Use Codex to find vulnerabilities.](https://github.com/crytic/slither/wiki/Detector-Documentation#codex) | High | Low\n17 | `arbitrary-send-erc20-permit` | [transferFrom uses arbitrary from with permit](https://github.com/crytic/slither/wiki/Detector-Documentation#arbitrary-from-in-transferfrom-used-with-permit)\n\n[... truncated ...]"
  },
  "ethdebug/format": {
    "fetchedAt": "2025-11-12T22:39:32.429Z",
    "content": "# ethdebug format\n\n_Because debugging on Ethereum is hard._\n\n## Problem statement\n\nSmart contracts offer the fundamental promise that code execution is verifiably\ntransparent. Not only is this necessary to ensure network liveness,\nbut this ability to _directly observe_ the step-by-step operation of the\nEthereum Virtual Machine (EVM) affords a foundation for public trust amongst\nsoftware developers, auditors, and end-users at large.\n\nUnfortunately, direct observation of the EVM fails to connect\nlow-level system behavior with any code authors' original framework of\nmeaning. Humans usually write programs in high-level languages that they must\ncompile to a form the machine can execute. It is\n_extremely impractical_ to reason about the machine-code that compilers\noutput and the system behavior that results upon executing this code.\n\nTraditional computing platforms have largely solved this problem through the\ndesign, standardization, and use of **debugging data formats**[^1], which allow\ncompilers a mechanism to specify precisely how to translate a program as the\nmachine runs it into a program as the human wrote it. Several such formats\nexist in use today, most notably DWARF[^2], and these allow ubiquitous\nsoftware integration between compilers, editors, and debuggers. Sadly, no existing\nformat suffices to cover the intrinsic differences present in smart contract\nprogramming, let alone cover some of the architectural decisions that\nhigh-level languages have made in response to the EVM's constraints.\n\nAlthough it's straightforward to observe and replay the EVM directly,\nunderstanding the EVM and the smart contracts running on it remains within the\ndomain of experts. Without a mechanism for machine-to-human translation,\nsmart contract software quality comes at a higher cost, and any promise of\ntrust risks erosion.\n\n## Purpose of this repository\n\nThis repository serves as a home for the **ethdebug/format** working group to\ndesign a standard debugging data format for smart contracts on\nEthereum-compatible networks.\n\n## Contents\n\nThis repository contains a\n[`schemas/`](https://github.com/ethdebug/format/tree/main/schemas) directory\nwith the formal JSON Schemas defined by this project (in YAML format).\n\nThis repository also contains the source materials for the following NPM packages:\n- **@ethdebug/format** in\n  [`packages/format/`](https://github.com/ethdebug/format/tree/main/packages/format)\n  distributes the formal schemas for use in TypeScript\n  or JavaScript projects, along with corresponding\n  type predicate functions[^3] to help maintain type-safety when reading\n  objects in these schemas.\n\n- **@ethdebug/pointers** in\n  [`packages/pointers/`](https://github.com/ethdebug/format/tree/main/packages/pointers)\n  provides a functional reference implementation for dereferencing\n  [ethdebug/format/pointer](https://ethdebug.github.io/format/spec/pointer/overview)\n  objects against running raw EVM machine state.\n\n  For more about this reference implementation, please see accompanying\n  [Dereferencing pointers](https://ethdebug.github.io/format/docs/implementation-guides/pointers/)\n  implementation guide on this project's homepage.\n\n- **@ethdebug/format-web** _(unpublished package)_ in\n  [`packages/web/`](https://github.com/ethdebug/format/tree/main/packages/web)\n  contains the materials for\n  the Docusaurus site powering\n  [this project's homepage](https://ethdebug.github.io/format).\n\n## Developing locally\n\nTo build and run the site locally, please ensure you have Node.js\n(LTS or better) and `yarn` installed globally.\n\nFirst, clone this repo and install the Node.js dependencies:\n```console\ngit clone https://github.com/ethdebug/format.git\ncd format\nyarn\n```\n\nThen, run this command to start a watcher process which rebuilds and reloads\non any changes. This will open your browser to `http://localhost:3000/format`:\n\n```console\nyarn start\n```\n\n## License\n\nThis project uses a dual-license approach:\n\n- The JSON schemas in the [`schemas/`](https://github.com/ethdebug/format/tree/main/schemas) directory are licensed under [CC0 1.0 Universal](https://creativecommons.org/publicdomain/zero/1.0/), allowing anyone to use, modify, and distribute them freely without attribution.\n\n- All other code and documentation in this repository is licensed under the [MIT License](LICENSE).\n\n[^1]: See [Debugging data format -\n  Wikipedia](https://en.wikipedia.org/wiki/Debugging_data_format)\n\n[^2]: See [DWARF - Wikipedia](https://en.wikipedia.org/wiki/DWARF)\n\n[^3]: See [Using type predicates](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#using-type-predicates)\n  section from TypeScript's Narrowing documentation.\n"
  },
  "wakeuplabs-io/op-ruaas": {
    "fetchedAt": "2025-11-12T22:39:39.715Z",
    "content": "# Opruaas - Optimism Rollup as a service\n\nOptimism Rollup As A Service. Easily deploy and manage rollups with the Optimism stack.\n\nIn particular we provide:\n\n- A [`cli`](packages/cli) for creating, testing, managing and deploying rollups.\n- A [`marketplace`](packages/marketplace) for those users who don't want to get involved in running infrastructure and prefer to buy a service from a vendor.\n- A [`console`](packages/console) for managing deployments and orders.\n\nYou'll find a `README.md` in each package to get started and know more details about them. Also you can go to `docs` to learn more about the project itself.\n"
  },
  "stereum-dev/ethereum-node": {
    "fetchedAt": "2025-11-12T22:39:47.096Z",
    "content": "![Stereum Ethereum Node Setup & Manager](https://github.com/stereum-dev/ethereum-node/assets/82385103/f2e797cd-ef2c-4ebe-9ec1-6b3a495f0677)\n\n---\n\n[![IE](https://img.shields.io/badge/Website-0076D6?style=for-the-badge&logo=Internet%20Explorer&logoColor=white)](https://www.stereum.com/?utm_source=github&utm_medium=stereum-repo&utm_id=0) [![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/8Znj8K6GjN)\n[![X](https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&logo=x&logoColor=white)](https://x.com/stereumdev)\n[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/channel/UCq_LYa0idkQcSnxBUmiJm3Q)\n[![Gmail](https://img.shields.io/badge/EMail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:stereum@stereum.net) [![App Store](https://img.shields.io/badge/App_Store-0D96F6?style=for-the-badge&logo=app-store&logoColor=white)](https://apps.apple.com/nz/app/stereum-node-monitor/id1605910573) [![Play Store](https://img.shields.io/badge/Google_Play-414141?style=for-the-badge&logo=google-play&logoColor=white)](https://play.google.com/store/apps/details?id=cloud.stereum.monitor&hl=en_US&gl=US&pli=1)\n[![proudhands Contribution Banner](https://github.com/stereum-dev/ethereum-node/assets/82385103/0d7cbc47-3b20-4dbe-ac9f-33a041cddf23)](https://www.instagram.com/mugan_art/) [![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/stereum-dev/ethereum-node/badge)](https://www.gitpoap.io/gh/stereum-dev/ethereum-node)\n\n---\n\n### üçÑ [Stereum](https://www.stereum.com/) - Ethereum Node Setup & Manager\n\n#### Become a Node Runner\n\nThis repository contains the code and scripts for Stereum 2.0\n\nüçÑ Stereum manages the process of setting up and maintaining an Ethereum node, focusing on self-sovereignty, privacy, and flexibility.\n\nüçÑ Stereum aims to offer the most flexible approach to leveraging your Ethereum node for various purposes‚Äîwhether for staking, data science, development, or any personal use case you envision. We hope to explore every Node Runners dream with you!\n\nüçÑ With Stereum, you can actively participate in the Ethereum network and engage with its diverse protocols such as the Lido SDVTM, SSV Network, MEV Boost, and more. Dive into the ecosystem and start benefiting from the decentralized technologies that Stereum facilitates.\n\n## Get Started\n\nAfter installing the launcher start it up and connect to a server of your choice. Take a look at the [guide](https://stereum.net/content/guides) to find out what server operating systems are supported and what you can do with Stereum!\n\n## Contribute\n\nWant to get involved? \nPlease use `npm run format:check` to check the format of your code and `run npm run format` to format your code, before making a pull request.\nPush the pull request & we'll have a look at it!\n\n- [Contribution Guidelines](launcher/CONTRIBUTING.md)\n\nNot sure how to help or where to start? Then visit us on [Discord](https://discord.gg/8Znj8K6GjN) or drop us an email at [stereum@stereum.net](mailto:stereum@stereum.net).\n\n### Tech Stack\n\n![Ansible](https://img.shields.io/badge/ansible-%231A1918.svg?style=for-the-badge&logo=ansible&logoColor=white) ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white) ![Ethereum](https://img.shields.io/badge/Ethereum-3C3C3D?style=for-the-badge&logo=Ethereum&logoColor=white) ![Electron.js](https://img.shields.io/badge/Electron-191970?style=for-the-badge&logo=Electron&logoColor=white) ![Grafana](https://img.shields.io/badge/grafana-%23F46800.svg?style=for-the-badge&logo=grafana&logoColor=white) ![JavaScript](https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E) ![Jest](https://img.shields.io/badge/-jest-%23C21325?style=for-the-badge&logo=jest&logoColor=white) ![Jinja](https://img.shields.io/badge/jinja-white.svg?style=for-the-badge&logo=jinja&logoColor=black) ![NodeJS](https://img.shields.io/badge/node.js-6DA55F?style=for-the-badge&logo=node.js&logoColor=white) ![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=Prometheus&logoColor=white) ![Shell Script](https://img.shields.io/badge/shell_script-%23121011.svg?style=for-the-badge&logo=gnu-bash&logoColor=white) ![Vue.js](https://img.shields.io/badge/vuejs-%2335495e.svg?style=for-the-badge&logo=vuedotjs&logoColor=%234FC08D)\n\n## Branches\n\n### `main`\n\nFor development automated tests running for each commit.\n\n#### Tests\n\n- [![Security: Shellcheck](https://github.com/stereum-dev/ethereum-node/actions/workflows/shellcheck.yml/badge.svg)](https://github.com/stereum-dev/ethereum-node/actions/workflows/shellcheck.yml) Security checking shell scripts\n- [![Tests: JEST](https://github.com/stereum-dev/ethereum-node/actions/workflows/test-jest.yml/badge.svg)](https://github.com/stereum-dev/ethereum-node/actions/workflows/test-jest.yml) JEST unit tests\n- [![Tests: Molecule](https://github.com/stereum-dev/ethereum-node/actions/workflows/test-molecule.yml/badge.svg)](https://github.com/stereum-dev/ethereum-node/actions/workflows/test-molecule.yml) Backend system tests with Molecule & Ansible\n- [![Tests: Integration](https://github.com/stereum-dev/ethereum-node/actions/workflows/test-integration.yml/badge.svg)](https://github.com/stereum-dev/ethereum-node/actions/workflows/test-integration.yml) JEST system integration tests\n\n#### Build\n\n- [![Build: Release](https://github.com/stereum-dev/ethereum-node/actions/workflows/electron.yaml/badge.svg)](https://github.com/stereum-dev/ethereum-node/actions/workflows/electron.yaml) Building Stereum Launcher\n"
  },
  "Rubilmax/viem-tracer": {
    "fetchedAt": "2025-11-12T22:39:54.349Z",
    "content": "# viem-tracer\n\n[![npm package][npm-img]][npm-url]\n[![Build Status][build-img]][build-url]\n[![Downloads][downloads-img]][downloads-url]\n[![Issues][issues-img]][issues-url]\n[![Commitizen Friendly][commitizen-img]][commitizen-url]\n[![Semantic Release][semantic-release-img]][semantic-release-url]\n\nDebug transactions via traces by automatically decoding them with the help of [openchain.xyz](https://openchain.xyz/)!\n\n- Automatically append traces to error messages of failed `eth_estimateGas` and `eth_sendTransaction` RPC requests.\n- Add support for [`debug_traceCall`](https://www.quicknode.com/docs/ethereum/debug_traceCall) to a Viem client with correct types!\n\n## Installation\n\n```bash\nnpm install viem-tracer\n```\n\n```bash\nyarn add viem-tracer\n```\n\n## Usage\n\n```typescript\nimport { createTestClient, http } from 'viem';\nimport { foundry } from 'viem/chains';\nimport { traceActions, traced } from 'viem-tracer';\n\nconst client = createTestClient({\n  mode: \"anvil\",\n  chain: foundry,\n  transport: traced( // Automatically trace failed transactions (or programmatically)\n    http(),\n    { all: false, next: false, failed: true } // Optional, default tracer config\n  ),\n}).extend(traceActions); // Extend client with the `client.traceCall` action\n\n// Returns the call trace as formatted by the requested tracer.\nawait client.traceCall({\n   account: \"0xA0Cf798816D4b9b9866b5330EEa46a18382f251e\",\n   to: \"0x70997970c51812dc3a010c7d01b50e0d17dc79c8\",\n   value: parseEther(\"1\"),\n   // tracer: \"prestateTracer\", // Defaults to \"callTracer\".\n});\n\n// Failing `eth_estimateGas` and `eth_sendTransaction` RPC requests will automatically append the transaction traces to the error:\nawait client.writeContract({\n   abi: erc20Abi,\n   address: \"0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48\",\n   functionName: \"transfer\",\n   args: [\"0xA0Cf798816D4b9b9866b5330EEa46a18382f251e\", 100_000000n],\n});\n\n// 0 ‚Ü≥ FROM 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266\n// 0 ‚Ü≥ CALL (0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48).transfer(0xf39F...0xf3, 100000000) -> ERC20: transfer amount exceeds balance\n//   1 ‚Ü≥ DELEGATECALL (0x43506849D7C04F9138D1A2050bbF3A0c054402dd).transfer(0xf39F...0xf3, 100000000) -> ERC20: transfer amount exceeds balance\n\nclient.transport.tracer.all = true; // If you want to trace all submitted transactions, failing or not.\nclient.transport.tracer.next = true; // If you want to trace the next submitted transaction.\nclient.transport.tracer.next = false; // If you DON'T want to trace the next submitted transaction.\nclient.transport.tracer.failed = false; // If you don't want to append traces to failed transactions.\n\n```\n\n> [!NOTE]  \n> You can disable colors via the `colors` package:\n> ```typescript\n> import { disable } from \"colors\";\n>\n> disable();\n> ```\n\n\n[build-img]: https://github.com/rubilmax/viem-tracer/actions/workflows/release.yml/badge.svg\n[build-url]: https://github.com/rubilmax/viem-tracer/actions/workflows/release.yml\n[downloads-img]: https://img.shields.io/npm/dt/viem-tracer\n[downloads-url]: https://www.npmtrends.com/viem-tracer\n[npm-img]: https://img.shields.io/npm/v/viem-tracer\n[npm-url]: https://www.npmjs.com/package/viem-tracer\n[issues-img]: https://img.shields.io/github/issues/rubilmax/viem-tracer\n[issues-url]: https://github.com/rubilmax/viem-tracer/issues\n[codecov-img]: https://codecov.io/gh/rubilmax/viem-tracer/branch/main/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/rubilmax/viem-tracer\n[semantic-release-img]: https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg\n[semantic-release-url]: https://github.com/semantic-release/semantic-release\n[commitizen-img]: https://img.shields.io/badge/commitizen-friendly-brightgreen.svg\n[commitizen-url]: http://commitizen.github.io/cz-cli/\n"
  },
  "Rubilmax/executooor": {
    "fetchedAt": "2025-11-12T22:40:02.446Z",
    "content": "# executooor\n\n[![npm package][npm-img]][npm-url]\n[![Build Status][build-img]][build-url]\n[![Downloads][downloads-img]][downloads-url]\n[![Issues][issues-img]][issues-url]\n[![Commitizen Friendly][commitizen-img]][commitizen-url]\n[![Semantic Release][semantic-release-img]][semantic-release-url]\n\n> üõ£Ô∏è Batch multiple calls to any onchain smart contract in a single transaction, handling any callback, without writing and deploying any contract!\n\nEthereum's environment evolves fast. So fast that you can't keep up writing and deploying a new contract everytime you want to do something atomically onchain (not mentioning you also have to approve this freshly deployed contract to spend your favorite ERC20/ERC721!).\n\nWelcome the `Executor` contract:\n\n1. Calculate whatever you need to submit your execution\n2. Chain calls / delegatecalls as needed to execute whatever you want to execute atomically onchain (using `viem` and/or `ethers-v6`!)\n3. Optionally prepend any ERC20/ERC721 approval via a third-party bundling service (such as Flashbots)\n4. Submit your execution transaction (or bundle)\n5. For MEV out there: tip the bundler\n\nYou can even atomically populate your chain of calls if it depends on some state change!\nFor example, you can skim ERC20 tokens after an execution by simply requesting the balance left onchain and replacing it in the onchain call.\n\n---\n\n## Installation\n\n### viem\n\n```bash\nnpm install executooor-viem\n```\n\n```bash\nyarn add executooor-viem\n```\n\n### ethers-v6\n\n```bash\nnpm install executooor-ethers\n```\n\n```bash\nyarn add executooor-ethers\n```\n\n---\n\n## Usage\n\n### Deployment\n\nDeploy your very own `Executor` contract with the owner address you want, once and for all, using the [custom deployment interface](https://rubilmax.github.io/executooor/) (that you can also build locally).\n\nThe exact deployment bytecode is given below for convenience. You can deploy the Executor by broadcasting a transaction with this exact bytecode, appended with the owner address you want (typically your bot address).\n\nA merely cost of [0.003 ETH @ 10 gwei](https://etherscan.io/tx/0x77831c7dd4062a158efa527fc43938e0bafedac8c1de86703addc36e9b8ef077)!\n\n```typescript\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{YOUR_20_BYTES_OWNER_ADDRESS}\n```\n\n### Execution\n\nCreate an `ExecutorEncoder` instance and chain any calls wanted. Then, submit the transaction using `exec` (or populate the transaction using `populateExec`!).\n\n#### Using viem\n\n```typescript\nimport { ExecutorEncoder } from \"executooor\";\n\nconst encoder = new ExecutorEncoder(executorAddress, signer);\n\nawait encoder\n  // Flash loan some tokens on Balancer (0% fee).\n  .balancerFlashLoan(\n    balancerVaultAddress,\n    [{ asset: dai, amount: collateralAmount }],\n    // Chain calls executed inside Balancer's flash loan callback then flush it.\n    encoder\n      .erc20Approve(dai, aaveV2PoolAddress, collateralAmount)\n      .aaveV2Supply(aaveV2PoolAddress, dai, collateralAmount)\n      .aaveV2Borrow(aaveV2PoolAddress, weth, borrowedAmount, 2)\n      .unwrapETH(weth, borrowedAmount)\n      .wrapETH(weth, borrowedAmount)\n      .erc20Approve(weth, aaveV2PoolAddress, borrowedAmount)\n      .aaveV2Repay(aaveV2PoolAddress, weth, borrowedAmount, 2)\n      .aaveV2Withdraw(aaveV2PoolAddress, dai, MaxUint256)\n      .flush(),\n  )\n  // Execute the transaction.\n  .exec();\n```\n\n#### Using ethers-v6\n\n```typescript\nimport { ExecutorEncoder } from \"executooor\";\n\nconst encoder = new ExecutorEncoder(executorAddress, walletClient);\n\nawait encoder\n  // Flash loan some tokens on Balancer (0% fee).\n  .balancerFlashLoan(\n    balancerVaultAddress,\n    [{ asset: dai, amount: collateralAmount }],\n    // Chain calls executed inside Balancer's flash loan callback then flush it.\n    encoder\n      .erc20Approve(dai, aaveV2PoolAddress, collateralAmount)\n      .aaveV2Supply(aaveV2PoolAddress, dai, collateralAmount)\n      .aaveV2Borrow(aaveV2PoolAddress, weth, borrowedAmount, 2)\n      .unwrapETH(weth, borrowedAmount)\n      .wrapETH(weth, borrowedAmount)\n      .erc20Approve(weth, aaveV2PoolAddress, borrowedAmount)\n      .aaveV2Repay(aaveV2PoolAddress, weth, borrowedAmount, 2)\n      .aaveV2Withdraw(aaveV2PoolAddress, dai, MaxUint256)\n      .flush(),\n  )\n  // Execute the transaction.\n  .exec();\n```\n\n[build-img]: https://github.com/rubilmax/executooor/actions/workflows/release.yml/badge.svg\n[build-url]: https://github.com/rubilmax/executooor/actions/workflows/release.yml\n[downloads-img]: https://img.shields.io/npm/dt/executooor\n[downloads-url]: https://www.npmtrends.com/executooor\n[npm-img]: https://img.shields.io/npm/v/executooor\n[npm-url]: https://www.npmjs.com/package/executooor\n[issues-img]: https://img.shields.io/github/issues/rubilmax/executooor\n[issues-url]: https://github.com/rubilmax/executooor/issues\n[c\n\n[... truncated ...]"
  },
  "zhiqiangxu/opup": {
    "fetchedAt": "2025-11-12T22:40:10.456Z",
    "content": "# opup, one-stop installation tool for OP Stack\n\n\n# Usage\n\nTo start all processes, just run `just up`.\n \nIf anything goes wrong, it'll stop immediately, indicating the exact line that's triggering it.\n\nIf everything goes well, it'll spin up these processes:\n\n![all-processes](assets/all-processes.png)\n\n(Each process is managed in a separate [screen](https://linuxize.com/post/how-to-use-linux-screen/) session.)\n\nTo show all L1 contracts, just run `just l1`.\n\nTo shut down all processes, just run `just down`.\n\nTo nuke all data, just run `just nuke`.\n\n# Service Ports\n\n1. `op-geth`: rpc port is `8545`.\n2. `op-node`: rpc port is `8547`.\n3. `da-server`: rpc port is `8888`.\n4. `blockscout`: frontend port is `80`.\n"
  },
  "Dhruv-2003/pipegate": {
    "fetchedAt": "2025-11-12T22:40:17.797Z",
    "content": "# PipeGate\n\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/Dhruv-2003/pipegate)\n\n<!-- Pay-per-Call API Monetisation - The Web3 Stripe for APIs -->\n\nThe Web3 Stripe for APIs. Create payment channels or streams, make API calls, payments happen automatically. No API keys, no gas fees per request, just use your wallet and start building.\n\n<img width=\"952\" alt=\"Screenshot 2024-11-17 at 12 32 48‚ÄØAM\" src=\"https://github.com/user-attachments/assets/fe1b3926-224d-48e6-8dea-44214e471406\">\n\n## Description\n\nPipeGate transforms how APIs handle payments by replacing traditional API keys with stablecoin payments and clever cryptography. Instead of managing countless API keys and dealing with complex billing systems, developers can simply connect their wallet and pay for API usage through payment channels, streams, or one-time transactions.\n\n### üÜï Now with x402 Standard Support\n\nAs of version 0.6.0, PipeGate implements the [x402 payment protocol](https://x402.org), providing standardized payment headers and seamless integration across different payment schemes. This means better interoperability and a unified payment experience.\n\n### Detailed documentation: [docs.pipegate.xyz](https://docs.pipegate.xyz)\n\n**The protocol consists of three main components:**\n\n- A client-side middleware that automatically handles payment channel creation, request signing, and payment management\n- A server-side middleware that verifies signatures and manages state with minimal integration effort\n- A smart contract for a new payment channel creation\n\n**What you get:**\n\n- Pay-per-call pricing without gas fees for each request\n- Multiple payment options: channels, streams, or one-time payments\n- No API key management - just connect your wallet\n- Real-time usage tracking and automatic payments\n- Self-service onboarding for both providers and consumers\n\n**Problems solved:**\n\n- Too many API keys for each product\n- Complex API & Authentication infrastructure for providers\n- High payment processor fees eating into margin\n\n## Demo\n\n- [With Payment channels](https://youtu.be/8KZ1sLNRUwY)\n- [With Streams](https://www.youtube.com/live/lxjodEw3YQo?si=R7FWGjJ0uCrenwqH&t=410)\n\n## How it's made\n\nPipeGate is built with a focus on developer experience and standards compliance, implementing the x402 payment protocol for maximum interoperability.\n\n**Core Components:**\n\n1. **[Server Middleware (Rust)](https://github.com/Dhruv-2003/pipegate/tree/main/core/server)**:\n\n   - Unified `PaymentsLayer` supporting all payment schemes (v0.6.0+)\n   - x402-compliant header parsing and verification\n   - Automatic scheme detection (one-time, streams, channels)\n   - WASM compatibility for browser environments\n   - Legacy per-scheme middleware for backward compatibility\n\n2. **[Client SDK (TypeScript)](https://github.com/Dhruv-2003/pipegate/tree/main/core/client)**:\n\n   - Single `withPaymentInterceptor` function for all payment types\n   - Automatic 402 Payment Required handling and retry logic\n   - x402 standard compliant payment headers\n   - Axios interceptors with state management\n   - Legacy interceptors available for migration\n\n3. **[Smart Contracts (Solidity)](https://github.com/Dhruv-2003/pipegate/tree/main/core/contract)**:\n   - Payment Channel Factory with provider registration\n   - Efficient channel contracts using Beacon Proxy pattern\n   - Integration with Superfluid for streaming payments\n   - One-time payment verification through transaction logs\n\n**Payment Schemes Supported:**\n\n- **Payment Channels**: Gasless microtransactions with off-chain state updates\n- **Superfluid Streams**: Continuous payment flows for subscription-like access\n- **One-time Payments**: Simple pay-per-request using on-chain transactions\n\n**x402 Integration:**\nAll payment schemes follow the x402 standard with unified `X-Payment` headers containing `{ x402Version, network, scheme, payload }`, making PipeGate compatible with other x402-compliant services.\n\n## x402 Standard Implementation\n\nPipeGate implements the [x402 payment protocol](https://x402.org) for standardized API payment flows:\n\n**Payment Flow:**\n\n1. Client requests API endpoint\n2. Server responds with `402 Payment Required` containing accepted payment schemes\n3. Client automatically selects scheme, signs payment, and retries with `X-Payment` header\n4. Server verifies payment and processes request\n\n**Supported Schemes:**\n\n- `one-time`: Pay-per-request using transaction hashes\n- `stream`: Continuous payments via Superfluid streams\n- `channel`: Gasless microtransactions through payment channels\n\nSee our [x402 implementation spec](./x402.md) for detailed payment header formats.\n\n## Architecture & Flow\n\n### With Payment channels\n\n<img width=\"983\" alt=\"Screenshot 2024-12-12 at 12 09 55‚ÄØPM\" src=\"https://github.com/user-attachments/assets/9ab25e8b-35b2-4f9e-a131-166e80643bf7\" />\n\n### With Streams\n\n<img width=\"988\" alt=\"Screenshot 2025-01-23 at 10 02 26‚ÄØPM\" src=\"https://github.com/user-attachments/assets/0ad5a98f-c8a6-4c03-bf11-8618db3cb22f\" />\n\n## Published Libraries\n\n**Latest (v0.6.0+) - x402 Standard Support:**\n\n- [Rust Crate](https://crates.io/crates/pipegate) - Unified server middleware\n- [TypeScript SDK](https://www.npmjs.com/package/pipegate-sdk) - Universal client interceptor\n\nBoth libraries support all payment schemes through a single unified API, replacing the need for separate per-scheme implementations.\n\n## Quick Start\n\n### For API Providers\n\n**1. Add server middleware (Recommended - x402 unified approach)**\n\n```rust\nuse pipegate::middleware::{PaymentsLayer, PaymentsState, Scheme, SchemeConfig, MiddlewareConfig};\n\n// Support multiple payment schemes with one middleware\nlet config = MiddlewareConfig::new(vec![\n    SchemeConfig::new(Scheme::OneTimePayments, \"1\".to_string()).await,\n    SchemeConfig::new(Scheme::SuperfluidStreams, \"2\".to_string()).await,\n    SchemeConfig::new(Scheme::PaymentChannels, \"0.001\".to_string()).await,\n]);\n\nlet app = Router::new()\n    .route(\"/api\", get(handler))\n    .layer(PaymentsLayer::new(PaymentsState::new(), config));\n```\n\n**2. Register your API** (for payment channels)\n\n- Add pricing info to the ChannelFactory contract\n- [Registration guide](https://github.com/Dhruv-2003/pipegate/tree/main/core/contract#for-api-providers)\n\n### For API Consumers\n\n**x402 Unified Client (Recommended)**\n\n```typescript\nimport { withPaymentInterceptor } from \"pipegate-sdk\";\n\n// Works with any payment scheme\nconst client = withPaymentInterceptor(\n  axios.create({ baseURL: \"https://api.example.com\" }),\n  PRIVATE_KEY,\n  { oneTimePaymentTxHash: \"0x...\" } // or streamSender, or channel\n);\n\n// Automatic payment handling\nconst response = await client.get(\"/api/endpoint\");\n```\n\n**Legacy usage instructions and detailed setup guides are available in our [documentation](https://docs.pipegate.xyz).**\n\n## Team\n\n- [Dhruv Agarwal](https://0xdhruv.me) - Server Side SDK & Smart Contract Development\n- [Kushagra Sarathe](https://bento.me/kushagrasarathe) - CLient Side SDK\n"
  },
  "memester-xyz/surl": {
    "fetchedAt": "2025-11-12T22:40:25.147Z",
    "content": "# <h1 align=\"center\"> surl </h1>\n\n**Perform web requests from Solidity scripts/tests**\n\n![Github Actions](https://github.com/memester-xyz/surl/workflows/test/badge.svg)\n\n## Installation\n\n```\nforge install memester-xyz/surl\n```\n\n## Usage\n\n1. Add this import to your script or test:\n\n```solidity\nimport {Surl} from \"surl/Surl.sol\";\n```\n\n2. Add this directive inside of your Contract:\n\n```solidity\nusing Surl for *;\n```\n\n3. Make your HTTP requests:\n\n```solidity\n// Perform a simple get request\n(uint256 status, bytes memory data) = \"https://httpbin.org/get\".get();\n\n// Perform a get request with headers\nstring[] memory headers = new string[](2);\nheaders[0] = \"accept: application/json\";\nheaders[1] = \"Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==\";\n(uint256 status, bytes memory data) = \"https://httpbin.org/get\".get(headers);\n\n// Perform a post request with headers and JSON body\nstring[] memory headers = new string[](1);\nheaders[0] = \"Content-Type: application/json\";\n(uint256 status, bytes memory data) = \"https://httpbin.org/post\".post(headers, '{\"foo\": \"bar\"}');\n\n// Perform a put request\n(uint256 status, bytes memory data) = \"https://httpbin.org/put\".put();\n\n// Perform a patch request\n(uint256 status, bytes memory data) = \"https://httpbin.org/put\".patch();\n\n// Perform a delete request (unfortunately 'delete' is a reserved keyword and cannot be used as a function name)\n(uint256 status, bytes memory data) = \"https://httpbin.org/delete\".del();\n```\n\n4. You must enable [ffi](https://book.getfoundry.sh/cheatcodes/ffi.html) in order to use the library. You can either pass the `--ffi` flag to any forge commands you run (e.g. `forge script Script --ffi`), or you can add `ffi = true` to your `foundry.toml` file.\n\n### Notes\n\n- It assumes you are running on a UNIX based machine with `bash`, `tail`, `sed`, `tr`, `curl` and `cast` installed.\n\n## Example\n\nWe have example usage for both [tests](./test/Surl.t.sol) and [scripts](./script/). The tests also demonstrate how surl can be used to request quotes from DEX aggregators and parse their json response with [cheatcodes](https://book.getfoundry.sh/cheatcodes/parse-json).\n\n## Contributing\n\nClone this repo and run:\n\n```\nforge install\n```\n\nGet a [1inch API Key](https://1inch.dev/) and set it in a `.env` file (copy `.env.example`).\n\nMake sure all tests pass, add new ones if needed:\n\n```\nforge test\n```\n\n## Why?\n\n[Forge scripting](https://book.getfoundry.sh/tutorials/solidity-scripting.html) is becoming more popular. With Surl you can extend your scripts easily with HTTP requests.\n\n## Development\n\nThis project uses [Foundry](https://getfoundry.sh). See the [book](https://book.getfoundry.sh/getting-started/installation.html) for instructions on how to install and use Foundry.\n"
  },
  "joshstevens19/evmc": {
    "fetchedAt": "2025-11-12T22:40:31.813Z",
    "content": "[![npm version](https://badge.fury.io/js/evmcontracts.svg)](https://badge.fury.io/js/evmcontracts)\n\n# evmc\n\nWhen browsing any evm blockchain, it is often useful to be able to see the source code of a contract. This is especially true when trying to understand the behavior of a contract, or when trying to verify the behavior of a contract. You may be able to hack around and see it on etherscan but really you know your true home is your IDE (any IDE). This tool allows you to fetch the source code of a contract from the blockchain, and create you the full project files for you to view in YOUR IDE, support to deploy on a local node, compile if you choose to. This uses etherscan API to grab the verified sources of the contract.\nIt will keep the same directory structure as how the contract was deployed, alongside all of the dependencies it uses, the project evmc fetches for you will be ready to go!\n\n## Features üöÄ\n\nüöÄ Fetch the source code of a contract from the blockchain and use it in your favourite editor\n<br/>\nüöÄ Support for hardhat project instantly creating you a hardhat project template with the compile, deploy scripts and local node running all ready to go.\n<br/>\n\n## Chains Supported üåê\n\nüåê Ethereum Mainnet - eth\n<br/>\nüåê Ethereum Ropsten - eth_ropsten\n<br/>\nüåê Ethereum Rinkeby - eth_rinkeby\n<br/>\nüåê Ethereum Goerli - eth_goerli\n<br/>\nüåê Ethereum Kovan - eth_kovan\n<br/>\nüåê Binance Smart Chain Mainnet - bsc\n<br/>\nüåê Binance Smart Chain Testnet - bsc_testnet\n<br/>\nüåê Polygon Mainnet - polygon\n<br/>\nüåê Polygon Mumbai - mumbai\n<br/>\nüåê Avalanche C-Chain - avalanche\n<br/>\nüåê Avalanche Fuji - avalance_testnet\n<br/>\nüåê Fantom - fantom\n<br/>\nüåê Fantom Testnet - fantom_testnet\n<br/>\nüåê Optimism - optimism\n<br/>\nüåê Optimism Goerli - optimism_goerli\n<br/>\nüåê Arbitrum - arbitrum\n<br/>\nüåê Arbitrum Goerli - arbitrum_goerli\n<br/>\nüåê Cronos - cronos\n<br/>\nüåê Cronos Testnet - cronos_testnet\n\n## Installation\n\n### npm:\n\n```bash\n$ npm install evmcontracts -g\n```\n\n### yarn:\n\n```bash\n$ yarn global add evmcontracts\n```\n\n## CLI usage\n\nOnce installed it will expose a command called `evmc` which can be executed anywhere.\n\n### Get\n\nplease note when executing these commands it will create a folder with the name of the contract in the current directory you are in, unless you use `--output`\n\n### Just contracts\n\nTo get just the contracts without any development tool:\n\n```bash\n$ evmc get <network> <contractAddress>\n```\n\n### Development toolset project setup\n\n#### hardhat\n\nTo get the contract and setup a hardhat development environment, with deploy scripts and compiling ready to go:\n\n```bash\n$ evmc get <network> <contractAddress> --hardhat\n```\n\n#### foundry\n\nalready supported by the foundry team already it seems.. nice work!\n\n### To change the output path\n\n```bash\n$ evmc get <network> <contractAddress> --output=PATH_DIRECTORY\n```\n\n### Incoming features\n\nThe following features are coming soon:\n\nüöÄ allow you to interact with the contract without downloading them on your machine\n<br/>\nüöÄ ability to config your main network and development kit (to avoid repeating yourself)\n<br/>\nüöÄ ability to fetch multiple contracts at once with a yaml file\n<br/>\nüöÄ bring your own API key\n\n### note\n\nI have generated API keys so its plug and play but these are rate limited at 5 requests per second, this should be plenty as long as the tool does not used by thousands of people, these are free API keys so nobody has motive of stealing them. Above we bring a way to bring your own API key in anyway so if this ever happens we can migrate and make it best practice.\n"
  },
  "joshstevens19/ethereum-abi-types-generator": {
    "fetchedAt": "2025-11-12T22:40:39.700Z",
    "content": "[![npm version](https://badge.fury.io/js/ethereum-abi-types-generator.svg)](https://badge.fury.io/js/ethereum-abi-types-generator)\n![downloads](https://img.shields.io/npm/dw/ethereum-abi-types-generator)\n\n## ethereum-abi-types-generator \n\nDev typings for all your ethereum ABI contract methods and events with 1 liner integrations with `web3` and `ethers` üëèüëèüëèüëè. Never have to have a runtime error again and bring them into compile time errors in 2 minutes.\n\n<img src=\"./images/gif-demo.gif\" />\n\nA CLI tool which allows you to convert an ABI json file into fully loaded interfaces types.\n\n## Features üöÄ\n\nüöÄ Compile time errors, never make easy dynamic mistakes again.\n<br/>\nüöÄ Easy 1 line solution to get working\n<br/>\nüöÄ Use the same interfaces as the provider your use to, no changes in how you develop\n<br/>\nüöÄ Works with just a simple ABI json file\n<br/>\nüöÄ Supports `ethers` and `web3` out the box\n<br/>\nüöÄ 0 bundle increase, its all dev dependencies so get all the benefit with no negative impact on your build size\n<br/>\nüöÄ Nice easy CLI to allow you to generate these however you like, build scripts, watch file change events its up to you\n<br/>\nüöÄ Supported multidimensional return types aka `bytes32[4] >`[string, string, string, string, string]`\n<br/>\nüöÄ Automatic documentation generated on each method outputting all the details about it which is on the ABI - no jumping back and forth\n<br/>\nüöÄ Generated event typings\n\n## Supports\n\n- Web3 1.x and 2.x\n- Ethers 5.x\n- Ethers 4.x\n- Hardhat\n\n## ethereum-abi-types-generator vs TypeChain\n\nThe first question I normally get is ‚Äúhave you seen TypeChain‚Äù, yes I have of course and it is a great tool but it was missing and did a few things which I didn't want as a developer. The main differences with this ethereum-abi-types-generator vs typechain are:\n\n### No bundle size at all added\n\nWith TypeChain you have a class factory you have to connect to adding size into the final bundle. This package is all interfaces meaning nothing is added to your final bundle size.\n\n### Exposes proper typed interfaces meaning you can use them in your application\n\nTypeChain has dynamic interfaces aka `public contractCall(): Promise<{ foo: BigNumber }>` so if you wanted to use that interface somewhere in your app its not exported so can not be used. This lib generates response interfaces which are exported aka:\n\n```ts\nexport interface ContractCallResponse {\n  foo: BigNumber\n}\n\npublic contractCall(): Promise<ContractCallResponse>\n```\n\nThis means you can use this interface anywhere in your app as its just exported for you. The naming for this is `${contractCallMethodName}Response` aka if a method was called HelloWorld the response interface would be `HelloWorldResponse`. This also follows suit on the request interfaces aka:\n\n```ts\nexport interface FooRequest {\n  foo: BigNumber,\n  boo: string;\n}\n\npublic contractCall(request: FooRequest): Promise<ContractCallResponse>\n```\n\nIf you have worked with dynamic interfaces you understand the pain it brings having to recreate everytime.\n\n### Use your provider interface your use too\n\nTypeChain you have to connect to the factory then use the contract that way. With this lib you just use web3 or ethers interface for every contract call meaning you don't have to get use to another process it just works and zero code changes just cast and you got compile time errors for contracts.\n\n## Motivation\n\nBlockchain development in JavaScript is already super hard. You have all these tools like `truffle,` `ethers`, `web3` (the list goes on) which you have to get use to and the learning curve is already quite high. On top of this, you have loads of other tools to get things to work as you need. TypeScript allows you to bring runtime errors in the compiler but on contract calls most developers have to either build their own types meaning maintaining them and easily getting out of sync or have no compile type errors using the dreaded `any` hoping and praying you don't break anything. The idea was to not have to make the developer wrap any kind of `web3` or `ethers` instance or use a new tool to get this working but with a simple 1 line change you can use all the same libraries interfaces as what the developer is use to but with `types` `auto-generated` for you to bring back compile-time errors on any contract calls with super ease.\n\nThe ABI file is the source of truth for all contract calls so by building types from this file we can be assured our types correct.\n\n## Installation\n\n### npm:\n\n```js\n$ npm install ethereum-abi-types-generator --save-dev\n```\n\n### yarn:\n\n```js\n$ yarn add ethereum-abi-types-generator --dev\n```\n\nYou can install this globally as well but you **must** make sure wherever the `--output` location is which generates the typings file has `ethereum-abi-types-generator` installed in that project, as it uses imports from this package to map the `ContractContext` to make your life easier handling the generic type build up automatically. We suggest always running this tool inside a project context.\n\n## Tsconfig compile time issues\n\nIf you get compile time errors due to it waiting `web3` dependencies when using ethers please set `skipLibCheck`: true in the tsconfig.json compiler options and this should fix that issue.\n\n## CLI usage\n\n### Web3 1.x and 2.x & Ethers 5.x & Ethers 4.x\n\n```ts\n$ abi-types-generator <abiFileLocation>\n$ abi-types-generator <abiFileLocation> --name=ABI_NAME\n$ abi-types-generator <abiFileLocation> --watch\n$ abi-types-generator <abiFileLocation> --name=ABI_NAME --watch\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --watch\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --name=ABI_NAME\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --name=ABI_NAME --watch\n$ abi-types-generator <abiFileLocation> --provider=web3|ethers|ethers_v5\n$ abi-types-generator <abiFileLocation> --provider=web3|ethers|ethers_v5 --watch\n$ abi-types-generator <abiFileLocation> --name=ABI_NAME --provider=web3|ethers|ethers_v5\n$ abi-types-generator <abiFileLocation> --name=ABI_NAME --provider=web3|ethers|ethers_v5 --watch\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --provider=web3|ethers|ethers_v5\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --provider=web3|ethers|ethers_v5 --watch\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --name=ABI_NAME --provider=web3|ethers|ethers_v5\n$ abi-types-generator <abiFileLocation> --output=PATH_DIRECTORY --name=ABI_NAME --provider=web3|ethers|ethers_v5 --watch\n```\n\n#### Hardhat\n\n```ts\n$ abi-types-generator hardhat\n```\n\nWe suggest running these within the `script` commands in npm or yarn this way you will not lose your commands and can be run on build agents as well. Also you will not get confused with sharing the script and others running in the wrong paths. Examples below:\n\n```json\n{\n  \"name\": \"examples\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"web3-example\": \"abi-types-generator './abi-examples/fake-contract-abi.json' --output='./web3/fake-contract-example/generated-typings' --name=fake-contract\",\n    \"web3-token-abi\": \"abi-types-generator './abi-examples/token-abi.json' --output='./web3/uniswap-example/generated-typings' --name=token-contract\",\n    \"web3-uniswap-exchange-abi\": \"abi-types-generator './abi-examples/uniswap-exchange-abi.json' --output='./web3/uniswap-example/generated-typings' --name=uniswap-exchange-contract\",\n    \"web3-uniswap-factory-abi\": \"abi-types-generator './abi-examples/uniswap-factory-abi.json' --output='./web3/uniswap-example/generated-typings' --name=uniswap-factory-contract\",\n    \"web3-uniswap\": \"npm run web3-token-abi && npm run web3-uniswap-exchange-abi && npm run web3-uniswap-factory-abi\",\n    \"ethers-example\": \"abi-types-generator './abi-examples/fake-contract-abi.json' --output='./ethers/fake-contract-example/generated-typings' --name=fake-\n\n[... truncated ...]"
  },
  "joshstevens19/simple-uniswap-sdk": {
    "fetchedAt": "2025-11-12T22:40:47.276Z",
    "content": "# simple-uniswap-sdk\n\n[![npm version](https://badge.fury.io/js/simple-uniswap-sdk.svg)](https://badge.fury.io/js/simple-uniswap-sdk)\n![downloads](https://img.shields.io/npm/dw/simple-uniswap-sdk)\n\nUniswap SDK which handles the routes automatically for you, changes in trade quotes reactive subscriptions, exposure to formatted easy to understand information, bringing back the best trade quotes automatically, generating transactions for you and much more. All the uniswap logic for you in a simple to easy understand interface to hook straight into your dApp without having to understand how it all works. \n\nPlease note this is not owned or maintained by uniswap and is a open source package for anyone to use freely.\n\n## Features üöÄ\n\nüöÄ Supports uniswap v2 and v3 prices together and returns you the best price, so you do not need to query both yourself\n<br/>\nüöÄ Queries all the best routes and finds the best price for you\n<br/>\nüöÄ Exposes all the route paths it tried so you can see every detail in how it worked out the best price\n<br/>\nüöÄ Factor in the cost of the transaction into the quotes with 1 config change\n<br/>\nüöÄ Easy subscriptions to get alerted when the price moves or the trade expires\n<br/>\nüöÄ The transaction is generated for you, just fill it with the gas details and send it on its way\n<br/>\nüöÄ All the figures are all formatted for you, no need to worry about timing it back to its decimal formatted place, just render it straight onto your UI\n<br/>\nüöÄ Exposes all the tokens metadata for you, name, symbol, decimals\n<br/>\nüöÄ Uses [multicall](https://github.com/joshstevens19/ethereum-multicall) for every on chain lookup, so even though it could be doing 100 JSONRPC calls it is all put into a few calls meaning it can stay very fast\n<br/>\nüöÄ Tidy bundle size\n<br/>\nüöÄ Fully typescript supported with full generated typings\n<br/>\nüöÄ query many tokens in 1 jsonrpc call perfect to get token metadata fast\n<br/>\nüöÄ and much more!!\n\n# Motivation\n\nAs a ethereum dApp developer you try to get your dApp experience as integrated as possible, Ethereum right now is hard to show in a web2.0 world as it is. On top of this as a developer you have to learn all the complex stuff for the blockchain which can take its toll on you.\n\nWhen I was integrating uniswap on our wallet I found that their `SDK` was a bit too much for what I needed. Deepdown from the dApp point of view I only really cared about getting the best price for the user with all the fees related. I also found myself having to write a lot of custom code which I thought could be abstracted away so nobody has to deal with that again. A lot of the uniswap features like routing is all done in their client itself which is great but not when you want to use it in a more integrated approach in your on dApp.\n\n`Uniswap` is one of the BEST projects on ethereum and one of my favourites. My motivation here is to create a library which allows more people to integrate it on their dApp without having to worry about how their amazing software links together. This makes the whole user experience better and allows more developers to get involved integrating uniswap in their dApp with a web2.0 experience, and on top of this also growing the usage of it.\n\np.s I have huge love for unicorns\n\n# Installing\n\n## npm\n\n```bash\n$ npm install simple-uniswap-sdk\n```\n\n## yarn\n\n```bash\n$ yarn add simple-uniswap-sdk\n```\n\n# SDK guide\n\n## Creating a uniswap pair factory\n\nThe uniswap pair factory is an instance which is joint together with the `from` token and the `to` token, it is all self contained in the instance and exposes easy methods for you to call to start using uniswap.\n\n```ts\nexport class UniswapPair {\n  constructor(\n    private _uniswapPairContext:\n      | UniswapPairContextForChainId\n      | UniswapPairContextForProviderUrl\n      | UniswapPairContextForEthereumProvider\n)\n```\n\n```ts\n// can support any network using the `CustomNetwork` and `CloneUniswapContractDetails` properties\nexport enum ChainId {\n  MAINNET = 1,\n  ROPSTEN = 3,\n  RINKEBY = 4,\n  G√ñRLI = 5,\n  KOVAN = 42,\n}\n\ninterface UniswapPairContextBase {\n  fromTokenContractAddress: string;\n  toTokenContractAddress: string;\n  ethereumAddress: string;\n  settings?: UniswapPairSettings | undefined;\n}\n\nexport interface UniswapPairContextForEthereumProvider\n  extends UniswapPairContextBase {\n  // can take any ethers provider, web3 provider or custom ethereum provider\n  ethereumProvider: any;\n}\n\nexport interface UniswapPairContextForChainId extends UniswapPairContextBase {\n  chainId: ChainId | number;\n}\n\nexport interface UniswapPairContextForProviderUrl\n  extends UniswapPairContextForChainId {\n  providerUrl: string;\n}\n```\n\n```ts\nexport interface GasSettings {\n  getGasPrice: () => Promise<number>;\n}\n\nexport type IRouterMethods = {\n  [key in IRouterMethodName]: string;\n};\n\nexport interface CloneUniswapContractDetailsV2 {\n  routerAddress: string;\n  factoryAddress: string;\n  pairAddress: string;\n  routerAbi?: JsonFragment[];\n  routerMethods?: Partial<IRouterMethods>;\n}\n\nexport interface CloneUniswapContractDetailsV3 {\n  routerAddress: string;\n  factoryAddress: string;\n  quoterAddress: string;\n}\n\nexport interface CloneUniswapContractDetails {\n  v2Override?: CloneUniswapContractDetailsV2 | undefined;\n  v3Override?: CloneUniswapContractDetailsV3 | undefined;\n}\n\nexport interface Token {\n  chainId: ChainId;\n  contractAddress: string;\n  decimals: number;\n  symbol: string;\n  name: string;\n}\n\nexport interface NativeCurrencyInfo {\n  name: string;\n  symbol: string;\n}\n\nexport interface CustomNetwork {\n  nameNetwork: string;\n  multicallContractAddress: string;\n  nativeCurrency: NativeCurrencyInfo;\n  nativeWrappedTokenInfo: Token;\n  // defined your base tokens here if any for your custom network!\n  baseTokens?: {\n    usdt?: Token | undefined;\n    dai?: Token | undefined;\n    comp?: Token | undefined;\n    usdc?: Token | undefined;\n    wbtc?: Token | undefined;\n  };\n}\n\nexport class UniswapPairSettings {\n  slippage: number;\n  deadlineMinutes: number;\n  disableMultihops: boolean;\n  uniswapVersions: UniswapVersion[] = [UniswapVersion.v2, UniswapVersion.v3];\n  gasSettings?: GasSettings = undefined;\n  // can be used to pass in a fork of uniswap contract details\n  cloneUniswapContractDetails?: CloneUniswapContractDetails = undefined;\n  // can be used to define unsupported networks\n  customNetwork?: CustomNetwork = undefined;\n\n  constructor(settings?: {\n    slippage?: number | undefined;\n    deadlineMinutes?: number | undefined;\n    disableMultihops?: boolean | undefined;\n    uniswapVersions?: UniswapVersion[] | undefined;\n    gasSettings?: GasSettings | undefined;\n    cloneUniswapContractDetails?: CloneUniswapContractDetails | undefined;\n    customNetwork?: CustomNetwork | undefined;\n  }) {\n    this.slippage = settings?.slippage || 0.0005;\n    this.deadlineMinutes = settings?.deadlineMinutes || 20;\n    this.disableMultihops = settings?.disableMultihops || false;\n    this.gasSettings = settings?.gasSettings;\n    this.cloneUniswapContractDetails = settings?.cloneUniswapContractDetails;\n    this.customNetwork = settings?.customNetwork;\n\n    if (\n      Array.isArray(settings?.uniswapVersions) &&\n      settings?.uniswapVersions.length === 0\n    ) {\n      throw new UniswapError(\n        '`uniswapVersions` must not be an empty array',\n        ErrorCodes.uniswapVersionsMustNotBeAnEmptyArray\n      );\n    }\n\n    if (\n      settings &&\n      Array.isArray(settings.uniswapVersions) &&\n      settings.uniswapVersions.length > 0\n    ) {\n      this.uniswapVersions = settings?.uniswapVersions;\n    }\n  }\n}\n```\n\n### With only the chainId\n\nThis will use a infura endpoint without you having to pass in a node\n\n```ts\nimport { UniswapPair, ChainId, UniswapVersion, ETH } from 'simple-uniswap-sdk';\n\nconst uniswapPair = new UniswapPair({\n  // the contract address of the token you want to convert FROM\n  fromTokenContractAddress: ETH.MAINNET().contractAddress,\n  // the contract address of the token you want to convert TO\n  toTokenContractAd\n\n[... truncated ...]"
  },
  "3loop/loop-decoder": {
    "fetchedAt": "2025-11-12T22:40:54.345Z",
    "content": "# Loop Decoder\n\n[![Action status](https://github.com/3loop/loop-decoder/actions/workflows/pull-request.yml/badge.svg)](https://github.com/3loop/loop-decoder/actions/workflows/pull-request.yml)\n\n## Decode and interpret any EVM-based transactions\n\nA library to transform any EVM transaction into a human-readable format. It consists of 2 parts:\n\n- [Transaction decoder](https://github.com/3loop/loop-decoder/tree/main/packages/transaction-decoder)\n- [Transaction interpreter](https://github.com/3loop/loop-decoder/tree/main/packages/transaction-interpreter) (experimental)\n\n> ‚ö†Ô∏è The Transaction Interpreter is still under development and breaking changes are expected.\n\n![Screenshot 2024-10-17 at 13 05 55](https://github.com/user-attachments/assets/c5f87539-7b21-43fe-8e8a-39359322e547)\n\n## Documentation\n\n[Head to the documentation](https://loop-decoder.3loop.io/) to read and learn more about the Loop Decoder, or check out our [playground](https://loop-decoder-web.vercel.app/) to see it in action.\n\n## Contribution to Interpretations\n\nIf you're familiar with a specific contract or protocol, or want your own contracts to appear in human-readable interpretations, please contribute to Transaction Interpreter! Check out our [Contribution Guide](https://loop-decoder.3loop.io/contribution/) to learn how to get started.\n\n## Why\n\nTransaction decoding is a crucial component of many dApps. Our goal is to create a library that can be integrated into any application without introducing any external infrastructure dependencies. This will allow developers to integrate decoding and interpretation into their stack without enforcing any data sources.\n\nCurrently, the available EVM transaction decoders require developers to use specific databases or provide a lower-level API that requires maintenance. The Loop Decoder, however, can be used as a plug-and-play component in any layer of dApp infrastructure.\n\nThe open-source nature of the Loop Decoder allows developers to also integrate new chains as they see fit. While using a third party closed-source decoder, developers are limited to the chains that the provider supports. This can be a significant burden for developers who want to support multiple emerging chains.\n\n### Glossary\n\n- **Transaction Decoder**: Decoder automates the decoding of any transaction data, event log and trace, in a unified format. We leverage multiple data sources for contract metadata and ABI resolution. With an unified interface to decode transactions across any protocol, developers don't have to manually understand and decode each individual transactions.\n- **Transaction Interpreter**: Interpreter is a flexible layer that allows developers to define custom interpretation of a decoded transactions. In context of this library, an interpretation is a transformation from a decoded transaction to a human-readable format. It is used to extract the most significant information that can be directly displayed to a non techincal user.\n\n## Features\n\n- [x] Can be used in any JavaScript environment\n- [x] Minimal external dependencies - connect your own storage\n- [x] Predefined ABI and Contract metadata resolvers\n- [x] Resolves contract proxise and multicalls\n- [x] Flexible interpreter that allows you to define any custom interpretation of EVM transactions.\n\n## Examples\n\n- [Decoder HTTP Server](https://github.com/3loop/decoder-api) - A simple HTTP server that exposes an REST API to decode transactions.\n- [Firebase Push Notifications](https://github.com/3loop/example-push-notifications) - Firebase Cloud Function that sends push notifications with decoded transactions.\n- [Farcaster Bot](https://loop-decoder.3loop.io/recipes/fc-bot/) - Farcaster Bot for human-readable transaction alerts\n- [Telegram Bot](https://loop-decoder.3loop.io/recipes/tg-bot/) - Telegram Bot for human-readable transaction alerts\n- [Next.JS Playground](https://github.com/3loop/loop-decoder/tree/main/apps/web) - Interactive playground to decode and interpret transactions\n\n## Monorepo Structure\n\n- `apps`\n  - [docs](https://github.com/3loop/loop-decoder/tree/main/apps/docs) - Documentation website using astro starlight.\n  - [web](https://github.com/3loop/loop-decoder/tree/main/apps/docs) - Interactive playground based on Next.js.\n- `packages`\n  - [transaction-decoder](https://github.com/3loop/loop-decoder/tree/main/packages/transaction-decoder) - Transaction decoder package\n  - [transaction-interpreter](https://github.com/3loop/loop-decoder/tree/main/packages/transaction-interpreter) - Transaction interpreters\n\n## Looking for feedback\n\nPlease let us know about your use cases and how this project can help you. You can reach us on Twitter [@nastyarods](https://twitter.com/nastyarods) and [@Ferossgp](https://twitter.com/Ferossgp), or through email at [contact@3loop.io](mailto:contact@3loop.io).\n"
  },
  "dl-solarity/hardhat-zkit": {
    "fetchedAt": "2025-11-12T22:41:03.247Z",
    "content": "![](https://github.com/dl-solarity/hardhat-zkit/assets/47551140/938bf108-194d-45de-a6f1-7280aaa0c8c1)\n\n[![npm](https://img.shields.io/npm/v/@solarity/hardhat-zkit.svg)](https://www.npmjs.com/package/@solarity/hardhat-zkit)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![tests](https://github.com/dl-solarity/hardhat-zkit/actions/workflows/tests.yml/badge.svg?branch=master)](https://github.com/dl-solarity/hardhat-zkit/actions/workflows/tests.yml)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/dl-solarity/hardhat-zkit/badge)](https://www.gitpoap.io/gh/dl-solarity/hardhat-zkit)\n[![hardhat](https://hardhat.org/buidler-plugin-badge.svg?1)](https://hardhat.org)\n\n# Hardhat ZKit\n\n**The ultimate TypeScript environment for Circom development.**\n\n## What\n\nThis hardhat plugin is a zero-config, one-stop Circom development environment that streamlines circuits management and lets you focus on the important - code.\n\n- Developer-oriented abstractions that simplify `r1cs`, `witness`, `zkey`, and `vkey` generation processes.\n- Support of `groth16` and `plonk` proving systems.\n- Recompilation and resetup of only the modified circuits.\n- Full TypeScript typization of signals and ZK proofs.\n- Automatic downloads of phase-1 `ptau` files.\n- Convenient phase-2 contributions to `zkey` files.\n- Practical witness (with signals substitution) and proof testing via chai assertions.\n- Invisible platform-specific and `wasm`-based Circom compiler management.\n- Simplified `node_modules` libraries resolution.\n- Rich plugin configuration.\n- And much more!\n\n## Installation\n\n```bash\nnpm install --save-dev @solarity/hardhat-zkit\n```\n\nAnd add the following line to your `hardhat.config`:\n\n```ts\nimport \"@solarity/hardhat-zkit\"; // TypeScript\n\nrequire(\"@solarity/hardhat-zkit\"); // JavaScript\n```\n\n> [!TIP]\n> There is no need to download the Circom compiler separately. The plugin automatically installs required compilers under the hood.\n\n## Usage\n\nThe `hardhat-zkit` is a zero-config plugin, however, you may add the following to your `hardhat.config` file:\n\n```ts\nmodule.exports = {\n  zkit: {\n    compilerVersion: \"2.1.9\",\n    circuitsDir: \"circuits\",\n    compilationSettings: {\n      artifactsDir: \"zkit/artifacts\",\n      onlyFiles: [],\n      skipFiles: [],\n      c: false,\n      json: false,\n      optimization: \"O1\",\n    },\n    setupSettings: {\n      contributionSettings: {\n        provingSystem: \"groth16\", // or \"plonk\"\n        contributions: 2,\n      },\n      onlyFiles: [],\n      skipFiles: [],\n      ptauDir: undefined,\n      ptauDownload: true,\n    },\n    verifiersSettings: {\n      verifiersDir: \"contracts/verifiers\",\n      verifiersType: \"sol\", // or \"vy\"\n    },\n    typesDir: \"generated-types/zkit\",\n    typesWitnessLimit: 50000,\n    quiet: false,\n  },\n};\n```\n\nWhere:\n\n- `compilerVersion` - The value to indicate which Circom compiler to use (latest by default).\n- `circuitsDir` - The directory where to look for the circuits.\n- `compilationSettings`\n  - `artifactsDir` - The directory where to save the circuits artifacts (r1cs, zkey, etc).\n  - `onlyFiles` - The list of directories (or files) to be considered for the compilation.\n  - `skipFiles` - The list of directories (or files) to be excluded from the compilation.\n  - `c` - The flag to generate the c-based witness generator (generates wasm by default).\n  - `json` - The flag to output the constraints in json format.\n  - `optimization` - The flag to set the level of constraint simplification during compilation (`\"O0\"`, `\"O1\"` or `\"O2\"`). \n- `setupSettings`\n  - `contributionSettings`\n    - `provingSystem` - The option to indicate which proving system to use (`\"groth16\"`, `\"plonk\"` or `[\"groth16\", \"plonk\"]`).\n    - `contributions` - The number of phase-2 `zkey` contributions to make if `groth16` is chosen.\n  - `onlyFiles` - The list of directories (or files) to be considered for the setup phase.\n  - `skipFiles` - The list of directories (or files) to be excluded from the setup phase.\n  - `ptauDir` - The directory where to look for the `ptau` files. `$HOME/.zkit/ptau/` by default.\n  - `ptauDownload` - The flag to allow automatic download of required `ptau` files.\n- `verifiersSettings`\n    - `verifiersDir` - The directory where to generate the Solidity | Vyper verifiers.\n    - `verifiersType` - The option (`\"sol\"` or `\"vy\"`) to indicate which language to use for verifiers generation.\n- `typesDir` - The directory where to save the generated typed circuits wrappers.\n- `typesWitnessLimit` - The maximum number of witness substitution signals to generate types for.\n- `quiet` - The flag indicating whether to suppress the output.\n\n### Tasks\n\nThere are several hardhat tasks in the `zkit` scope that the plugin provides:\n\n- `compile` task that compiles or recompiles the modified circuits with the main component.\n- `setup` task that generates or regenerates `zkey` and `vkey` for the previously compiled circuits.\n- `make` task that executes both `compile` and `setup` for convenience.\n- `verifiers` task that generates Solidity | Vyper verifiers for all the previously setup circuits.\n- `clean` task that cleans up the generated artifacts, types, etc.\n\nTo view the available options, run the help command:\n\n```bash\nnpx hardhat help zkit <zkit task name>\n```\n\n### Typization\n\nThe plugin provides full TypeScript typization of Circom circuits leveraging [`zktype`](https://github.com/dl-solarity/zktype) library. Both `groth16` and `plonk` proving systems are supported.\n\nThe following config may be added to `tsconfig.json` file to allow for a better development experience:\n\n```json\n{\n  \"compilerOptions\": {\n    \"paths\": {\n      \"@zkit\": [\"./generated-types/zkit\"]\n    }\n  }\n}\n```\n\n### Testing\n\nIn order to utilize user-friendly [Chai](https://www.chaijs.com/) assertions for witness and ZK proof testing, the [`chai-zkit`](https://github.com/dl-solarity/chai-zkit) package needs to be installed:\n\n```bash\nnpm install --save-dev @solarity/chai-zkit\n```\n\nAnd add the following line to your `hardhat.config`:\n\n```ts\nimport \"@solarity/chai-zkit\"; // TypeScript\n\nrequire(\"@solarity/chai-zkit\"); // JavaScript\n```\n\nThe package extends `expect` chai assertion to recognize typed `zktype` objects for frictionless testing experience.\n\nThe plugin supports:\n\n1. Basic witness `input` -> `output` testing.\n2. Deep witness (signals) substitution testing.\n3. Proof generation success/failure testing.\n4. Circuit constraints number testing.\n\n> [!NOTE]\n> Please note that for witness testing purposes it is sufficient to compile circuits just with `zkit compile` task, without generating the keys.\n\n### Example\n\nThe plugin extends the hardhat environment with the `zkit` object that allows typed circuits to be used in scripts and tests:\n\n<table style=\"width:100%\">\n<tr>\n<th>Circom circuit</th>\n<th>Usage example</th>\n</tr>\n\n<tr>\n<td>\n\n```circom\n// file location: ./circuits/multiplier.circom\n\npragma circom 2.0.0;\n\ntemplate Multiplier() {\n   signal input in1;\n   signal input in2;\n   signal output out;\n\n   out <== in1 * in2;\n}\n\n// main component to compile the circuit\ncomponent main = Multiplier();\n```\n\n</td>\n<td>\n\n```ts\n// file location: ./test/multiplier.test.ts\n\nimport { zkit } from \"hardhat\"; // hardhat-zkit plugin\nimport { expect } from \"chai\"; // chai-zkit extension\nimport { Multiplier } from \"@zkit\"; // zktype circuit-object\n\ndescribe(\"Multiplier\", () => {\n  it(\"should test the circuit\", async () => {\n    const circuit: Multiplier = await zkit.getCircuit(\"Multiplier\");\n    // or await zkit.getCircuit(\"circuits/multiplier.circom:Multiplier\");\n\n    // witness testing\n    await expect(circuit)\n        // provide a second parameter here to override witness values\n        .with.witnessInputs({ in1: \"3\", in2: \"7\" })\n        .to.have.witnessOutputs({ out: \"21\" });\n\n    // proof testing\n    const proof = await circuit.generateProof({ in1: \"4\", in2: \"2\" });\n\n    await expect(circuit).to.verifyProof(proof);\n  });\n});\n```\n\n</td>\n</tr>\n</table>\n\nTo s\n\n[... truncated ...]"
  },
  "dl-solarity/solidity-lib": {
    "fetchedAt": "2025-11-12T22:41:03.539Z",
    "content": "![](https://github.com/dl-solarity/solidity-lib/assets/47551140/87464015-a97a-4f5b-a16f-b34c98eb6549)\n\n[![npm](https://img.shields.io/npm/v/@solarity/solidity-lib.svg)](https://www.npmjs.com/package/@solarity/solidity-lib)\n[![Coverage Status](https://codecov.io/gh/dl-solarity/solidity-lib/graph/badge.svg)](https://codecov.io/gh/dl-solarity/solidity-lib)\n[![Tests](https://github.com/dl-solarity/solidity-lib/actions/workflows/tests.yml/badge.svg)](https://github.com/dl-solarity/solidity-lib/actions/workflows/tests.yml)\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-yellow)](https://docs.solarity.dev/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/dl-solarity/solidity-lib/badge)](https://www.gitpoap.io/gh/dl-solarity/solidity-lib)\n\n# Solarity Solidity Library\n\nSolidity contracts and utilities that **go far beyond mediocre solidity**.\n\n## Contracts\n\n```ml\ncontracts\n‚îú‚îÄ‚îÄ access\n‚îÇ   ‚îú‚îÄ‚îÄ AMerkleWhitelisted ‚Äî \"Whitelists via Merkle proofs\"\n‚îÇ   ‚îú‚îÄ‚îÄ AMultiOwnable ‚Äî \"Multiple owners with the equal access level\"\n‚îÇ   ‚îú‚îÄ‚îÄ ARBAC ‚Äî \"A powerful implementation of a true RBAC\"\n‚îÇ   ‚îî‚îÄ‚îÄ extensions\n‚îÇ       ‚îî‚îÄ‚îÄ ARBACGroupable ‚Äî \"Groupable extension of ARBAC\"\n‚îú‚îÄ‚îÄ account‚Äîabstraction\n‚îÇ   ‚îú‚îÄ‚îÄ AAccountRecovery ‚Äî \"ERC-7947 account recovery base implementation\"\n‚îÇ   ‚îî‚îÄ‚îÄ ARecoverableAccount ‚Äî \"All-in-one account with batching, gas sponsorship, and recovery\"\n‚îú‚îÄ‚îÄ bridge\n‚îÇ   ‚îú‚îÄ‚îÄ batcher\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Batcher ‚Äî \"Batch calls execution during bridge redemption\"\n‚îÇ   ‚îú‚îÄ‚îÄ handlers\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ERC20Handler ‚Äî \"ERC-20 bridging (liquidity pool, mint-and-burn, or USDC-specific)\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageHandler ‚Äî \"Arbitrary cross-chain message dispatch and redemption\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NativeHandler ‚Äî \"Native asset bridging\"\n‚îÇ   ‚îî‚îÄ‚îÄ ABridge ‚Äî \"Simple and modular arbitrary message bridge with batching logic\"\n‚îú‚îÄ‚îÄ contracts‚Äîregistry\n‚îÇ   ‚îú‚îÄ‚îÄ AContractsRegistry ‚Äî \"Reference registry implementation of ERC-6224 pattern\"\n‚îÇ   ‚îú‚îÄ‚îÄ ADependant ‚Äî \"Reference dependant implementation of ERC-6224 pattern\"\n‚îÇ   ‚îî‚îÄ‚îÄ pools\n‚îÇ       ‚îú‚îÄ‚îÄ APoolContractsRegistry ‚Äî \"Adaptation of ERC-6224 for factory-like contracts\"\n‚îÇ       ‚îî‚îÄ‚îÄ APoolFactory ‚Äî \"Factory implementation for a pooled registry\"\n‚îú‚îÄ‚îÄ diamond\n‚îÇ   ‚îú‚îÄ‚îÄ ADiamondStorage ‚Äî \"The storage part of ERC-2535 diamond\"\n‚îÇ   ‚îú‚îÄ‚îÄ Diamond ‚Äî \"Revised ERC-2535 diamond implementation\"\n‚îÇ   ‚îî‚îÄ‚îÄ utils\n‚îÇ       ‚îî‚îÄ‚îÄ DiamondERC165 ‚Äî \"ERC-165 introspection for diamond facets\"\n‚îú‚îÄ‚îÄ finance\n‚îÇ   ‚îú‚îÄ‚îÄ staking\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AStaking ‚Äî \"Flexible rewards staking implementation\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AValueDistributor ‚Äî \"Efficient distribution algorithm implementation\"\n‚îÇ   ‚îî‚îÄ‚îÄ vesting\n‚îÇ       ‚îî‚îÄ‚îÄ AVesting ‚Äî \"Linear and exponential vesting implementation\"\n‚îú‚îÄ‚îÄ libs\n‚îÇ   ‚îú‚îÄ‚îÄ arrays\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ArrayHelper ‚Äî \"Common functions to work with arrays\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Paginator ‚Äî \"Return array slices from view function\"\n‚îÇ   ‚îú‚îÄ‚îÄ bitcoin\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BlockHeader ‚Äî \"Parse and format Bitcoin block headers\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TxMerkleProof ‚Äî \"Verify transaction inclusion in Bitcoin block\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TxParser ‚Äî \"Parse and format Bitcoin transactions\"\n‚îÇ   ‚îú‚îÄ‚îÄ bn\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ U512 ‚Äî \"A hyperoptimized uint512 implementation\"\n‚îÇ   ‚îú‚îÄ‚îÄ crypto\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EC256 ‚Äî \"Weierstrass elliptic curve arithmetic over a 256-bit prime field\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ED256 ‚Äî \"Twisted Edwards elliptic curve arithmetic over a 256-bit prime field\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ECDSA256 ‚Äî \"ECDSA verification over any 256-bit curve\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ECDSA384 ‚Äî \"ECDSA verification over any 384-bit curve\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ECDSA512 ‚Äî \"ECDSA verification over any 512-bit curve\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Schnorr256 ‚Äî \"Schnorr + adaptor signature verification over any 256-bit curve\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RSASSAPSS ‚Äî \"RSASSA-PSS signature verification with MGF1\"\n‚îÇ   ‚îú‚îÄ‚îÄ data‚Äîstructures\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AvlTree ‚Äî \"AVL tree implementation with an iterator traversal\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CartesianMerkleTree ‚Äî \"CMT reference implementation\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DynamicSet ‚Äî \"Set for strings and bytes\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IncrementalMerkleTree ‚Äî \"IMT implementation with flexible tree height\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PriorityQueue ‚Äî \"Max queue heap implementation\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SparseMerkleTree ‚Äî \"SMT optimized implementation\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memory\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Vector ‚Äî \"A pushable memory array\"\n‚îÇ   ‚îú‚îÄ‚îÄ utils\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DecimalsConverter ‚Äî \"Simplify interaction with ERC-20 decimals\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EndianConverter ‚Äî \"Convert between little-endian and big-endian formats\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MemoryUtils ‚Äî \"Functions for memory manipulation\"\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ReturnDataProxy ‚Äî \"Bypass extra returndata copy when returning data\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Typecaster ‚Äî \"Cast between various Solidity types\"\n‚îÇ   ‚îî‚îÄ‚îÄ zkp\n‚îÇ       ‚îú‚îÄ‚îÄ Groth16VerifierHelper ‚Äî \"Simplify integration with Groth16 proofs\"\n‚îÇ       ‚îî‚îÄ‚îÄ PlonkVerifierHelper ‚Äî \"Simplify integration with Plonk proofs\"\n‚îú‚îÄ‚îÄ proxy\n‚îÇ   ‚îî‚îÄ‚îÄ adminable\n‚îÇ       ‚îú‚îÄ‚îÄ AdminableProxy ‚Äî \"A slight modification of a transparent proxy\"\n‚îÇ       ‚îî‚îÄ‚îÄ AdminableProxyUpgrader ‚Äî \"A slight modification of a proxy admin\"\n‚îú‚îÄ‚îÄ tokens\n‚îÇ   ‚îî‚îÄ‚îÄ ASBT ‚Äî \"A minimal implementation of an SBT\"\n‚îú‚îÄ‚îÄ utils\n‚îÇ   ‚îú‚îÄ‚îÄ ABlockGuard ‚Äî \"Protect against flashloans\"\n‚îÇ   ‚îú‚îÄ‚îÄ ADeployerGuard ‚Äî \"Prevent proxy initialization frontrunning\"\n‚îÇ   ‚îî‚îÄ‚îÄ Globals ‚Äî \"Some commonly used constants\"\n‚îú‚îÄ‚îÄ presets ‚Äî \"Presets for the library contracts\"\n‚îú‚îÄ‚îÄ interfaces ‚Äî \"Interfaces for the library contracts\"\n‚îî‚îÄ‚îÄ mock ‚Äî \"Mocks for testing purposes\"\n```\n\nBuilt with courage and aspiration to perfection.\n\n> [!TIP]\n> The library is designed to work cohesively with [hardhat-zkit](https://github.com/dl-solarity/hardhat-zkit) and [circom-lib](https://github.com/dl-solarity/circom-lib) packages.\n\n## Installation\n\n```bash\nnpm install @solarity/solidity-lib\n```\n\nThe latest stable version is always in the `master` branch.\n\n## Documentation\n\nCheck out the project's [documentation](https://docs.solarity.dev) with broad explanations and usage examples of every contract. Full `natspec` guides are also available in the source code.\n\n## Contributing\n\nWe are open to any mind-blowing ideas! Please take a look at our [contributing guidelines](CONTRIBUTING.md) to get involved.\n\n## License\n\nThe library is released under the MIT License.\n"
  },
  "Rubilmax/foundry-gas-diff": {
    "fetchedAt": "2025-11-12T22:41:11.528Z",
    "content": "<p align=\"center\">\n<img width=\"800\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3147812/208614591-bcbeafce-e99d-43ae-a427-96b63eae1fb9.png\">\n</p>\n\n# üî•üõ†Ô∏è Foundry Gas Diff Reporter\n\n- Easily compare gas reports generated by Foundry automatically on each of your Pull Requests!\n- Check out the [Live example](https://github.com/morpho-dao/morpho-tokenized-vaults/pull/228#issuecomment-1352919862) to see how it looks!\n\n## Getting started\n\n### Automatically generate a gas report diff on every PR\n\nAdd a workflow (`.github/workflows/foundry-gas-diff.yml`):\n\n```yaml\nname: Report gas diff\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    # Optionally configure to run only for changes in specific files. For example:\n    # paths:\n    # - src/**\n    # - test/**\n    # - foundry.toml\n    # - remappings.txt\n    # - .github/workflows/foundry-gas-diff.yml\n\njobs:\n  compare_gas_reports:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          submodules: recursive\n\n      - name: Install Foundry\n        uses: onbjerg/foundry-toolchain@v1\n        with:\n          version: nightly\n\n      # Add any step generating a gas report to a temporary file named gasreport.ansi. For example:\n      - name: Run tests\n        run: forge test --gas-report > gasreport.ansi # <- this file name should be unique in your repository!\n        env:\n          # make fuzzing semi-deterministic to avoid noisy gas cost estimation\n          # due to non-deterministic fuzzing (but still use pseudo-random fuzzing seeds)\n          FOUNDRY_FUZZ_SEED: 0x${{ github.event.pull_request.base.sha || github.sha }}\n\n      - name: Compare gas reports\n        uses: Rubilmax/foundry-gas-diff@v3\n        with:\n          summaryQuantile: 0.9 # only display the 10% most significant gas diffs in the summary (defaults to 20%)\n          sortCriteria: avg,max # sort diff rows by criteria\n          sortOrders: desc,asc # and directions\n          ignore: test-foundry/**/* # filter out gas reports from specific paths (test/ is included by default)\n        id: gas_diff\n\n      - name: Add gas diff to sticky comment\n        if: github.event_name == 'pull_request' || github.event_name == 'pull_request_target'\n        uses: marocchino/sticky-pull-request-comment@v2\n        with:\n          # delete the comment in case changes no longer impact gas costs\n          delete: ${{ !steps.gas_diff.outputs.markdown }}\n          message: ${{ steps.gas_diff.outputs.markdown }}\n```\n\n> :information_source: **An error will appear at first run!**<br/>\n> üî¥ <em>**Error:** No workflow run found with an artifact named \"main.gasreport.ansi\"</em><br/>\n> As the action is expecting a comparative file stored on the base branch and cannot find it (because the action never ran on the target branch and thus has never uploaded any gas report)\n\n---\n\n## How it works\n\nEverytime somebody opens a Pull Request, the action expects [Foundry](https://github.com/foundry-rs/foundry) `forge` to run a test suite, generating a gas report to a temporary file (named `gasreport.ansi` by default).\n\nOnce generated, the action will fetch the comparative gas report stored as an artifact from previous runs; parse & compare them, storing the results in the action's outputs as shell and as markdown.\n\nYou can then do whatever you want with the results!\n\n> **Our recommandation:** Automatically submit a sticky comment displaying the gas diff!\n\n---\n\n## Options\n\n### `report` _{string}_\n\nThis should correspond to the path of a file where the output of forge's gas report has been logged.\nOnly necessary when generating multiple gas reports on the same repository.\n\n‚ö†Ô∏è Make sure this file uniquely identifies a gas report, to avoid messing up with a gas report of another workflow on the same repository!\n\n_Defaults to: `gasreport.ansi`_\n\n### `base` _{string}_\n\nThe gas diff reference branch name, used to fetch the previous gas report to compare the freshly generated gas report to.\n\n_Defaults to: `${{ github.base_ref || github.ref_name }}`_\n\n### `head` _{string}_\n\nThe gas diff target branch name, used to upload the freshly generated gas report.\n\n_Defaults to: `${{ github.head_ref || github.ref_name }}`_\n\n### `token` _{string}_\n\nThe github token allowing the action to upload and download gas reports generated by foundry. You should not need to customize this, as the action already has access to the default Github Action token.\n\n_Defaults to: `${{ github.token }}`_\n\n### `header` _{string}_\n\nThe top section displayed in the markdown output. Can be used to identify multiple gas diffs in the same PR or add metadata/information to the markdown output.\n\n_Defaults to:_\n\n```markdown\n# Changes to gas cost\n```\n\n### `summaryQuantile` _{number}_\n\nThe quantile threshold to filter avg gas cost diffs to display in the summary top section.\n\n_Defaults to: `0.8`_\n\n### `sortCriteria` _{string[]}_\n\nA list of criteria to sort diff rows by in the report table (can be `name | min | avg | median | max | calls`), separated by a comma.\nMust have the same length as sortOrders.\n\n_Defaults to: name_\n\n### `sortOrders` _{string[]}_\n\nA list of directions to sort diff rows by in the report table (can be `asc | desc`), for each sort criterion, separated by a comma.\nMust have the same length as sortCriteria.\n\n_Defaults to: asc_\n\n### `ignore` _{string[]}_\n\nThe list of contract paths from which to ignore gas reports, separated by a comma.\nThis allows to clean out gas diffs from dependency contracts impacted by a change (e.g. Proxies, ERC20, ...).\n\n_No default assigned: optional opt-in (Please note that node dependencies are always discarded from gas reports)_\n\n### `match` _{string[]}_\n\nThe list of contract paths of which only to keep gas reports, separated by a comma.\nThis allows to only display gas diff of specific contracts.\n\n_No default assigned: optional opt-in_\n\n## ‚ö†Ô∏è Known limitations\n\n> **Library gas reports**<br/>\n> Forge does not generate library gas reports. You need to wrap their usage in a contract calling the library to be able to compare gas costs of calling the library.\n\n> **Average gas cost estimation**<br/>\n> Average & median gas costs for each function is estimated based on the test suite, which means they are easily impacted by small changes in the tests. We recommend using a separate, specific test suite, rarily updated, designed to perform accurate gas estimations.\n\n> **Fuzzing impacts gas costs**<br/>\n> Fuzzing can lead differences in gas costs estimated each time a test suite is ran. We thus recommend setting a deterministic fuzzing seed via the `--fuzz-seed` argument.\n\nThis repository is maintained independently from [Foundry](https://github.com/foundry-rs/foundry) and may not work as expected with all versions of `forge`.\n"
  },
  "Rubilmax/foundry-storage-check": {
    "fetchedAt": "2025-11-12T22:41:19.077Z",
    "content": "<p align=\"center\">\n<img width=\"836\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3147812/209434273-ff5eb5e6-0b32-4bb0-854b-dda2693e0175.png\">\n</p>\n\n# üî•üõ†Ô∏è Foundry Storage Upgrade Seatbelt\n\n- Protect your Smart Contract Proxy from storage collisions upon upgrading, by running this action in a CI on each of your Pull Requests!\n- Feel safe when extending your storage layout by trusting this action to check that extended layout is zero-ed out on-chain!\n\n## Live Example\n\nCheck out [PR #21](/pulls/21) for a live example:\n\n- Action is ran on [contracts/Example.sol:Example](./contracts/Example.sol)\n- Warnings & errors appear on the [Pull Request changes](https://github.com/Rubilmax/foundry-storage-check/pull/21/files)\n\n## Getting started\n\n### Automatically generate & compare to the previous storage layout on every PR\n\nAdd a workflow (`.github/workflows/foundry-storage-check.yml`):\n\n```yaml\nname: Check storage layout\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    # Optionally configure to run only for changes in specific files. For example:\n    # paths:\n    # - src/**\n    # - test/**\n    # - foundry.toml\n    # - remappings.txt\n    # - .github/workflows/foundry-storage-check.yml\n\njobs:\n  check_storage_layout:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install Foundry\n        uses: foundry-rs/foundry-toolchain@v1.2.0\n\n      - name: Check storage layout\n        uses: Rubilmax/foundry-storage-check@v3.8\n        with:\n          contract: src/Contract.sol:Contract\n          # settings below are optional, but allows to check whether the added storage slots are empty on the deployed contract\n          rpcUrl: wss://eth-mainnet.g.alchemy.com/v2/<YOUR_ALCHEMY_KEY> # the RPC url to use to query the deployed contract's storage slots\n          address: 0x0000000000000000000000000000000000000000 # the address at which the contract check is deployed\n          failOnRemoval: true # fail the CI when removing storage slots (default: false)\n```\n\n> :information_source: **An error will appear at first run!**<br/>\n> üî¥ <em>**Error:** No workflow run found with an artifact named \"...\"</em><br/>\n> As the action is expecting a comparative file stored on the base branch and cannot find it (because the action never ran on the target branch and thus has never uploaded any storage layout)\n\n---\n\n## How it works\n\nEverytime somebody opens a Pull Request, the action runs [Foundry](https://github.com/foundry-rs/foundry) `forge` to generate the storage layout of the Smart Contract you want to check.\n\nOnce generated, the action will fetch the comparative storage layout stored as an artifact from previous runs and compare them, to perform a series of checks at each storage byte, and raise a notice accordingly:\n\n- Variable changed: `error`\n- Type definition changed: `error`\n- Type definition removed: `warning`\n- Different variable naming: `warning`\n- Variable removed (optional): `error`\n\nThe action automatically checks for:\n\n- All canonic storage bytes\n- Array value (32 bytes) at index `#0`\n- Mapping value (32 bytes) at key `0x00`\n- Zero-ed bytes for added storage variables\n\n---\n\n## Options\n\n### `contract` _{string}_\n\nThe path and name of the contract of which to inspect storage layout (e.g. src/Contract.sol:Contract).\n\n_Required_\n\n### `address` _{string}_\n\nThe address at which the contract is deployed on the EVM-compatible chain queried via `rpcUrl`.\n\n### `rpcUrl` _{string}_\n\nThe HTTP/WS url used to query the EVM-compatible chain for storage slots to check for clashing.\n\n### `failOnRemoval` _{string}_\n\nWhether to fail the CI when removing a storage slot (to only allow added or renamed storage slots).\n\n_Defaults to: `false`_\n\n### `base` _{string}_\n\nThe gas diff reference branch name, used to fetch the previous gas report to compare the freshly generated gas report to.\n\n_Defaults to: `${{ github.base_ref || github.ref_name }}`_\n\n### `head` _{string}_\n\nThe gas diff target branch name, used to upload the freshly generated gas report.\n\n_Defaults to: `${{ github.head_ref || github.ref_name }}`_\n\n### `workingDirectory` _{string}_\n\nThe directory inside which to run forge inspect.\n\n_Defaults to: `.`_\n\n### `retryDelay` _{string}_\n\nThe retry delay (in milliseconds) between each GitHub API query.\n\n_Defaults to: `1000`_\n\n### `token` _{string}_\n\nThe github token allowing the action to upload and download gas reports generated by foundry. You should not need to customize this, as the action already has access to the default Github Action token.\n\n_Defaults to: `${{ github.token }}`_\n\nThis repository is maintained independently from [Foundry](https://github.com/foundry-rs/foundry) and may not work as expected with all versions of `forge`.\n"
  },
  "Rubilmax/ethers-multicall-provider": {
    "fetchedAt": "2025-11-12T22:41:26.440Z",
    "content": "# ethers-multicall-provider\n\n[![npm package][npm-img]][npm-url]\n[![Build Status][build-img]][build-url]\n[![Downloads][downloads-img]][downloads-url]\n[![Issues][issues-img]][issues-url]\n[![Commitizen Friendly][commitizen-img]][commitizen-url]\n[![Semantic Release][semantic-release-img]][semantic-release-url]\n\n> ‚ö°üöÄ Call any set of functions from any set of smart contracts in a single RPC query, seamlessly using ethers' providers API!\n\nQuerying an RPC endpoint can be very costly (**100+ queries**) when loading data from multiple smart contracts.\nWith multicall, batch these queries into a single, on-chain query, without additional over-head!\n\n- Integrates both Multicall2 & Multicall3, enabling faster queries up to block #12_336_033 on mainnet\n- Natively supports 25+ EVM-compatible chains on which Multicall3 & Multicall2 are deployed\n- Enables 10x faster off-chain data queries, making UIs faster to render and reload\n- Built-in support for blockTag-specific contract calls, batching all calls made at the same block tag (if applicable)\n- Only fails specific failing smart contract calls when batching, which makes debugging as easy as with native ethers\n\n### `ethers-multicall-provider` is a drop-in solution batching ALL smart contract calls!\n\n```diff\n-  const provider = getDefaultProvider(\"...\");\n+  const provider = MulticallWrapper.wrap(getDefaultProvider(\"...\"));\n```\n\n---\n\n## Installation\n\n### Using ethers-v6\n\n> [!WARNING]  \n> Ethers made changes to their `Provider` & `Signer` classes throughout v6, that are breaking types. For versions `v6.7` to `v6.10`, use `ethers-multicall-provider@6.2.0`. For later versions, use `ethers-multicall-provider@6.3.0`.\n\n```bash\nnpm install ethers-multicall-provider\n```\n\n```bash\nyarn add ethers-multicall-provider\n```\n\n### Using ethers-v5\n\n> [!WARNING]  \n> This version is deprecated and probably is not as efficient as with v6.\n\n```bash\nnpm install ethers-multicall-provider@3.1.2\n```\n\n```bash\nyarn add ethers-multicall-provider@3.1.2\n```\n\n---\n\n## Usage\n\nWrap any ethers provider using `MulticallWrapper.wrap` and use the wrapped provider anywhere you want to batch calls!\n\n```typescript\nimport { ethers } from \"ethers\";\nimport { MulticallWrapper } from \"ethers-multicall-provider\";\n\nconst provider = MulticallWrapper.wrap(getDefaultProvider(\"...\"));\n\nMulticallWrapper.isMulticallProvider(provider); // Returns true, only useful for type safety.\n\nlet uni = new ethers.Contract(\"0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984\", UniAbi, provider);\n\n// Calls performed simultaneously are automatically batched when using the multicall provider.\nPromise.all([\n  uni.name(),\n  uni.symbol(),\n  uni.decimals(),\n  uni.inexistantFunction().catch(() => \"default value\"),\n]).then(console.log);\n\n// When batching calls is no longer expected, just disable it.\nprovider.isMulticallEnabled = false;\n\n// Calls performed simultaneously will still perform 2 separate on-chain calls.\nPromise.all([uni.name(), uni.symbol()]).then(console.log);\n```\n\n## Limits\n\n### `msg.sender` override\n\nBecause calls are batched through the Multicall contract, all calls will inherently have the Multicall contract as `msg.sender`. This has no impact on most queries, because most of the time `msg.sender` is not used in view functions ; but it may introduce unexpected behaviors in specific smart contracts.\n\nTo circumvent this, just use the default ethers provider in places where you don't want `msg.sender` to be overriden.\n\n### Network cache\n\nStarting from `ethers-v6`, network is no longer cached in the provider, so that each RPC call first requests the network and updates the provider consequently. Using `ethers-multicall-provider`, the first network the provider is connected to is cached and can only be changed by calling `fetchNetwork()`.\n\n[build-img]: https://github.com/rubilmax/ethers-multicall-provider/actions/workflows/release.yml/badge.svg\n[build-url]: https://github.com/rubilmax/ethers-multicall-provider/actions/workflows/release.yml\n[downloads-img]: https://img.shields.io/npm/dt/ethers-multicall-provider\n[downloads-url]: https://www.npmtrends.com/ethers-multicall-provider\n[npm-img]: https://img.shields.io/npm/v/ethers-multicall-provider\n[npm-url]: https://www.npmjs.com/package/ethers-multicall-provider\n[issues-img]: https://img.shields.io/github/issues/rubilmax/ethers-multicall-provider\n[issues-url]: https://github.com/rubilmax/ethers-multicall-provider/issues\n[codecov-img]: https://codecov.io/gh/rubilmax/ethers-multicall-provider/branch/main/graph/badge.svg\n[codecov-url]: https://codecov.io/gh/rubilmax/ethers-multicall-provider\n[semantic-release-img]: https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg\n[semantic-release-url]: https://github.com/semantic-release/semantic-release\n[commitizen-img]: https://img.shields.io/badge/commitizen-friendly-brightgreen.svg\n[commitizen-url]: http://commitizen.github.io/cz-cli/\n"
  },
  "keccak256js/keccak256": {
    "fetchedAt": "2025-11-12T22:41:33.526Z",
    "content": "# keccak256\n\n> A wrapper for the [`keccak`](https://www.npmjs.com/package/keccak) library to compute 256 bit keccak hash in JavaScript.\n\n[![License](http://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/miguelmota/keccak256/master/LICENSE.md)\n\n[![js-standard-style](https://cdn.rawgit.com/feross/standard/master/badge.svg)](https://github.com/feross/standard)\n\n## Install\n\n```bash\nnpm install keccak256\n```\n\n### CDN\n\nAvailable on [jsDelivr](https://www.jsdelivr.com/) CDN:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/keccak256@latest/keccak256.js\"></script>\n```\n\n## Usage\n\n- **keccak256**(data) -> {Buffer}\n  - {String | Buffer} data - data string or Buffer\n\n  Returns a Buffer\n\n## Getting Started\n\n```js\nconst keccak256 = require('keccak256')\n\nconsole.log(keccak256('hello').toString('hex')) // \"1c8aff950685c2ed4bc3174f3472287b56d9517b9c948127319a09a7a36deac8\"\n\nconsole.log(keccak256(Buffer.from('hello')).toString('hex')) // \"1c8aff950685c2ed4bc3174f3472287b56d9517b9c948127319a09a7a36deac8\"\n```\n\n\n## Test\n\n```bash\nnpm test\n```\n\n## License\n\nReleased under the [MIT](./LICENSE) license.\n\n¬© [Miguel Mota](https://github.com/miguelmota)\n\n"
  },
  "PraneshASP/vscode-solidity-inspector": {
    "fetchedAt": "2025-11-12T22:41:40.775Z",
    "content": "<img align=\"right\" width=\"150\" height=\"150\" top=\"100\" src=\"./assets/m-icon.jpg\">\n\n# VSCode Solidity Inspector ‚Ä¢ [![license](https://img.shields.io/badge/MIT-brown.svg?label=license)](https://github.com/PraneshASP/vscode-solidity-inspector/blob/main/LICENSE)\n\nAn extension for VSCode editor that offers multiple utilities to work with the Solidity smart-contracts.\n\n> Note: This extension is not tested across multiple platforms yet. Only the contracts under foundry project are supported for now.\n\n---\n\n## Motivation:\n\n0age üëë dropped the optimization alpha in his [tweet](https://twitter.com/z0age/status/1578443876615929857) and when I tried it out for the first time I thought it was really a cool trick. The tweet has the configuration only for hardhat projects. But forge helps to do the same thing in a single command. So I thought instead of typing out the command for each contract in the CLI, it would be handy for the buildooors if there's an extension to inspect solidity contracts and generate low-level code for the contracts. The o/p generated is very useful for gas optimizations. Later I started adding more features to this extension. \n\nTL;DR, this is my first VSCode extension, so feel free to provide feedback as I know that there's a plenty of room for improvements, as always^^\n\n### Features at a glance:\n\n- Forge ir-optimized o/p generation for the current file (or) selected file(s).\n- Forge asm-optimized o/p generation for the current file (or) selected file(s).\n- Forge storage-layout o/p generation for the current file (or) selected file(s).\n- Flatten current file (or) selected file(s).\n- Inline highlighting in code editor for unused imports.\n- Generate and view Foundry deployment report in a clean and concise table format. \n- Syntax highlighting of for `.tree` files.\n- Generate foundry test stub using [bulloak](https://github.com/alexfertel/bulloak)'s `scaffold` command. \n- Auto-complete path suggestions for importing files and dependencies (with forge remappings support). \n- Inline code-separator suggestion (solmate and solady style)\n- Contract code size decorator. \n- Foundry test analysis dashboard (supports per test, per suite or all tests)\n\n---\n\n## Requirements\n\nThe following will need to be installed in order to use this template. Please follow the links and instructions.\n\n- [Foundry / Foundryup](https://github.com/gakonst/foundry)\n  - This will install `forge`, `cast`, and `anvil`\n  - You can test you've installed them right by running `forge --version` and get an output like: `forge 0.2.0 (f016135 2022-07-04T00:15:02.930499Z)`\n  - To get the latest of each, just run `foundryup`\n\n- [Bulloak](https://github.com/alexfertel/bulloak)\n  - This is required to generate test stub from `.tree` spec files.\n \n ---\n\n## Usage\n\nThe usage of this extension is straightforward.\n\n- From the context menu: Select file(s) -> Right click -> `SolidityInspector: <ACTION>`\n- From the command pallet: Press `Cmd + Shift + P` -> Search `Solidity Inspector - <ACTION>`\n\n\n\n---\n\n#### Highlights unused imports:\n\n<video width=\"700\" height=\"480\" controls>\n <source src=\"https://github.com/PraneshASP/vscode-solidity-inspector/assets/42379522/e4906ad3-69e6-4cea-b986-7712ec342fca\">\n</video>\n\n---\n\n#### Generate foundry deployment report:\n\n<video width=\"700\" height=\"480\" controls>\n <source src=\"https://github.com/PraneshASP/vscode-solidity-inspector/assets/42379522/cfaf987e-ad91-4927-9042-7562bc8684dc\">\n</video>\n\n---\n\n#### Support for `.tree` files and test stub generation: \n\n<video width=\"700\" height=\"480\" controls>\n <source src=\"https://github.com/PraneshASP/vscode-solidity-inspector/assets/42379522/2a3d591b-bc80-46cc-88c9-7e4faa0bb043\">\n</video>\n\n---\n\n#### File import auto-complete suggestions (with forge remappings support):\n\n> [!TIP] \n> If you have updated your remappings.txt file, you can press `CMD+CTRL+X` to refresh remappings.  \n\n![](./assets/auto-import.gif)\n\n\n---\n\n#### Inline separator suggestions: \n\n<video width=\"700\" height=\"480\" controls>\n <source src=\"https://github.com/user-attachments/assets/abbbd466-520f-464e-aa59-1ba628a57d18\">\n</video>\n\n---\n\n#### Inline contract size decoration:\n> [!TIP] \n> This uses the `deployedBytecode` object from the build file. So it will get updated only after every build. This setting can be also turned on/off via the extension settings.\n\n![](./assets/inline-contract-size.png)\n\n---\n\n> [!NOTE] \n> For more demos, see [./assets](https://github.com/PraneshASP/vscode-solidity-inspector/tree/main/assets)\n\n<!-- CONTRIBUTING -->\n\n## Contributing\n\nContributions are welcomed. Any contributions you make are **greatly appreciated**.\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n## Disclaimer\n\n_The outputs generated are not always safe for production usage. No guarantee, representation or warranty is being made, express or implied, as to the safety or correctness of the result. They have not been audited and as such there can be no assurance they will work as intended, and users may experience delays, failures, errors, omissions, loss of transmitted information or loss of funds. The creators are not liable for any of the foregoing. Users should proceed with caution and use at their own risk._\n"
  },
  "SaraxCG/Test": {
    "fetchedAt": "2025-11-12T22:41:47.878Z",
    "content": "# Test"
  },
  "derivexyz/cockpit": {
    "fetchedAt": "2025-11-12T22:41:55.146Z",
    "content": "# Lyra Cockpit\n\n![b12o-wpOJdNDrowamoTho](https://github.com/lyra-finance/cockpit/assets/46257136/2ebcb497-1f73-45cc-96fd-952f2f70a454)\n\nClient / SDK for Lyra Exchange, types, automated trading algorithms, vault executors, and more.\n\n## 1. Installation\n\nCurrently, the binary needs to be compiled from source.\n\n```bash\ngit clone https://github.com/lyra-finance/cockpit.git\ncd cockpit\n# if cargo is not installed:\n# curl https://sh.rustup.rs -sSf | sh\ncargo build --release\n```\n\n## 2. Environment\n\nEvery binary from the repo (e.g. a CLI) expects a set of environment variables to be set,\nsuch as public / private keys. There are two ways of setting them:\n\n1. Create a `.env.keys.staging` and/or `.env.keys.prod` files and fill them with the env variables below.\n\n```dotenv\nSESSION_PRIVATE_KEY=0x0000000000000000000000000000000000000000000000000000000000000000\nOWNER_PUBLIC_KEY=0x0000000000000000000000000000000000000000\n```\n\nMake sure to never commit the secretes to the repo! The `.env.keys.*` patterns is present in .gitignore already.\n\n2. Set the environment variables via AWS parameter store using the following path rules:\n\n- Add `SESSION_KEY_NAME` and `OWNER_KEY_NAME` to the .env files (e.g. `.env.keys.staging` or `.env.keys.prod`)\n\n```dotenv\nSESSION_KEY_NAME=alice_session\nOWNER_KEY_NAME=bob_owner\n```\n\n- Use the following paths for the AWS parameter store:\n    - `\"/session_keys/prod/{}\"` or `\"/session_keys/staging/{}\"` for `SESSION_PRIVATE_KEY` where `{}` is the key name (\n      e.g. `\"/session_keys/prod/alice_session\"`)\n    - `\"/owners/prod/{}\"` or `\"/owners/staging/{}\"` for `OWNER_PUBLIC_KEY` where `{}` is the key name (\n      e.g. `\"/owners/prod/bob_owner\"`)\n\nThe parameters should use a secret string type.\n\n## 3. Build\n\n- `cargo build --release` to build the release binary\n- `cargo build` to build the debug binary\n\n## 4. Run CLI\n\nThe CLI is one of the several apps built by the repo. It supports sending API requests to the Lyra Exchange.\n\n### Commands\n\nTo run an API RPC request (e.g. sending an order or getting ticker), two approaches are supported:\n\n- Create a JSON file with `rpc_params.json` name and place the request parameters there. For example, to\n  call `public/get_ticker`, the following json will work:\n\n```json\n{\n  \"instrument_name\": \"ETH-PERP\"\n}\n```\n\n- Then call the CLI using `target/release/lyra-client rpc -m public/get_ticker -f rpc_params.json`\n- Alternatively the json string can be supplied via `--inline` or `-i`\n  parameter: `target/release/lyra-client rpc -m public/get_ticker -i '{\"instrument_name\": \"ETH-USDC\"}'`\n\nThe CLI also supports printing orderbook for any instrument (even if not supported by the Lyra UI):\n\n- `target/release/lyra-client orderbook -i ETH-USDC`\n\nFor more info: `target/release/lyra-client -h`.\n"
  },
  "derivexyz/op-geth": {
    "fetchedAt": "2025-11-12T22:42:02.485Z",
    "content": "## Go Ethereum\n\nGolang execution layer implementation of the Ethereum protocol.\n\n[![API Reference](\nhttps://pkg.go.dev/badge/github.com/ethereum/go-ethereum\n)](https://pkg.go.dev/github.com/ethereum/go-ethereum?tab=doc)\n[![Go Report Card](https://goreportcard.com/badge/github.com/ethereum/go-ethereum)](https://goreportcard.com/report/github.com/ethereum/go-ethereum)\n[![Travis](https://app.travis-ci.com/ethereum/go-ethereum.svg?branch=master)](https://app.travis-ci.com/github/ethereum/go-ethereum)\n[![Discord](https://img.shields.io/badge/discord-join%20chat-blue.svg)](https://discord.gg/nthXNEv)\n\nAutomated builds are available for stable releases and the unstable master branch. Binary\narchives are published at https://geth.ethereum.org/downloads/.\n\n## Building the source\n\nFor prerequisites and detailed build instructions please read the [Installation Instructions](https://geth.ethereum.org/docs/getting-started/installing-geth).\n\nBuilding `geth` requires both a Go (version 1.21 or later) and a C compiler. You can install\nthem using your favourite package manager. Once the dependencies are installed, run\n\n```shell\nmake geth\n```\n\nor, to build the full suite of utilities:\n\n```shell\nmake all\n```\n\n## Executables\n\nThe go-ethereum project comes with several wrappers/executables found in the `cmd`\ndirectory.\n\n|  Command   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| :--------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **`geth`** | Our main Ethereum CLI client. It is the entry point into the Ethereum network (main-, test- or private net), capable of running as a full node (default), archive node (retaining all historical state) or a light node (retrieving data live). It can be used by other processes as a gateway into the Ethereum network via JSON RPC endpoints exposed on top of HTTP, WebSocket and/or IPC transports. `geth --help` and the [CLI page](https://geth.ethereum.org/docs/fundamentals/command-line-options) for command line options. |\n|   `clef`   | Stand-alone signing tool, which can be used as a backend signer for `geth`.                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|  `devp2p`  | Utilities to interact with nodes on the networking layer, without running a full blockchain.                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|  `abigen`  | Source code generator to convert Ethereum contract definitions into easy-to-use, compile-time type-safe Go packages. It operates on plain [Ethereum contract ABIs](https://docs.soliditylang.org/en/develop/abi-spec.html) with expanded functionality if the contract bytecode is also available. However, it also accepts Solidity source files, making development much more streamlined. Please see our [Native DApps](https://geth.ethereum.org/docs/developers/dapp-developer/native-bindings) page for details.                                  |\n| `bootnode` | Stripped down version of our Ethereum client implementation that only takes part in the network node discovery protocol, but does not run any of the higher level application protocols. It can be used as a lightweight bootstrap node to aid in finding peers in private networks.                                                                                                                                                                                                                                               |\n|   `evm`    | Developer utility version of the EVM (Ethereum Virtual Machine) that is capable of running bytecode snippets within a configurable environment and execution mode. Its purpose is to allow isolated, fine-grained debugging of EVM opcodes (e.g. `evm --code 60ff60ff --debug run`).                                                                                                                                                                                                                                               |\n| `rlpdump`  | Developer utility tool to convert binary RLP ([Recursive Length Prefix](https://ethereum.org/en/developers/docs/data-structures-and-encoding/rlp)) dumps (data encoding used by the Ethereum protocol both network as well as consensus wise) to user-friendlier hierarchical representation (e.g. `rlpdump --hex CE0183FFFFFFC4C304050583616263`).                                                                                                                                                                                |\n\n## Running `geth`\n\nGoing through all the possible command line flags is out of scope here (please consult our\n[CLI Wiki page](https://geth.ethereum.org/docs/fundamentals/command-line-options)),\nbut we've enumerated a few common parameter combos to get you up to speed quickly\non how you can run your own `geth` instance.\n\n### Hardware Requirements\n\nMinimum:\n\n* CPU with 2+ cores\n* 4GB RAM\n* 1TB free storage space to sync the Mainnet\n* 8 MBit/sec download Internet service\n\nRecommended:\n\n* Fast CPU with 4+ cores\n* 16GB+ RAM\n* High-performance SSD with at least 1TB of free space\n* 25+ MBit/sec download Internet service\n\n### Full node on the main Ethereum network\n\nBy far the most common scenario is people wanting to simply interact with the Ethereum\nnetwork: create accounts; transfer funds; deploy and interact with contracts. For this\nparticular use case, the user doesn't care about years-old historical data, so we can\nsync quickly to the current state of the network. To do so:\n\n```shell\n$ geth console\n```\n\nThis command will:\n * Start `geth` in snap sync mode (default, can be changed with the `--syncmode` flag),\n   causing it to download more data in exchange for avoiding processing the entire history\n   of the Ethereum network, which is very CPU intensive.\n * Start the built-in interactive [JavaScript console](https://geth.ethereum.org/docs/interacting-with-geth/javascript-console),\n   (via the trailing `console` subcommand) through which you can interact using [`web3` methods](https://github.com/ChainSafe/web3.js/blob/0.20.7/DOCUMENTATION.md) \n   (note: the `web3` version bundled within `geth` is very old, and not up to date with official docs),\n   as well as `geth`'s own [management APIs](https://geth.ethereum.org/docs/interacting-with-geth/rpc).\n   This tool is optional and if you leave it out you can always attach it to an already runni\n\n[... truncated ...]"
  },
  "tokenguardio/dapp-marvels": {
    "fetchedAt": "2025-11-12T22:42:10.439Z",
    "content": "<div align=\"left\">\n    <img src=\"https://cdn.prod.website-files.com/6645e490e589077daad8a58e/67dd4b0fa3a811e079705ef8_Github%20header_20250321.jpg\" alt=\"patterns\" height=\"240\" />\n    </div>\n\n## Analyze wallet behaviour and preview CRM of your Solidity & Ink! based dApp\n\nPatterns was founded to help web3 projects grow and build utility around their products. We know how to build successful dApps & ecosystems solving real problems with blockchain technology and we want to allow the whole industry to follow this path.\n\n[Patterns app is available for free here >>](https://patterns.build/web3-crm) \n\n[Learn more about Patterns](https://patterns.build/about-us)\n\n### Social channels:\n<div style=\"display: flex; gap: 24px;\">\n  <a href=\"https://x.com/patterns_build\"><img src=\"https://uploads-ssl.webflow.com/6645e490e589077daad8a58e/667193cb5fbe25aecdd789ce_twitter.png\" style=\"height: 24px\"></a>\n  <a href=\"https://www.linkedin.com/company/patterns-build/\"><img src=\"https://uploads-ssl.webflow.com/6645e490e589077daad8a58e/667193cbdf5adefa16664be0_linkedin.png\" style=\"height: 24px\"></a>\n  <a href=\"https://t.me/Patterns_io\"><img src=\"https://uploads-ssl.webflow.com/6645e490e589077daad8a58e/667193cb5a75346d735fe5bf_telegram.png\" style=\"height: 24px\"></a>\n</div>\n\n### Supported blockchains:\n<div style=\"display: flex; gap: 16px;\">\n  <img src=\"https://cdn.prod.website-files.com/6645e490e589077daad8a58e/67dd4eb81d68da2f66bbf6f9_optimism-logo.png\" style=\"height: 40px\">\n  <img src=\"https://cdn.prod.website-files.com/6645e490e589077daad8a58e/67dd4eb80b8ce16c28ace135_ethereum-logo.png\" style=\"height: 40px\">\n  <img src=\"https://cdn.prod.website-files.com/6645e490e589077daad8a58e/67dd4eb887f98cfcd2581673_binance-logo.png\" style=\"height: 40px\">\n  <img src=\"https://cdn.prod.website-files.com/6645e490e589077daad8a58e/67dd4eb8a7c76f3fc39a975f_arbitrum-logo.png\" style=\"height: 40px\">\n  <img src=\"https://uploads-ssl.webflow.com/6645e490e589077daad8a58e/667193cb305eadd978bfb9f5_azero.png\" style=\"height: 40px\">\n  <img src=\"https://uploads-ssl.webflow.com/6645e490e589077daad8a58e/667193cb70cf38587b87f488_moonbeam.png\" style=\"height: 40px\">\n  <img src=\"https://uploads-ssl.webflow.com/6645e490e589077daad8a58e/667193cdaa25d6c28bfea28f_astar.png\" style=\"height: 40px\">\n</div>\n\n## dApp Marvels üíé\n\nWelcome to the dApp Marvels repository! This repository consists of handy setup scripts to help you get started with dApp Marvels - an on-chain analytics tool designed for Ink! dApps builders to support their growth and operations through in-depth metrics and analytics of on-chain user behavior.\n\ndApp Marvels will help to Polkadot builders create their dApps & protocols faster and easily analyze data coming from their smart contracts without additional hassle.\n  \nThis guide covers how to set up and run the project for Substrate-bases chains. This respository is umbrella part of a bigger system consisting of 3 components + corresponding databases.\n\n1. [dashboard-creator-server](https://github.com/tokenguardio/dashboard-creator-server/) - the backend service storing information about built dashboards and queries\n2. [dashboard-creator-client](https://github.com/tokenguardio/dashboard-creator-client/) - frontend app\n3. [db-api](https://github.com/tokenguardio/db-api) - REST interface between PostgreSQL database and backend service.  \n4. [subsquid-indexer](https://github.com/tokenguardio/substrate-squids/blob/wasabi/) - custom squid indexer suited for decoded ABIs for dApps\n  \nTo fully function backend service needs mongodb to store dashboard configuration, layout and displayed dashboard elements and PostgreSQL database to store indexing data pulled by subsquid indexer.\n\n## Prerequisites\n\nBefore you begin, make sure you have the following installed on your system:\n\n- [Docker](https://www.docker.com/get-started)\n- [Docker Compose](https://docs.docker.com/compose/install/)\n\n### Features\n- **dApp decoding**: with user-provided contract ABIs this app is able to index decoded interactions with the dApp\n- **dApp indexing**: automated deployments of subsquid indexers\n- **API Reading Mechanism**: Connect frontend visualizations with underlying data through a RESTful API built with NodeJS and Express.\n- **Data Storage**: Store visualization and dashboard-related data in MongoDB for efficient retrieval and management.\n- **Scalability**: Built with scalability in mind to handle large datasets and user traffic effectively.\n- **Metrics Visualisation**: Visualize data from raw sources using customizable visualizations such as line charts, bar charts, pie charts, and more.\n- **Dashboard Layout**: Create, save, modify, and delete dashboards with drag-and-drop functionality. Customize dashboard layouts with captions, titles, and links.\n- **User-Friendly Interface**: Intuitive user interface for seamless dashboard creation and customization.\n\n### Use examples\n<img src=\"https://github.com/tokenguardio/dapp-marvels/assets/56157619/977843b7-f9c3-4b97-a3c5-097ca7c3e0fc\" style=\"height: 300px\">\n<img src=\"https://github.com/tokenguardio/dapp-marvels/assets/56157619/be60d7fb-581b-4b81-8414-64029d6c5a1d\" style=\"height: 300px\">\n<img src=\"https://github.com/tokenguardio/dapp-marvels/assets/56157619/87dda95e-721b-49a1-8ae6-c27ba8c76a24\" style=\"height: 300px\">\n<img src=\"https://github.com/tokenguardio/dapp-marvels/assets/56157619/19069b6c-4db6-49aa-b75c-b43849049977\" style=\"height: 300px\">\n<img src=\"https://github.com/tokenguardio/dapp-marvels/assets/56157619/aa9780df-e363-4d94-9fab-9f8dd9cc0e1a\" style=\"height: 300px\">\n\n\n### Getting started\n\n#### Fastest\nIf you just want to start the project to see how it works, just run `docker-compose up` and it will pull recent images of services and run the app.  \n\n#### For devs\nFor simple and smooth application rollout for further customization and development purposes you can pull all required repositories into fresh directory using a script provided in this repository: \n```\n./setup-env.sh\n```\n\nThe script pulls repositories in locations expected by `docker-compose-dev.yml` file enclosed in this repository.\n```\ngit clone https://github.com/tokenguardio/dashboard-creator-client.git\ncd dashboard-creator-client\ngit checkout dapp-analytics-dev\ncd ..\ngit clone https://github.com/tokenguardio/dashboard-creator-server.git\ncd dashboard-creator-server\ngit checkout dapp-analytics-dev\ncd ..\ngit clone https://github.com/tokenguardio/db-api.git\ncd db-api\ngit checkout dev\ncd ..\n```\nAfter the script is done, all you have to do is to let docker-compose run and build/pull all required images.\n```\ndocker-compose -f docker-compose-dev.yml up\n```\nAfter the environment starts, you should be able to see the frontend app of dApp Marvels at [localhost:5173](http://localhost:5173)\n\n### Cleanup\nTo clean up environment, simply run \n```\n./cleanup.sh\n```\n\n### Tech Stack\n\n- **Backend Framework**: NodeJS with Express\n- **Database**: MongoDB, PostgreSQL\n- **API Documentation**: OpenAPI\n- **Development Tool**: Docker\n- **Frontend Framework**: ReactJS, TypeScript, ViteJS\n- **Data Storage**: MongoDB\n- **Visualization Library**: Apache ECharts\n\n### Contributing\n\nWe encourage contributions from the community! If you'd like to contribute to the Patterns Dashboard Builder Server, please refer to our [contribution guidelines](CONTRIBUTING.md) for more information.\n\n### License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n"
  },
  "Brahma-fi/console-kit": {
    "fetchedAt": "2025-11-12T22:42:18.456Z",
    "content": "## Welcome to Brahma ConsoleKit!\n\nBrahma ConsoleKit equips developers with the tools to build **automated** and **agentic workflows** on-chain, enabling secure, autonomous operations without the need for custom smart contract development or managing user funds. It provides a framework for creating multi-step, cross-chain automated workflows that users can subscribe to, while retaining full control of their assets.\n\nDevelopers can focus on building logic and workflows, while ConsoleKit handles the complexities of security, execution, and automation.\n\n### Supported Chains\n- Base, Arbitrum, Ethereum, Binance Smart Chain, Berachain\nSei support has been deprecated and is therefore not supported\n\n### Key Features\n\n- **User Custody & Delegated Execution:**\nUsers maintain full custody of their assets in their accounts, delegating execution permissions to workflows with defined restrictions.\n    \n- **Simplified Infrastructure:**\nAccount management, policy enforcement, execution, and RPC management are all handled by ConsoleKit, eliminating the need for developers to manage these components manually.\n    \n- **DeFi Primitives & Cross-Chain Integration:**\nModular functions for DeFi primitives, such as optimal routing, MEV protection, and cross-chain liquidity, are exposed for easy integration into workflows.\n    \n- **On-Chain Policy Enforcement:**\nPrevent unauthorized transactions and ensure compliance of the workflow with security policies.\n    \n- **Interface Agnostic:**\nExpose workflows on any interface, whether it's a website, mobile app, or custom frontend, enabling seamless user experiences.\n    \n- **Cross-Chain Capabilities:**\nManage interactions across multiple blockchains using a single programmable account, allowing for flexible cross-chain workflows.\n\n\n### Differences Between Automated and Agentic Workflows\n\n1. **Automated Workflows**\n    - Automate multi-step transactions onchain with any offchain trigger logic, such as bots or external scripts.\n    - Example: A workflow that automatically rebalances assets between two DeFi protocol positions based on set conditions.\n    \n2. **Agentic Workflows**\n    - Enable intelligent, multi-step reasoning in workflows using LLMs or any other AI framework.\n    - Support for custom models or frameworks of choice, allowing for more sophisticated decision-making and execution.\n    - Example: An agent that optimizes yield across multiple vaults while adapting to market conditions, adjusting collateral, and maintaining risk thresholds.\n    \n    *Future roadmap: Brahma will support cross-agent interactions, enabling complex, multi-agent collaboration and coordination.*\n    \n\n### Developer Benefits:\n\n- **Simplified Development:** Focus on building workflows and logic without worrying about the complex mechanics of user accounts, workflow management and execution, protocol integration, or security. Cut 90% of development time.\n- **Customization:** Developers can integrate offchain logic or frameworks using Brahma‚Äôs flexible TypeScript SDK or native API's, abstracting built-in security, execution, and policy management tools.\n- **Scalable & Secure:** ConsoleKit handles user onboarding, cross-chain interactions, and security checks, allowing developers to focus on logic and functionality.\n- **Built-In User Accounts:**¬†ConsoleKit provides secure, multi-chain accounts for onboarding users, managing permissions, and executing transactions automatically without the need for external solutions.\n\n---\n\n## System Architecture & Core Concepts\n\nThe [Introduction](./docs/introduction.md) provides a comprehensive overview of ConsoleKit's components, and terminology. This section is essential reading for developers to understand:\n\n- Core architectural components and their interactions\n- Key terminologies and concepts used throughout the SDK\n- Security model and policy engine fundamentals\n- Integration patterns and best practices\n\nWe recommend reviewing this documentation before starting development to ensure a solid foundation in ConsoleKit's principles.\n\n## Installation\n\nTo install the SDK, use npm or yarn:\n\n```sh\nnpm install brahma-console-kit\n```\n\nor\n\n```sh\nyarn add brahma-console-kit\n```\n\n## Getting Started with templates\n\nTo quickly bootstrap your ConsoleKit project, you can use our [scaffold agent repository](https://github.com/Brahma-fi/scaffold-agent)\n\nThe scaffold repository includes a collection of example implementations showcasing how to build automated workflows using ConsoleKit. This repository demonstrates integration patterns ranging from automated workflows to agentic ones.\n\nCheck out the ConsoleKit video explainer and setup workshop below\n[![YouTube](http://i.ytimg.com/vi/pLGP0Ag1Y8M/hqdefault.jpg)](https://www.youtube.com/watch?v=pLGP0Ag1Y8M)\n\n\n## Overview\n\n### ConsoleKit\n\n[`ConsoleKit`](./src/kit.ts) is the main class that provides access to the core functionalities of the SDK. It requires an API key and a base URL for initialization.\n\n**Example:**\n\n```typescript\nimport ConsoleKit from \"brahma-console-kit\";\n\nconst apiKey = \"your-api-key\";\nconst baseURL = \"https://api.consolekit.com\";\n\nconst consoleKit = new ConsoleKit(apiKey, baseURL);\n```\n\n### CoreActions\n\n[`CoreActions`](./src/helpers/CoreActions/index.ts) provides core DeFi functions such as sending tokens and swapping assets, as well as fetching user information.\n\n**Example:**\n\n```typescript\nconst coreActions = consoleKit.coreActions;\n\nasync function fetchAccounts(eoa: string) {\n  const accounts = await coreActions.fetchExistingAccounts(eoa);\n  console.log(accounts);\n}\n```\n\n### PublicDeployer\n\n[`PublicDeployer`](./src/helpers/PublicDeployer/index.ts) handles executor subscription and brahma account deployments directly through EOAs in a gasless manner.\n\n**Example:**\n\n```typescript\nconst publicDeployer = consoleKit.publicDeployer;\n\nasync function deployStrategy(\n  owner: string,\n  chainId: number,\n  feeToken: string\n) {\n  const preComputeData = await publicDeployer.fetchPreComputeData(\n    owner,\n    chainId,\n    feeToken\n  );\n  console.log(preComputeData);\n}\n```\n\n### AutomationContext\n\n[`AutomationContext`](./src/helpers/AutomationContext/index.ts) manages automation services, including subscribing to, updating, and canceling automated tasks.\n\n**Example:**\n\n```typescript\nconst automationContext = consoleKit.automationContext;\n\nasync function subscribeToAutomation(params: any) {\n  const response = await automationContext.subscribeToAutomation(params);\n  console.log(response);\n}\n```\n\n#### Fetching Automation Subscriptions\n\nThe `fetchAutomationSubscriptions` function retrieves subscriptions associated with a given account address and blockchain network. You can specify a custom metadata type, or use the default structure.\n\nConsoleKit provides flexible functions to fetch automation subscriptions with customizable metadata. This allows you to tailor the metadata structure to your specific needs.\n\n- **Default Metadata**: If no template is provided, the metadata will include only `baseToken` and `every`. See the [BaseMetadata](./src/helpers/AutomationContext/types.ts#L57) type definition.\n- **Custom Metadata**: Specify a template to include additional fields. See the [CustomMetadata](./src/helpers/AutomationContext/types.ts#L69) type definition.\n\n**Example:**\n\n```typescript\n// Default metadata\nconst subscriptions = await automationContext.fetchAutomationSubscriptions(\n  accountAddress,\n  chainId\n);\n\n// Custom metadata\ntype CustomMetadata = { customField1?: string; customField2?: number };\nconst customSubscriptions =\n  await automationContext.fetchAutomationSubscriptions<CustomMetadata>(\n    accountAddress,\n    chainId\n  );\n```\n\n#### Fetching Automation Subscriptions by Registry Id\n\nThe `fetchSubscriptionsByRegistryID` function retrieves subscriptions for a specific externally owned account (EOA) and registry ID. Similar to the previous function, you can specify a custom metadata type.\n\n**Example:**\n\n```typescript\n// Default metadata\nconst subscriptions = await automati\n\n[... truncated ...]"
  },
  "Cyfrin/Updraft": {
    "fetchedAt": "2025-11-12T22:42:27.087Z",
    "content": "\n[contributors-shield]: https://img.shields.io/github/contributors/cyfrin/updraft.svg?style=for-the-badge\n\n[contributors-url]: https://github.com/cyfrin/updraft/graphs/contributors\n\n[forks-shield]: https://img.shields.io/github/forks/cyfrin/updraft.svg?style=for-the-badge\n\n[forks-url]: https://github.com/cyfrin/updraft/network/members\n\n[stars-shield]: https://img.shields.io/github/stars/cyfrin/updraft.svg?style=for-the-badge\n\n[stars-url]: https://github.com/cyfrin/updraft/stargazers\n\n[issues-shield]: https://img.shields.io/github/issues/cyfrin/updraft.svg?style=for-the-badge\n\n[issues-url]: https://github.com/cyfrin/updraft/issues\n\n[license-shield]: https://img.shields.io/github/license/cyfrin/updraft.svg?style=for-the-badge\n\n[license-url]: https://github.com/Cyfrin/Updraft/blob/main/LICENSE\n\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n\n<div align=\"center\">\n<h1 align=\"center\"><a href='https://updraft.cyfrin.io/'>Cyfrin Updraft</a> </h1>\n\n\n<p align=\"center\"><strong>The ultimate learning platform for web3 developers\n</strong></p>\n\n\n\n[![Stargazers][stars-shield]][stars-url] [![Forks][forks-shield]][forks-url]\n[![Contributors][contributors-shield]][contributors-url]\n[![Issues][issues-shield]][issues-url]\n[![MIT License][license-shield]][license-url]\n<p align=\"center\">\n    <br />\n    <a href=\"https://cyfrin.io/\">\n        <img src=\".github/images/poweredbycyfrinblue.png\" width=\"145\" alt=\"\"/></a>\n    <br />\n</p>\n</div>\n\nWelcome to the official GitHub repository for Cyfrin Updraft. This repository houses the written content of our courses, organized to facilitate easy access and contribution from our community.\nPlease refer to this for an in depth explanation of the content:\n\n-   [Website](https://updraft.cyfrin.io/) - Join Cyfrin Updraft and enjoy 50+ hours of smart contract development courses\n-   [Twitter](https://twitter.com/CyfrinUpdraft/) - Stay updated with the latest course releases\n-   [LinkedIn](https://www.linkedin.com/school/cyfrin-updraft/) - Add Updraft to your learning experiences\n-   [Discord](https://discord.gg/cyfrin) - Join a community of 3000+ developers and auditors\n-   [Newsletter](https://www.cyfrin.io/newsletter) - Weekly security research tips and resources to level up your career\n-   [CodeHawks](https://www.codehawks.com/) - Smart contracts auditing competitions to help secure web3\n\n</br>\n\n\n**Have a question about the courses?**\n- Join us on [Discord](https://discord.gg/cyfrin)\n- Or refer to the courses' GitHub discussions repositories linked on the lesson pages\n\n\n## Repository Structure\n\nOur content is structured as follows:\n\n- `courses/`\n  - `course_name/`\n    - `section_name/`\n       - `lesson_name/`\n          - `lesson_content.md`\n\nEach course is contained within its directory, and for each course, you will find directories for each lesson, which contain a Markdown file (.md) with the lesson's content.\n\n## How to Contribute\n\nWe deeply value every kind of community contribution:\n- Correcting typos or subtitles\n- Enhancing code snippets\n- Refining our educational content\n\nHere's how you can contribute:\n\n### Prerequisites\n\n- Familiarity with GitHub and basic Markdown syntax.\n- Understanding of the specific course material you wish to contribute to.\n\n### Steps for Contribution\n\n1. **Fork the Repository:** Start by forking the Cyfrin Updraft repository to your GitHub account.\n\n2. **Clone the Forked Repository:** Clone your forked repository to your local machine for easy editing.\n\n   ```bash\n   git clone https://github.com/your-username/Updraft.git\n   cd Updraft\n   ```\n\n3. **Create a New Branch:** Create a new branch for your changes. Use a clear branch name that reflects the nature of your contribution.\n\n   ```bash\n   git checkout -b your-branch-name\n   ```\n\n4. **Make Your Changes:** Navigate to the specific course and lesson you wish to update and make your changes in the Markdown file.\n\n5. **Commit Your Changes:** Once you've made your changes, commit them with a clear and concise commit message.\n\n   ```bash\n   git add .\n   git commit -m \"A brief description of your changes\"\n   ```\n\n6. **Push Changes to GitHub:** Push your changes to your forked repository.\n\n   ```bash\n   git push origin your-branch-name\n   ```\n\n7. **Create an Issue**: This repo reviews pull requests that have an associated issue, so please make an issue and tag the issue somewhere in your pull request (which you'll make in the next step). \n\n8. **Create a Pull Request (PR):** Go to the original Cyfrin Updraft repository on GitHub and create a pull request from your forked repository. In your PR, explain the changes you've made and why they're beneficial.\n\n9. **Await Review:** The Cyfrin team or community maintainers will review your PR. Be responsive to any feedback or requested changes.\n\n### Best Practices for Contribution\n\n- **Small, Focused Changes:** Keep your changes focused on a single issue or improvement for easier review and merging.\n\n- **Follow the Style Guide:** Ensure your contributions adhere to the existing style and formatting of the lessons.\n\n- **Update Documentation:** If your changes are significant, update the relevant documentation within the same PR.\n\n- **Respect the Community:** Engage constructively with the community and maintain the ethos of collaboration and respect.\n\n## Reporting Issues\n\nEncounter an issue or have a suggestion? Open an issue on this repository with a clear, descriptive title and detailed information.\n## Credits\n\nThis project exists thanks to all the people who contribute.<br>\n\n<a href=\"https://github.com/Cyfrin/Updraft/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=Cyfrin/Updraft\" />\n</a>\n\n## License\n\nCyfrin Updraft content is open-sourced [licensed as AGPLv3](https://github.com/cyfrin/updraft/blob/main/LICENSE).\n\n\n[![Cyfrin Twitter](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/cyfrinupdraft)\n[![Cyfrin YouTube](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/@CyfrinAudits)\n[![Cyfrin LinkedIn](https://img.shields.io/badge/Linkedin-0e76a8?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/school/cyfrin-updraft/)\n\n"
  },
  "paulmillr/noble-ciphers": {
    "fetchedAt": "2025-11-12T22:42:34.830Z",
    "content": "# noble-ciphers\n\nAudited & minimal JS implementation of Salsa20, ChaCha and AES.\n\n- üîí [**Audited**](#security) by an independent security firm\n- üîª Tree-shakeable: unused code is excluded from your builds\n- üèé Fast: hand-optimized for caveats of JS engines\n- üîç Reliable: property-based / cross-library / wycheproof tests ensure correctness\n- üíº AES: ECB, CBC, CTR, CFB, GCM, SIV (nonce misuse-resistant), AESKW, AESKWP\n- üíÉ Salsa20, ChaCha, XSalsa20, XChaCha, ChaCha8, ChaCha12, Poly1305\n- ü•à Two AES implementations: pure JS or friendly WebCrypto wrapper\n- ü™∂ 11KB (gzipped) for everything, 3KB for ChaCha-only build\n\nCheck out [Upgrading](#upgrading) for information about upgrading from previous versions.\nTake a glance at [GitHub Discussions](https://github.com/paulmillr/noble-ciphers/discussions) for questions and support.\n\n### This library belongs to _noble_ cryptography\n\n> **noble cryptography** ‚Äî high-security, easily auditable set of contained cryptographic libraries and tools.\n\n- Zero or minimal dependencies\n- Highly readable TypeScript / JS code\n- PGP-signed releases and transparent NPM builds\n- All libraries:\n  [ciphers](https://github.com/paulmillr/noble-ciphers),\n  [curves](https://github.com/paulmillr/noble-curves),\n  [hashes](https://github.com/paulmillr/noble-hashes),\n  [post-quantum](https://github.com/paulmillr/noble-post-quantum),\n  5kb [secp256k1](https://github.com/paulmillr/noble-secp256k1) /\n  [ed25519](https://github.com/paulmillr/noble-ed25519)\n- [Check out homepage](https://paulmillr.com/noble/)\n  for reading resources, documentation and apps built with noble\n\n## Usage\n\n> `npm install @noble/ciphers`\n\n> `deno add jsr:@noble/ciphers`\n\nWe support all major platforms and runtimes.\nFor React Native, you may need a\n[polyfill for getRandomValues](https://github.com/LinusU/react-native-get-random-values).\nA standalone file\n[noble-ciphers.js](https://github.com/paulmillr/noble-ciphers/releases) is also available.\n\n```ts\n// import * from '@noble/ciphers'; // Error: use sub-imports, to ensure small app size\nimport { gcm, gcmsiv } from '@noble/ciphers/aes.js';\nimport { chacha20poly1305, xchacha20poly1305 } from '@noble/ciphers/chacha.js';\nimport { xsalsa20poly1305 } from '@noble/ciphers/salsa.js';\n\n// Unauthenticated encryption: make sure to use HMAC or similar\nimport { ctr, cfb, cbc, ecb } from '@noble/ciphers/aes.js';\nimport { salsa20, xsalsa20 } from '@noble/ciphers/salsa.js';\nimport { chacha20, xchacha20, chacha8, chacha12 } from '@noble/ciphers/chacha.js';\nimport { aeskw, aeskwp } from '@noble/ciphers/aes.js'; // KW\nimport { bytesToHex, hexToBytes, managedNonce, randomBytes } from '@noble/ciphers/utils.js';\n```\n\n- [Examples](#examples)\n  - [XChaCha20-Poly1305 encryption](#xchacha20-poly1305-encryption)\n  - [AES-256-GCM encryption](#aes-256-gcm-encryption)\n  - [managedNonce: automatic nonce handling](#managednonce-automatic-nonce-handling)\n  - [AES: gcm, siv, ctr, cfb, cbc, ecb, aeskw](#aes-gcm-siv-ctr-cfb-cbc-ecb-aeskw)\n  - [AES: friendly WebCrypto wrapper](#aes-friendly-webcrypto-wrapper)\n  - [Reuse array for input and output](#reuse-array-for-input-and-output)\n  - [Use password for encryption](#use-password-for-encryption)\n- [Internals](#internals)\n  - [Picking a cipher](#picking-a-cipher)\n  - [How to encrypt properly](#how-to-encrypt-properly)\n  - [Nonces](#nonces)\n  - [Encryption limits](#encryption-limits)\n  - [AES block modes](#aes-block-modes)\n  - [Implemented primitives](#implemented-primitives)\n- [Security](#security)\n- [Speed](#speed)\n- [Upgrading](#upgrading)\n- [Contributing & testing](#contributing--testing)\n- [License](#license)\n\n## Examples\n\n> [!NOTE]\n> Use different nonce every time `encrypt()` is done.\n\n#### XChaCha20-Poly1305 encryption\n\n```js\nimport { xchacha20poly1305 } from '@noble/ciphers/chacha.js';\nimport { randomBytes } from '@noble/ciphers/utils.js';\nconst key = randomBytes(32); // random key\n// const key = new Uint8Array([ // existing key\n//   169, 88, 160, 139, 168, 29, 147, 196, 14, 88, 237, 76, 243, 177, 109, 140,\n//   195, 140, 80, 10, 216, 134, 215, 71, 191, 48, 20, 104, 189, 37, 38, 55,\n// ]);\n// import { hexToBytes } from '@noble/ciphers/utils.js'; // hex key\n// const key = hexToBytes('4b7f89bac90a1086fef73f5da2cbe93b2fae9dfbf7678ae1f3e75fd118ddf999');\nconst nonce = randomBytes(24);\nconst chacha = xchacha20poly1305(key, nonce);\nconst data = new TextEncoder().encode('hello noble');\nconst ciphertext = chacha.encrypt(data);\nconst data_ = chacha.decrypt(ciphertext); // new TextDecoder().decode(data_) === data\n```\n\n#### AES-256-GCM encryption\n\n```js\nimport { gcm } from '@noble/ciphers/aes.js';\nimport { randomBytes } from '@noble/ciphers/utils.js';\nconst key = randomBytes(32);\nconst nonce = randomBytes(24);\nconst data = new TextEncoder().encode('hello noble');\nconst aes = gcm(key, nonce);\nconst ciphertext = aes.encrypt(data);\nconst data_ = aes.decrypt(ciphertext); // new TextDecoder().decode(data_) === data\n```\n\n#### managedNonce: automatic nonce handling\n\nWe provide API that manages nonce internally instead of exposing them to library's user.\n\nFor `encrypt`: a `nonceBytes`-length buffer is fetched from CSPRNG and prenended to encrypted ciphertext.\n\nFor `decrypt`: first `nonceBytes` of ciphertext are treated as nonce.\n\n> [!NOTE]\n> AES-GCM & ChaCha (NOT XChaCha) [limit amount of messages](#encryption-limits)\n> encryptable under the same key.\n\n```js\nimport { xchacha20poly1305 } from '@noble/ciphers/chacha.js';\nimport { hexToBytes, managedNonce } from '@noble/ciphers/utils.js';\nconst key = hexToBytes('fa686bfdffd3758f6377abbc23bf3d9bdc1a0dda4a6e7f8dbdd579fa1ff6d7e1');\nconst chacha = managedNonce(xchacha20poly1305)(key); // manages nonces for you\nconst data = new TextEncoder().encode('hello noble');\nconst ciphertext = chacha.encrypt(data);\nconst data_ = chacha.decrypt(ciphertext);\n```\n\n#### AES: gcm, siv, ctr, cfb, cbc, ecb, aeskw\n\n```js\nimport { gcm, gcmsiv, ctr, cfb, cbc, ecb } from '@noble/ciphers/aes.js';\nimport { randomBytes } from '@noble/ciphers/utils.js';\nconst plaintext = new Uint8Array(32).fill(16);\nfor (let cipher of [gcm, gcmsiv]) {\n  const key = randomBytes(32); // 24 for AES-192, 16 for AES-128\n  const nonce = randomBytes(12);\n  const ciphertext_ = cipher(key, nonce).encrypt(plaintext);\n  const plaintext_ = cipher(key, nonce).decrypt(ciphertext_);\n}\nfor (const cipher of [ctr, cbc, cfb]) {\n  const key = randomBytes(32); // 24 for AES-192, 16 for AES-128\n  const nonce = randomBytes(16);\n  const ciphertext_ = cipher(key, nonce).encrypt(plaintext);\n  const plaintext_ = cipher(key, nonce).decrypt(ciphertext_);\n}\nfor (const cipher of [ecb]) {\n  const key = randomBytes(32); // 24 for AES-192, 16 for AES-128\n  const ciphertext_ = cipher(key).encrypt(plaintext);\n  const plaintext_ = cipher(key).decrypt(ciphertext_);\n}\n\n// AESKW, AESKWP\nimport { aeskw, aeskwp } from '@noble/ciphers/aes.js';\nimport { hexToBytes } from '@noble/ciphers/utils.js';\n\nconst kek = hexToBytes('000102030405060708090A0B0C0D0E0F');\nconst keyData = hexToBytes('00112233445566778899AABBCCDDEEFF');\nconst ciphertext = aeskw(kek).encrypt(keyData);\n```\n\n#### AES: friendly WebCrypto wrapper\n\nNoble implements AES. Sometimes people want to use built-in `crypto.subtle` instead. However, it has terrible API. We simplify access to built-ins.\n\n> [!NOTE]\n> Webcrypto methods are always async.\n\n```js\nimport { gcm, ctr, cbc, randomBytes } from '@noble/ciphers/utils.js';\nconst plaintext = new Uint8Array(32).fill(16);\nconst key = randomBytes(32);\nfor (const cipher of [gcm]) {\n  const nonce = randomBytes(12);\n  const ciphertext_ = await cipher(key, nonce).encrypt(plaintext);\n  const plaintext_ = await cipher(key, nonce).decrypt(ciphertext_);\n}\nfor (const cipher of [ctr, cbc]) {\n  const nonce = randomBytes(16);\n  const ciphertext_ = await cipher(key, nonce).encrypt(plaintext);\n  const plaintext_ = await cipher(key, nonce).decrypt(ciphertext_);\n}\n```\n\n#### Reuse array for input and output\n\nTo avoid additional allocations, Uint8Array can be reused\nbetween encry\n\n[... truncated ...]"
  },
  "paulmillr/noble-curves": {
    "fetchedAt": "2025-11-12T22:42:35.239Z",
    "content": "# noble-curves\n\nAudited & minimal JS implementation of elliptic curve cryptography.\n\n- üîí [**Audited**](#security) by independent security firms\n- üîª Tree-shakeable: unused code is excluded from your builds\n- üèé Fast: hand-optimized for caveats of JS engines\n- üîç Reliable: cross-library / wycheproof tests and fuzzing ensure correctness\n- ‚û∞ Weierstrass, Edwards, Montgomery curves; ECDSA, EdDSA, Schnorr, BLS signatures\n- ‚úçÔ∏è ECDH, hash-to-curve, OPRF, Poseidon ZK-friendly hash\n- üîñ Non-repudiation (SUF-CMA, SBS) & consensus-friendliness (ZIP215) in ed25519, ed448\n- ü•à Optional, friendly wrapper over native WebCrypto\n- ü™∂ 29KB (gzipped) including bundled hashes, 11KB for single-curve build\n\nCurves have 5kb sister projects\n[secp256k1](https://github.com/paulmillr/noble-secp256k1) & [ed25519](https://github.com/paulmillr/noble-ed25519).\nThey have smaller attack surface, but less features.\n\nTake a glance at [GitHub Discussions](https://github.com/paulmillr/noble-curves/discussions) for questions and support.\n\n### This library belongs to _noble_ cryptography\n\n> **noble cryptography** ‚Äî high-security, easily auditable set of contained cryptographic libraries and tools.\n\n- Zero or minimal dependencies\n- Highly readable TypeScript / JS code\n- PGP-signed releases and transparent NPM builds\n- All libraries:\n  [ciphers](https://github.com/paulmillr/noble-ciphers),\n  [curves](https://github.com/paulmillr/noble-curves),\n  [hashes](https://github.com/paulmillr/noble-hashes),\n  [post-quantum](https://github.com/paulmillr/noble-post-quantum),\n  5kb [secp256k1](https://github.com/paulmillr/noble-secp256k1) /\n  [ed25519](https://github.com/paulmillr/noble-ed25519)\n- [Check out homepage](https://paulmillr.com/noble/)\n  for reading resources, documentation and apps built with noble\n\n## Usage\n\n> `npm install @noble/curves`\n\n> `deno add jsr:@noble/curves`\n\nWe support all major platforms and runtimes.\nFor React Native, you may need a [polyfill for getRandomValues](https://github.com/LinusU/react-native-get-random-values).\nA standalone file [noble-curves.js](https://github.com/paulmillr/noble-curves/releases) is also available.\n\n```ts\n// import * from '@noble/curves'; // Error: use sub-imports, to ensure small app size\nimport { secp256k1, schnorr } from '@noble/curves/secp256k1.js';\nimport { ed25519, ed25519ph, ed25519ctx, x25519, ristretto255 } from '@noble/curves/ed25519.js';\nimport { ed448, ed448ph, x448, decaf448 } from '@noble/curves/ed448.js';\nimport { p256, p384, p521 } from '@noble/curves/nist.js';\nimport { bls12_381 } from '@noble/curves/bls12-381.js';\nimport { bn254 } from '@noble/curves/bn254.js';\nimport { jubjub, babyjubjub, brainpoolP256r1, brainpoolP384r1, brainpoolP512r1 } from '@noble/curves/misc.js';\n\n// hash-to-curve\nimport { secp256k1_hasher } from '@noble/curves/secp256k1.js';\nimport { p256_hasher, p384_hasher, p521_hasher } from '@noble/curves/nist.js';\nimport { ristretto255_hasher } from '@noble/curves/ed25519.js';\nimport { decaf448_hasher } from '@noble/curves/ed448.js';\n\n// OPRFs\nimport { p256_oprf, p384_oprf, p521_oprf } from '@noble/curves/nist.js';\nimport { ristretto255_oprf } from '@noble/curves/ed25519.js';\nimport { decaf448_oprf } from '@noble/curves/ed448.js';\n\n// utils\nimport { bytesToHex, hexToBytes, concatBytes } from '@noble/curves/abstract/utils.js';\nimport { Field } from '@noble/curves/abstract/modular.js';\nimport { weierstrass, ecdsa } from '@noble/curves/abstract/weierstrass.js';\nimport { edwards, eddsa } from '@noble/curves/abstract/edwards.js';\nimport { poseidon, poseidonSponge } from '@noble/curves/abstract/poseidon.js';\nimport { FFT, poly } from '@noble/curves/abstract/fft.js';\n```\n\n- Examples\n  - [ECDSA, EdDSA, Schnorr signatures](#ecdsa-eddsa-schnorr-signatures)\n    - [secp256k1, p256, p384, p521, ed25519, ed448, brainpool](#secp256k1-p256-p384-p521-ed25519-ed448-brainpool)\n    - [ristretto255, decaf448](#ristretto255-decaf448)\n    - [Prehashed signing](#prehashed-signing)\n    - [Hedged ECDSA with noise](#hedged-ecdsa-with-noise)\n    - [Consensus-friendliness vs e-voting](#consensus-friendliness-vs-e-voting)\n  - [ECDH: Diffie-Hellman shared secrets](#ecdh-diffie-hellman-shared-secrets)\n  - [webcrypto: Friendly wrapper](#webcrypto-friendly-wrapper)\n  - [BLS signatures, bls12-381, bn254 aka alt\\_bn128](#bls-signatures-bls12-381-bn254-aka-alt_bn128)\n  - [Hashing to curve points](#hash-to-curve-hashing-to-curve-points)\n  - [OPRFs](#oprfs)\n  - [Poseidon hash](#poseidon-poseidon-hash)\n  - [Fast Fourier Transform](#fft-fast-fourier-transform)\n  - [utils](#utils-byte-shuffling-conversion)\n- [Internals](#internals)\n  - [Elliptic curve Point math](#elliptic-curve-point-math)\n  - [modular: Modular arithmetics \\& finite fields](#modular-modular-arithmetics--finite-fields)\n  - [weierstrass: Custom Weierstrass curve](#weierstrass-custom-weierstrass-curve)\n  - [edwards: Custom Edwards curve](#edwards-custom-edwards-curve)\n  - [Custom ECDSA instance](#custom-ecdsa-instance)\n- [Security](#security)\n- [Speed](#speed)\n- [Contributing & testing](#contributing--testing)\n- [Upgrading](#upgrading)\n\n### ECDSA, EdDSA, Schnorr signatures\n\n#### secp256k1, p256, p384, p521, ed25519, ed448, brainpool\n\n```js\nimport { secp256k1, schnorr } from '@noble/curves/secp256k1.js';\nimport { p256, p384, p521 } from '@noble/curves/nist.js';\nimport { ed25519 } from '@noble/curves/ed25519.js';\nimport { ed448 } from '@noble/curves/ed448.js';\nimport { brainpoolP256r1, brainpoolP384r1, brainpoolP512r1 } from '@noble/curves/misc.js';\nfor (const curve of [\n  secp256k1, schnorr,\n  p256, p384, p521,\n  ed25519, ed448,\n  brainpoolP256r1, brainpoolP384r1, brainpoolP512r1\n]) {\n  const { secretKey, publicKey } = curve.keygen();\n  const msg = new TextEncoder().encode('hello noble');\n  const sig = curve.sign(msg, secretKey);\n  const isValid = curve.verify(sig, msg, publicKey);\n  console.log(curve, secretKey, publicKey, sig, isValid);\n}\n\n// Specific private key\nimport { hexToBytes } from '@noble/curves/utils.js';\nconst secret2 = hexToBytes('46c930bc7bb4db7f55da20798697421b98c4175a52c630294d75a84b9c126236');\nconst pub2 = secp256k1.getPublicKey(secret2);\n```\n\nECDSA signatures use deterministic k, conforming to [RFC 6979](https://www.rfc-editor.org/rfc/rfc6979).\nEdDSA conforms to [RFC 8032](https://www.rfc-editor.org/rfc/rfc8032).\nSchnorr (secp256k1-only) conforms to [BIP 340](https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki).\n\n#### ristretto255, decaf448\n\n```ts\nimport { ristretto255, ristretto255_hasher, ristretto255_oprf } from '@noble/curves/ed25519.js';\nimport { decaf448, decaf448_hasher, decaf448_oprf } from '@noble/curves/ed448.js';\n\nconsole.log(ristretto255.Point, decaf448.Point);\n```\n\nCheck out [RFC 9496](https://www.rfc-editor.org/rfc/rfc9496) more info on ristretto255 & decaf448.\nCheck out separate documentation for [Point](#elliptic-curve-point-math), [hasher](#hash-to-curve-hashing-to-curve-points) and [oprf](#oprfs).\n\n#### Prehashed signing\n\n```js\nimport { secp256k1 } from '@noble/curves/secp256k1.js';\nimport { keccak256 } from '@noble/hashes/sha3.js';\nconst { secretKey } = curve.keygen();\nconst msg = new TextEncoder().encode('hello noble');\n// prehash: true (default) - hash using secp256k1.hash (sha256)\nconst sig = secp256k1.sign(msg, secretKey);\n// prehash: false - hash using custom hash\nconst sigKeccak = secp256k1.sign(keccak256(msg), secretKey, { prehash: false });\n```\n\nECDSA `sign()` allows providing `prehash: false`, which enables using custom hashes.\n\nA ECDSA signature is not just \"math over elliptic curve points\".\nIt's actually math + hashing: p256 is in fact p256 point + sha256 hash.\nBy default, we hash messages. To use custom hash methods,\nmake sure to disable prehashing.\n\n> [!NOTE]\n> Previously, in noble-curves v1, `prehash: false` was the default.\n> Some other libraries (like libsecp256k1) have no prehashing.\n\n#### Hedged ECDSA with noise\n\n```js\nimport { secp256k1 } from '@noble/curves/secp256k1.js';\nconst { secretKey } = curve.keygen();\nconst msg = new\n\n[... truncated ...]"
  },
  "paulmillr/noble-hashes": {
    "fetchedAt": "2025-11-12T22:42:35.542Z",
    "content": "# noble-hashes\n\nAudited & minimal JS implementation of hash functions, MACs and KDFs.\n\n- üîí [**Audited**](#security) by an independent security firm\n- üîª Tree-shakeable: unused code is excluded from your builds\n- üèé Fast: hand-optimized for caveats of JS engines\n- üîç Reliable: chained / sliding window / DoS / ACVP tests and fuzzing\n- üîÅ No unrolled loops: makes it easier to verify and reduces source code size up to 5x\n- ü¶ò Includes SHA, RIPEMD, BLAKE, HMAC, HKDF, PBKDF, Scrypt, Argon2\n- ü•à Optional, friendly wrapper over native WebCrypto\n- ü™∂ 21KB (gzipped) for everything, 2.4KB for single-hash build\n\nCheck out [Upgrading](#upgrading) for information about upgrading from previous versions.\nTake a glance at [GitHub Discussions](https://github.com/paulmillr/noble-hashes/discussions) for questions and support.\nThe library's initial development was funded by [Ethereum Foundation](https://ethereum.org/).\n\n### This library belongs to _noble_ cryptography\n\n> **noble cryptography** ‚Äî high-security, easily auditable set of contained cryptographic libraries and tools.\n\n- Zero or minimal dependencies\n- Highly readable TypeScript / JS code\n- PGP-signed releases and transparent NPM builds\n- All libraries:\n  [ciphers](https://github.com/paulmillr/noble-ciphers),\n  [curves](https://github.com/paulmillr/noble-curves),\n  [hashes](https://github.com/paulmillr/noble-hashes),\n  [post-quantum](https://github.com/paulmillr/noble-post-quantum),\n  5kb [secp256k1](https://github.com/paulmillr/noble-secp256k1) /\n  [ed25519](https://github.com/paulmillr/noble-ed25519)\n- [Check out homepage](https://paulmillr.com/noble/)\n  for reading resources, documentation and apps built with noble\n\n## Usage\n\n> `npm install @noble/hashes`\n\n> `deno add jsr:@noble/hashes`\n\nWe support all major platforms and runtimes.\nFor React Native, you may need a [polyfill for getRandomValues](https://github.com/LinusU/react-native-get-random-values).\nA standalone file [noble-hashes.js](https://github.com/paulmillr/noble-hashes/releases) is also available.\n\n```js\n// import * from '@noble/hashes'; // Error: use sub-imports, to ensure small app size\nimport { sha256 } from '@noble/hashes/sha2.js';\nconst hash = sha256(Uint8Array.from([0xca, 0xfe, 0x01, 0x23]));\n\n// Available modules\nimport { sha256, sha384, sha512, sha224, sha512_224, sha512_256 } from '@noble/hashes/sha2.js';\nimport {\n  sha3_256, sha3_512,\n  keccak_256, keccak_512,\n  shake128, shake256,\n} from '@noble/hashes/sha3.js';\nimport {\n  cshake256, turboshake256, kmac256, tuplehash256,\n  kt128, kt256, keccakprg,\n} from '@noble/hashes/sha3-addons.js';\nimport { blake3 } from '@noble/hashes/blake3.js';\nimport { blake2b, blake2s } from '@noble/hashes/blake2.js';\nimport { blake256, blake512 } from '@noble/hashes/blake1.js';\nimport { sha1, md5, ripemd160 } from '@noble/hashes/legacy.js';\nimport { hmac } from '@noble/hashes/hmac.js';\nimport { hkdf } from '@noble/hashes/hkdf.js';\nimport { pbkdf2, pbkdf2Async } from '@noble/hashes/pbkdf2.js';\nimport { scrypt, scryptAsync } from '@noble/hashes/scrypt.js';\nimport { argon2d, argon2i, argon2id } from '@noble/hashes/argon2.js';\nimport * as webcrypto from '@noble/hashes/webcrypto.js';\n// const { sha256, sha384, sha512, hmac, hkdf, pbkdf2 } = webcrypto;\nimport * as utils from '@noble/hashes/utils.js';\nconst { bytesToHex, concatBytes, equalBytes, hexToBytes } = utils;\n```\n\n- [sha2: sha256, sha384, sha512](#sha2-sha256-sha384-sha512-and-others)\n- [sha3: FIPS, SHAKE, Keccak](#sha3-fips-shake-keccak)\n- [sha3-addons: cSHAKE, KMAC, KT128, TurboSHAKE](#sha3-addons-cshake-kmac-kt128-turboshake)\n- [blake1, blake2, blake3](#blake1-blake2-blake3)\n- [legacy: sha1, md5, ripemd160](#legacy-sha1-md5-ripemd160)\n- MACs: [hmac](#hmac) | [kmac](#sha3-addons-cshake-kmac-kt128-turboshake) | [blake3 key mode](#blake1-blake2-blake3)\n- KDFs: [hkdf](#hkdf) | [pbkdf2](#pbkdf2) | [scrypt](#scrypt) | [argon2](#argon2)\n- [webcrypto: friendly wrapper](#webcrypto-friendly-wrapper)\n- [utils](#utils)\n- [Security](#security) | [Speed](#speed) | [Contributing & testing](#contributing--testing) | [License](#license)\n\n### Implementations\n\nHash functions:\n\n- `sha256()`: receive & return `Uint8Array`\n- `sha256.create().update(a).update(b).digest()`: support partial updates\n- `blake3.create({ context: 'e', dkLen: 32 })`: can have options\n- support little-endian architecture; also experimentally big-endian\n- can hash up to 4GB per chunk, with any amount of chunks\n\n#### sha2: sha256, sha384, sha512 and others\n\n```typescript\nimport { sha224, sha256, sha384, sha512, sha512_224, sha512_256 } from '@noble/hashes/sha2.js';\nconst res = sha256(Uint8Array.from([0xbc])); // basic\nfor (let hash of [sha256, sha384, sha512, sha224, sha512_224, sha512_256]) {\n  const arr = Uint8Array.from([0x10, 0x20, 0x30]);\n  const a = hash(arr);\n  const b = hash.create().update(arr).digest();\n}\n```\n\nCheck out [RFC 4634](https://datatracker.ietf.org/doc/html/rfc4634) and\n[the paper on truncated SHA512/256](https://eprint.iacr.org/2010/548.pdf).\n\n#### sha3: FIPS, SHAKE, Keccak\n\n```typescript\nimport {\n  sha3_224, sha3_256, sha3_384, sha3_512,\n  keccak_224, keccak_256, keccak_384, keccak_512,\n  shake128, shake256,\n} from '@noble/hashes/sha3.js';\nfor (let hash of [\n  sha3_224, sha3_256, sha3_384, sha3_512,\n  keccak_224, keccak_256, keccak_384, keccak_512,\n]) {\n  const arr = Uint8Array.from([0x10, 0x20, 0x30]);\n  const a = hash(arr);\n  const b = hash.create().update(arr).digest();\n}\nconst shka = shake128(Uint8Array.from([0x10]), { dkLen: 512 });\nconst shkb = shake256(Uint8Array.from([0x30]), { dkLen: 512 });\n```\n\nCheck out [FIPS-202](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.202.pdf),\n[Website](https://keccak.team/keccak.html).\n\nCheck out [the differences between SHA-3 and Keccak](https://crypto.stackexchange.com/questions/15727/what-are-the-key-differences-between-the-draft-sha-3-standard-and-the-keccak-sub)\n\n#### sha3-addons: cSHAKE, KMAC, K12, TurboSHAKE\n\n```typescript\nimport {\n  cshake128, cshake256, kt128, kt256,\n  keccakprg, kmac128, kmac256,\n  parallelhash256, tuplehash256,\n  turboshake128, turboshake256,\n} from '@noble/hashes/sha3-addons.js';\nconst data = Uint8Array.from([0x10, 0x20, 0x30]);\nconst ec1 = cshake128(data, { personalization: 'def' });\nconst ec2 = cshake256(data, { personalization: 'def' });\nconst et1 = turboshake128(data);\nconst et2 = turboshake256(data, { D: 0x05 });\n// tuplehash(['ab', 'c']) !== tuplehash(['a', 'bc']) !== tuplehash([data])\nconst et3 = tuplehash256([new TextEncoder().encode('ab'), new TextEncoder().encode('c')]);\n// Not parallel in JS (similar to blake3 / kt128), added for compat\nconst ep1 = parallelhash256(data, { blockLen: 8 });\nconst kk = Uint8Array.from([0xca]);\nconst ek10 = kmac128(kk, data);\nconst ek11 = kmac256(kk, data);\nconst ek12 = kt128(data); // kangarootwelve 128-bit\nconst ek13 = kt256(data); // kangarootwelve 256-bit\n// pseudo-random generator, first argument is capacity. XKCP recommends 254 bits capacity for 128-bit security strength.\n// * with a capacity of 254 bits.\nconst p = keccakprg(254);\np.feed('test');\nconst rand1b = p.fetch(1);\n```\n\n- cSHAKE, KMAC, TupleHash, ParallelHash + XOF are available, matching\n  [NIST SP 800-185](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-185.pdf)\n- Reduced-round Keccak KT128 (KangarooTwelve ü¶ò, K12) and TurboSHAKE are available, matching\n  [RFC 9861](https://datatracker.ietf.org/doc/rfc9861/).\n- [KeccakPRG](https://keccak.team/files/CSF-0.1.pdf): pseudo-random generator based on Keccak\n\n#### blake1, blake2, blake3\n\n```typescript\nimport { blake224, blake256, blake384, blake512 } from '@noble/hashes/blake1.js';\nimport { blake2b, blake2s } from '@noble/hashes/blake2.js';\nimport { blake3 } from '@noble/hashes/blake3.js';\n\nfor (let hash of [blake224, blake256, blake384, blake512, blake2b, blake2s, blake3]) {\n  const arr = Uint8Array.from([0x10, 0x20, 0x30]);\n  const a = hash(arr);\n  const b = hash.create().update(arr).digest();\n}\n\n// blake2 advanced usage\nconst ab = Uint8Array.f\n\n[... truncated ...]"
  },
  "meldsun0/utp": {
    "fetchedAt": "2025-11-12T22:42:42.983Z",
    "content": "# utp - Micro Transport Protocol for Java\r\n[![GitHub License](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)]()\r\n[![Discord](https://img.shields.io/badge/Chat-on%20Discord-%235865F2?logo=discord&logoColor=white)](https://discord.com/channels/890617081744220180/1301231225276465152)\r\n\r\nThis library is based on [uTP](https://www.bittorrent.org/beps/bep_0029.html) and it was originally forked from [Tribler/utp4j](https://github.com/Tribler/utp4j).\r\n\r\n\r\n# UTPClient Usage Example over UDP\r\n\r\nThis example demonstrates how to send and receive data between two local uTP clients over UDP using `UTPClient`.\r\n\r\n---\r\n### Step 1: Initialize Executors and UDP Transport Layers\r\n\r\n```java\r\n        var readerExecutor = Executors.newVirtualThreadPerTaskExecutor();\r\n        var writerExecutor = Executors.newVirtualThreadPerTaskExecutor();\r\n\r\n        var readerTransport = new UDPTransportLayer(124);\r\n        var writerTransport = new UDPTransportLayer(123);\r\n```\r\n\r\n> Sets up virtual thread executors for concurrent I/O operations and initializes UDP transport layers on different ports for the sender and receiver.\r\n\r\n---\r\n\r\n### Step 2: Create uTP Clients and Define Peer Addresses\r\n\r\n```java\r\n        var utpReader = new UTPClient(readerTransport);\r\n        var utpWriter = new UTPClient(writerTransport);\r\n\r\n        var readerAddress = new UDPAddress(\"localhost\", 124);\r\n        var writerAddress = new UDPAddress(\"localhost\", 123);\r\n```\r\n\r\n> Creates two `UTPClient` instances ‚Äî one for receiving, one for sending ‚Äî and defines their respective socket addresses.\r\n\r\n---\r\n\r\n### Step 3: Start Listening Threads for Incoming Packets\r\n\r\n```java\r\n        readerExecutor.submit(receivingListener(utpReader, readerTransport, writerAddress));\r\n        writerExecutor.submit(receivingListener(utpWriter, writerTransport, readerAddress));\r\n```\r\n\r\n> Starts background threads that continuously listen for incoming UDP packets and pass them to the `UTPClient`.\r\n\r\n---\r\n\r\n### Step 4: Prepare Receiver to Accept and Read Incoming Data\r\n\r\n```java\r\n        CompletableFuture<Bytes> receivedFuture = new CompletableFuture<>();\r\n        utpReader.startListening(111, writerAddress)\r\n            .thenCompose(__ -> utpReader.read(readerExecutor))\r\n            .thenAccept(receivedFuture::complete);\r\n```\r\n\r\n> Configures the reader to listen on channel `111` and asynchronously read data into a future.\r\n\r\n---\r\n\r\n### Step 5: Connect Sender and Send the Message\r\n\r\n```java\r\n        utpWriter.connect(111, readerAddress)\r\n            .thenCompose(__ -> utpWriter.write(getContentToSend(\"Hello from uTP!\"), writerExecutor))\r\n            .get();\r\n```\r\n\r\n> The sender connects to the receiver and writes a UTF-8 message. The `get()` call blocks until sending is complete.\r\n\r\n---\r\n\r\n### Step 6: Wait for the Receiver and Print the Message\r\n\r\n```java\r\n        Bytes received = receivedFuture.get();\r\n        System.out.println(\"‚úÖ Received: \" + new String(received.toArray(), StandardCharsets.UTF_8));\r\n    }\r\n```\r\n\r\n> The receiver awaits incoming data and prints it to the console once received.\r\n\r\n---\r\n\r\n### Helper Methods\r\n\r\n```java\r\n    private static Runnable receivingListener(UTPClient utpClient, UDPTransportLayer transport, UDPAddress remoteAddress) {\r\n        return () -> {\r\n            while (true) {\r\n                try {\r\n                    var packet = transport.onPacketReceive();\r\n                    utpClient.receivePacket(packet, remoteAddress);\r\n                } catch (SocketException e) {\r\n                    break;\r\n                } catch (Exception e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        };\r\n    }\r\n\r\n    private static Bytes getContentToSend(String input) {\r\n        byte[] byteArray = input.getBytes(StandardCharsets.UTF_8);\r\n        ByteBuffer buffer = ByteBuffer.wrap(byteArray);\r\n        return Bytes.of(buffer.array());\r\n    }\r\n}\r\n```\r\n\r\n> - `receivingListener(...)`: Listens for incoming UDP packets and passes them to the uTP client.\r\n> - `getContentToSend(...)`: Converts a string into a `Bytes` object suitable for transmission.\r\n\r\n---\r\n\r\n## Expected Output\r\n\r\n```bash\r\nReceived: Hello from uTP!\r\n```\r\n---\r\n\r\n## Notes\r\n\r\n- There are two interfaces that need to be implemented before using UTP for reading or writing operations:\r\n  - TransportLayer:\r\n    - You define how a packet will be sent over the wire by receiving a UtpPacket and RemoteAddress\r\n    - You define what to do once the transfer has finished.\r\n  - TransportAddress:\r\n    - You define your own RemoteAddress needed to be sent by the TransportLayer previously defined.\r\n\r\n---\r\n\r\n## Current Flaws\r\n* Closing connection while sending/reading is not yet handled good enough\r\n* High CPU consumption\r\n* Probably some minor bugs.\r\n* The uTP reference implementation deviates from the uTP specification on the initialization of the `ack_nr` when receiving the `ACK` of a `SYN` packet. The reference implementation [initializes](https://github.com/bittorrent/libutp/blob/master/utp_internal.cpp#L1874) this as `c.ack_nr = pkt.seq_nr - 1` while the specification indicates `c.ack_nr = pkt.seq_nr`. This uTP specifications follows the uTP reference implementation: `c.ack_nr = pkt.seq_nr - 1`.\r\n\r\n\r\n\r\n## License\r\nutp is licensed under the Apache 2.0 [license]. \r\n"
  },
  "openfort-xyz/mobile-wallet-protocol-unity-client": {
    "fetchedAt": "2025-11-12T22:42:49.969Z",
    "content": "# Mobile Wallet Protocol (MWP) for Unity\n\nüöÄ **MWP for Unity is now publicly available!** This implementation allows Unity game developers to seamlessly connect their in-game wallets with the broader Web3 ecosystem using **secure deep linking**.\n\n## ‚ú® Features\nAllow any game build on Unity to interact with any wallet supporting the Mobile Wallet Protocol.\n\n## Getting Started\n\nCheck out our **[comprehensive documentation](https://www.openfort.io/docs/guides/ecosystem/unity-integration)** for step-by-step guidance.\n\n## Platform Support\n\n| Platform  | Supported |\n|-----------|:--------:|\n| iOS       | ‚úÖ       |\n| Android   | ‚úÖ       |\n| Mac       | ‚úÖ       |\n| Windows   | ‚úÖ       |\n\n## [Example Project](https://github.com/openfort-xyz/mobile-wallet-protocol-unity-client/tree/main/Project)\n\n### Reference\nThis implementation is based on the original **Mobile Wallet Protocol** standard developed by [Coinbase](https://mobilewalletprotocol.github.io/wallet-mobile-sdk/).\n\n"
  },
  "alchemyplatform/modular-account": {
    "fetchedAt": "2025-11-12T22:42:57.654Z",
    "content": "# Modular Account\n\n[![gh_ci_badge]][gh_ci_link]\n[![tg_badge]][tg_link]\n\n[gh_ci_badge]: https://github.com/alchemyplatform/modular-account/actions/workflows/test.yml/badge.svg\n[gh_ci_link]: https://github.com/alchemyplatform/modular-account/actions/workflows/test.yml\n[tg_badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&url=https://mogyo.ro/quart-apis/tgmembercount?chat_id=modular_account_standards\n[tg_link]: https://t.me/modular_account_standards\n\n![](./img/ma.png)\n\nAlchemy's Modular Account is a maximally modular, upgradeable smart contract account that is compatible with [ERC-4337](https://eips.ethereum.org/EIPS/eip-4337) and [ERC-6900](https://eips.ethereum.org/EIPS/eip-6900).\n\n> [!WARNING]  \n> **This branch contains changes that are under development.** To use the latest audited version make sure to use the correct commit. The tagged versions can be found in the [releases](https://github.com/alchemyplatform/modular-account/releases).\n\n## Overview\n\nThis repository contains:\n\n- ERC-6900 compatible account implementations: [src/account](src/account)\n- Account factory: [src/factory](src/factory)\n- Helper contracts and libraries: [src/helpers](src/helpers), [src/libraries](src/libraries)\n- ERC-6900 compatible modules: [src/modules](src/modules)\n  - Validation modules:\n    - [SingleSignerValidationModule](src/modules/validation/SingleSignerValidationModule.sol): Enables validation for a single signer (EOA or contract).\n    - [WebAuthnValidationModule](src/modules/validation/WebAuthnValidationModule.sol): Enables validation for passkey signers.\n  - Permission-enforcing hook modules:\n    - [AllowlistModule](src/modules/permissions/AllowlistModule.sol): Enforces ERC-20 spend limits and address/selector allowlists.\n    - [NativeTokenLimitModule](src/modules/permissions/NativeTokenLimitModule.sol): Enforces native token spend limits.\n    - [PaymasterGuardModule](src/modules/permissions/PaymasterGuardModule.sol): Enforces use of a specific paymaster.\n    - [TimeRangeModule](src/modules/permissions/TimeRangeModule.sol): Enforces time ranges for a given entity.\n\nThe contracts conform to these ERC versions:\n\n- ERC-4337: [v0.7.0](https://github.com/eth-infinitism/account-abstraction/blob/releases/v0.7/erc/ERCS/erc-4337.md)\n- ERC-6900: [v0.8.0](https://github.com/ethereum/ERCs/blob/c081c445424505d549e0236650917a2aaf3c5743/ERCS/erc-6900.md)\n\n## Development\n\n### Building and testing\n\n```bash\n# Install dependencies\nforge install\npnpm install\n\n# Build\nforge build\nFOUNDRY_PROFILE=optimized-build forge build --sizes\n\n# Lint\npnpm lint\n\n# Format\npnpm fmt\n\n# Coverage\npnpm lcov\n\n# Generate gas snapshots\npnpm gas\n\n# Test\npnpm test\nforge test -vvv\n```\n\n### Deployment\n\nDeployment scripts can be found in the `scripts/` folder, and depend on reading parameters from your local environment or from `.env`. A sample for the required fields can be found at `.env.example`. Note that some have specific foundry profiles needed for deployment.\n\nYou will also need provide a wallet to use for deployment. Available options can be found [here](https://book.getfoundry.sh/reference/forge/forge-script#wallet-options---raw).\n\n```bash\nFOUNDRY_PROFILE=<profile> forge script script/<deploy_script>.s.sol --rpc-url $RPC_URL --broadcast\n```\n\n## Features overview\n\n### Features\n\nModular Account can:\n\n1. Deploy contracts via `CREATE` or `CREATE2`.\n2. Receive ERC-721 and ERC-1155 tokens.\n3. Use applications that depend on ERC-1271 contract signatures.\n4. Use applications that use the ERC-165 introspection standard.\n5. Be upgradeable to or from most other smart contract account implementations.\n6. Be customized in many ways. All customization options can be found [here](./2-customizing-your-modular-account.md).\n\n#### ERC-1271 contract signatures support\n\nCertain applications such as Permit2 or Cowswap use the ERC-1271 contract signatures standard to determine if a smart contract has approved a certain action. Modular Account implements ERC-1271 to allow smart accounts to use these applications.\n\n#### Upgradeability\n\nWhen modular accounts are created from the factory, an ERC-1967 proxy contract is deployed. Users can update the implementation their proxy points to to choose which smart account implementations to use. Modular Account adheres to the ERC-7201 namespaced storage standard to prevent storage collisions when updating between different implementations.\n\n### Customizing your Modular Account\n\nModular Account can be customized by:\n\n1. Installing execution functions to add custom execution logic to run, or uninstalling to remove them\n2. Installing validations to apply custom validation logic for one or all execution functions, or uninstalling to remove them\n3. Installing pre validation hooks that are attached to module entities, or removing them\n4. Installing execution hooks that are attached to execution functions, or removing them\n5. Installing execution hooks that are attached to module entities, or removing them\n\n#### Lifecycle of a user operation\n\n![](./img/userop-flow.png)\n\n#### Lifecycle of a runtime call\n\n![](./img/runtime-flow.png)\n\n#### Pre-validation hooks\n\nPre validation hooks are run before validations. Pre-validation hooks are necessary to perform gas related checks for User Operations (session key gas limits, or gas metering taking into account paymaster usage). These checks must happen in the validation phase since a validation success would allow the entrypoint to charge gas for the user operation to the account.\n\n#### Validations\n\nValidations are usually signature validation functions (secp256k1, BLS, WebAuthn, etc). While it‚Äôs feasible to implement signature validation as a pre-validation hook, it‚Äôs more efficient and ergonomic to do these in validations since it allows us to apply permissions per module entity using execution hooks. In ERC-4337, accounts can return validation data that‚Äôs not 0 or 1 to signal the usage of a signature aggregator.\n\n#### Execution hooks\n\nExecution hooks are useful for applying permissions on execution functions to limit the set of possible actions that can be taken. Post-execution hooks are useful for checking the final state after an execution. Pre and post-execution hook pairs are useful for measuring differences in state due to an execution. For example, you could use a pre and post execution hook pair to enforce that swap outputs from a DCA swap performed by a session key fall within a some tolerance price determined by a price oracle.\n\nExecution hooks can be associated either with a module entity to apply permissions on that specific entity, or with an execution selector on the account to apply global restrictions on the account across all entities. A example of a useful global restriction would be to block NFT transfers for NFTs in cold storage, or to apply resource locks.\n\n#### Execution functions\n\nExecution hooks are applied across execution functions. Modular account comes with native execution functions such as `installValidation`, `installExecution`, or `upgradeToAndCall`. However, you could customize the account by installing additional execution functions. After a new execution is installed, when the account is called with that function selector, the account would forward the call to the module associated with that installed execution. An example of a useful execution functions would be to implement callbacks for the account to be able to take flash loans.\n\n## Security\n\n### Audits\n\nOur audit reports can be found in [audits](/audits). The filenames for the reports have the format: `YYYY-MM-DD_VENDOR_FFFFFFF.pdf`, where `YYYY-MM-DD` refers to the date on which the final report was received, `VENDOR` refers to the conductor of the audit, and `FFFFFFF` refers to the short commit hash on which the audit was conducted.\n\n### Bug bounty program\n\nOur Modular Account bug bounty is hosted on the [Cantina](https://cantina.xyz/bounties/246de4d3-e138-4340-bdfc-fc4c95951491) platform.\n\n### Other security considerations\n\nThis s\n\n[... truncated ...]"
  },
  "alchemyplatform/aa-benchmarks": {
    "fetchedAt": "2025-11-12T22:42:58.079Z",
    "content": "# Smart Account Benchmarks\n\nThese comprehensive benchmarks are intended to serve as a resource for evaluating popular ERC-4337 compatible smart contract accounts. They are built on Hardhat for accurate, transaction-based fee measurements (see [Methodology](#methodology)) and for use of existing TypeScript utilities around fee calculations.\n\n## Methodology\n\nWhen using smart contract accounts, it's important to consider both deployment gas costs and transaction gas costs which are dependent on the contract implementation. Unlike EOAs, smart contract accounts incur gas costs when being deployed on each chain.\nThis tool seeks to measure the cost of the entire transaction landed on-chain for each action, including associated L1 fees. As smart accounts are expected to proliferate on L2s, it's important to consider L1 fees (measured as a function of the RLP-encoded signed transaction and the blob gas market) on top of L2 execution costs. L1 fees can impact the cost of transactions on L2s, so optimizing the size of calldata is important.\n\nThe L1 fee calculations are done following the formula and constants specified in [Optimism Ecotone](https://docs.optimism.io/stack/transactions/fees#ecotone).\n\nThere are two different categories of benchmarks measured in this test: **User Operation** and **Runtime**.\n\n- **User Operation**: This test measures the onchain cost for a bundler to execute the user operation in a bundle of size 1, to present a lower-bound fee required for the user operation to land in an exclusive bundle. The cost per individual user operation can vary, because each bundler may calculate pre-verification gas differently and the costs can differ based on the number of user operations in a bundle. This benchmark, much like most other benchmarks, calculates fees based on the transaction receipt and the serialized signed EIP-1559 transaction for `entryPoint.handleUserOp([userOp])`. As multi-user-op bundles become more prevalent, we can expect actual fees to undercut the data presented here.\n- **Runtime**: Runtime transactions are defined as those performed outside of the ERC-4337 flow. This can be done by calling from one smart account into another during the execution phase in ERC-4337, or by using an EOA account to initiate a transaction and skip the ERC-4337 EntryPoint contract. While this is a possible flow with smart accounts, it is uncommon in practice. Runtime benchmarks can be found within each chain's benchmark page. For this flow, fees are also calculated based on the transaction's receipt and the serialized signed EIP-1559 transaction.\n\nBelow, we compare the deployment costs and various transaction costs across multiple popular smart contract account implementations.\n\n## Results\n\nThese numbers are derived from local simulations with fixed inputs (see [Run benchmark](#run-benchmark) below to try different inputs) and actual on-chain numbers may differ.\n\nRelative costs are computed relative to Alchemy Modular Account v2. Latest fees were benchmarked on 2025-01-30. High blob fees were benchmarked on 2024-03-31.\n\n#### ‚õΩÔ∏è Benchmarks for other networks\n\n[Ethereum Mainnet](/benchmarks/ethereum.md) | [Arbitrum Mainnet](/benchmarks/arbitrum.md) | [Polygon Mainnet](/benchmarks/polygon.md) | **Optimism Mainnet** | [Base Mainnet](/benchmarks/base.md) | [Zora Mainnet](/benchmarks/zora.md)\n\n---\n\n<!-- BENCHMARK_RESULTS -->\n\n### Optimism Mainnet\n\n#### Run parameters\n\n| Parameter            |        Latest | High Blob Fees |\n| :------------------- | ------------: | -------------: |\n| Gas price (gwei)     | `0.001000555` |  `0.060233618` |\n| L1 base fee (gwei)   | `1.121228232` |        `24.05` |\n| L1 base fee scalar   |        `5227` |         `1368` |\n| Blob base fee (wei)  |     `7736427` |  `46930000000` |\n| Blob base fee scalar |     `1014213` |       `810949` |\n| ETH price (USD)      |    `$3192.59` |            `-` |\n\n#### Account creation\n\n##### Total fee (USD)\n\n|                                        | Absolute - Latest | Absolute - High Blob Fees | Relative - Latest | Relative - High Blob Fees |\n| :------------------------------------- | ----------------: | ------------------------: | ----------------: | ------------------------: |\n| Alchemy Modular Account v2             |        `$0.00036` |                `$0.03651` |         `100.00%` |                 `100.00%` |\n| Biconomy Nexus                         |        `$0.00074` |                `$0.06471` |         `204.96%` |                 `177.24%` |\n| ZeroDev Kernel v3.1                    |        `$0.00067` |                `$0.06984` |         `186.38%` |                 `191.30%` |\n| Safe v1.4.1 (non-modular)              |        `$0.00104` |                `$0.10092` |         `290.60%` |                 `276.41%` |\n| Alchemy Light Account v2 (non-modular) |        `$0.00059` |                `$0.05033` |         `163.97%` |                 `137.86%` |\n| Coinbase Smart Wallet (non-modular)    |        `$0.00067` |                `$0.05933` |         `186.20%` |                 `162.52%` |\n| Simple Account (non-modular)           |        `$0.00060` |                `$0.05176` |         `168.44%` |                 `141.78%` |\n\n<details>\n<summary><b>Details</b></summary>\n\n##### Latest\n\n|                                        | Execution gas | Execution fee (ETH) | L1 gas |  L1 fee (ETH) | Total fee (ETH) | Total fee (USD) |\n| :------------------------------------- | ------------: | ------------------: | -----: | ------------: | --------------: | --------------: |\n| Alchemy Modular Account v2             |       `97772` |       `0.000000098` | `2300` | `0.000000015` |   `0.000000112` |      `$0.00036` |\n| Biconomy Nexus                         |      `210309` |       `0.000000210` | `3152` | `0.000000020` |   `0.000000230` |      `$0.00074` |\n| ZeroDev Kernel v3.1                    |      `180465` |       `0.000000181` | `4564` | `0.000000029` |   `0.000000210` |      `$0.00067` |\n| Safe v1.4.1 (non-modular)              |      `289207` |       `0.000000289` | `5884` | `0.000000037` |   `0.000000327` |      `$0.00104` |\n| Alchemy Light Account v2 (non-modular) |      `169655` |       `0.000000170` | `2300` | `0.000000015` |   `0.000000184` |      `$0.00059` |\n| Coinbase Smart Wallet (non-modular)    |      `190525` |       `0.000000191` | `2948` | `0.000000019` |   `0.000000209` |      `$0.00067` |\n| Simple Account (non-modular)           |      `174219` |       `0.000000174` | `2372` | `0.000000015` |   `0.000000189` |      `$0.00060` |\n\n##### High Blob Fees\n\n|                                        | Execution gas | Execution fee (ETH) | L1 gas |  L1 fee (ETH) | Total fee (ETH) | Total fee (USD) |\n| :------------------------------------- | ------------: | ------------------: | -----: | ------------: | --------------: | --------------: |\n| Alchemy Modular Account v2             |       `97772` |       `0.000005889` | `2300` | `0.000005546` |   `0.000011436` |      `$0.03651` |\n| Biconomy Nexus                         |      `210309` |       `0.000012668` | `3152` | `0.000007601` |   `0.000020269` |      `$0.06471` |\n| ZeroDev Kernel v3.1                    |      `180465` |       `0.000010870` | `4564` | `0.000011006` |   `0.000021876` |      `$0.06984` |\n| Safe v1.4.1 (non-modular)              |      `289207` |       `0.000017420` | `5884` | `0.000014189` |   `0.000031609` |      `$0.10092` |\n| Alchemy Light Account v2 (non-modular) |      `169655` |       `0.000010219` | `2300` | `0.000005546` |   `0.000015765` |      `$0.05033` |\n| Coinbase Smart Wallet (non-modular)    |      `190525` |       `0.000011476` | `2948` | `0.000007109` |   `0.000018585` |      `$0.05933` |\n| Simple Account (non-modular)           |      `174219` |       `0.000010494` | `2372` | `0.000005720` |   `0.000016214` |      `$0.05176` |\n\n</details>\n\n#### User Operation: Native transfer\n\n##### Total fee (USD)\n\n|                                        | Absolute - Latest | Absolute - High Blob Fees | Relative \n\n[... truncated ...]"
  },
  "alchemyplatform/multisig-plugin": {
    "fetchedAt": "2025-11-12T22:42:58.467Z",
    "content": "# Multisig Plugin\n\nMultisig Plugin is an ERC6900-compatible k-of-n ownership plugin that supports both EOA and smart contract owners.\n\n## Overview\n\nThis repository contains:\n1. An ERC6900-compatible k-of-n Multisig Plugin\n2. A factory contract that deploys [Modular Account](https://github.com/alchemyplatform/modular-account)s with Multisig Plugin installed\n\nThe plugin conforms to these ERC versions:\n- ERC-4337: [0.6.0](https://github.com/eth-infinitism/account-abstraction/blob/releases/v0.6/eip/EIPS/eip-4337.md)\n- ERC-6900: [0.7.0](https://github.com/erc6900/reference-implementation/blob/v0.7.x/standard/ERCs/erc-6900.md)\n\n## Core Functionalities\n\nMultisig Plugin is an plugin that provides validation functions for a k-of-n ownership scheme. **Multisig validation only works in the user operation context.**\n\nIts core features include:\n1. Multisig user operation validation on native account functions (`installPlugin`, `uninstallPlugin`, `execute`, `executeBatch`, `upgradeToAndCall`).\n2. An execution function that modifies account ownership by adding or removing owners, and/or modifies the threshold. This is guarded by the above validation function.\n3. Support for ERC-1271 smart contract signatures based on the same multisig scheme.\n4. Variable gas feature that allows for more flexibility and control over gas spent.\n\n### Technical Decisions\n\n#### Multisig validation scheme is applied only for the User Operation context\nWe expect multisig signers to implement key management best practices such as key rotation. By using the user operation path, keys can be used just for signing without needing to procure native tokens for gas. Like other ERC-4337 operations, the transaction would be paid for by the account or by a paymaster service.\n\n#### Variable gas feature\nUser operations contain several gas/fee related fields - `preVerificationGas`, `maxFeePerGas` and `maxPriorityFeePerGas` - that specify the maximum fees that can be used for the user op. These fields (among others) are used to form the `userOpHash` which has to be signed over by the k signers. If collecting the k signatures takes too long, it's likely that network prices would have shifted. If the user op is overpriced, the account would end up overpaying for transaction inclusion. However, if the user op is underpriced, the bundler would reject the user op and the k signers have to re-sign this user operation.\n\nThis multisig plugin includes a variable gas feature to address this problem. The fee values selected and signed over by the first k-1 signers are treated as a \"maximum fee\" and the k-th signer is able to choose final fee values to use based on the current network conditions. With this feature, there is no longer a risk of overpaying, or having to re-collect the k signatures.\n\n> [!NOTE] \n> Since paymasters sign over the user op with max gas values, the variable gas feature is very likely incompatible with most ERC-4337 paymasters. \n\n#### Multisig signature spec\nThe multisig signature scheme has the following format:\n\n`k signatures` || `contract signatures (if any)`\n\nEach signature in the `k signatures` is sorted in ascending order by owner address, is 65 bytes long, uses packed encoding and has the following format:\n1. If it's an EOA signature, `signature = abi.encodePacked(r, s, v)`\n2. If it's a contract signature, it is also `abi.encodePacked(r, s, v)` with `v` set to 0, `r` set to the address of the contract owner expanded to 32 bytes, and `s` being the bytes offset of where the actual signature is located. This is relative to the starting location of `k signatures`. The actual contract signature has regular ABI encoding, appended after the `k signatures`.\n\nThe above is the format for a ERC-1271 signature. For user operation signatures, prepend the signature above with the 3 gas values from the variable gas feature to form this full signature:  \n`uint256 upperLimitPreVerificationGas` || `uint256 upperLimitMaxFeePerGas` || `uint256 upperLimitMaxPriorityFeePerGas` || `k signatures` || `contract signatures (if any)`\n\nIf the variable gas feature is used, the first k-1 signatures should sign over a user op with the upper limit gas values, and the k-th signature should sign over a user op with actual gas values. Additionally, the `v` value of the k-th signature should be incremented by 32 to denote that the signature is over the actual gas values. \n\n## Development\n\n### Building and testing\n\n```bash\n# Build\nforge build\n\n# Lint\npnpm lint\n\n# Test\nforge test -vvv\n```\n\n### Deployment\n\nA deployment script can be found in the `scripts/` folder\n\n```bash\nforge script script/Deploy.s.sol --rpc-url $RPC_URL --broadcast\n```\n\n## Security and audits\n\nOur audit report from Quantstamp can be found in [audits](/audits).\n\n## Collaborators\n\n[<img src=\"https://assets-global.website-files.com/65d123ed4c76575a9e69648c/65db9e5db75bfd6e0a2a6065_maple-logo.png\" alt=\"Maple Finance\" height=\"32px\">](https://maple.finance/)\n\n## Acknowledgements\n\nThe signature verification logic takes inspiration from the work done by [Gnosis Safe](https://github.com/safe-global/safe-smart-account).\n\n## License\n\nThe Multisig Plugin code is licensed under the GNU General Public License v3.0, also included in our repository in [LICENSE-GPL](LICENSE-GPL).\n\nAlchemy Insights, Inc., 548 Market St., PMB 49099, San Francisco, CA 94104; legal@alchemy.com\n"
  },
  "alchemyplatform/light-account": {
    "fetchedAt": "2025-11-12T22:43:07.923Z",
    "content": "# Light Account\n\n[![gh_ci_badge]][gh_ci_link] [![discord_badge]][discord_link]\n\n[gh_ci_badge]: https://github.com/alchemyplatform/light-account/actions/workflows/test.yml/badge.svg\n[gh_ci_link]: https://github.com/alchemyplatform/light-account/actions/workflows/test.yml\n[discord_badge]: https://dcbadge.vercel.app/api/server/alchemyplatform?style=flat\n[discord_link]: https://discord.gg/alchemyplatform\n\n![](./img/light-account.jpg)\n\nA set of lightweight ERC-4337 compatible smart contract accounts with designated ownership. [Account Kit](https://accountkit.alchemy.com) is the easiest way to integrate Light Account.\n\n## Features\n\n### `LightAccount`\n\nLike [eth-infinitism](https://github.com/eth-infinitism/account-abstraction)'s [`SimpleAccount`](https://github.com/eth-infinitism/account-abstraction/blob/develop/contracts/samples/SimpleAccount.sol), but with the following changes:\n\n1. Instead of the default storage slots, uses namespaced storage to avoid clashes when switching implementations.\n\n2. Ownership can be transferred via `transferOwnership`, similar to the behavior of an `Ownable` contract. This is a simple single-step operation, so care must be taken to ensure that the ownership is being transferred to the correct address.\n\n3. Supports [ERC-1271](https://eips.ethereum.org/EIPS/eip-1271) signature validation for both validating the signature on user operations and in exposing its own `isValidSignature` method. This only works when the owner of `LightAccount` also support ERC-1271.\n\n   _ERC-4337's bundler validation rules limit the types of contracts that can be used as owners to validate user operation signatures. For example, the contract's `isValidSignature` function may not use any forbidden opcodes such as `TIMESTAMP` or `NUMBER`, and the contract may not be an ERC-1967 proxy as it accesses a constant implementation slot not associated with the account, violating storage access rules. This also means that the owner of a `LightAccount` may not be another `LightAccount` if you want to send user operations through a bundler._\n\n4. Improves gas estimation by enabling switching between `ecrecover` and ERC-1271 signature validation by prepending a `SignatureType` byte to the user operation signature. Allowed `SignatureType` values:\n\n   - `SignatureType.EOA`: For an EOA owner. Signature is validated using `ecrecover`.\n   - `SignatureType.CONTRACT`: For a contract owner. Signature is validated using `owner.isValidSignature`.\n\n5. The factory uses Solady's `LibClone.createDeterministicERC1967` instead of OpenZeppelin's `ERC1967Proxy`.\n\n6. The factory includes ownership and entry point staking capabilities to address mempool limitations for unstaked entities as defined in [ERC-7562](https://eips.ethereum.org/EIPS/eip-7562).\n\n7. Event `SimpleAccountInitialized` renamed to `LightAccountInitialized`.\n\n8. Uses custom errors.\n\n### `MultiOwnerLightAccount`\n\nLike `LightAccount`, but with the following changes:\n\n1. Multiple owners are supported. They can be specified at account deployment, or updated via `updateOwners`. This is a simple single-step operation, so care must be taken to ensure that the ownership is being updated to the correct address(es).\n\n2. Allowed `SignatureType` values:\n\n   - `SignatureType.EOA`: For EOA owners. Signature is validated using `ecrecover`.\n   - `SignatureType.CONTRACT_WITH_ADDR`: For contract owners. Signature is validated using `owner.isValidSignature`. The contract owner address MUST be passed as part of the signature, following the format: `SignatureType.CONTRACT_WITH_ADDR || contractOwnerAddress || signature`, where `||` is the byte concatenation operator.\n\n## Deployments\n\nSee the current deployments by network under the [deployments](./deployments) folder.\n\n## Build\n\n```bash\nforge build\n```\n\n## Test\n\n```bash\nforge test -vvv\n```\n\n## Deploy\n\nThe deploy script supports any [wallet options](https://book.getfoundry.sh/reference/forge/forge-script#wallet-options---raw) provided by Foundry, including local private keys, mneumonics, hardware wallets, and remote signers. Append the chosen signing method's option to the field marked `[WALLET_OPTION]` in the following script command, and set the sender address in the field `[SENDER_ADDRESS]`.\n\n```bash\nforge script script/Deploy_LightAccountFactory.s.sol [WALLET_OPTION] --sender [SENDER_ADDRESS] --rpc-url [RPC_URL] -vvvv --broadcast --verify\nforge script script/Deploy_MultiOwnerLightAccountFactory.s.sol [WALLET_OPTION] --sender [SENDER_ADDRESS] --rpc-url [RPC_URL] -vvvv --broadcast --verify\n```\n\nMake sure the provided `RPC_URL` is set to an RPC for the chain you wish to deploy on.\n\n## Generate Inspections\n\n```bash\nbash utils/inspect.sh\n```\n\n## Static Analysis\n\n```bash\nslither .\n```\n\n## Dependencies\n\nLight Account uses dependencies via git submodules, pinned to release branches. Dependencies that cannot be reliably pinned (or those that needed to be modified) have been copied directly into the repository. These are listed below:\n\n| File                                                                    | Description                                                                                    | Source                                                                                                                                                                      |\n| ----------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [CustomSlotInitializable.sol](./src/common/CustomSlotInitializable.sol) | A fork of OpenZeppelin's `Initializable` contract that allows custom storage slots to be used. | [Initializable.sol (932fddf)](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/932fddf69a699a9a80fd2396fd1a2ab91cdda123/contracts/proxy/utils/Initializable.sol) |\n| [EIP712.sol](./src/external/solady/EIP712.sol)                          | Copied from Solady.                                                                            | [EIP712.sol (eac17da)](https://github.com/Vectorized/solady/blob/eac17da6d57d864f179a6d81e02127cabe3b77d9/src/utils/EIP712.sol)                                             |\n| [LibClone.sol](./src/external/solady/LibClone.sol)                      | Copied from Solady.                                                                            | [LibClone.sol (7a1f591)](https://github.com/Vectorized/solady/blob/7a1f591fe53487bd6952c4df23d3bed26a4b678d/src/utils/LibClone.sol)                                         |\n| [UUPSUpgradeable.sol](./src/external/solady/UUPSUpgradeable.sol)        | Copied from Solady.                                                                            | [UUPSUpgradeable.sol (a061f38)](https://github.com/Vectorized/solady/blob/a061f38f27cd7ae330a86d42d3f15b4e7237f064/src/utils/UUPSUpgradeable.sol)                           |\n"
  },
  "RathFinance/tachyon-forwarder": {
    "fetchedAt": "2025-11-12T22:43:16.884Z",
    "content": "## Tachyon Forwarder\n> This is Sample forwarder to use Rath Finance's Tachyon "
  },
  "RathFinance/tachyon-account": {
    "fetchedAt": "2025-11-12T22:43:17.298Z",
    "content": "## Tachyon Account\n\n**Smart Contracts for Tachyon Account**\n\n### Build\n\n```shell\n$ forge build\n```\n"
  },
  "openlabelsinitiative/oli": {
    "fetchedAt": "2025-11-12T22:43:24.317Z",
    "content": "# Open Labels Initiative\n***A standardized framework and data model for address labeling.***\n\nUpcoming community calls can be found in our [Google Calendar](https://calendar.google.com/calendar/u/3?cid=MmQ0MzYxNzQ3ZGFiY2M3ZDJkZjk0NjZiYmY3MmNmZDUwZTNjMjE2OTQ4YzgyNmI4OTBmYjYyN2VmNGRjNjQ4OEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t)!\n\n## Goal\nThis initiative tackles the issue of isolated and non-standardized datasets of address labels within the blockchain community. It introduces a flexible, open and community owned framework for anyone to use and contribute to. \n\nBy aligning on a single framework for address labels, we avoid redundant work and make it easier to share datasets within the community.\n\nThe OLI repository functions as the community maintainer. Additionally, it serves as a neutral entity that provides tooling to get started.\n\n## The 3 Pillars of OLI Framework\n  - **1) Label Schema:** We should all speak the same language when it comes to labels. The first step is implementing a unified data model that enables seamless synchronization of labels across different databases and ensures alignment on value sets. More details in [Label Schema](/1_label_schema/README.md).\n  - **2) Label Pool:** Sharing labels in a decentralized manner is the next logical step. Using attestations, we've created a pool of raw labels that anyone can contribute to. By consolidating all labels in one place, both labellers and data teams can share their work, reducing redundant work. All attestations will remain permanently accessible, fostering a collaborative, community-driven labeling effort. More details in [Label Pool](/2_label_pool/README.md)\n  - **3) Label Trust:** Trust algorithms optimized for specific use cases are applied to the raw labels contributed to the Label Pool. In doing so, raw labels are transformed into valuable, use-case-specific labels‚Äîoptimized for analytics, security and beyond. More details coming soon in [Label Trust](/3_label_trust/README.md).\n\n![OLI pillars](src/images/oli_pillars.png)\n\nThe three pillars of OLI are designed to build on one another, like stacking Lego blocks. At the base lies the OLI Label Schema, providing the core structure. On top of that comes the Label Pool, which enables broad collaboration and sharing. Finally, the Label Trust layer builds on both to establish confidence and reliability. You don‚Äôt need to adopt all three pillars at once, start small and implement only what you need.\n\n<div align=\"center\">\n<img src=\"src/images/oli_lego.png\" alt=\"OLI pillars\" width=\"300\">\n</div>\n\n## Products Using OLI\n- [growthepie - Smart Contract Explorer](https://labels.growthepie.com/)\n- [growthepie - Applications Page](https://www.growthepie.com/applications/)\n- [Agnostic - Public Data Warehouse](https://agx.app/)\n- [Sourcify - Verified Contract Repository](https://repo.sourcify.dev/)\n- [Enscribe - Tool to Assign ENS to contracts](https://app.enscribe.xyz/)\n- ...\n- *please list your projects here*\n\n\n## Frequently Asked Questions (FAQ)\n\n<details>\n  <summary><strong>This sounds great, how can I get started / participate?</strong></summary>\n\n  Great to hear! To stay updated on the latest happenings, feel free to join our [monthly OLI calls](https://calendar.google.com/calendar/u/3?cid=MmQ0MzYxNzQ3ZGFiY2M3ZDJkZjk0NjZiYmY3MmNmZDUwZTNjMjE2OTQ4YzgyNmI4OTBmYjYyN2VmNGRjNjQ4OEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t). You can also start submitting labels through our [frontend](https://www.openlabelsinitiative.org/attest) or by using one of our [bulk attestation scripts](2_label_pool/tooling_write/). If you‚Äôre just interested in reading labels from the label pool, you can access them via a [GraphQL endpoints](2_label_pool/tooling_read/graphql_python).\n\n</details>\n\n<details>\n  <summary><strong>Who will submit labels to the OLI Label Pool?</strong></summary>\n\n  We identified three core user groups among label submitters, which primarily differ in the volume of labels they contribute.\n\n| Submitter                | Volume        | Description | Entry method\n  |------------------------|--------------------|-------------|------------\n  | **High-volume labelers** | High (1000+)       | Data teams & indexing companies that have automated and highly optimized scripts running to label a high number of smart contracts. | pip package or typescript script |\n  | **Casual labelers**      | Medium (5-1000)    | Individuals who have a set of labels they want to submit. Could be analysts collecting labels manually or dApp teams that deployed multiple contracts and want to share metadata. | OLI frontend end or pip package |\n  | **Single labelers**      | Low (1-5)         | Individuals submitting a very small amount of labels, usually smart contract deployers who want to make metadata on their smart contract available. | OLI front end |\n\n</details>\n\n<details>\n  <summary><strong>Why should I submit my labels to the OLI label pool?</strong></summary>\n\n  This is a public, open initiative designed to break down data silos and empower everyone with higher-quality labels. The more people who contribute, the higher the quality of the labels‚Äîand the more possibilities they unlock.\n\n  While OLI itself will not sponsor participants, we aim to maintain complete transparency about the number of labels contributed by different teams and individuals. This transparency can serve as a qualifying factor for public goods funding rounds such as Gitcoin, Optimism Retro Funding, Octant, and many more.\n\n</details>\n\n<details>\n  <summary><strong>Why do you use attestations for data entry / label submission?</strong></summary>\n\n  Attestations are a powerful tool for standardizing data entry while cryptographically verifying who submitted each label. This enables anyone to build robust trust algorithms that boost confidence in the submitted labels.\n\n</details>\n\n<details>\n  <summary><strong>Can every label in the label pool be blindly trusted?</strong></summary>\n\n  No. Currently, these labels are raw and haven't undergone any additional trust verification. A straightforward trust layer involves relying solely on labels submitted by verified, whitelisted entities ‚Äî a process made easy since every label is associated with an attestation. Looking ahead, we plan to develop trust algorithms tailored to specific use cases. All future tools related to this will be made available [here](3_label_trust).\n\n</details>\n\n<details>\n  <summary><strong>I want to submit metadata, but I couldn't find a fitting tag in the data model. What should I do?</strong></summary>\n\n  Great! Simply open a pull request to our [tag_definitions.yml](1_label_schema/tags/tag_definitions.yml) file in this repository and include an explanation for why this tag should be added to OLI. We'll periodically review all new tags and incorporate them into the schema.\n\n</details>\n\n<details>\n  <summary><strong>How can I access the labels in the OLI Label Pool?</strong></summary>\n\n  There are multiple ways to access all labels in the OLI Label Pool, please see [tooling documentation](2_label_pool/README.md).\n\n</details>\n\n## Contributors\n- [growthepie](https://www.growthepie.xyz/): Ethereum & Layer 2 analytics platform with focus on labeling smart contracts in terms of their usage and project owners.\n\n<img src=\"https://i.ibb.co/54W8j8K/Group-165.png\" alt=\"growthepie logo\" width=\"300\">\n\n### Sponsors\n\nThe [Ethereum Foundation](https://ethereum.foundation/) funded this effort as part of the [Data Collection Grants](https://esp.ethereum.foundation/data-collection-grants). This standardized data structure was part of their [wish list](https://notes.ethereum.org/@drigolvc/DataCollectionWishlist) and other foundations and data teams also expressed interest in the past.\n\n### Other Supporters\nIndividuals or data teams that are involved in active feedback for this initiative and/or opened up their labeled databases.\n\n- [walletlabels](https://www.walletlabels.xyz/): Wallet labeling platform with focus on labels for Ethereum as well as social labels / labeling of\n\n[... truncated ...]"
  },
  "openlabelsinitiative/oli-frontend": {
    "fetchedAt": "2025-11-12T22:43:24.756Z",
    "content": "# Open Labels Initiative (OLI)\n\nA Next.js application providing a user interface for the Open Labels Initiative - a standardized framework and data model for EVM address labeling.\n\n## About the Project\n\nOpen Labels Initiative (OLI) is built on three core pillars:\n\n1. **Data Model** - A standardized framework for blockchain address labeling that ensures consistency across different databases.\n2. **Label Pool** - A publicly accessible database of attested labels, collected through blockchain attestations.\n3. **Label Confidence** - Trust algorithms applied to raw labels, optimized for various use cases like analytics and security.\n\n## Features\n\n- **Search** - Find and explore detailed information about EVM addresses\n- **Attest** - Contribute to the ecosystem by creating attestations for blockchain addresses\n- **Analytics** - View statistics, leaderboards of attestors, and explore attestation distribution\n\n\n## Technology Stack\n\n- **Frontend**: Next.js 15, React 19, TailwindCSS 3\n- **State Management**: React Hooks\n- **GraphQL**: Apollo Client for data fetching\n- **Blockchain Integration**: Ethereum Attestation Service (EAS) SDK, ethers.js\n- **UI Components**: Recharts for data visualization, Headless UI for accessible components\n- **Styling**: TailwindCSS with custom gradients\n\n## Getting Started\n\n### Prerequisites\n\n- Node.js (v18 or later)\n- NPM or Yarn\n- MetaMask or compatible Ethereum wallet for creating attestations\n\n### Installation\n\n1. Clone the repository\n   ```\n   git clone https://github.com/openlabelsinitiative/oli.git\n   cd oli\n   ```\n\n2. Install dependencies\n   ```\n   npm install\n   # or\n   yarn install\n   ```\n\n\n3. Run the development server\n   ```\n   npm run dev\n   # or\n   yarn dev\n   ```\n\n4. Open [http://localhost:3000](http://localhost:3000) in your browser\n\n## Project Structure\n\n- `/src/app`: Next.js app directory structure containing pages\n- `/src/components`: Reusable React components\n- `/src/services`: API services and data fetching logic\n- `/src/constants`: Project constants and configuration\n- `/src/lib`: Utility functions and shared libraries\n\n## Key Components\n\n- **AttestationForm**: Form for creating new address attestations\n- **SearchTab**: Interface for searching and exploring address labels\n- **LeaderboardTable**: Displays top attestors in the ecosystem\n- **LatestAttestations**: Shows recent attestation activity\n\n## Blockchain Integration\n\nThe application integrates with the Ethereum Attestation Service (EAS) on Base network and optionaly Arbitrum. Attestations use a standardized schema with the UID:\n```\n0xb763e62d940bed6f527dd82418e146a904e62a297b8fa765c9b3e1f0bc6fdd68\n```\n\n### Arbitrum Orbit Chains Integration\n\nOLI automatically syncs and supports all mainnet Arbitrum Orbit chains. The system:\n- Fetches chain data monthly from the [Arbitrum Portal API](https://portal-data.arbitrum.io/__auto-generated-orbitChains.json)\n\n**Quick Setup:**\n```bash\n# Fetch Orbit chains for the first time\nnpm run sync-orbit-chains\n```\n\n## Contributing\n\nContributions are welcome! Please check out our community calls and join the ecosystem.\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add some amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## Community\n\n- Join our [community calls](https://calendar.google.com/calendar/u/3?cid=MmQ0MzYxNzQ3ZGFiY2M3ZDJkZjk0NjZiYmY3MmNmZDUwZTNjMjE2OTQ4YzgyNmI4OTBmYjYyN2VmNGRjNjQ4OEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t)\n- Follow us on [Twitter](https://x.com/open_labels)\n- Check out our main [GitHub repository](https://github.com/openlabelsinitiative/OLI)\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Products Using OLI\n\n- [Enscribe](https://app.enscribe.xyz/) - Tool to Assign ENS to contracts\n- [growthepie Labels](https://labels.growthepie.com/) - Label explorer and analytics platform\n- [growthepie Applications](https://www.growthepie.com/applications/) - L2 analytics platform\n- [AGX](https://agx.app/) - Blockchain analytics platform\n- [Sourcify](https://repo.sourcify.dev/) - Contract verification service\n\n## Supporters\n\n- Ethereum Foundation\n- growthepie"
  },
  "metacraft-labs/codetracer": {
    "fetchedAt": "2025-11-12T22:43:31.860Z",
    "content": "[![CI Status](https://github.com/metacraft-labs/codetracer/actions/workflows/codetracer.yml/badge.svg?branch=main)](https://github.com/metacraft-labs/codetracer/actions/workflows/codetracer.yml)\n[![Discord](https://img.shields.io/discord/1326949714679038014?label=Discord&logo=discord&style=flat)](https://discord.gg/aH5WTMnKHT)\n\nAvailable downloads:\n\n<a href=\"https://deb.codetracer.com/\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/9e/UbuntuCoF.svg\"></a>\n<a href=\"https://deb.codetracer.com/\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/6/66/Openlogo-debianV2.svg\"></a>\n<a href=\"https://rpm.codetracer.com/\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/d8/Red_Hat_logo.svg\"></a>\n<a href=\"https://rpm.codetracer.com/\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/3f/Fedora_logo.svg\"></a>\n<a href=\"https://github.com/metacraft-labs/metacraft-overlay\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/4/48/Gentoo_Linux_logo_matte.svg\"></a>\n<a href=\"https://aur.archlinux.org/packages/codetracer\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/1/13/Arch_Linux_%22Crystal%22_icon.svg\"></a>\n<a href=\"https://downloads.codetracer.com/CodeTracer-latest-amd64.AppImage\"><img width=\"100px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/73/App-image-logo.svg\"></a>\n<a href=\"https://downloads.codetracer.com/CodeTracer-latest-arm64.dmg\"><img width=\"75px\" height=\"100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/1/1b/Apple_logo_grey.svg\"></a>\n\nKey signatures:\n\n[![Download macOS Signature](https://img.shields.io/badge/Download-macOS%20Signature-blue?style=for-the-badge)](https://downloads.codetracer.com/CodeTracer-latest-arm64.dmg.asc)\n[![Download AppImage Signature](https://img.shields.io/badge/Download-AppImage%20Signature-blue?style=for-the-badge)](https://downloads.codetracer.com/CodeTracer-latest-amd64.AppImage.asc)\n[![Download PGP Key](https://img.shields.io/badge/Download-PGP%20key-blue?style=for-the-badge)](https://downloads.codetracer.com/CodeTracer.pub.asc)\n\n> [!TIP]\n> You can place the downloaded app in a location of your choosing (e.g., the `Applications` folder on macOS or `~/.local/bin` on Linux).\n>\n> When you launch CodeTracer for the first time, it will prompt you to complete the remaining installation steps, such as adding the command-line utilities to your PATH.\n\n> [!CAUTION]\n> Upon the first launch, macOS users will see the error message \"CodeTracer is damaged and can't be opened\". To resolve this problem, please execute the command `user $ xattr -c <path/to/CodeTracer.app>`.\n>\n> We expect this inconvenience will be remedied soon through our enrollment in the Apple Developer program which will ensure CodeTracer is properly signed and whitelisted by Apple.\n> See [this discussion](https://discussions.apple.com/thread/253714860?sortBy=rank) for more details.\n\n> [!CAUTION]\n> Recording ruby on macOS requires you to install ruby through [homebrew](https://brew.sh), otherwise trying to record ruby programs will fail due to the built-in ruby binary on macOS being more than 7 years old.\n>\n> Once homebrew is installed, simply install ruby with `user $ brew install ruby`.\n\n# Introduction\n\nCodeTracer is a user-friendly time-traveling debugger designed to support a wide range of programming languages.\n\nIt records the execution of a program into a sharable self-contained trace file. You can load the produced trace files in a GUI environment that allows you to move forward and backward through the execution and to examine the history of all memory locations. They say a picture is worth a thousand words ‚Äî well, a video is even better! Watch the demo below to see CodeTracer in action:\n\n  [![Watch the video](https://img.youtube.com/vi/xZsJ55JVqmU/maxresdefault.jpg)](https://www.youtube.com/watch?v=xZsJ55JVqmU)\n\n## The Benefits of Time-Travel\n\nCompared to traditional debuggers, CodeTracer gives you two major superpowers:\n\n* **Once you capture a bug in a recording, consider it squashed!**\n\n  Bugs that are hard to reproduce can be painful to fix ‚Äî you‚Äôve surely been there. Once such a bug is captured with CodeTracer, you'll rarely need more than 30 minutes to track it down! This is largely a consequence of the next superpower:\n\n* **Most bugs are easily revealed when you know the origin of any value in the program.**\n\n  All programs produce output. Some examples are bytes generated as a response to a web request, pixels being drawn on your screen or perhaps a simple log line written to the terminal.\n\n  When CodeTracer creates a recording, it captures a user-extensible set of output events relevant to the program. The GUI displays these events in a searchable chronological event log.\n\n  Consider a misbehaving program that prints unexpected output to a log file midway through its execution. Clicking on the specific output event in CodeTracer will take you to the precise moment and code line where it was generated.\n\n  The unexpected value must be originating from some variable that's being passed to the logging function. With CodeTracer, you can now ask the question \"Where did this value come from?\". CodeTracer will find another moment in the execution, potentially multiple seconds earlier, in a completely different part of the program where this particular memory location was last written to.\n\n  This could be memory corruption or a genuine logical error. Either way, CodeTracer will report the origin. Let's say that you end up in the correct function that is responsible for computing the problematic value, but another input there leads to the issue. You can continue the search by repeating the question \"Where did this input come from\"? It usually takes just a few of these jumps to earlier moments in time to arrive at the root cause for the bug.\n\n  Every time you jump to a new moment in the execution, you can fearlessly explore your surroundings by stepping forward or backwards, having access to a back button that can always get you to any previous point of interest. At every point of the journey, our novel UI shows you details about the past and future program states at a glance and you know your position in the precisely recorded call trace of the program.\n\n  These features combined, make for a truly powerful debugging experience.\n\n## Current state of the project and 2025 roadmap\n\nThe initial release of CodeTracer supports the Noir programming language. It has been developed in collaboration with the Blocksense team and currently requires the use of the [Blocksense Noir Compiler](https://github.com/blocksense-network/noir), which is included in the CodeTracer distribution.\n\nCodeTracer‚Äôs open-source development is made possible by the generous support of Aztec Network, Arbitrum Foundation, and Aptos Foundation. During 2025, CodeTracer will evolve into a comprehensive Web3 development toolkit by gaining support for many additional smart contract and zero-knowledge programming languages. Most of its functionality will be packaged into reusable libraries that will power the creation of block explorers with advanced transaction tracing capabilities and omniscient debugging plugins for Visual Studio Code and other IDEs.\n\nCodeTracer uses an [open format](https://github.com/metacraft-labs/runtime_tracing) for its trace files and we've started several community-driven projects which aim to add support for other programming languages:\n\n* [Ruby](https://github.com/metacraft-labs/codetracer-ruby-recorder)\n* [Python](https://github.com/metacraft-labs/codetracer-python-recorder)\n\nMetacraft Labs is also developing an alternative back-end, capable of working with [RR](https://rr-project.org/) recordings, which will make CodeTracer suitable for debugging large-scale programs in a variety of system programming languages such as C\n\n[... truncated ...]"
  },
  "apoorvlathey/evm-rpcs-list": {
    "fetchedAt": "2025-11-12T22:43:38.788Z",
    "content": "# evm-rpcs-list\n\nList of EVM chains & their RPCs in one place. Sourced from chainlist.org.\n\n## Installation\n\n`yarn add evm-rpcs-list` or `npm i evm-rpcs-list`\n\n## Usage\n\n```\nimport networksList from \"evm-rpcs-list\";\n```\n\n## Project Setup\n\n- Clone this repo with the submodules\n\n```\ngit clone --recurse-submodules\n```\n\n- Install packages\n\n```\npnpm i\n```\n\n- Install packages for the submodule\n\n```\ncd lib/chainlist\nyarn\ncd ../..\n```\n\n- Build the package (in /dist)\n\n```\npnpm run buildAll\n```\n"
  },
  "EIPTools/eip-tools": {
    "fetchedAt": "2025-11-12T22:43:46.360Z",
    "content": "# eip.tools\n"
  },
  "swiss-knife-xyz/forge-stack-tracer": {
    "fetchedAt": "2025-11-12T22:43:54.042Z",
    "content": "# forge-stack-tracer\n\nCLI tool that converts your Foundry test output into interactive stack traces!\n\n‚ú® Powered by [Swiss-Knife.xyz Calldata Decoder](https://calldata.swiss-knife.xyz/decoder) to decode even the unverified contracts!\n\n## Installation\n\n```\nnpm i -g forge-stack-tracer\n```\n\n## Usage\n\nSimply pipe the forge tests result into `fst`.\n\n```\nforge test --mt test_case -vvvv | fst\n```\n\n![output screenshot](./github-assets/output.png)\n\nTo delete the `./out/_fst` folder, run:\n\n```\nfst clean\n```\n\n## Output\n\nThe package generates a static html file in your current foundry project, at: `./out/_fst/fst-{timestamp}.html`\n\n## Options\n\nYou can also pass an extra argument to specify the output html file name & path:\n\n```\nforge test --mt test_case -vvvv | fst temp/fst.html\n```\n\n## Development\n\n### Install Dependencies\n\n```\npnpm i\n```\n\n### Overview\n\n1. `./src/` contains the react code, which gets compiled into a single html file: `dist/index.html`.\n2. This html file acts as a template.\n3. `src/bin/index.ts` script allows to use this template and generate new static html files for any given foundry tests output.\n\n### Running locally\n\n1. `pnpm run build` to build into `dist` folder\n2. Install the package locally: `npm install -g .`\n3. Make the script executeable: `chmod +x dist/index.js` (have to do it each time after build)\n"
  },
  "swiss-knife-xyz/swiss-knife": {
    "fetchedAt": "2025-11-12T22:44:01.579Z",
    "content": "<img alt=\"Swiss Knife Logo\" src=\".github/logo.png\" />\n\nAll your EVM tools in one place: https://swiss-knife.xyz/\n\n## List of Tools\n\n1. [Explorer](https://explorer.swiss-knife.xyz/): Quickly view any address/ens or transaction across a variety explorers, in just a click!\n2. [Calldata](https://calldata.swiss-knife.xyz/decoder): Decode any calldata, and view the parameters in a human-readable format, even without having the contract ABI.\n3. [Transact](https://transact.swiss-knife.xyz/send-tx): Send custom bytes calldata to transact with any contract, or leave the address blank to deploy a new contract.\n4. [Converter](https://converter.swiss-knife.xyz/eth): All the essential unit converters on one-page. Convert between:\n   1. Ether, wei & gwei\n   2. Hexadecimal, decimal & binary\n   3. String or hex to keccack256 hash & 4 bytes selector\n   4. Hex to 32 bytes left-padded & right-padded values\n5. [Constants](https://constants.swiss-knife.xyz/): Have frequently used constants at your fingertips, like Zero Address, Max Uint256, etc.\n6. [Epoch-Converter](https://epoch-converter.swiss-knife.xyz/): Grab unix timestamp, get timestamp `x` minutes/hours/days in the future, or convert timestamp to human-readable format.\n7. [Storage-Slots](https://storage-slots.swiss-knife.xyz/): Query EIP-1967 slots or custom storage slot value of any contract.\n8. [Uniswap](https://uniswap.swiss-knife.xyz/tick-to-price): Calculator to convert UniswapV3 tick to price for any token pair addresses.\n9. [Character Counter](https://character-counter.swiss-knife.xyz/): Count the length of the input string. Also allows to select on the input text to only get the character count for the selection.\n10. [Contract Address](https://contract-address.swiss-knife.xyz/): Determine the contract address which will get deployed by an address at a particular nonce\n\n## Setup\n\n1. This repository is a Nextjs 14 project. To run it locally, clone the repo and run the following commands:\n   ```bash\n   pnpm i\n   ```\n2. Copy `.example.env.local` to `.env.local` and fill in the required values.\n3. Run the dev server:\n   ```bash\n   pnpm dev\n   ```\n   Visit http://localhost:3000 to view the app.\n\n## Contributing\n\n### To add a new Explorer\n\n1. For an address explorer, modify [./data/addressExplorers.ts](./data/addressExplorers.ts)\n2. For a transaction explorer, modify [./data/txExplorers.ts](./data/txExplorers.ts)\n"
  },
  "impersonator-eth/impersonator": {
    "fetchedAt": "2025-11-12T22:44:10.143Z",
    "content": "# üé≠ Impersonator üïµÔ∏è‚Äç‚ôÇÔ∏è\n\n### Login into DApps by impersonating any Ethereum address via WalletConnect! <br />\n\n<hr />\n\n## Website:\n\n**[https://www.impersonator.xyz/](https://www.impersonator.xyz/)**\n\n## Screenshots:\n\n![demo-by-address](./.github/demo-address-connected.png)\n\n(PS: Users won't be able to transact (obviously) as no private keys are being used here)\n\n## Local Installation\n\n1. Install required packages <br/>\n   `yarn install`\n\n2. Start local development server <br />\n   `yarn start`\n\n3. Build react project <br />\n   `yarn build`\n"
  },
  "impersonator-eth/impersonator-extension": {
    "fetchedAt": "2025-11-12T22:44:10.581Z",
    "content": "# Impersonator Extension\n\n<i><b>Log-in as ANY address on ALL dapps.</b></i><br />\n<br />\nImpersonator injects into the dapps just like Metamask, but gives you the freedom to set custom address which tricks the dapp into thinking you own that address.\n\n## How to Install\n\n<ol>\n  <li>\n    Download extension from the <a href=\"https://chrome.google.com/webstore/detail/impersonator/hgihfkmoibhccfdohjdbklmmcknjjmgl\">Chrome Web Store</a>\n  </li>\n\n  <li> \n    <b>NOTE:</b> Extension should not be installed along with Metamask, here are 3 different ways to avoid it:<br/>\n    <ol type=\"a\">\n      <li>\n        Create a new browser profile <br />\n        <img src=\"./.github/installation/browser-profile.png\" width=\"300rem\"/>\n      </li>\n      <li>\n        OR disable Metamask when using Impersonator <br />\n        <img src=\"./.github/installation/disable-mm.png\" width=\"300rem\" />\n      </li>\n      <li>\n        OR use a different browser.\n      </li>\n    </ol>\n  </li>\n</ol>\n\n## Using the Extension\n\n1. Click on üïµÔ∏è icon in the extensions bar to open Impersonator popup <br />\n   <img src=\"./.github/usage/popup.png\" width=\"300rem\" />\n2. Open settings -> \"Add Chain\" button<br />\n   Fill Chain Name, Paste RPC URL and the Chain Id would get auto filled. Press \"Add Chain\". <br />\n   <img src=\"./.github/usage/add-chain.png\" width=\"300rem\" />\n3. You can view all the saved chains in the Settings tab <br />\n   <img src=\"./.github/usage/chains.png\" width=\"300rem\" />\n4. Clicking on any of the chains would open up the Edit page. You can modify or delete the chain. <br />\n   <img src=\"./.github/usage/edit-chain.png\" width=\"300rem\" />\n5. On the homepage, you can enter address or ENS. Select preferred network and set the Enabled toggle. <br />\n   <img src=\"./.github/usage/homepage.png\" width=\"300rem\" />\n6. You can now open any dapp and connect wallet as Metamask. The dapp would detect your custom address and network.\n\n<br />\n‚≠ê Unique feature that differentiates it from other wallets: <b>You can have different address & chain injected in different browser tabs at the same time! </b><br /><br />\nSo in one tab you might have Uniswap connected to <code>Polygon</code> with <code>apoorv.eth</code> and in another one you can have Sushiswap connected to <code>Ethereum Mainnet</code> with <code>vitalik.eth</code>\n"
  },
  "Diffuse-fi/datafeed-cli": {
    "fetchedAt": "2025-11-12T22:44:17.992Z",
    "content": "# Data Feed CLI\n\n## Overview\nThis repository provides a CLI for Diffuse Data Feeds powered by zk Serverless. In its current state, the on-chain endpoints provide the latest information about the Price Pairs from CEXs and DEXs. The product is currently in the testnet phase, and Binance is used as a data provider.\n\n---\nReach out for any collaboration. We are constantly growing the number of chains and the list of supported data. If you need fast and trustless Data Feeds of your favourite token on your favourite chain - you know what to do:\n\n[![X (formerly Twitter) URL](https://img.shields.io/twitter/follow/diffusefi)](https://x.com/diffusefi)\n\n---\n\n## Instruction\n1. Clone repo:\n```\ngit clone https://github.com/Diffuse-fi/datafeed-cli\ncd ¬¥datafeed-cli¬¥\ngit submodule update --init --recursive\n```\n\n2. Go to `zktls-enclave` and build the enclave according to the readme file. If all prerequisites are installed then it will look like this:\n```\ncd lib/zktls-enclave\ncargo sgx build\ncd -\n```\n\n3. Go to the CLI directory for Bonsai and build it. If all prerequisites are installed then it will look like this:\n```\ncd lib/automata-dcap-zkvm-cli/dcap-bonsai-cli/\ncargo build --release\ncd -\n```\n\n4. (optional) If you want to work on the local node, launch `anvil`:\n```\nanvil\n```\nand switch to another tab\n\n5. (optional) Go to cd `lib/sgx_verifier_deployer/` and deploy on-chain infrastructure or update collaterals. This is also needed if you are working on a fresh local node.\n\n6. export current location to `PYTHONPATH`:\n```\nexport PYTHONPATH=\"$(pwd):$PYTHONPATH\"\n```\n\n7. Create an `.env` file and write all needed env variables listed in `.env.example`. Then source the env variables:\n```\nsource .env\n```\n\n8. There is a CLI for interactions with the deployed endpoint.\n\nThere are three contracts: proxy, feeder and storage.\nStorage contract stores price data, every pair has its own storage. Only owner can upload data to storages.\nFeeder contract owns all storage contracts. It receives proofs, verifies them and uploads data to storages after verification. It guarantees that only proven data is stored in storage contracts.\nProxy contract contains list of all pairs and storage addresses. It has predetermined address on all chains because CREATE2 insrtuction is used for deployment. Deployed only once.\n\n\nDeploy (example for the local network):\nFor the first time you will need to deploy proxy, skip this step if you are redeploying feeder:\n```\npython3 cli/delpoy_proxy.py -n local\n```\nthen deploy feeder:\n```\npython3 cli/delpoy_feeder.py -n local\n```\n\nParse price data (example for the local network, off-chain verification and proving with bonsai):\n```\npython3 cli/parse_and_prove.py -n local --binance-zk-bonsai\n```\n\nPublish data on chain (example for the local network using zk proof from zkVM):\n```\npython3 cli/feed_feeder.py -n local --zk\n```\n\nRequest data from chain (example for requesting latest round data for BTCUSDT from local network):\n```\npython3 cli/request_storage.py -n local -p BTCUSDT -m latestRoundData\n```\n\n## How to add new pairs\nPairs are listed in `pairs/list.txt`, please use `cli/add_new_pair.py` to add new pairs, it checks if pair was already added and is listed on binance.\n"
  },
  "BuidlGuidl/abi.ninja": {
    "fetchedAt": "2025-11-12T22:44:25.484Z",
    "content": "# ABI Ninja\n\nInteract with smart contracts on any EVM chain. ABI Ninja provides an intuitive frontend for contracts from most popular EVM networks, currently supporting:\n\n- **Verified contracts**. Fetches contract ABIs and source code directly using [Etherscan's API v2 endpoints](https://docs.etherscan.io/etherscan-v2/getting-started/v2-quickstart).\n- **Unverified contracts**. Two different options are available:\n  - Decompile using [`heimdall-rs`](https://github.com/Jon-Becker/heimdall-rs) (experimental).\n  - Provide the ABI and the contract address.\n- **Proxy contracts**. Autodetects most popular proxy patterns, and allows to read and write as proxy.\n\nABI Ninja (v2) is built with üèó [Scaffold-ETH 2](https://github.com/scaffold-eth/scaffold-eth-2).\n\n|                                                     Homepage                                                      |                                                   Unverified Contract Options                                                   |\n| :---------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------: |\n| ![ABINinja - Index](https://github.com/BuidlGuidl/abi.ninja/assets/55535804/3b7e0f12-1423-4835-bda3-2e12d65b4f15) | ![ABINinja - Unverified Contract](https://github.com/BuidlGuidl/abi.ninja/assets/55535804/d30d76a3-35d0-4b3f-8633-c8e531999be6) |\n\n### Features included:\n\n- **Customize your chains.** We provide a default list of chains (Mainnets + Testnets), but you can add or remove networks from a large selection using the \"Other Chains\" option in the network dropdown.\n- **Add custom chains.** If you can't find a network using the \"Other Chains\" option, you can manually add custom chains by entering the network details.\n- **Use it on localhost!** Run ABI Ninja on chain ID 31337 (localhost) to debug your local contracts.\n- **ENS resolution on address inputs.** Automatically resolves ENS names (Mainnet).\n- **Shareable URLs with dynamic unfurling.** Share an ABI Ninja contract URL, and it will unfurl with the contract name, network icon and address.\n- **Transaction results display.** View detailed transaction results directly in the interface after executing contract calls, making debugging and monitoring easier.\n\n- **Friendly UI even for the most complex data structures:**\n\n  ![ABINinja - Contract UI](https://github.com/BuidlGuidl/abi.ninja/assets/55535804/7b3ec72b-c70b-4357-9f76-d10cb673530c)\n\n# üèÑ‚Äç‚ôÇÔ∏è Development Quick Start\n\nBefore you begin, you need to install the following tools:\n\n- [Node (v18 LTS)](https://nodejs.org/en/download/)\n- Yarn ([v1](https://classic.yarnpkg.com/en/docs/install/) or [v2+](https://yarnpkg.com/getting-started/install))\n- [Git](https://git-scm.com/downloads)\n\n1. Clone this repo & install dependencies\n\n```\ngit clone https://github.com/BuidlGuidl/abi.ninja.git\ncd abi.ninja\nyarn install\n```\n\n2. Start the frontend\n\n```\nyarn start\n```\n\nVisit your local instance of ABI Ninja at: `http://localhost:3000`.\n\n# üß™ Testing\n\nABI Ninja uses Cypress for end-to-end testing. Our test suite covers user flows and ensures the application works correctly across different networks and contract types. The test suite will automatically run on pull requests.\n\n## Running Tests\n\nTo run the Cypress tests:\n\n1. Ensure your development server is running:\n\n```\nyarn start\n```\n\n2. In a new terminal window, run the Cypress tests:\n\n```\nyarn cypress:open\n```\n\nThis will open the Cypress Test Runner, where you can run individual tests or the entire suite.\n\n3. For headless testing, use:\n\n```\nyarn cypress:run\n```\n\n## Test Coverage\n\nOur tests cover the following key areas:\n\n- Loading and interacting with verified contracts on various networks\n- Handling unverified contracts and manual ABI input\n- Detecting and interacting with proxy contracts\n- Network switching and custom network addition\n\n## Writing New Tests\n\nWhen adding new features or modifying existing ones, please update or add corresponding tests. Test files are located in the `cypress/e2e` directory.\n\nFor more information on writing Cypress tests, refer to the Cypress Documentation.\n\n## Contributing to ABI Ninja\n\nWe welcome contributions to ABI Ninja!\n\nPlease see [CONTRIBUTING.MD](https://github.com/BuidlGuidl/abi.ninja/blob/main/CONTRIBUTING.md) for more information and guidelines for contributing to ABI Ninja.\n"
  },
  "probe-lab/website": {
    "fetchedAt": "2025-11-12T22:44:34.971Z",
    "content": "# [probelab.io](https://probelab.io) website\n\n## Install Hugo\n\nVersion `v0.85.0` is used by our Netlify deployment container. Therefore, run:\n\n```shell\nCGO_ENABLED=1 go install -tags extended github.com/gohugoio/hugo@v0.85.0\n```\n\nVerify installation\n\n```shell\nhugo version\n```\n\n## New Blog Post\n\n1. Copy one of the existing Markdown files in `content.en/blog/` and rename it to your liking. Make sure to prefix it with the rough date.\n2. Remove all the content and only edit the frontmatter\n   ```yml\n   ---\n   title: \"Introducing Probelab\"   # the fat title at the top\n   date: 2024-01-11T12:33:50+01:00 # relevant for ordering\n   slug: introducing-probelab      # this will become the path component \n   ---\n   ```\n\nThe list of blog posts at `https://probelab.io/blog/` will automatically be updated to also include the new post. \n"
  },
  "dennis-tra/nebula": {
    "fetchedAt": "2025-11-12T22:44:35.312Z",
    "content": "![Nebula Logo](./docs/nebula-logo.svg)\n\n# Nebula\n\n[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg)](https://github.com/RichardLitt/standard-readme)\n[![go test](https://github.com/dennis-tra/nebula/actions/workflows/pull_request_main.yml/badge.svg)](https://github.com/dennis-tra/nebula/actions/workflows/pull_request_main.yml)\n[![readme nebula](https://img.shields.io/badge/readme-Nebula-blueviolet)](README.md)\n[![GitHub license](https://img.shields.io/github/license/dennis-tra/nebula)](https://github.com/dennis-tra/nebula/blob/main/LICENSE)\n[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fdennis-tra%2Fnebula&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)\n\nA network agnostic peer crawler and monitor. Nebula starts with a set of bootstrap peers, \nasks them for other peers in the network and recursively repeats the process until all\npeers in the network have been contacted. Originally, Nebula only supported DHT\nnetworks, but this restriction was lifted.\n\nCurrently, Nebula supports the following networks:\n\n- [IPFS](https://ipfs.network) - [_Amino DHT_](https://blog.ipfs.tech/2023-09-amino-refactoring/)\n- [Bitcoin](https://bitcoin.org/) | [Litecoin](https://litecoin.org/) | [Dogecoin](https://dogecoin.com/) (alpha)\n- [Ethereum](https://ethereum.org/en/) - [_Consensus Layer (discv5)_](https://ethereum.org/uz/developers/docs/networking-layer/#consensus-discovery) | [_Execution Layer (discv4)_](https://ethereum.org/uz/developers/docs/networking-layer/#discovery)\n- [Optimism](https://www.optimism.io/) compatible chains\n- [Portal](https://www.portal.network/) - (_alpha - [wire protocol](https://github.com/ethereum/portal-network-specs/blob/master/portal-wire-protocol.md) not implemented_)\n- [Filecoin](https://filecoin.io)\n- [Polkadot](https://polkadot.network/) - [_Kusama_](https://kusama.network/) | [_Rococo_](https://substrate.io/developers/rococo-network/) | [_Westend_](https://wiki.polkadot.network/docs/maintain-networks#westend-test-network)\n- [Avail](https://www.availproject.org/) - [_Mainnet_](https://docs.availproject.org/docs/networks#mainnet) | [_Turing_](https://docs.availproject.org/docs/networks#turing-testnet) | _<small>Light Client + Full Node versions</small>_\n- [Celestia](https://celestia.org/) - [_Mainnet_](https://blog.celestia.org/celestia-mainnet-is-live/) | [_Mocha_](https://docs.celestia.org/nodes/mocha-testnet) | [_Arabica_](https://github.com/celestiaorg/celestia-node/blob/9c0a5fb0626ada6e6cdb8bcd816d01a3aa5043ad/nodebuilder/p2p/bootstrap.go#L40)\n- [Pactus](https://pactus.org)\n- [Dria](https://dria.co/)\n- [Gnosis](https://www.gnosis.io/)\n- ... your network? Get in touch [team@probelab.io](team@probelab.io).\n\nYou can run `nebula networks` to get a list of all supported networks\n\nNebula supports the following storage backends: JSON, Postgres, ClickHouse\n\n\nThe crawler was:\n\n- üèÜ _awarded a prize in the [DI2F Workshop hackathon](https://research.protocol.ai/blog/2021/decentralising-the-internet-with-ipfs-and-filecoin-di2f-a-report-from-the-trenches/)._ üèÜ\n- üéì _used for the ACM SigCOMM'22 paper [Design and Evaluation of IPFS: A Storage Layer for the Decentralized Web](https://research.protocol.ai/publications/design-and-evaluation-of-ipfs-a-storage-layer-for-the-decentralized-web/trautwein2022.pdf)_ üéì\n\nNebula powers:\n\n- üìä _the weekly reports for the IPFS Amino DHT [here](https://github.com/probe-lab/network-measurements/tree/main/reports)!_ üìä\n- üåê _many graphs on [probelab.io](https://probelab.io) for most of the supported networks above_ üåê\n\nYou can find a demo on YouTube: [Nebula: A Network Agnostic DHT Crawler](https://www.youtube.com/watch?v=QDgvCBDqNMc) üì∫\n\n![Screenshot from a Grafana dashboard](./docs/grafana-screenshot.png)\n\n<small>_Grafana Dashboard is not part of this repository_</small>\n\n## Table of Contents\n\n- [Table of Contents](#table-of-contents)\n- [Project Status](#project-status)\n- [Usage](#usage)\n- [Install](#install)\n  - [From source](#from-source)\n- [How does it work?](#how-does-it-work)\n  - [`crawl`](#crawl)\n  - [`monitor`](#monitor)\n  - [`resolve`](#resolve)\n- [Development](#development)\n  - [Database](#database)\n  - [Tests](#tests)\n- [Report](#report)\n- [Related Efforts](#related-efforts)\n- [Demo](#demo)\n- [Maintainers](#maintainers)\n- [Contributing](#contributing)\n- [Support](#support)\n- [Other Projects](#other-projects)\n- [License](#license)\n\n## Project Status\n\nThe crawler is powering critical [IPFS](https://ipfs.tech) [Amino DHT](https://blog.ipfs.tech/2023-09-amino-refactoring/) [KPIs](https://de.wikipedia.org/wiki/Key-Performance-Indicator), used for [Weekly IPFS Reports](https://github.com/probe-lab/network-measurements/tree/main/reports) as well as for many metrics on [`probelab.io`](https://probelab.io).\nThe `main` branch will contain the latest changes and should not be considered stable. The latest stable release that is production ready is version [2.4.0](https://github.com/dennis-tra/nebula/releases/tag/2.4.0).\n\n## Install\n\n### Precompile Binaries\n\nHead over to the release section and download binaries from the [latest stable release](https://github.com/dennis-tra/nebula/releases).\n\n### From source\n\n```shell\ngit clone https://github.com/dennis-tra/nebula\ncd nebula\njust build\n```\n\nNow you should find the `nebula` executable in the `dist` subfolder.\n\n## Usage\n\nNebula is a command line tool and provides the `crawl` sub-command.\n\n### Dry-Run\n\nTo simply crawl the IPFS Amino DHT network run:\n\n```shell\nnebula --dry-run crawl\n```\n\n> [!NOTE]\n> For backwards compatibility reasons IPFS is the default if no network is specified\n\nThe crawler can store its results as JSON documents, in a [Postgres](https://www.postgresql.org/), or in a [Clickhouse](https://clickhouse.com/) database -\nthe `--dry-run` flag prevents it from doing any of it. Nebula will just print a\nsummary of the crawl at the end instead. For the IPFS network, a crawl takes ~5-10 min depending on\nyour internet connection. You can also specify the network you want to crawl by\nappending, e.g., `--network FILECOIN` and limit the number of peers to crawl by\nproviding the `--limit` flag with the value of, e.g., `1000`. Example:\n\n```shell\nnebula --dry-run crawl --network FILECOIN --limit 1000\n```\n\nTo find out which other network values are supported, you can run:\n\n```shell\nnebula networks\n```\n\n### JSON Output\n\nTo store crawl results as JSON files provide the `--json-out` command line flag like so:\n\n```shell\nnebula --json-out ./results/ crawl\n```\n\nAfter the crawl has finished, you will find the JSON files in the `./results/` subdirectory.\n\nWhen providing only the `--json-out` command line flag you will see that the\n`*_neighbors.json` document is empty. This document would contain the full\nrouting table information of each peer in the network which is quite a bit of\ndata (~250MB for the Amino DHT as of April '23) and is therefore disabled by\ndefault\n\n### Track Routing Table Information\n\nTo populate the document, you'll need to pass the `--neighbors` flag to\nthe `crawl` subcommand.\n\n```shell\nnebula --json-out ./results/ crawl --neighbors\n```\n\nThe routing table information forms a graph and graph visualization tools often\noperate with [adjacency lists](https://en.wikipedia.org/wiki/Adjacency_list). To convert the `*_neighbors.json` document\nto an adjacency list, you can use [`jq`](https://stedolan.github.io/jq/) and the following command:\n\n```shell\njq -r '.NeighborIDs[] as $neighbor | [.PeerID, $neighbor] | @csv' ./results/2025-02-16T14:32_neighbors.json > ./results/2025-02-16T14:32_neighbors.csv\n```\n\n### Postgres\n\nIf you want to store the information in a proper database, you could run `just start-postgres` to start a local postgres instance via docker in the background and run Nebula like:\n\n```shell\nnebula --db-user nebula_local --db-name nebula_local crawl --neighbors\n```\n\nAt this point, you \n\n[... truncated ...]"
  },
  "ipfs/kubo": {
    "fetchedAt": "2025-11-12T22:44:45.321Z",
    "content": "<h1 align=\"center\">\n  <br>\n  <a href=\"https://github.com/ipfs/kubo/blob/master/docs/logo/\"><img src=\"https://user-images.githubusercontent.com/157609/250148884-d6d12db8-fdcf-4be3-8546-2550b69845d8.png\" alt=\"Kubo logo\" title=\"Kubo logo\" width=\"200\"></a>\n  <br>\n  Kubo: IPFS Implementation in GO\n  <br>\n</h1>\n\n<p align=\"center\" style=\"font-size: 1.2rem;\">The first implementation of IPFS.</p>\n\n<p align=\"center\">\n  <a href=\"https://ipfs.tech\"><img src=\"https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square\" alt=\"Official Part of IPFS Project\"></a>\n  <a href=\"https://discuss.ipfs.tech\"><img alt=\"Discourse Forum\" src=\"https://img.shields.io/discourse/posts?server=https%3A%2F%2Fdiscuss.ipfs.tech\"></a>\n  <a href=\"https://matrix.to/#/#ipfs-space:ipfs.io\"><img alt=\"Matrix\" src=\"https://img.shields.io/matrix/ipfs-space%3Aipfs.io?server_fqdn=matrix.org\"></a>\n  <a href=\"https://github.com/ipfs/kubo/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/ipfs/kubo/gobuild.yml?branch=master\"></a>\n  <a href=\"https://github.com/ipfs/kubo/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/v/release/ipfs/kubo?filter=!*rc*\"></a>\n</p>\n\n<hr />\n\n## What is Kubo?\n\nKubo was the first IPFS implementation and is the most widely used one today. Implementing the *Interplanetary Filesystem* - the standard for content-addressing on the Web, interoperable with HTTP. Thus powered by future-proof data models and the libp2p for network communication. Kubo is written in Go.\n\nFeatureset\n- Runs an IPFS-Node as a network service that is part of LAN and WAN DHT\n- Native support for UnixFS (most popular way to represent files and directories on IPFS)\n- [HTTP Gateway](https://specs.ipfs.tech/http-gateways/) (`/ipfs` and `/ipns`) functionality for trusted and [trustless](https://docs.ipfs.tech/reference/http/gateway/#trustless-verifiable-retrieval) content retrieval\n- [HTTP Routing V1](https://specs.ipfs.tech/routing/http-routing-v1/) (`/routing/v1`) client and server implementation for [delegated routing](./docs/delegated-routing.md) lookups\n- [HTTP Kubo RPC API](https://docs.ipfs.tech/reference/kubo/rpc/) (`/api/v0`) to access and control the daemon\n- [Command Line Interface](https://docs.ipfs.tech/reference/kubo/cli/) based on (`/api/v0`) RPC API\n- [WebUI](https://github.com/ipfs/ipfs-webui/#readme) to manage the Kubo node\n- [Content blocking](/docs/content-blocking.md) support for operators of public nodes\n\n### Other implementations\n\nSee [List](https://docs.ipfs.tech/basics/ipfs-implementations/)\n\n## What is IPFS?\n\nIPFS is a global, versioned, peer-to-peer filesystem. It combines good ideas from previous systems such as Git, BitTorrent, Kademlia, SFS, and the Web. It is like a single BitTorrent swarm, exchanging git objects. IPFS provides an interface as simple as the HTTP web, but with permanence built-in. You can also mount the world at /ipfs.\n\nFor more info see: https://docs.ipfs.tech/concepts/what-is-ipfs/\n\nBefore opening an issue, consider using one of the following locations to ensure you are opening your thread in the right place:\n  - kubo (previously named go-ipfs) _implementation_ bugs in [this repo](https://github.com/ipfs/kubo/issues).\n  - Documentation issues in [ipfs/docs issues](https://github.com/ipfs/ipfs-docs/issues).\n  - IPFS _design_ in [ipfs/specs issues](https://github.com/ipfs/specs/issues).\n  - Exploration of new ideas in [ipfs/notes issues](https://github.com/ipfs/notes/issues).\n  - Ask questions and meet the rest of the community at the [IPFS Forum](https://discuss.ipfs.tech).\n  - Or [chat with us](https://docs.ipfs.tech/community/chat/).\n\n[![YouTube Channel Subscribers](https://img.shields.io/youtube/channel/subscribers/UCdjsUXJ3QawK4O5L1kqqsew?label=Subscribe%20IPFS&style=social&cacheSeconds=3600)](https://www.youtube.com/channel/UCdjsUXJ3QawK4O5L1kqqsew) [![Follow @IPFS on Twitter](https://img.shields.io/twitter/follow/IPFS?style=social&cacheSeconds=3600)](https://twitter.com/IPFS)\n\n## Next milestones\n\n[Milestones on GitHub](https://github.com/ipfs/kubo/milestones)\n\n\n## Table of Contents\n\n- [What is Kubo?](#what-is-kubo)\n- [What is IPFS?](#what-is-ipfs)\n- [Next milestones](#next-milestones)\n- [Table of Contents](#table-of-contents)\n- [Security Issues](#security-issues)\n- [Install](#install)\n  - [Minimal System Requirements](#minimal-system-requirements)\n  - [Docker](#docker)\n  - [Official prebuilt binaries](#official-prebuilt-binaries)\n    - [Updating](#updating)\n      - [Downloading builds using IPFS](#downloading-builds-using-ipfs)\n  - [Unofficial Linux packages](#unofficial-linux-packages)\n    - [ArchLinux](#arch-linux)\n    - [Gentoo Linux](#gentoo-linux)\n    - [Nix](#nix)\n    - [Solus](#solus)\n    - [openSUSE](#opensuse)\n    - [Guix](#guix)\n    - [Snap](#snap)\n    - [Ubuntu PPA](#ubuntu-ppa)\n    - [Fedora](#fedora-copr)\n  - [Unofficial Windows packages](#unofficial-windows-packages)\n    - [Chocolatey](#chocolatey)\n    - [Scoop](#scoop)\n  - [Unofficial MacOS packages](#unofficial-macos-packages)\n    - [MacPorts](#macports)\n    - [Nix](#nix-macos)\n    - [Homebrew](#homebrew)\n  - [Build from Source](#build-from-source)\n    - [Install Go](#install-go)\n    - [Download and Compile IPFS](#download-and-compile-ipfs)\n      - [Cross Compiling](#cross-compiling)\n    - [Troubleshooting](#troubleshooting)\n- [Getting Started](#getting-started)\n  - [Usage](#usage)\n  - [Some things to try](#some-things-to-try)\n  - [Troubleshooting](#troubleshooting-1)\n- [Packages](#packages)\n- [Development](#development)\n  - [Map of Implemented Subsystems](#map-of-implemented-subsystems)\n  - [CLI, HTTP-API, Architecture Diagram](#cli-http-api-architecture-diagram)\n  - [Testing](#testing)\n  - [Development Dependencies](#development-dependencies)\n  - [Developer Notes](#developer-notes)\n- [Maintainer Info](#maintainer-info)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Security Issues\n\nPlease follow [`SECURITY.md`](SECURITY.md).\n\n## Install\n\nThe canonical download instructions for IPFS are over at: https://docs.ipfs.tech/install/. It is **highly recommended** you follow those instructions if you are not interested in working on IPFS development.\n\nFor production use, Release Docker images (below) are recommended.\n\n### Minimal System Requirements\n\nKubo runs on most Linux, macOS, and Windows systems. For optimal performance, we recommend at least 6 GB of RAM and 2 CPU cores (more is ideal, as Kubo is highly parallel).\n\n> [!IMPORTANT]\n> Larger pinsets require additional memory, with an estimated ~1 GiB of RAM per 20 million items for reproviding to the Amino DHT.\n\n> [!CAUTION]\n> Systems with less than the recommended memory may experience instability, frequent OOM errors or restarts, and missing data announcement (reprovider window), which can make data fully or partially inaccessible to other peers. Running Kubo on underprovisioned hardware is at your own risk.\n\n### Docker\n\nOfficial images are published at https://hub.docker.com/r/ipfs/kubo/: [![Docker Image Version (latest semver)](https://img.shields.io/docker/v/ipfs/kubo?color=blue&label=kubo%20docker%20image&logo=docker&sort=semver&style=flat-square&cacheSeconds=3600)](https://hub.docker.com/r/ipfs/kubo/)\n\n#### üü¢ Release Images\n  - These are production grade images. Use them.\n  - `latest` and [`release`](https://hub.docker.com/r/ipfs/kubo/tags?name=release) tags always point at [the latest stable release](https://github.com/ipfs/kubo/releases/latest). If you use this, remember to `docker pull` periodically to update.\n  - [`vN.N.N`](https://hub.docker.com/r/ipfs/kubo/tags?name=v) points at a specific [release tag](https://github.com/ipfs/kubo/releases)\n\n#### üü† Developer Preview Images\n  - These tags are used by developers for internal testing, not intended for end users or production use.\n  - [`master-latest`](https://hub.docker.com/r/ipfs/kubo/tags?name=master-latest) always points at the `HEAD` of the [`master`](https://github.com/ipfs/kubo/commits/master/) branch\n  - [`master\n\n[... truncated ...]"
  },
  "ipfs/helia": {
    "fetchedAt": "2025-11-12T22:44:45.685Z",
    "content": "<p align=\"center\">\n  <a href=\"https://github.com/ipfs/helia\" title=\"Helia\">\n    <img src=\"https://raw.githubusercontent.com/ipfs/helia/main/assets/helia.png\" alt=\"Helia logo\" width=\"300\" />\n  </a>\n</p>\n\n[![ipfs.tech](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](https://ipfs.tech)\n[![Discuss](https://img.shields.io/discourse/https/discuss.ipfs.tech/posts.svg?style=flat-square)](https://discuss.ipfs.tech)\n[![codecov](https://img.shields.io/codecov/c/github/ipfs/helia.svg?style=flat-square)](https://codecov.io/gh/ipfs/helia)\n[![CI](https://img.shields.io/github/actions/workflow/status/ipfs/helia/main.yml?branch=main\\&style=flat-square)](https://github.com/ipfs/helia/actions/workflows/main.yml?query=branch%3Amain)\n\n[Helia](https://github.com/ipfs/helia) is a lean, modular, and modern TypeScript implementation of IPFS for the prolific JS and browser environments.\n\nSee the [Manifesto](https://github.com/ipfs/helia/wiki/Manifesto), the [FAQ](https://github.com/ipfs/helia/wiki/FAQ), and the [State of IPFS in JS blog post from October 2022](https://blog.ipfs.tech/state-of-ipfs-in-js/) for more info.\n\n# üåü Usage\n\nA quick overview of how to get different types of data in and out of your Helia\nnode.\n\n## ü™¢ Strings\n\nYou can use the [@helia/strings](https://www.npmjs.com/package/@helia/strings)\nmodule to easily add and get strings from your Helia node:\n\n```js\nimport { createHelia } from 'helia'\nimport { strings } from '@helia/strings'\n\nconst helia = await createHelia()\nconst s = strings(helia)\n\nconst myImmutableAddress = await s.add('hello world')\n\nconsole.log(await s.get(myImmutableAddress))\n// hello world\n```\n\n## üåÉ JSON\n\nThe [@helia/json](https://www.npmjs.com/package/@helia/json) module lets you add\nor get plain JS objects:\n\n```js\nimport { createHelia } from 'helia'\nimport { json } from '@helia/json'\n\nconst helia = await createHelia()\nconst j = json(helia)\n\nconst myImmutableAddress = await j.add({ hello: 'world' })\n\nconsole.log(await j.get(myImmutableAddress))\n// { hello: 'world' }\n```\n\n## üå† DAG-JSON\n\nThe [@helia/dag-json](https://www.npmjs.com/package/@helia/dag-json) allows you\nto store references to linked objects as\n[CIDs](https://docs.ipfs.tech/concepts/content-addressing):\n\n```js\nimport { createHelia } from 'helia'\nimport { dagJson } from '@helia/dag-json'\n\nconst helia = await createHelia()\nconst d = dagJson(helia)\n\nconst object1 = { hello: 'world' }\nconst myImmutableAddress1 = await d.add(object1)\n\nconst object2 = { link: myImmutableAddress1 }\nconst myImmutableAddress2 = await d.add(object2)\n\nconst retrievedObject = await d.get(myImmutableAddress2)\nconsole.log(retrievedObject)\n// { link: CID(baguqeerasor...) }\n\nconsole.log(await d.get(retrievedObject.link))\n// { hello: 'world' }\n```\n\n## üåå DAG-CBOR\n\n[@helia/dag-cbor](https://www.npmjs.com/package/@helia/dag-cbor) works in a\nsimilar way to `@helia/dag-json` but stores objects using\n[Concise Binary Object Representation](https://cbor.io/):\n\n```js\nimport { createHelia } from 'helia'\nimport { dagCbor } from '@helia/dag-cbor'\n\nconst helia = await createHelia()\nconst d = dagCbor(helia)\n\nconst object1 = { hello: 'world' }\nconst myImmutableAddress1 = await d.add(object1)\n\nconst object2 = { link: myImmutableAddress1 }\nconst myImmutableAddress2 = await d.add(object2)\n\nconst retrievedObject = await d.get(myImmutableAddress2)\nconsole.log(retrievedObject)\n// { link: CID(baguqeerasor...) }\n\nconsole.log(await d.get(retrievedObject.link))\n// { hello: 'world' }\n```\n\n## üîí Custom Hasher\n\nA [hasher](https://github.com/multiformats/js-multiformats?tab=readme-ov-file#multihash-hashers) is used to determine the immutable address of the content (aka the [**CID**](https://github.com/multiformats/cid?tab=readme-ov-file#what-is-it)) being imported into helia. The default hasher used by the methods above is [sha2-256 multihash](https://github.com/multiformats/js-multiformats?tab=readme-ov-file#multihash-hashers-1), but others can be provided with [AddOptions](https://ipfs.github.io/helia/interfaces/_helia_dag_cbor.AddOptions.html). This is useful for applications that require hashers with specific properties; so in most cases keeping the default is recommended.\n\n> **Changing the hasher will cause a different CID to be returned for the same content! In other words: the same content imported with different hashers is treated like unique content with a unique address.**\n\n```js\nimport { createHelia } from 'helia'\nimport { dagCbor } from '@helia/dag-cbor'\nimport { sha512 } from 'multiformats/hashes/sha2'\n\nconst helia = await createHelia()\nconst d = dagCbor(helia)\n\nconst object1 = { hello: 'world' }\n\nconst cidWithSHA256 = await d.add(object1)\nconst cidWithSHA512 = await d.add(object1, {\n  hasher: sha512\n})\n\n/** The same objects with different CIDs are treated as different objects */\n\nconsole.log(cidWithSHA256)\n// CID(bafyreidykglsfhoixmivffc5uwhcgshx4j465xwqntbmu43nb2dzqwfvae)\nconsole.log(cidWithSHA512)\n// CID(bafyrgqhai26anf3i7pips7q22coa4sz2fr4gk4q4sqdtymvvjyginfzaqewveaeqdh524nsktaq43j65v22xxrybrtertmcfxufdam3da3hbk)\n\nconst retrievedObject1 = await d.get(cidWithSHA256)\nconst retrievedObject2 = await d.get(cidWithSHA512)\n\nconsole.log(retrievedObject1)\n// { hello: 'world' }\nconsole.log(retrievedObject2)\n// { hello: 'world' }\n```\n\n# üêæ Next steps\n\nCheck out the [helia-examples](https://github.com/ipfs-examples/helia-examples)\nrepo for how to do mostly anything with your Helia node.\n\n# üèÉ‚Äç‚ôÄÔ∏è Getting Started\n\nCheck out the [Helia examples repo](https://github.com/ipfs-examples/helia-examples#examples), which covers a wide variety of use cases. If you feel something has been missed, follow the [contribution guide](https://github.com/ipfs-examples/helia-examples#contributing) and create a PR to the examples repo.\n\n# üìó Project Docs\n\n- See the [project wiki](https://github.com/ipfs/helia/wiki).\n\n# üìí API Docs\n\n- <https://ipfs.github.io/helia>\n\n# üìê System diagram\n\n```mermaid\ngraph TD;\n    User[\"User or application\"]-->IPNS[\"@helia/ipns\"];\n    User-->UnixFS[\"@helia/unixfs\"];\n    User-->Libp2p;\n    User-->Datastore;\n    User-->Blockstore;\n    UnixFS-->Blockstore;\n    IPNS-->Datastore;\n    subgraph helia [Helia]\n      Datastore\n      Blockstore-->BlockBrokers;\n      BlockBrokers-->Bitswap;\n      BlockBrokers-->TrustlessGateways;\n      Libp2p-->DHT;\n      Libp2p-->PubSub;\n      Libp2p-->IPNI;\n      Libp2p-->Reframe;\n    end\n    Blockstore-->BlockStorage[\"File system/IDB/S3/etc\"];\n    Datastore-->DataStorage[\"Level/S3/IDB/etc\"];\n    Bitswap-->Network;\n    TrustlessGateways-->Gateway1;\n    TrustlessGateways-->GatewayN;\n    DHT-->Network;\n    PubSub-->Network;\n    IPNI-->Network;\n    Reframe-->Network;\n```\n\n# üè≠ Code Structure\n\nHelia embraces a modular approach and encourages users to bring their own implementations of various APIs to suit their needs.\n\nThe basic Helia API is defined in:\n\n- [`/packages/interface`](./packages/interface) The Helia API\n\nThe API is implemented by:\n\n- [`/packages/helia`](./packages/helia) An peer to peer implementation that uses [bitswap](https://docs.ipfs.tech/concepts/bitswap/), [libp2p](https://www.npmjs.com/package/libp2p) and [HTTP gateways](https://docs.ipfs.tech/reference/http/gateway/) as fallback\n- [`/packages/http`](./packages/http) A lightweight implementation that uses [HTTP gateways](https://docs.ipfs.tech/reference/http/gateway/) exclusively\n\nHelia also ships a number of supplemental libraries and tools that can be combined with Helia API implementations to accomplish tasks in distributed and trustless ways.\n\nThese libraries are not intended to be the \"one true implementation\" of any given API, but are made available for users to include depending on the need of their particular application:\n\n- [./packages/car](./packages/car) The `@helia/car` module\n- [./packages/dag-cbor](./packages/dag-cbor) The `@helia/dag-cbor` module\n- [./packages/dag-json](./packages/dag-json) The `@helia/dag-json` module\n- [./packages/ipns](./packages/ipns) The `@helia/ipns` module\n- [./packages/json](\n\n[... truncated ...]"
  },
  "ipfs/boxo": {
    "fetchedAt": "2025-11-12T22:44:46.035Z",
    "content": "<h1 align=\"center\">\n  <br>\n  <a href=\"https://github.com/ipfs/boxo/blob/main/docs/logo/\"><img src=\"https://github.com/ipfs/boxo/assets/157609/3c5e7391-fbc2-405b-9efc-920f4fd13b39\" alt=\"Boxo logo\" title=\"Boxo logo\" width=\"200\"></a>\n  <br>\n  BOXO: IPFS SDK for GO\n  <br>\n</h1>\n\n<p align=\"center\" style=\"font-size: 1.2rem;\">A set of libraries for building IPFS applications and implementations in GO.</p>\n\n<p align=\"center\">\n  <a href=\"https://ipfs.tech\"><img src=\"https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square\" alt=\"Official Part of IPFS Project\"></a>\n  <a href=\"https://discuss.ipfs.tech\"><img alt=\"Discourse Forum\" src=\"https://img.shields.io/discourse/posts?server=https%3A%2F%2Fdiscuss.ipfs.tech\"></a>\n  <a href=\"https://matrix.to/#/#ipfs-space:ipfs.io\"><img alt=\"Matrix\" src=\"https://img.shields.io/matrix/ipfs-space%3Aipfs.io?server_fqdn=matrix.org\"></a>\n  <a href=\"https://github.com/ipfs/boxo/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/ipfs/boxo/go-test.yml?branch=main\" alt=\"ci\"></a>\n  <a href=\"https://codecov.io/gh/ipfs/boxo\"><img src=\"https://codecov.io/gh/ipfs/boxo/branch/main/graph/badge.svg?token=9eG7d8fbCB\" alt=\"coverage\"></a>\n  <a href=\"https://github.com/ipfs/boxo/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/v/release/ipfs/boxo?filter=!*rc*\"></a>\n  <a href=\"https://godoc.org/github.com/ipfs/boxo\"><img src=\"https://img.shields.io/badge/godoc-reference-5272B4.svg?style=flat-square\" alt=\"godoc reference\"></a>  \n</p>\n\n<hr />\n\n<!-- TOC -->\n\n- [About](#about)\n  - [Motivation](#motivation)\n- [Scope](#scope)\n  - [What kind of components does Boxo have?](#what-kind-of-components-does-boxo-have)\n  - [Does Boxo == IPFS?](#does-boxo--ipfs)\n  - [Is everything related to IPFS in the Go ecosystem in this repo?](#is-everything-related-to-ipfs-in-the-go-ecosystem-in-this-repo)\n- [Consuming](#consuming)\n  - [Getting started](#getting-started)\n  - [Migrating to Boxo](#migrating-to-boxo)\n  - [Deprecations and Breaking Changes](#deprecations-and-breaking-changes)\n- [Development](#development)\n  - [Should I add my IPFS component to Boxo?](#should-i-add-my-ipfs-component-to-boxo)\n  - [Release Process](#release-process)\n  - [Why is the code coverage so bad?](#why-is-the-code-coverage-so-bad)\n- [General](#general)\n  - [Help](#help)\n  - [What is the response time for issues or PRs filed?](#what-is-the-response-time-for-issues-or-prs-filed)\n  - [What are some projects that depend on this project?](#what-are-some-projects-that-depend-on-this-project)\n  - [Governance and Access](#governance-and-access)\n  - [Why is this named \"Boxo\"?](#why-is-this-named-boxo)\n  - [Additional Docs and FAQs](#additional-docs-and-faqs)\n  - [License](#license)\n\n<!-- /TOC -->\n\n## About\n\nBoxo is a component library for building IPFS applications and implementations in Go.\n\nSome scenarios in which you may find Boxo helpful:\n\n* You are building an application that interacts with the IPFS network\n* You are building an IPFS implementation\n* You want to reuse some components of IPFS such as its Kademlia DHT, Bitswap, data encoding, etc.\n* You want to experiment with IPFS\n\nBoxo powers [Kubo](https://github.com/ipfs/kubo), which is [the most popular IPFS implementation](https://github.com/protocol/network-measurements/tree/master/reports),\nso its code has been battle-tested on the IPFS network for years, and is well-understood by the community.\n\n### Motivation\n\n**TL;DR** The goal of this repo is to help people build things.  Previously users struggled to find existing useful code or to figure out how to use what they did find.  We observed many running Kubo and using its HTTP RPC API.  This repo aims to do better.  We're taking the libraries that many were already effectively relying on in production and making them more easily discoverable and usable.\n\nThe maintainers primarily aim to help people trying to build with IPFS in Go that were previously either giving up or relying on the [Kubo HTTP RPC API](https://docs.ipfs.tech/reference/kubo/rpc/). Some of these people will end up being better served by IPFS tooling in other languages (e.g., Javascript, Rust, Java, Python), but for those who are either looking to write in Go or to leverage the set of IPFS tooling we already have in Go we‚Äôd like to make their lives easier.\n\nWe‚Äôd also like to make life easier on ourselves as the maintainers by reducing the maintenance burden that comes from being the owners on [many repos](https://github.com/ipfs/kubo/issues/8543) and then use that time to contribute more to the community in the form of easier to use libraries, better implementations, improved protocols, new protocols, etc.\n\nBoxo is not exhaustive nor comprehensive--there are plenty of useful IPFS protocols, specs, libraries, etc. that are not in Boxo. The goal of Boxo is to provide cohesive and well-maintained components for common IPFS use cases.\n\nMore details can also be found in the [Rationale FAQ](./docs/FAQ.md#rationale-faq).\n\n## Scope\n\n### What kind of components does Boxo have?\n\nBoxo includes high-quality components useful for interacting with IPFS protocols, public and private IPFS networks, and content-addressed data, such as:\n\n- Content routing (DHT, delegated content routing, providing)\n- Data transfer (gateways, Bitswap, incremental verification)\n- Naming and mutability (name resolution, IPNS)\n- Interacting with public and private IPFS networks\n- Working with content-addressed data\n\nBoxo aims to provide a cohesive interface into these components. Note that not all of the underlying components necessarily reside in this repository.\n\n### Does Boxo == IPFS?\n\nNo. This repo houses some IPFS functionality written in Go that has been useful in practice, and is maintained by a group that has long term commitments to the IPFS project\n\n### Is everything related to IPFS in the Go ecosystem in this repo?\n\nNo. Not everything related to IPFS is intended to be in Boxo. View it as a starter toolbox (potentially among multiple). If you‚Äôd like to build an IPFS implementation with Go, here are some tools you might want that are maintained by a group that has long term commitments to the IPFS project. There are certainly repos that others maintain that aren't included here (e.g., ipfs/go-car) which are still useful to IPFS implementations. It's expected and fine for new IPFS functionality to be developed that won't be part of Boxo.\n\n## Consuming\n\n### Getting started\n\nSee [examples](./examples/README.md).\n\nIf you are migrating to Boxo, see [Migrating to Boxo](#migrating-to-boxo).\n\n### Migrating to Boxo\n\nMany Go modules under github.com/ipfs have moved here. Boxo provides a tool to ease this migration, which does most of the work for you:\n\n* `cd` into the root directory of your module (where the `go.mod` file is)\n* Run: `go run github.com/ipfs/boxo/cmd/boxo-migrate@latest update-imports`\n  * This will upgrade your module to Boxo v0.8.0 and rewrite your import paths\n* Run: `go run github.com/ipfs/boxo/cmd/boxo-migrate@latest check-dependencies`\n  * This will print unmaintained dependencies you still have\n  * These aren't necessarily an immediate problem, but you should eventually get them out of your dependency graph\n  \nThis tool only upgrades your module to Boxo v0.8.0, to minimize backwards-incompatible changes. Depending on the versions of IPFS modules before the upgrade, your code may require additional changes to build.\n\nWe recommend upgrading to v0.8.0 first, and _then_ upgrading to the latest Boxo release.\n\nIf you encounter any challenges, please [open an issue](https://github.com/ipfs/boxo/issues/new/choose) and Boxo maintainers will help you.\n\n### Deprecations and Breaking Changes\n\nSee [RELEASE.md](./RELEASE.md).\n\n## Development\n\n### Should I add my IPFS component to Boxo?\n\nWe happily accept external contributions! However, Boxo maintains a high quality bar, so code accepted into Boxo must meet some minimum maintenance criteria:\n\n* Actively maintained\n  * Must be actively used by, or\n\n[... truncated ...]"
  },
  "ipfs/js-kubo-rpc-client": {
    "fetchedAt": "2025-11-12T22:44:46.496Z",
    "content": "## Kubo RPC Client\n\n<h3 align=\"center\">JavaScript client library for the Kubo RPC API</h3>\n\n<p align=\"center\">\n  <a href=\"https://app.element.io/#/room/#ipfs-chatter:ipfs.io\"><img src=\"https://img.shields.io/badge/matrix-%23ipfs%3Amatrix.org-blue.svg?style=flat\" /> </a>\n  <a href=\"https://discord.gg/ipfs\"><img src=\"https://img.shields.io/discord/806902334369824788?color=blueviolet&label=discord&style=flat\" /></a>\n  <a href=\"https://github.com/ipfs/team-mgmt/blob/master/MGMT_JS_CORE_DEV.md\"><img src=\"https://img.shields.io/badge/team-mgmt-blue.svg?style=flat\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://codecov.io/gh/ipfs/js-kubo-rpc-client\"><img src=\"https://img.shields.io/codecov/c/github/ipfs/js-kubo-rpc-client/master.svg?style=flat-square\"></a>\n   <a href=\"https://bundlephobia.com/result?p=kubo-rpc-client\"><img src=\"https://flat.badgen.net/bundlephobia/minzip/kubo-rpc-client\"></a>\n  <br>\n  <a href=\"https://github.com/feross/standard\"><img src=\"https://img.shields.io/badge/code%20style-standard-brightgreen.svg?style=flat-square\"></a>\n  <a href=\"https://github.com/RichardLitt/standard-readme\"><img src=\"https://img.shields.io/badge/standard--readme-OK-green.svg?style=flat-square\" /></a>\n  <a href=\"\"><img src=\"https://img.shields.io/badge/npm-%3E%3D3.0.0-orange.svg?style=flat-square\" /></a>\n  <a href=\"\"><img src=\"https://img.shields.io/badge/Node.js-%3E%3D10.0.0-orange.svg?style=flat-square\" /></a>\n  <a href=\"https://www.npmjs.com/package/kubo-rpc-client\"><img src=\"https://img.shields.io/npm/dm/kubo-rpc-client.svg\" /></a>\n  <a href=\"https://www.jsdelivr.com/package/npm/kubo-rpc-client\"><img src=\"https://data.jsdelivr.com/v1/package/npm/kubo-rpc-client/badge\"/></a>\n  <br>\n</p>\n\n> A client library for the Kubo RPC API\n\n# Install\n\n```console\n$ npm i kubo-rpc-client\n```\n\n## Browser `<script>` tag\n\nLoading this module through a script tag will make its exports available as `KuboRpcClient` in the global namespace.\n\n```html\n<script src=\"https://unpkg.com/kubo-rpc-client/dist/index.min.js\"></script>\n```\n\nBoth the Current and Active LTS versions of Node.js are supported. Please see [nodejs.org](https://nodejs.org/) for what these currently are.\n\n### Next Steps\n\n- Read the [docs](https://ipfs.github.io/js-kubo-rpc-client)\n- Look into the [examples](https://github.com/ipfs-examples/js-ipfs-examples) to learn how to spawn an RPC client or a full IPFS node in Node.js and in the Browser\n- Consult the [Core API docs](https://github.com/ipfs/js-ipfs/tree/master/docs/core-api) to see what you can do with an IPFS node\n- Check out <https://docs.ipfs.tech> for tips, how-tos and more\n- Head over to <https://proto.school> to take interactive tutorials that cover core IPFS APIs\n- See <https://blog.ipfs.tech> for news and more\n- Need help? Please ask 'How do I?' questions on <https://discuss.ipfs.tech>\n\n## Usage\n\n#### `create([options])`\n\n> create an instance of the HTTP API client\n\n#### Parameters\n\nNone\n\n#### Options\n\n`options` can be a `String`, a `URL` or a `Multiaddr` which will be interpreted as the address of the IPFS node we wish to use the API of.\n\nAlternatively it can be an object which may have the following keys:\n\n| Name     | Type                                                                 | Default                                          | Description                                                                                                    |\n| -------- | -------------------------------------------------------------------- | ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------- |\n| url      | `String` or `URL` or `Multiaddr`                                     | `'http://localhost:5001/api/v0'`                 | A URL that resolves to a running instance of the IPFS [HTTP RPC API](https://docs.ipfs.io/reference/http/api/) |\n| protocol | `String`                                                             | `'http'`                                         | The protocol to used (ignored if url is specified)                                                             |\n| host     | `String`                                                             | `'localhost'`                                    | The host to used (ignored if url is specified)                                                                 |\n| port     | `number`                                                             | `5001`                                           | The port to used (ignored if url is specified)                                                                 |\n| path     | `String`                                                             | `'api/v0'`                                       | The path to used (ignored if url is specified)                                                                 |\n| agent    | [http.Agent](https://nodejs.org/api/http.html#http_class_http_agent) | `http.Agent({ keepAlive: true, maxSockets: 6 })` | An `http.Agent` used to control client behaviour (node.js only)                                                |\n\n#### Returns\n\n| Type     | Description                                                                                               |\n| -------- | --------------------------------------------------------------------------------------------------------- |\n| `Object` | An object that conforms to the [IPFS Core API](https://github.com/ipfs/js-ipfs/tree/master/docs/core-api) |\n\n#### Example\n\n```JavaScript\nimport { create } from 'kubo-rpc-client'\n\n// connect to the default API address http://localhost:5001\nconst client = create()\n\n// connect to a different API\nconst client = create({ url: \"http://127.0.0.1:5002/api/v0\" });\n\n// connect using a URL\nconst client = create(new URL('http://127.0.0.1:5002'))\n\n// call Core API methods\nconst { cid } = await client.add('Hello world!')\n```\n\nDo you use Kubo's [**`API.Authorizations`**](https://github.com/ipfs/kubo/blob/master/docs/config.md#apiauthorizations)? Check the [Custom Headers](#custom-headers) section.\n\n### API\n\n`kubo-rpc-client` will not implement the [IPFS Core API](https://github.com/ipfs/js-ipfs/tree/master/docs/core-api). Please see <https://github.com/ipfs/kubo/issues/9125> for more information.\n\n### Additional Options\n\nAll core API methods take *additional* `options` specific to the HTTP API:\n\n- `headers` - An object or [Headers](https://developer.mozilla.org/en-US/docs/Web/API/Headers) instance that can be used to set custom HTTP headers. Note that this option can also be [configured globally](#custom-headers) via the constructor options.\n- `searchParams` - An object or [`URLSearchParams`](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams) instance that can be used to add additional query parameters to the query string sent with each request.\n\n### Instance Utils\n\n- `ipfs.getEndpointConfig()`\n\nCall this on your client instance to return an object containing the `host`, `port`, `protocol` and `api-path`.\n\n### Static Types and Utils\n\nAside from the default export, `kubo-rpc-client` exports various types and utilities that are included in the bundle:\n\n- [`multiaddr`](https://www.npmjs.com/package/multiaddr)\n- [`multibase`](https://www.npmjs.com/package/multibase)\n- [`multicodec`](https://www.npmjs.com/package/multicodec)\n- [`multihash`](https://www.npmjs.com/package/multihashes)\n- [`CID`](https://www.npmjs.com/package/cids)\n- [`globSource`](https://github.com/ipfs/js-ipfs-utils/blob/master/src/files/glob-source.js) (not available in the browser)\n- [`urlSource`](https://github.com/ipfs/js-ipfs-utils/blob/master/src/files/url-source.js)\n\nThese can be accessed like this, for example:\n\n```js\nimport { CID } from 'kubo-rpc-client'\n```\n\n#### Glob source\n\nA utility to allow files on the file system to be easily added to IPFS.\n\n##### `globSource(path, pattern, [options])`\n\n- `path`: A path to a single file or directory to glob from\n- `pattern`: A\n\n[... truncated ...]"
  },
  "ipfs/protons": {
    "fetchedAt": "2025-11-12T22:44:46.915Z",
    "content": "# protons <!-- omit in toc -->\n\n[![ipfs.tech](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](https://ipfs.tech)\n[![Discuss](https://img.shields.io/discourse/https/discuss.ipfs.tech/posts.svg?style=flat-square)](https://discuss.ipfs.tech)\n[![codecov](https://img.shields.io/codecov/c/github/ipfs/protons.svg?style=flat-square)](https://codecov.io/gh/ipfs/protons)\n[![CI](https://img.shields.io/github/actions/workflow/status/ipfs/protons/js-test-and-release.yml?branch=main\\&style=flat-square)](https://github.com/ipfs/protons/actions/workflows/js-test-and-release.yml?query=branch%3Amain)\n\n> Protobuf to ts transpiler\n\n`protons` is a high performance implementation of [Protocol Buffers v3](https://protobuf.dev/programming-guides/proto3/).\n\n# Packages\n\n- [`/packages/protons`](./packages/protons) The transpiler\n- [`/packages/protons-benchmark`](./packages/protons-benchmark) A benchmark suite\n- [`/packages/protons-runtime`](./packages/protons-runtime) Shared components that turn values to bytes and back again\n\n# API Docs\n\n- <https://ipfs.github.io/protons>\n\n# License\n\nLicensed under either of\n\n- Apache 2.0, ([LICENSE-APACHE](LICENSE-APACHE) / <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT ([LICENSE-MIT](LICENSE-MIT) / <http://opensource.org/licenses/MIT>)\n\n# Contribute\n\nContributions welcome! Please check out [the issues](https://github.com/ipfs/protons/issues).\n\nAlso see our [contributing document](https://github.com/ipfs/community/blob/master/CONTRIBUTING_JS.md) for more information on how we work, and about contributing in general.\n\nPlease be aware that all interactions related to this repo are subject to the IPFS [Code of Conduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.\n\n[![](https://cdn.rawgit.com/jbenet/contribute-ipfs-gif/master/img/contribute.gif)](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md)\n"
  },
  "ipfs/service-worker-gateway": {
    "fetchedAt": "2025-11-12T22:44:47.261Z",
    "content": "<h1 align=\"center\">\n  <br>\n  <img src=\"https://github.com/ipfs/service-worker-gateway/assets/157609/4931e739-a899-4b18-91f2-2a2bcafb5c33\" alt=\"logo\" title=\"logo\" width=\"200\"></a>\n  <br>\n  Service Worker IPFS Gateway\n  <br>\n</h1>\n\n<p align=\"center\" style=\"font-size: 1.2rem;\">Decentralizing IPFS Gateways by verifying hashes in the user's browser.</p>\n\n<p align=\"center\">\n  <a href=\"https://ipfs.tech\"><img src=\"https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square\" alt=\"Official Part of IPFS Project\"></a>\n  <a href=\"https://discuss.ipfs.tech\"><img alt=\"Discourse Forum\" src=\"https://img.shields.io/discourse/posts?server=https%3A%2F%2Fdiscuss.ipfs.tech\"></a>\n  <a href=\"https://github.com/ipfs/service-worker-gateway/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/ipfs/service-worker-gateway/main.yml?branch=main\" alt=\"ci\"></a>\n  <a href=\"https://github.com/ipfs/service-worker-gateway/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/v/release/ipfs/service-worker-gateway?filter=!*rc*\"></a>\n</p>\n\n<hr />\n\n## About\n\nThis project demonstrates\nthe use of [Helia](https://github.com/ipfs/helia) (IPFS implementation in JS)\nand the [`verified-fetch` library](https://github.com/ipfs/helia-verified-fetch)\n([Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) for IPFS)\nwithin a [Service Worker](https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API)\nto facilitate direct verified retrieval of content-addressed data.\n\nA Service Worker is registered on the initial page load, and then intercepts\nHTTP requests for content stored on IPFS paths such as `/ipfs/*` (immutable) and\n`/ipns/*` (mutable) and returns [`Response`](https://developer.mozilla.org/en-US/docs/Web/API/Response)\nobjects to the browser.\n\nIt functions as an IPFS gateway within the browser, offering enhanced security\n([hash verification](https://docs.ipfs.tech/concepts/content-addressing/)\nhappens on end user's machine) and reliability (ability to use multiple sources\nof content-addressed blocks) without reliance on a single HTTP server for IPFS\ntasks.\n\n<a href=\"http://ipshipyard.com/\"><img align=\"right\" src=\"https://github.com/user-attachments/assets/39ed3504-bb71-47f6-9bf8-cb9a1698f272\" /></a>\n\nThis project  was brought to you by the [Shipyard](http://ipshipyard.com/) team.\n\n\n### Goals\n\nThe main goals of this project are:\n\n- **Enhancing the robustness of IPFS-based web hosting by eliminating reliance\n  on a single HTTP backend.**\n  - Tasks such as fetching blocks from IPFS content providers (both\n    peer-to-peer and HTTP), verifying that block hashes match the expected CID,\n    and re-assembling blocks into deserialized bytes that can be rendered by\n    the browser, all happens within the end user's machine.\n- **Reducing the operational costs associated with running an HTTP backend.**\n  - By shifting the majority of data retrieval tasks to the user's browser, the\n    backend hosting a website no longer needs to serve as a conduit for all of\n    its data. This means that a gateway operator could potentially run a simple\n    HTTP server on a Raspberry Pi, serving only small static HTML+JS files\n    (<10MiB), while allowing all other operations to occur within the user's\n    browser, with data fetched either peer-to-peer or from remote HTTP\n    trustless gateways.\n- **Improving JS tooling, IPFS specifications, and gateway-conformance tests.**\n   - By having to implement gateway semantics end-to-end we identify bugs and\n     gaps, and improve quality of libraries, specifications, and interop tests.\n\n\n\n### Feature Set\n\n- üöß **WIP:** Web interface for adjusting routing and retrieval settings.\n- üöß **WIP:** [Trustless](https://docs.ipfs.tech/reference/http/gateway/#trustless-verifiable-retrieval) content retrieval from multiple HTTP gateways.\n- üöß **WIP:** Support for [Web Gateway](https://specs.ipfs.tech/http-gateways/) feature set for website hosting (`index.html`, [web pathing](https://github.com/ipfs/specs/issues/432), `_redirects`).\n- üöß **Future:** [HTTP Routing V1](https://specs.ipfs.tech/routing/http-routing-v1/) (`/routing/v1`) client for discovering additional direct content providers.\n- üöß **Future:** [Denylist](https://specs.ipfs.tech/compact-denylist-format/) support for operators of public nodes.\n\n## Usage\n\n### Running locally\n\nYou can build and run the project locally:\n\n```console\n> npm i\n> npm run build\n> npm start\n```\n\nNow open your browser and go to `http://localhost:3000`\n\nBelow is an explanation of the different URLs and what they do:\n\nWith reverse-proxy:\n* `http://localhost:3333` - The service worker gateway front-end served directly with esbuild. (localhost:3333 -> localhost:8345)\n* `http://localhost:3334` - The service worker gateway front-end hosted by an IPFS gateway running on 'localhost:8088'. (localhost:3334 -> localhost:8088 with x-forwarded-host header)\n\nWithout reverse-proxy:\n* `http://localhost:8345` - The service worker gateway front-end served directly with esbuild.\n\nFor the above URLs with reverse-proxy, the reverse proxy ensures subdomain\nsupport. This ensures you can access URLs like `https://<hash>.ipfs.localhost:<port>/`\nand `https://<dnslink>.ipns.localhost:<port>/`\n\nAs you type in a content path, you will be redirected to appropriate URL\n(typically that means [subdomain style resolution](https://docs.ipfs.tech/how-to/gateway-best-practices/#use-subdomain-gateway-resolution-for-origin-isolation)).\n\nFor more information about local development setup, see [/docs/DEVELOPMENT.md](/docs/DEVELOPMENT.md).\n\n### Try hosted instance\n\nWe provide a public good instance of this projct configured to run in[subdomain mode](https://docs.ipfs.tech/how-to/address-ipfs-on-web/#subdomain-gateway),\naiming to be a drop-in replacement for `dweb.link`:\n\n- üöß **WIP: alpha quality** https://inbrowser.link hosts the `release` branch, with a stable [release](https://github.com/ipfs/service-worker-gateway/releases)\n- üöß **WIP: alpha quality** https://inbrowser.dev hosts the `staging` branch with development / testing version\n\nThere is also an instance running in [path mode](https://docs.ipfs.tech/how-to/address-ipfs-on-web/#path-gateway),\naiming to be a drop-in replacement for `ipfs.io`:\n\n- üöß **WIP: alpha quality** https://ipfs-service-worker-gateway.pages.dev hosts the `release` branch, with a stable [release](https://github.com/ipfs/service-worker-gateway/releases)\n- üöß **WIP: alpha quality** https://staging.ipfs-service-worker-gateway.pages.dev hosts the `staging` branch with development / testing version\n\n#### Deploying to `production` and `staging`\n\nDeploying to [production](https://github.com/ipfs/service-worker-gateway/actions/workflows/deploy-to-production.yml)\nand [staging](https://github.com/ipfs/service-worker-gateway/actions/workflows/deploy-to-staging.yml)\nis done by manually running the deployment action and passing the release\nversion to the action.\n\n## Manual Service Worker Deregistration\n\nIn some cases, you might want to manually unregister or remove the Helia service\nworker from your browser. This can be useful for debugging purposes or to ensure\na clean state.\n\nYou can instruct the service worker to unregister itself by appending the\n`?ipfs-sw-unregister=true` query parameter to the URL of any page controlled by\nthe service worker.\n\nFor example, if the service worker is active for `https://example.com`,\nnavigating to `https://example.com/?ipfs-sw-unregister=true` will cause the\nservice worker to unregister itself and attempt to reload all controlled clients\n(browser tabs).\n\nThis option is also available via a button on the service worker's configuration\npage (`#/ipfs-sw-config`).\n\n## License\n\nThis project is dual-licensed under `SPDX-License-Identifier: Apache-2.0 OR MIT`\n\nSee [LICENSE](./LICENSE) for more details.\n"
  },
  "ipfs/js-ipns": {
    "fetchedAt": "2025-11-12T22:44:47.986Z",
    "content": "# ipns\n\n[![ipfs.tech](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](https://ipfs.tech)\n[![Discuss](https://img.shields.io/discourse/https/discuss.ipfs.tech/posts.svg?style=flat-square)](https://discuss.ipfs.tech)\n[![codecov](https://img.shields.io/codecov/c/github/ipfs/js-ipns.svg?style=flat-square)](https://codecov.io/gh/ipfs/js-ipns)\n[![CI](https://img.shields.io/github/actions/workflow/status/ipfs/js-ipns/js-test-and-release.yml?branch=main\\&style=flat-square)](https://github.com/ipfs/js-ipns/actions/workflows/js-test-and-release.yml?query=branch%3Amain)\n\n> IPNS record definitions\n\n# About\n\n<!--\n\n!IMPORTANT!\n\nEverything in this README between \"# About\" and \"# Install\" is automatically\ngenerated and will be overwritten the next time the doc generator is run.\n\nTo make changes to this section, please update the @packageDocumentation section\nof src/index.js or src/index.ts\n\nTo experiment with formatting, please run \"npm run docs\" from the root of this\nrepo and examine the changes made.\n\n-->\n\nImplements parsing and serialization of [IPNS Records](https://specs.ipfs.tech/ipns/ipns-record/).\n\n## Example - Create record\n\n```TypeScript\nimport { createIPNSRecord } from 'ipns'\nimport { generateKeyPair } from '@libp2p/crypto/keys'\n\nconst privateKey = await generateKeyPair('Ed25519')\nconst value = 'hello world'\nconst sequenceNumber = 0\nconst lifetime = 3_600_000 // ms, e.g. one hour\n\nconst ipnsRecord = await createIPNSRecord(privateKey, value, sequenceNumber, lifetime)\n```\n\n## Example - Validate record against public key\n\n```TypeScript\nimport { validate } from 'ipns/validator'\nimport { generateKeyPair } from '@libp2p/crypto/keys'\n\nconst privateKey = await generateKeyPair('Ed25519')\nconst publicKey = privateKey.publicKey\nconst marshalledRecord = Uint8Array.from([0, 1, 2, 3])\n\nawait validate(publicKey, marshalledRecord)\n// if no error thrown, the record is valid\n```\n\n## Example - Validate record against routing key\n\nThis is useful when validating IPNS names that use RSA keys, whose public key is embedded in the record (rather than in the routing key as with Ed25519).\n\n```TypeScript\nimport { ipnsValidator } from 'ipns/validator'\nimport { multihashToIPNSRoutingKey } from 'ipns'\nimport { generateKeyPair } from '@libp2p/crypto/keys'\n\nconst privateKey = await generateKeyPair('Ed25519')\nconst routingKey = multihashToIPNSRoutingKey(privateKey.publicKey.toMultihash())\nconst marshalledRecord = Uint8Array.from([0, 1, 2, 3])\n\nawait ipnsValidator(routingKey, marshalledRecord)\n```\n\n## Example - Extract public key from record\n\n```TypeScript\nimport { extractPublicKeyFromIPNSRecord, createIPNSRecord } from 'ipns'\nimport { generateKeyPair } from '@libp2p/crypto/keys'\n\nconst privateKey = await generateKeyPair('Ed25519')\nconst record = await createIPNSRecord(privateKey, 'hello world', 0, 3_600_000)\n\nconst publicKey = await extractPublicKeyFromIPNSRecord(record)\n```\n\n## Example - Marshal data with proto buffer\n\n```TypeScript\nimport { createIPNSRecord, marshalIPNSRecord } from 'ipns'\nimport { generateKeyPair } from '@libp2p/crypto/keys'\n\nconst privateKey = await generateKeyPair('Ed25519')\nconst record = await createIPNSRecord(privateKey, 'hello world', 0, 3_600_000)\n// ...\nconst marshalledData = marshalIPNSRecord(record)\n// ...\n```\n\nReturns the record data serialized.\n\n## Example - Unmarshal data from proto buffer\n\n```TypeScript\nimport { unmarshalIPNSRecord } from 'ipns'\n\nconst storedData = Uint8Array.from([0, 1, 2, 3, 4])\nconst ipnsRecord = unmarshalIPNSRecord(storedData)\n```\n\nReturns the `IPNSRecord` after being deserialized.\n\n# Install\n\n```console\n$ npm i ipns\n```\n\n## Browser `<script>` tag\n\nLoading this module through a script tag will make its exports available as `Ipns` in the global namespace.\n\n```html\n<script src=\"https://unpkg.com/ipns/dist/index.min.js\"></script>\n```\n\n# API Docs\n\n- <https://ipfs.github.io/js-ipns>\n\n# License\n\nLicensed under either of\n\n- Apache 2.0, ([LICENSE-APACHE](https://github.com/ipfs/js-ipns/LICENSE-APACHE) / <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT ([LICENSE-MIT](https://github.com/ipfs/js-ipns/LICENSE-MIT) / <http://opensource.org/licenses/MIT>)\n\n# Contribute\n\nContributions welcome! Please check out [the issues](https://github.com/ipfs/js-ipns/issues).\n\nAlso see our [contributing document](https://github.com/ipfs/community/blob/master/CONTRIBUTING_JS.md) for more information on how we work, and about contributing in general.\n\nPlease be aware that all interactions related to this repo are subject to the IPFS [Code of Conduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.\n\n[![](https://cdn.rawgit.com/jbenet/contribute-ipfs-gif/master/img/contribute.gif)](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md)\n"
  },
  "ipfs/helia-delegated-routing-v1-http-api": {
    "fetchedAt": "2025-11-12T22:44:48.396Z",
    "content": "<p align=\"center\">\n  <a href=\"https://github.com/ipfs/helia\" title=\"Helia\">\n    <img src=\"https://raw.githubusercontent.com/ipfs/helia/main/assets/helia.png\" alt=\"Helia logo\" width=\"300\" />\n  </a>\n</p>\n\n# helia-delegated-routing-v1-http-api\n\n[![ipfs.tech](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](https://ipfs.tech)\n[![Discuss](https://img.shields.io/discourse/https/discuss.ipfs.tech/posts.svg?style=flat-square)](https://discuss.ipfs.tech)\n[![codecov](https://img.shields.io/codecov/c/github/ipfs/helia-delegated-routing-v1-http-api.svg?style=flat-square)](https://codecov.io/gh/ipfs/helia-delegated-routing-v1-http-api)\n[![CI](https://img.shields.io/github/actions/workflow/status/ipfs/helia-delegated-routing-v1-http-api/js-test-and-release.yml?branch=main\\&style=flat-square)](https://github.com/ipfs/helia-delegated-routing-v1-http-api/actions/workflows/js-test-and-release.yml?query=branch%3Amain)\n\n> The Delegated Routing V1 HTTP API powered by Helia\n\n## About\n\nThis repo contains a server implementation of the IPFS [Delegated Routing V1 HTTP API](https://specs.ipfs.tech/routing/http-routing-v1/) along with a client that can be used to interact with any compliant server implementation.\n\n# Packages\n\n- [`packages/client`](https://github.com/ipfs/helia-delegated-routing-v1-http-api/tree/main/packages/client) A Delegated Routing V1 HTTP API client\n- [`packages/interop`](https://github.com/ipfs/helia-delegated-routing-v1-http-api/tree/main/packages/interop) Interop tests for the Delegated Routing V1 HTTP API server powered by Helia\n- [`packages/server`](https://github.com/ipfs/helia-delegated-routing-v1-http-api/tree/main/packages/server) A Delegated Routing V1 HTTP API server powered by Helia\n\n# API Docs\n\n- <https://ipfs.github.io/helia-delegated-routing-v1-http-api>\n\n# License\n\nLicensed under either of\n\n- Apache 2.0, ([LICENSE-APACHE](https://github.com/ipfs/helia-delegated-routing-v1-http-api/blob/main/LICENSE-APACHE) / <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT ([LICENSE-MIT](https://github.com/ipfs/helia-delegated-routing-v1-http-api/blob/main/LICENSE-MIT) / <http://opensource.org/licenses/MIT>)\n\n# Contribute\n\nContributions welcome! Please check out [the issues](https://github.com/ipfs/helia-delegated-routing-v1-http-api/issues).\n\nAlso see our [contributing document](https://github.com/ipfs/community/blob/master/CONTRIBUTING_JS.md) for more information on how we work, and about contributing in general.\n\nPlease be aware that all interactions related to this repo are subject to the IPFS [Code of Conduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.\n\n[![](https://cdn.rawgit.com/jbenet/contribute-ipfs-gif/master/img/contribute.gif)](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md)\n"
  },
  "ipfs/js-stores": {
    "fetchedAt": "2025-11-12T22:44:48.780Z",
    "content": "# stores\n\n[![ipfs.tech](https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square)](https://ipfs.tech)\n[![Discuss](https://img.shields.io/discourse/https/discuss.ipfs.tech/posts.svg?style=flat-square)](https://discuss.ipfs.tech)\n[![codecov](https://img.shields.io/codecov/c/github/ipfs/js-stores.svg?style=flat-square)](https://codecov.io/gh/ipfs/js-stores)\n[![CI](https://img.shields.io/github/actions/workflow/status/ipfs/js-stores/js-test-and-release.yml?branch=main\\&style=flat-square)](https://github.com/ipfs/js-stores/actions/workflows/js-test-and-release.yml?query=branch%3Amain)\n\n> Blockstores and datastores used by IP-JS internals\n\n# Packages\n\n- [`packages/blockstore-core`](https://github.com/ipfs/js-stores/tree/main/packages/blockstore-core) Contains various implementations of the API contract described in interface-blockstore\n- [`packages/blockstore-fs`](https://github.com/ipfs/js-stores/tree/main/packages/blockstore-fs) Blockstore implementation with file system backend\n- [`packages/blockstore-idb`](https://github.com/ipfs/js-stores/tree/main/packages/blockstore-idb) Blockstore implementation with IndexedDB backend\n- [`packages/blockstore-level`](https://github.com/ipfs/js-stores/tree/main/packages/blockstore-level) Blockstore implementation with level(up|down) backend\n- [`packages/blockstore-s3`](https://github.com/ipfs/js-stores/tree/main/packages/blockstore-s3) IPFS blockstore implementation backed by s3\n- [`packages/datastore-core`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-core) Wrapper implementation for interface-datastore\n- [`packages/datastore-fs`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-fs) Datastore implementation with file system backend\n- [`packages/datastore-idb`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-idb) Datastore implementation with IndexedDB backend.\n- [`packages/datastore-level`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-level) Datastore implementation with level(up|down) backend\n- [`packages/datastore-s3`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-s3) IPFS datastore implementation backed by s3\n- [`packages/interface-blockstore`](https://github.com/ipfs/js-stores/tree/main/packages/interface-blockstore) An interface for storing and retrieving blocks\n- [`packages/interface-blockstore-tests`](https://github.com/ipfs/js-stores/tree/main/packages/interface-blockstore-tests) Compliance tests for the blockstore interface\n- [`packages/interface-datastore`](https://github.com/ipfs/js-stores/tree/main/packages/interface-datastore) datastore interface\n- [`packages/interface-datastore-tests`](https://github.com/ipfs/js-stores/tree/main/packages/interface-datastore-tests) Compliance tests for the datastore interface\n- [`packages/interface-store`](https://github.com/ipfs/js-stores/tree/main/packages/interface-store) A generic interface for storing and retrieving data\n\n# API Docs\n\n- <https://ipfs.github.io/js-stores>\n\n# License\n\nLicensed under either of\n\n- Apache 2.0, ([LICENSE-APACHE](https://github.com/ipfs/js-stores/blob/main/LICENSE-APACHE) / <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT ([LICENSE-MIT](https://github.com/ipfs/js-stores/blob/main/LICENSE-MIT) / <http://opensource.org/licenses/MIT>)\n\n# Contribute\n\nContributions welcome! Please check out [the issues](https://github.com/ipfs/js-stores/issues).\n\nAlso see our [contributing document](https://github.com/ipfs/community/blob/master/CONTRIBUTING_JS.md) for more information on how we work, and about contributing in general.\n\nPlease be aware that all interactions related to this repo are subject to the IPFS [Code of Conduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.\n\n[![](https://cdn.rawgit.com/jbenet/contribute-ipfs-gif/master/img/contribute.gif)](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md)\n"
  },
  "gelatodigital/relay-sdk": {
    "fetchedAt": "2025-11-12T22:44:56.468Z",
    "content": "# Gelato Relay SDK <!-- omit in toc -->\n\n- [Documentation](https://docs.gelato.network/developer-products/gelato-relay-sdk)\n"
  },
  "gelatodigital/automate-sdk": {
    "fetchedAt": "2025-11-12T22:45:04.307Z",
    "content": "# Gelato Automate SDK <!-- omit in toc -->\n\nAutomate your smart contracts using Automate SDK\n\n- [Installation](#installation)\n- [How to use?](#how-to-use)\n- [Examples](#examples)\n\n## Installation\n\n```bash\nyarn add @gelatonetwork/automate-sdk\n```\n\nor\n\n```bash\nnpm install @gelatonetwork/automate-sdk\n```\n\n## How to use?\n\n1. Import the Automate SDK into your project:\n\n```typescript\nimport { AutomateSDK } from \"@gelatonetwork/automate-sdk\";\n```\n\n2. Instantiate Automate using the static `create` method with your chain ID and signer:\n\n```typescript\nconst automate = await AutomateSDK.create(chainId, signer);\n```\n\n3. Create an automation task:\n\n```typescript\ninterface CreateTaskOptions {\n  name: string; // your task name\n\n  // Function to execute\n  execAddress: string; // address of your target smart contract\n  execSelector: string; // function selector to execute on your target smart contract\n  execAbi?: string; // ABI of your target smart contract\n\n  // Proxy caller\n  dedicatedMsgSender: boolean; // task will be called via a dedicated msg.sender which you can whitelist (recommended: true)\n\n  // Optional: Pre-defined / static target smart contract inputs\n  execData?: string; // exec call data\n\n  // Optional: Dynamic target smart contract inputs (using a resolver)\n  resolverAddress?: string; // resolver contract address\n  resolverData?: string; // resolver call data (encoded data with function selector)\n  resolverAbi?: string; // your resolver smart contract ABI\n\n  // Optional: Single execution task\n  singleExec?: boolean; // task cancels itself after 1 execution if true.\n\n  // Web3 function params\n  web3FunctionHash?: string; // ipfs hash of your web3 function\n  web3FunctionArgs?: { [key: string]: unknown }; // web3 function arguments object\n\n  // Optional: Payment params\n  useTreasury?: boolean; // use false if your task is self-paying (default: true)\n\n  // Optional: Trigger params, 60s time interval trigger as default if undefined\n  trigger?:\n    | {\n        type: TriggerType.TIME; // time interval trigger\n        interval: number; // task interval in ms\n        start?: number; // task start timestamp, task will start immediately if undefined or 0\n      }\n    | {\n        type: TriggerType.CRON; // cron trigger\n        cron: string; // cron expression\n      };\n    | {\n        type: TriggerType.EVENT; // event trigger\n        filter: {\n          address: string; // address to listen events for\n          topics: Array<Array<string | null>>; // topics to listen for check Ethers.js doc (https://docs.ethers.org/v5/concepts/events/#events--filters)\n        };\n        blockConfirmations: number; // number of blocks to confirm event before triggering\n      };\n    |\n      {\n        type: TriggerType.BLOCK; // block trigger\n      };\n}\n\nconst params: CreateTaskOptions = {\n  name,\n  execAddress,\n  execSelector,\n  interval,\n  dedicatedMsgSender,\n};\nconst { taskId, tx }: TaskTransaction = await automate.createTask(params);\nawait tx.wait(); // Optionally wait for tx confirmation\nconsole.log(`Task created, taskId: ${taskId} (tx hash: ${tx.hash})`);\n```\n\n4. Retrieve all your tasks:\n\n```typescript\nconst activeTasks = await automate.getActiveTasks();\nactiveTasks.forEach((task: Task) => {\n  console.log(`- ${task.name} (${task.taskId})`);\n});\n```\n\n5. Rename a task:\n\n```typescript\nawait automate.renameTask(taskId, \"Another Gelato name\");\n```\n\n6. Cancel a task:\n\n```typescript\nconst { taskId, tx }: TaskTransaction = await automate.cancelTask(taskId);\nawait tx.wait(); // Optionally wait for tx confirmation\nconsole.log(`Task canceled, taskId: ${taskId} (tx hash: ${tx.hash})`);\n```\n\n7. Overriding gas settings:\n\nIf you need to override gas settings, you can pass an additional `Overrides` object to `createTask` & `cancelTask` methods:\n\n```typescript\nconst params: CreateTaskOptions = {\n  name,\n  execAddress,\n  execSelector,\n  interval,\n  dedicatedMsgSender,\n};\nconst overrides: Overrides = { gasLimit: 2000000 };\nconst tx: TaskTransaction = await automate.createTask(params, overrides);\n```\n\n8. Whitelisting msg.sender of function:\n\nIf you enabled `dedicatedMsgSender`, your task will be called via a dedicated `msg.sender` which you can whitelist on your smart contract for extra security.\n\nIf `dedicatedMsgSender` is set to false, `msg.sender` of the task will be the Automate contract.\n\nTo fetch your dedicated `msg.sender`:\n\n```typescript\nconst { address } = await automate.getDedicatedMsgSender();\nconsole.log(\"Dedicated msg.sender: \", address);\n```\n\n## Examples\n\nCheck out our tutorial repository [automate-sdk-hello-world](https://github.com/gelatodigital/automate-sdk-hello-world) for more in-depth examples.\n"
  },
  "NomicFoundation/edr": {
    "fetchedAt": "2025-11-12T22:45:11.781Z",
    "content": "# EDR - Ethereum Development Runtime\n\n**EDR**, or **Ethereum Development Runtime** in full, is a library for creating developer tooling on top of the Ethereum Virtual Machine (EVM), such as an EVM debugger or state inspector. EDR provides a performant API, written in Rust, with bindings for the Node API (TypeScript).\n\nEDR finds its origins in Hardhat but will be a complete rewrite of our Hardhat Network TypeScript code to Rust, incorporating all of the lessons we have learned over the years, and much more to come.\n"
  },
  "nomicfoundation/hardhat": {
    "fetchedAt": "2025-11-12T22:45:12.218Z",
    "content": "![](https://raw.githubusercontent.com/NomicFoundation/hardhat/main/img/hardhat-header.png)\n\nHardhat is an Ethereum development environment for professionals. It facilitates performing frequent tasks, such as running tests, automatically checking code for mistakes or interacting with smart contracts.\n\nBuilt by the [Nomic Foundation](https://nomic.foundation/) for the Ethereum community.\n\n---\n\n> üí° This is the README for Hardhat 3, the new major version of Hardhat. For the previous version (v2), see [this branch](https://github.com/NomicFoundation/hardhat/tree/v2) instead.\n\n---\n\n## Getting started\n\nTo install Hardhat and initialize a new project, run the following command in an empty directory:\n\n```bash\nnpx hardhat --init\n```\n\nThis will take you through an interactive setup process to get started.\n\n## Learn more\n\nTo learn more about Hardhat, check out the [documentation](https://hardhat.org/docs/).\n\n## Contributing\n\nContributions are always welcome! Feel free to open any issue or send a pull request.\n\nGo to [CONTRIBUTING.md](https://github.com/NomicFoundation/hardhat/blob/main/CONTRIBUTING.md) to learn about how to set up Hardhat's development environment.\n"
  },
  "vaariance/variance-dart": {
    "fetchedAt": "2025-11-12T22:45:19.798Z",
    "content": "# Variance SDK\n\nVariance is a comprehensive toolkit for Ethereum Account Abstraction development, streamlining the creation and management of smart accounts and their interactions with Entrypoints. Built on top of the [Web3dart](https://pub.dev/packages/web3dart) library, it provides a robust foundation for blockchain development.\n\n## Features\n\n- **Smart Contract Integration:** Seamlessly handle ABI encoding and decoding for smooth interaction with Solidity smart contracts and the Entrypoint.\n- **Streamlined Operations:** Build and execute UserOperations with minimal complexity\n- **Token Management:** Comprehensive support for ERC20 and ERC721 token operations, from transfers to approvals\n- **RPC Connectivity:** Direct interface with Ethereum networks and bundler services\n- **Advanced Authentication:** Enable secure transaction signing using Passkeys.\n\n## Getting Started\n\n### Installation\n\nopen your terminal and run the following command:\n\n```sh\nflutter pub add variance_dart\nflutter pub add web3_signers\nflutter pub add web3dart\n```\n\n### Usage\n\n```dart\n// Import the packages\nimport 'package:web3_signers/web3_signers.dart';\nimport 'package:variance_dart/variance_dart.dart';\nimport 'package:web3dart/web3dart.dart';\n```\n\n### Chain Configuration\n\nVariance now supports using your favorite closed source bundlers.\nYou can set api-keys to the headers like below or leave empty:\n\n```dart\nconst bundler = \"https://api.pimlico.io/v2/84532/rpc?apikey=API_KEY\";\n\nfinal Chain chain = Chain(\n            bundlerUrl:  (url: bundler, headers: {'x-api-key': 'api-key'}),\n            paymasterUrl: (url: bundleUrl, headers: {'x-api-key': 'api-key'}),\n            testnet: true,\n            chainId: 84532,\n            jsonRpcUrl: \"https://sepolia.base.org\",\n            accountFactory: Addresses.safeProxyFactoryAddress,\n            explorer: \"https://base-sepolia.blockscout.com/\",\n            entrypoint: EntryPointAddress.v07);\n```\n\nWhen creating Safe/Modular Accounts, specify `Addresses.safeProxyFactoryAddress` as the account factory address.\nWhen creating LightAccounts, specify `Addresses.lightAccountFactoryAddress` as the account factory address.\n\nThe SDK supports all EVM compatible networks.\n\nPaymaster Configuration:\n\n- By default, no paymaster is configured (null)\n- To enable paymaster functionality, provide the paymaster's RPC endpoint when setting up your smart wallet\n- Additional paymaster settings can be configured after wallet creation:\n\n```dart\nwallet.paymasterAddress = Address.fromHex(\"0x\");\nwallet.paymasterContext = {'key': 'value'};\n```\n\n### Signers\n\nCreating a smart wallet client requires configuring a signer to validate useroperation hashes on-chain. The signer must be from the [web3signers](https://pub.dev/packages/web3_signers) package.\n\n> Each account type requires a specific signer configuration:\n\n1. `PrivateKeys` - Compatible with all account types\n2. `Passkey` - Specifically for Safe Passkey and modular accounts\n3. `EOA Wallet (seed phrases)` - Compatible with all account types\n\nVisit the [web3signers](https://pub.dev/packages/web3_signers) documentation for complete implementation details.\n\n### Smart Wallet Factory\n\nBefore creating a smart wallet instance, initialize a SmartWalletFactory using your chain configuration and signer (configured in the steps above).\n\n```dart\nfinal SmartWalletFactory smartWalletFactory = SmartWalletFactory(chain, signer);\n```\n\n### To Create an Alchemy Light Account\n\nWhen using an [Alchemy Light Account](https://accountkit.alchemy.com/smart-contracts/light-account), you must configure your signer with a signature prefix. Add a `Uint8` prefix value when initializing your web3_signer - this prefix will be automatically included in all signatures generated for your smart wallet.\nExample:\n\n```dart\n// prefix is required for alchemy light accounts\nfinal salt = Uint256.zero;\nconst prefix = const SignatureOptions(prefix: [0])\nfinal signer = EOAWallet.createWallet(WordLength.word_12, prefix);\nfinal smartWalletFactory = SmartWalletFactory(chain, signer);\n\nfinal Smartwallet wallet = await smartWalletFactory.createAlchemyLightAccount(salt);\nprint(\"light account wallet address: ${wallet.address.with0x}\");\n```\n\n### To create a [Safe](https://safe.global) Smart Account\n\n```dart\nfinal salt = Uint256.zero;\nfinal signer = EOAWallet.createWallet();\nfinal smartWalletFactory = SmartWalletFactory(chain, signer);\n\nfinal Smartwallet wallet = await smartWalletFactory.createSafeAccount(salt);\nprint(\"safe wallet address: ${wallet.address.with0x}\");\n```\n\n> For all safe accounts including modular accounts, the `safeSingleton` address can be customized during account creation. If not specified, it defaults to `SafeSingletonAddress.l1` for mainnet or `SafeSingletonAddress.l2` for L2 chains.\n\n### To create a [Safe](https://safe.global) Smart Account with Passkey\n\n```dart\nfinal salt = Uint256.zero;\nfinal options = PassKeysOptions(\n          name: \"domain\",\n          namespace: \"domain.com\",\n          authenticatorAttachment: \"cross-platform\",\n          sharedWebauthnSigner: Addresses.sharedSignerAddress,\n        );\nfinal signer = PassKeySigner(options: options);\nfinal smartWalletFactory = SmartWalletFactory(chain, signer);\nfinal keypair = await signer.register(name, displayName); // email can be used in place of name\n\nfinal Smartwallet wallet = await smartWalletFactory.createSafeAccountWithPasskey(\n           keypair, salt);\nprint(\"p256 wallet address: ${wallet.address.with0x}\");\n```\n\n> The `PassKeyPair` object, obtained during registration with your `PasskeySigner`, is required for this operation.\n> It is recommended serialize and persist the keypair for later use in your application.\n\n### To create a [Modular Safe](https://docs.safe.global/advanced/erc-7579/7579-safe) Smart Account\n\nFor more details about the technical specifications and implementation, visit [ERC7579](https://erc7579.com/) and [Rhinestone](https://rhinestone.dev).\n\nTo access all available modules, install the `eip7579` package by running: `flutter pub add eip7579`\n\n```dart\nfinal salt = Uint256.zero;\nfinal launchpad =\n        Address.fromHex(\"0x7579011aB74c46090561ea277Ba79D510c6C00ff\");\n    final attester =\n        Address.fromHex(\"0x000000333034E9f539ce08819E12c1b8Cb29084d\");\nfinal signer = EOAWallet.createWallet();\n\nfinal smartWalletFactory = SmartWalletFactory(chain, signer);\n\nfinal Smartwallet wallet = await smartWalletFactory.createSafe7579Account(salt, launchpad,\n              attesters: [attester], attestersThreshold: 1);\nprint(\"safe wallet address: ${wallet.address.with0x}\");\n```\n\n> For all Modular Accounts, Additional modules (`validator`, `hooks`, `executors`, or `fallback`) can be initialized during account creation. For Passkey-enabled accounts, the `WebAuthnValidator` module must be included during initialization.\n\n### To create a [Modular Safe](https://docs.safe.global/advanced/erc-7579/7579-safe) Smart Account with Passkey\n\nNote that you must initialize the `WebAuthnValidator` module when creating the safe account.\n\n```dart\nimport 'package:eip7579/eip7579.dart';\n\nfinal salt = Uint256.zero;\nfinal options = PassKeysOptions(\n          name: \"domain\",\n          namespace: \"domain.com\",\n          authenticatorAttachment: \"cross-platform\",\n          sharedWebauthnSigner: Addresses.sharedSignerAddress,\n        );\n\nfinal signer = PassKeySigner(options: options);\nfinal smartWalletFactory = SmartWalletFactory(chain, signer);\n\nfinal keypair = await signer.register(name, displayName);\nfinal launchpad =\n        Address.fromHex(\"0x7579011aB74c46090561ea277Ba79D510c6C00ff\");\n    final attester =\n        Address.fromHex(\"0x000000333034E9f539ce08819E12c1b8Cb29084d\");\nfinal signer = EOAWallet.createWallet();\n\nfinal smartWalletFactory = SmartWalletFactory(chain, signer);\n\nSmartwallet wallet = await smartWalletFactory.createSafe7579AccountWithPasskey(\n              keypair, salt, launchpad,\n              attesters: [attester],\n              attestersThreshold: 1,\n              validators: List.f\n\n[... truncated ...]"
  },
  "merkletreejs/merkletreejs": {
    "fetchedAt": "2025-11-12T22:45:28.426Z",
    "content": "<h3 align=\"center\">\n  <br />\n  <img src=\"https://user-images.githubusercontent.com/4885186/193118010-2a9f5129-6232-42bd-8efe-dfb29753508e.png\" alt=\"merkletree.js logo\" width=\"600\" />\n  <br />\n  <br />\n  <br />\n</h3>\n\n# MerkleTree.js\n\n> Construct [Merkle Trees](https://en.wikipedia.org/wiki/Merkle_tree) and verify proofs in JavaScript.\n\n[![License](http://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/miguelmota/merkletreejs/master/LICENSE)\n[![Documentation](https://img.shields.io/badge/documentation-latest-blue.svg)](https://github.com/miguelmota/merkletreejs/tree/master/docs)\n[![NPM version](https://badge.fury.io/js/merkletreejs.svg)](http://badge.fury.io/js/merkletreejs)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](#contributing)\n\n## Contents\n\n- [Install](#install)\n- [Example](#example)\n- [Getting started](#Getting-started)\n- [Diagrams](#diagrams)\n- [Documentation](#documentation)\n- [Test](#test)\n- [FAQ](#faq)\n- [Notes](#notes)\n- [Resources](#resources)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Install\n\nFrom [NPM](https://www.npmjs.com/package/merkletreejs):\n\n```bash\nnpm install merkletreejs\n```\n\nImport as ES6 module\n\n```js\nimport { MerkleTree } from 'merkletreejs'\n```\n\nImport as path import\n\n```js\nimport { MerkleTree } from 'merkletreejs/MerkleTree'\n```\n\nImport as CommonJs\n\n```js\nconst { MerkleTree } = require('merkletreejs')\n```\n\n### CDN\n\nAvailable on [jsDelivr](https://www.jsdelivr.com/) CDN:\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/merkletreejs@latest/merkletree.js\"></script>\n```\n\nThe exported classes will be available on `window` object, e.g. `window.MerkleTree`\n\n## Example\n\n[https://lab.miguelmota.com/merkletreejs](https://lab.miguelmota.com/merkletreejs)\n\n## Getting started\n\nConstruct tree, generate proof, and verify proof:\n\n```js\nconst { MerkleTree } = require('merkletreejs')\nconst SHA256 = require('crypto-js/sha256')\n\nconst leaves = ['a', 'b', 'c'].map(x => SHA256(x))\nconst tree = new MerkleTree(leaves, SHA256)\nconst root = tree.getRoot().toString('hex')\nconst leaf = SHA256('a')\nconst proof = tree.getProof(leaf)\nconsole.log(tree.verify(proof, leaf, root)) // true\n\n\nconst badLeaves = ['a', 'x', 'c'].map(x => SHA256(x))\nconst badTree = new MerkleTree(badLeaves, SHA256)\nconst badLeaf = SHA256('x')\nconst badProof = badTree.getProof(badLeaf)\nconsole.log(badTree.verify(badProof, badLeaf, root)) // false\n```\n\nPrint tree to console:\n\n```js\nconsole.log(tree.toString())\n```\n\nOutput:\n\n```bash\n‚îî‚îÄ 7075152d03a5cd92104887b476862778ec0c87be5c2fa1c0a90f87c49fad6eff\n   ‚îú‚îÄ e5a01fee14e0ed5c48714f22180f25ad8365b53f9779f79dc4a3d7e93963f94a\n   ‚îÇ  ‚îú‚îÄ ca978112ca1bbdcafac231b39a23dc4da786eff8147c4e72b9807785afee48bb\n   ‚îÇ  ‚îî‚îÄ 3e23e8160039594a33894f6564e1b1348bbd7a0088d42c4acb73eeaed59c009d\n   ‚îî‚îÄ 2e7d2c03a9507ae265ecf5b5356885a53393a2029d241394997265a1a25aefc6\n      ‚îî‚îÄ 2e7d2c03a9507ae265ecf5b5356885a53393a2029d241394997265a1a25aefc6\n```\n\n## Diagrams\n\n‚ñæ Visualization of Merkle Tree\n\n<img src=\"https://user-images.githubusercontent.com/168240/43616375-15330c32-9671-11e8-9057-6e61c312c856.png\" alt=\"Merkle Tree\" width=\"500\">\n\n‚ñæ Visualization of Merkle Tree Proof\n\n<img src=\"https://user-images.githubusercontent.com/168240/204968384-dbd16f5b-415c-4cc6-b993-5bbd7599ec8b.png\" alt=\"Merkle Tree Proof\" width=\"420\">\n\n‚ñæ Visualization of Invalid Merkle Tree Proofs\n\n<img src=\"https://user-images.githubusercontent.com/168240/204968414-fefedb52-d27f-4b14-bf70-e3f96a50b6a3.png\" alt=\"Merkle Tree Proof\" width=\"420\">\n\n‚ñæ Visualization of Bitcoin Merkle Tree\n\n<img src=\"https://user-images.githubusercontent.com/168240/43616417-46d3293e-9671-11e8-81c3-8cdf7f8ddd77.png\" alt=\"Merkle Tree Proof\" width=\"420\">\n\n## Documentation\n\nSee [documentation](docs/classes/_src_merkletree_.merkletree.md) (under [docs/](docs/))\n\n## Test\n\n```bash\nnpm test\n```\n\n## FAQ\n\n- Q: How do you verify merkle proofs in Solidity?\n  - A: Check out the example repo [merkletreejs-solidity](https://github.com/miguelmota/merkletreejs-solidity) on how to generate merkle proofs with this library and verify them in Solidity.\n\n- Q: How do you verify merkle [multiproofs](https://github.com/ethereum/eth2.0-specs/blob/dev/ssz/merkle-proofs.md#merkle-multiproofs) in Solidity?\n  - A: Check out the example repo [merkletreejs-multiproof-solidity](https://github.com/miguelmota/merkletreejs-multiproof-solidity) on how to generate merkle multiproofs with this library and verify them in Solidity.\n\n- Q: Is there an NFT whitelist example in Solidity?\n  - A: Check out the example repo [merkletreejs-nft-whitelist](https://github.com/miguelmota/merkletreejs-nft-whitelist) on how to generate merkle root of whitelisted accounts and merkle proofs with this library and verify them in Solidity.\n\n- Q: What other types of merkle trees are supported?\n\n  - Besides standard [`MerkleTree`](./README-MerkleTree.md), there's these implementation classes available:\n    - [`MerkleMountainRange`](./README-MerkleMountainRange.md)\n    - [`MerkleSumTree`](./README-MerkleSumTree.md)\n    - [`IncrementalMerkleTree`](./README-IncrementalMerkleTree.md)\n    - [`MerkleRadixTree`](./README-MerkleRadixTree.md)\n    - [`UnifiedBinaryTree`](./README-UnifiedBinaryTree.md) (EIP-7864)\n\n    Example import of other classes:\n\n    ```js\n    import { MerkleMountainRange } from 'merkletreejs/MerkleMountainRange'\n    ```\n\n    Note: For Merkle Patricia Tree, see [`@ethereumjs/trie`](https://www.npmjs.com/package/@ethereumjs/trie).\n\n- Q: How do I hash a JSON object?\n\n- See [`https://www.npmjs.com/package/json-stable-stringify`](https://www.npmjs.com/package/json-stable-stringify) for deterministic stringifying of JSON objects.\n\n- Q: Is there a CLI version of this library?\n\n  - Yes, see [merkletreejs-cli](https://github.com/miguelmota/merkletreejs-cli).\n\n- Q: Is there a way to visualize the merkle trees in the browser?\n\n  - Yes, see [example ui](https://lab.miguelmota.com/merkletreejs) and [merkletree-viz](https://github.com/miguelmota/merkletree-viz).\n\n## Notes\n\nAs is, this implementation is vulnerable to a [second pre-image attack](https://en.wikipedia.org/wiki/Merkle_tree#Second_preimage_attack). Use a difference hashing function for leaves and nodes, so that `H(x) != H'(x)`.\n\nAlso, as is, this implementation is vulnerable to a forgery attack for an unbalanced tree, where the last leaf node can be duplicated to create an artificial balanced tree, resulting in the same Merkle root hash. Do not accept unbalanced tree to prevent this. More info [here](https://bitcointalk.org/?topic=102395).\n\nPlease use the library [`@openzeppelin/merkle-tree`](https://github.com/OpenZeppelin/merkle-tree) if you're integrating with OpenZeppelin contracts or using multiproofs. There are known issues with the current multiproof implementation as pointed out in [issues](https://github.com/merkletreejs/merkletreejs/issues/63).\n\n### Disclaimer\n\nThis library was created for my own purposes and is provided as-is. Use at your own risk.\n\n## Resources\n\n- [Bitcoin mining the hard way: the algorithms, protocols, and bytes](http://www.righto.com/2014/02/bitcoin-mining-hard-way-algorithms.html)\n\n- [Bitcoin Talk - Merkle Trees](https://bitcointalk.org/index.php?topic=403231.msg9054025#msg9054025)\n\n- [How Log Proofs Work](https://www.certificate-transparency.org/log-proofs-work)\n\n- [Raiden Merkle Tree Implementation](https://github.com/raiden-network/raiden/blob/f9cf12571891cdf54feb4667cd2fffcb3d5daa89/raiden/mtree.py)\n\n- [Why aren't Solidity sha3 hashes not matching what other sha3 libraries produce?](https://ethereum.stackexchange.com/questions/559/why-arent-solidity-sha3-hashes-not-matching-what-other-sha3-libraries-produce)\n\n- [What is the purpose of using different hash functions for the leaves and internals of a hash tree?](https://crypto.stackexchange.com/questions/2106/what-is-the-purpose-of-using-different-hash-functions-for-the-leaves-and-interna)\n\n- [Why is the full Merkle path needed to verify a transaction?](https://bitcoin.s\n\n[... truncated ...]"
  },
  "OpenZeppelin/ethernaut": {
    "fetchedAt": "2025-11-12T22:45:35.553Z",
    "content": "# Ethernaut\n \n[![Twitter Follow](https://img.shields.io/twitter/follow/OpenZeppelin?style=plastic&logo=twitter)](https://twitter.com/OpenZeppelin)\n[![OpenZeppelin Forum](https://img.shields.io/badge/Ethernaut%20Forum%20-discuss-blue?style=plastic&logo=discourse)](https://forum.openzeppelin.com/tag/ethernaut)\n\nEthernaut is a Web3/Solidity based wargame inspired by [overthewire](https://overthewire.org), to be played in the Ethereum Virtual Machine. Each level is a smart contract that needs to be 'hacked'.\n\nThe game acts both as a tool for those interested in learning ethereum, and as a way to catalogue historical hacks as levels. There can be an infinite number of levels and the game does not require to be played in any particular order.\n\n## Deployed Versions\n\nYou can find the current, official version at: [ethernaut.openzeppelin.com](https://ethernaut.openzeppelin.com)\n\n## Install and Build\n\nThere are three components to Ethernaut that are needed to run/deploy in order to work with it locally:\n\n- Test Network - A testnet that is running locally, like ganache, hardhat network, geth, etc\n- Contract Deployment - In order to work with the contracts, they must be deployed to the locally running testnet\n- The Client/Frontend - This is a React app that runs locally and can be accessed on localhost:3000\n\nIn order to install, build, and run Ethernaut locally, follow these instructions:\n\n0. Be sure to use a compatible Node version. If you use `nvm` you can run `nvm use` at the root level to be sure to select a compatible version.\n\n1. Clone the repo and install dependencies:\n\n    ```bash\n    git clone git@github.com:OpenZeppelin/ethernaut.git\n    cd ethernaut\n    yarn install\n    ```\n\n2. Start deterministic rpc\n\n    ```bash\n    yarn network\n    ```\n\n3. Import one of the private keys from the ganache-cli output to your Metamask wallet.\n4. Compile contracts\n\n    ```bash\n    yarn compile:contracts\n    ```\n\n5. Set `client/src/constants.js` `ACTIVE_NETWORK` to `NETWORKS.LOCAL`\n6. Deploy contracts\n\n    ```bash\n    yarn deploy:contracts\n    ```\n\n7. Start Ethernaut locally\n\n    ```bash\n    yarn start:ethernaut\n    ```\n\n### Running locally (sepolia network)\n\nThe same as using the local network but steps 2, 3 and 6 are not necessary.\n\nIn this case, replace point 5 with:\n5. Set `client/src/constants.js` `ACTIVE_NETWORK` to `NETWORKS.SEPOLIA`\n\n### Running tests\n\n```bash\nyarn test:contracts\n```\n\n### Building\n\n```bash\nyarn build:ethernaut\n```\n\n### Deploying\n\nYou will normally need to deploy it on a local network, for this you can just run `yarn deploy:contracts` and all the contracts will be deployed on your local node running on `localhost:8545` and you will be able to check each level address in the `deploy.local.json` file.\n\nTo deploy the contracts on Sepolia, first set the `ACTIVE_NETWORK` variable in `constants.js` and then edit `deploy.sepolia.json`. This file keeps a history of all level and contract instances. To deploy a new instance, add an \"x\" entry to the array, like so:\n\n```json\n{\n  \"0\": \"x\",\n  \"1\": \"0x4b1d5eb6cd2849c7890bcacd63a6855d1c0e79d5\",\n  \"2\": \"0xdf51a9e8ce57e7787e4a27dd19880fd7106b9a5c\",\n  ...\n},\n```\n\nThen run `yarn deploy:contracts`.\n\n## Contributing\n\nContributions and corrections are always welcome!\n\nPlease follow the [Contributor's Guide](./CONTRIBUTING.md) if you would like to help out.\n"
  },
  "DexKit/open-nft-marketplace": {
    "fetchedAt": "2025-11-12T22:45:43.306Z",
    "content": "# NFT Marketplace [![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Open%20source%20nft%20marketplace:&url=https://github.com/DexKit/open-nft-marketplace)\n\n[![NFT marketplace](https://img.youtube.com/vi/9UxtgAkNG1k/0.jpg)](https://www.youtube.com/watch?v=9UxtgAkNG1k 'Marketplace by DexKit')\n\nThis marketplace is the DexKit open source showcase on how to use 0x v4 nft smart contracts on a production app. Additionally, we are building a [zero code solution](https://whitelabel-nft.dexkit.com/admin/setup) with premium features to help artists deploy their own marketplace in an easy and secure way. Check our docs about it [here](https://docs.dexkit.com/defi-products/nft-marketplace/overview).\n\nOn this marketplace you can make offers and listings of ERC721 Tokens on the chains supported by 0x smart contracts, namely: Ethereum, Binance Smart Chain, Polygon, Fantom, Avalanche, Celo and Optimism.\n\n# How to Start\n\nclone this repo\n\n```\ngit clone https://github.com/DexKit/open-nft-marketplace.git\n```\n\nInstall it:\n\n```sh\nyarn\n```\n\nCreate an .env file with INFURA_API_KEY set with your Infura API key and then run the app\n\n```sh\nyarn dev\n```\n\n# Contributing\n\nCheck [Contributing](CONTRIBUTING.md) for a more in depth way how to contribute.\n\n# Deployment\n\nWe recommend Vercel to deploy this app, after you made your changes on the app.json config file, just use the button below:\n\n[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDexKit%2Fopen-nft-marketplace&env=INFURA_API_KEY)\n\nNote that you need to set up INFURA_API_KEY to Next js be able to generate pages.\n\n# Tech used\n\nStarted from [NEXT JS + Material UI+ Typescript + Boilerplat](https://github.com/mui/material-ui/tree/master/examples/nextjs-with-typescript)\n\nAdditionally we use trader sdk to handle nft smart contract interactions, react query to handle all http and blockchain requests, format js for internalization, web3 react to handle wallet logic. You can check our requirements [here](REQUIREMENTS.md).\n\n# Roadmap\n\nWe will be adding any new evm network that 0x smart contracts will support.\n\nIt is also planned to extract all common hooks and state used to interact with the blockchain to a library repo.\n\n# Customization\n\nIf you need a zero code solution we are building one currently in beta at [wizard](https://whitelabel-nft.dexkit.com/admin/setup), check our [docs](https://docs.dexkit.com/defi-products/nft-marketplace/overview) as well about it. Instead, if you want to deploy your own custom solution using this repo, please fork it, update the app.json file accordingly on the config folder and then deploy on Vercel (Recommended) or Heroku.\n\n# Missing feature?\n\nWe welcome missing features, but take in mind that this repo is intended to be a base app for any dev to start working on, if it makes sense to have that feature on this base app we will include, if it is considered a premium feature, we will be including on our premium marketplace which uses this one as a base.\n\nWe at the moment consider premium features as follows:\n\n- [ ] - NFT trading history\n\n- [ ] - Artist page\n\n- [ ] - Cache optimizations\n\n- [ ] - Fetch NFT and token balances via api without the need to import, using Alchemy for instance\n\n- [ ] - Swap ERC20 <-> ERC20 tokens\n\n- [ ] - Collection level stats like orders, max supply, floor price, number of trades\n\n- [ ] - Improved SEO\n\n# Acknowledgements\n\nWe would like to thank ZRX project for these amazing tools and ZRX DAO for the support on building this open source app.\n\n# Wanna talk about this repo\n\nJoin our dedicated channel [Open NFT Support](https://discord.gg/FnkrFAY7Za)\n"
  },
  "DexKit/dexkit-monorepo": {
    "fetchedAt": "2025-11-12T22:45:43.741Z",
    "content": "<div align=\"center\">\n  <img src=\"apps/dexappbuilder/public/assets/dexappbuilder/DexAppBuilder-readme.png\" alt=\"DexKit Logo\" width=\"200\"/>\n  <h3>Web3 Innovation Hub: DApps Builder & Blockchain Gaming</h3>\n  <em>Building the future of Web3, one block at a time</em>\n</div>\n\n## üì¶ Projects\n\n### [üõ†Ô∏è DexAppBuilder](apps/dexappbuilder)\nCreate powerful Web3 applications without code. If you can click and drag, you can make a DApp! ü™Ñ\n\n#### Featured DApps built with DexAppBuilder:\n- üêÆ [CyberCows](https://cybercows.dexkit.app/) - NFT Collection with Daily Rewards\n- ü™ô [The Midas Touch](https://themidastouch.dexkit.app/) - Gold-Backed Tokens Platform\n- üí± [ScaleSwap](https://scaleswap.dexkit.app/) - Streamlined DEX\n- üëπ [The Bestiary](https://thebestiary.dexkit.app/) - Lovecraftian NFT Collection\n\n### [üéÆ Coin League](apps/coinleague)\nThe ultimate blockchain price racing game. Compete in real-time races based on cryptocurrency price movements!\n\n## üöÄ Getting Started\n\nThis monorepo uses Yarn as the preferred package manager.\n\n```bash\n# Clone the repo\ngit clone https://github.com/DexKit/dexkit-monorepo.git\ncd dexkit-monorepo\n\n# Install dependencies and build packages automatically\nyarn install\n# Note: The postinstall script will automatically build all required packages\n\n# Alternative: Manual setup (if needed)\nyarn setup\n```\n\n> **üìù Note**: After cloning, the `yarn install` command automatically builds all internal packages to prevent module resolution errors. This ensures all `@dexkit/*` packages are properly compiled and available.\n\n### Environment Setup\n\n```bash\n# Set up environment variables for DexAppBuilder\ncp apps/dexappbuilder/.env.example apps/dexappbuilder/.env\n\n# Set up environment variables for Coin League\ncp apps/coinleague/.env.example apps/coinleague/.env\n```\n\n### Running Projects\n\n#### DexAppBuilder:\n```bash\ncd apps/dexappbuilder\nyarn dev\n# Visit http://localhost:3000\n```\n\n#### Coin League:\n```bash\ncd apps/coinleague\nyarn dev\n# Visit http://localhost:3001\n```\n\n## üîß Troubleshooting\n\n### Module Resolution Issues\nIf you encounter errors like `Module not found: Can't resolve '@dexkit/dexappbuilder-render'`, it means the internal packages haven't been built. This is automatically handled by the postinstall script, but you can manually resolve it:\n\n```bash\n# Build all required packages\nyarn build:packages\n\n# Or build individual packages in dependency order\nyarn workspace @dexkit/ui build\nyarn workspace @dexkit/core build\nyarn workspace @dexkit/unlock-widget build\nyarn workspace @dexkit/darkblock-evm-widget build\nyarn workspace @dexkit/dexappbuilder-render build\nyarn workspace @dexkit/dexappbuilder-viewer build\n```\n\n### General Guidelines:\n1. Fork the repository\n2. Create your feature branch\n3. Commit your changes\n4. Push to the branch\n5. Open a Pull Request\n\n## üìö Documentation\n\n- [DexAppBuilder Documentation](https://docs.dexkit.com/defi-products/dexappbuilder)\n- [Coin League Documentation](https://docs.dexkit.com/gaming/predictions-hub/coin-league)\n\n## üîó Links\n\n- [Official Website](https://dexkit.com)\n- [Documentation](https://docs.dexkit.com)\n- [Blog](https://dexkit.com/blog)\n- [Discord Community](https://discord.com/invite/dexkit-official-943552525217435649)\n- [X / Twitter](https://x.com/intent/follow?screen_name=dexkit)\n- [YouTube tutorials](https://www.youtube.com/@DexKit)\n\n## üìú License\n\nThis project is licensed under the MIT License.\n\n---\n\n## Support the Project\n\nIf you'd like to support the ongoing development of DexAppBuilder, consider making a donation through Giveth. Click the link below to contribute:\n\n[Donate with Giveth](https://giveth.io/project/dexappbuilder-the-no-codelow-code-toolkit-of-dexkit)\n\nYour contribution helps keep the project alive and continuously improve our tools. Thank you for your support!\n\n<div align=\"center\">\n  Made with ‚ù§Ô∏è by <a href=\"https://dexkit.com\">DexKit</a>\n</div>\n\n"
  },
  "Cyfrin/foundry-devops": {
    "fetchedAt": "2025-11-12T22:45:50.693Z",
    "content": "# foundry-devops\n\nA repo to get the most recent deployment from a given environment in foundry. This way, you can do scripting off previous deployments in solidity.\n\nIt will look through your `broadcast` folder at your most recent deployment.\n\n## Features\n- Get the most recent deployment of a contract in foundry\n- Checking if you're on a zkSync based chain\n\n- [foundry-devops](#foundry-devops)\n  - [Features](#features)\n- [Getting Started](#getting-started)\n  - [Requirements](#requirements)\n  - [Installation](#installation)\n  - [Usage - Getting the most recent deployment](#usage---getting-the-most-recent-deployment)\n  - [Usage - zkSync Checker](#usage---zksync-checker)\n- [Contributing](#contributing)\n  - [Testing](#testing)\n\n\n# Getting Started\n\n## Requirements\n\n> [!IMPORTANT]  \n> As of `0.3.0`, nightly builds of foundry may not work as expected. Please use `foundryup -v stable` for the stable version of foundry.\n\n-   [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)\n    -   You'll know you did it right if you can run `git --version` and you see a response like `git version x.x.x`\n-   [foundry](https://getfoundry.sh/)\n    -   You'll know you did it right if you can run `forge --version` and you see a response like `forge 0.2.0 (816e00b 2023-03-16T00:05:26.396218Z)`\n-   [jq](https://stackoverflow.com/questions/37668134/how-to-install-jq-on-mac-on-the-command-line)\n    -   A lot already have it installed. Try it with `jq --version` and see a response like `jq-1.6`\n\n## Installation\n\n```bash\nforge install Cyfrin/foundry-devops\n```\n\n- Update forge-std to use newer FS cheatcodes\n```\ngit rm -rf lib/forge-std\n```\n```\n rm -rf lib/forge-std\n```\n```\n forge install foundry-rs/forge-std@v1.8.2 \n```\n\n## Usage - Getting the most recent deployment\n\n1. Update your `foundry.toml` to have read permissions on the `broadcast` folder.\n\n```toml\nfs_permissions = [\n    { access = \"read\", path = \"./broadcast\" },\n    { access = \"read\", path = \"./reports\" },\n]\n```\n\n2. Import the package, and call `DevOpsTools.get_most_recent_deployment(\"MyContract\", chainid);`\n\nie:\n\n```javascript\nimport {DevOpsTools} from \"lib/foundry-devops/src/DevOpsTools.sol\";\nimport {MyContract} from \"my-contract/MyContract.sol\";\n.\n.\n.\nfunction interactWithPreviouslyDeployedContracts() public {\n    address contractAddress = DevOpsTools.get_most_recent_deployment(\"MyContract\", block.chainid);\n    MyContract myContract = MyContract(contractAddress);\n    myContract.doSomething();\n}\n```\n\n## Usage - zkSync Checker\n\n### Prerequisites\n- [foundry-zksync](https://github.com/matter-labs/foundry-zksync)\n  - You'll know you did it right if you can run `foundryup-zksync --help` and you see a response like:\n```\nThe installer for Foundry-zksync.\n\nUpdate or revert to a specific Foundry-zksync version with ease.\n.\n.\n.\n```\n\n### Usage - ZkSyncChainChecker\n\nIn your contract, you can import and inherit the abstract contract `ZkSyncChainChecker` to check if you are on a zkSync based chain. And add the `skipZkSync` modifier to any function you want to skip if you are on a zkSync based chain.\n\nIt will check both the precompiles or the `chainid` to determine if you are on a zkSync based chain.\n\n```javascript\nimport {ZkSyncChainChecker} from \"lib/foundry-devops/src/ZkSyncChainChecker.sol\";\n\ncontract MyContract is ZkSyncChainChecker {\n\n  function doStuff() skipZkSync {\n```\n\n### ZkSyncChainChecker modifiers:\n- `skipZkSync`: Skips the function if you are on a zkSync based chain.\n- `onlyZkSync`: Only allows the function if you are on a zkSync based chain.\n  \n### ZkSyncChainChecker Functions:\n- `isZkSyncChain()`: Returns true if you are on a zkSync based chain.\n- `isOnZkSyncPrecompiles()`: Returns true if you are on a zkSync based chain using the precompiles.\n- `isOnZkSyncChainId()`: Returns true if you are on a zkSync based chain using the chainid.\n\n### Usage - FoundryZkSyncChecker\n\nIn your contract, you can import and inherit the abstract contract `FoundryZkSyncChecker` to check if you are on the `foundry-zksync` fork of `foundry`. \n\n> !Important: Functions and modifiers in `FoundryZkSyncChecker` are only available if you run `foundry-zksync` with the `--zksync` flag.\n\n```javascript\nimport {FoundryZkSyncChecker} from \"lib/foundry-devops/src/FoundryZkSyncChecker.sol\";\n\ncontract MyContract is FoundryZkSyncChecker {\n\n  function doStuff() onlyFoundryZkSync {\n```\n\nYou must also add `ffi = true` to your `foundry.toml` to use this feature. \n\n### FoundryZkSync modifiers:\n- `onlyFoundryZkSync`: Only allows the function if you are on `foundry-zksync`\n- `onlyVanillaFoundry`: Only allows the function if you are on `foundry`\n\n### FoundryZkSync Functions:\n- `is_foundry_zksync`: Returns true if you are on `foundry-zksync`\n\n\n# Testing\n\nFor testing on vanilla foundry, run:\n\n```bash\nmake test\n```\n\nFor testing with `foundry-zksync`, run:\n\n```bash\nmake test-zksync\n```\n\n# Limitations\n- You cannot deploy a contract with `FoundryZkSyncChainChecker` or `ZkSyncChainChecker` because `foundry-zksync` gets confused by a lot of cheatcodes, and doesn't recognize cheatcodes after compiling to the EraVM. \n\n# Contributing\n\nPRs are welcome!\n\n```\ngit clone https://github.com/Cyfrin/foundry-devops\ncd foundry-devops\nmake\n```\n"
  },
  "PaulRBerg/prb-math": {
    "fetchedAt": "2025-11-12T22:45:57.426Z",
    "content": "# PRBMath [![GitHub Actions][gha-badge]][gha] [![Foundry][foundry-badge]][foundry] [![License: MIT][license-badge]][license]\n\n[gha]: https://github.com/PaulRBerg/prb-math/actions\n[gha-badge]: https://github.com/PaulRBerg/prb-math/actions/workflows/ci.yml/badge.svg\n[foundry]: https://getfoundry.sh/\n[foundry-badge]: https://img.shields.io/badge/Built%20with-Foundry-FFDB1C.svg\n[license]: https://opensource.org/licenses/MIT\n[license-badge]: https://img.shields.io/badge/License-MIT-blue.svg\n\n<div align=\"center\">\n  <img src=\"./assets/logo.png\" alt=\"PRBMath Logo\" width=\"250\">\n</div>\n\n**Solidity library for advanced fixed-point math** that operates with signed 59.18-decimal fixed-point and unsigned 60.18-decimal fixed-point numbers.\nThe name of the number format comes from the integer part having up to 59 digits for signed numbers and 60 digits for unsigned numbers, while the\nfractional part has up to 18 decimals. The numbers are bound by the minimum and the maximum values permitted by the Solidity types int256 and uint256.\n\n- Operates with signed and unsigned denary fixed-point numbers, with 18 trailing decimals\n- Offers advanced math functions like logarithms, exponentials, powers and square roots\n- Provides type safety via user-defined value types\n- Gas efficient, but still user-friendly\n- Ergonomic developer experience thanks to using free functions instead of libraries\n- Bakes in overflow-safe multiplication and division via `mulDiv`\n- Reverts with custom errors instead of reason strings\n- Well-documented with NatSpec comments\n- Built and tested with Foundry\n\n> [!NOTE]\n>\n> PRBMath is a fixed-point math library that is at the same time intuitive, efficient and safe.\n> [ABDKMath64x64](https://github.com/abdk-consulting/abdk-libraries-solidity) is fast, but uses binary numbers, which are counter-intuitive.\n> [Solmate](https://github.com/transmissions11/solmate) is fast and intuitive, but lacks type safety.\n\n## üì¶ Install\n\n### üü¢ Node.js\n\nThis is the recommended approach.\n\nInstall PRBMath using your favorite package manager, e.g., with Bun:\n\n```shell\nbun add @prb/math\n```\n\nThen, if you are using Foundry, you need to add this to your `remappings.txt` file:\n\n```text\n@prb/math/=node_modules/@prb/math/\n```\n\n### üîó Git Submodules\n\nThis installation method is not recommended, but it is available for those who prefer it.\n\nFirst, install the submodule using Forge:\n\n```shell\nforge install --no-commit PaulRBerg/prb-math@release-v4\n```\n\nYour `.gitmodules` file should now contain the following entry:\n\n```toml\n[submodule \"lib/prb-math\"]\n  branch = \"release-v4\"\n  path = \"lib/prb-math\"\n  url = \"https://github.com/PaulRBerg/prb-math\"\n```\n\nFinally, add this to your `remappings.txt` file:\n\n```text\n@prb/math/=lib/prb-math/\n```\n\n## üöÄ Usage\n\nThere are two user-defined value types:\n\n1. SD59x18 (signed)\n2. UD60x18 (unsigned)\n\nIf you don't know what a user-defined value type is, check out this [blog post](https://blog.soliditylang.org/2021/09/27/user-defined-value-types/).\n\nIf you don't need negative numbers, there's no point in using the signed flavor `SD59x18`. The unsigned flavor `UD60x18` is more gas efficient.\n\nNote that PRBMath is not a library in the Solidity [sense](https://docs.soliditylang.org/en/v0.8.17/contracts.html#libraries). It's just a collection\nof free functions.\n\n### üì• Importing\n\nIt is recommended that you import PRBMath using specific symbols. Importing full files can result in Solidity complaining about duplicate definitions\nand static analyzers like Slither erroring, especially as repos grow and have more dependencies with overlapping names.\n\n```solidity\npragma solidity >=0.8.19;\n\nimport { SD59x18 } from \"@prb/math/src/SD59x18.sol\";\nimport { UD60x18 } from \"@prb/math/src/UD60x18.sol\";\n```\n\nAny function that is not available in the types directly has to be imported explicitly. Here's an example for the `sd` and the `ud` functions:\n\n```solidity\npragma solidity >=0.8.19;\n\nimport { SD59x18, sd } from \"@prb/math/src/SD59x18.sol\";\nimport { UD60x18, ud } from \"@prb/math/src/UD60x18.sol\";\n```\n\nNote that PRBMath can only be used in Solidity v0.8.19 and above.\n\n### ‚ûï SD59x18\n\n```solidity\n// SPDX-License-Identifier: UNLICENSED\npragma solidity >=0.8.19;\n\nimport { SD59x18, sd } from \"@prb/math/src/SD59x18.sol\";\n\ncontract SignedConsumer {\n  /// @notice Calculates 5% of the given signed number.\n  /// @dev Try this with x = 400e18.\n  function signedPercentage(SD59x18 x) external pure returns (SD59x18 result) {\n    SD59x18 fivePercent = sd(0.05e18);\n    result = x.mul(fivePercent);\n  }\n\n  /// @notice Calculates the binary logarithm of the given signed number.\n  /// @dev Try this with x = 128e18.\n  function signedLog2(SD59x18 x) external pure returns (SD59x18 result) {\n    result = x.log2();\n  }\n}\n```\n\n### ‚ûï UD60x18\n\n```solidity\n// SPDX-License-Identifier: UNLICENSED\npragma solidity >=0.8.19;\n\nimport { UD60x18, ud } from \"@prb/math/src/UD60x18.sol\";\n\ncontract UnsignedConsumer {\n  /// @notice Calculates 5% of the given signed number.\n  /// @dev Try this with x = 400e18.\n  function unsignedPercentage(UD60x18 x) external pure returns (UD60x18 result) {\n    UD60x18 fivePercent = ud(0.05e18);\n    result = x.mul(fivePercent);\n  }\n\n  /// @notice Calculates the binary logarithm of the given signed number.\n  /// @dev Try this with x = 128e18.\n  function unsignedLog2(UD60x18 x) external pure returns (UD60x18 result) {\n    result = x.log2();\n  }\n}\n```\n\n## ‚ú® Features\n\nBecause there's significant overlap between the features available in SD59x18 and UD60x18, there is only one table per section. If in doubt, refer to\nthe source code, which is well-documented with NatSpec comments.\n\n### üî¢ Mathematical Functions\n\n| Name    | Operator | Description                                      |\n| ------- | -------- | ------------------------------------------------ |\n| `abs`   | N/A      | Absolute value                                   |\n| `avg`   | N/A      | Arithmetic average                               |\n| `ceil`  | N/A      | Smallest whole number greater than or equal to x |\n| `div`   | `/`      | Fixed-point division                             |\n| `exp`   | N/A      | Natural exponential e^x                          |\n| `exp2`  | N/A      | Binary exponential 2^x                           |\n| `floor` | N/A      | Greatest whole number less than or equal to x    |\n| `frac`  | N/A      | Fractional part                                  |\n| `gm`    | N/A      | Geometric mean                                   |\n| `inv`   | N/A      | Inverse 1√∑x                                      |\n| `ln`    | N/A      | Natural logarithm ln(x)                          |\n| `log10` | N/A      | Common logarithm log10(x)                        |\n| `log2`  | N/A      | Binary logarithm log2(x)                         |\n| `mul`   | `*`      | Fixed-point multiplication                       |\n| `pow`   | N/A      | Power function x^y                               |\n| `powu`  | N/A      | Power function x^y with y simple integer         |\n| `sqrt`  | N/A      | Square root                                      |\n\n### üîó Adjacent Value Types\n\nPRBMath provides adjacent value types that serve as abstractions over other vanilla types:\n\n| Value Type | Underlying Type |\n| ---------- | --------------- |\n| `SD1x18`   | int64           |\n| `SD21x18`  | int128          |\n| `UD2x18`   | uint64          |\n| `UD21x18`  | uint128         |\n\nThese are useful if you want to save gas by using a lower bit width integer, e.g., in a struct.\n\nNote that these types don't have any mathematical functionality. To do math with them, you will have to unwrap them into a simple integer and then to\nthe core types `SD59x18` and `UD60x18`.\n\n### üîÑ Casting Functions\n\nAll PRBMath types have casting functions to and from all other types, including a few basic types like `uint128` and `uint40`.\n\n| Name          | Description               |\n| ------------- | ------------------------- |\n| `intoSD1x18`  | Casts a number to SD1x18  |\n| `intoSD59\n\n[... truncated ...]"
  },
  "tryethernal/ethernal-cli": {
    "fetchedAt": "2025-11-12T22:46:04.547Z",
    "content": "# ethernal-cli\n\nCLI to sync transactions with [Ethernal](https://www.tryethernal.com).\n\nTruffle & Brownie artifacts are also synced through this CLI, if you are using Hardhat, use [this plugin](https://github.com/antoinedc/hardhat-ethernal).\n\nIf you are looking for more detailed doc about Ethernal: https://doc.tryethernal.com\n\n## Installation\n\n### OSX / Windows\n```bash\nnpm install ethernal -g\n```\n\n### Linux\nOn Linux systems, Ethernal CLI relies on libsecret to securely store your password.\nMake sure it's installed by running the following command, depending on your distribution:\n- Debian/Ubuntu: sudo apt-get install libsecret-1-dev\n- Red Hat-based: sudo yum install libsecret-devel\n- Arch Linux: sudo pacman -S libsecret\n\n[Source](https://github.com/atom/node-keytar#on-linux)\n\nThen run:\n```bash\nnpm install ethernal -g\n```\n\n## Usage\n\n### Authentication\nAuthentication is done through the env variables ```ETHERNAL_EMAIL``` abd ```ETHERNAL_PASSWORD```. They need to be set for all the following commands to work properly.\n\n### Listening to transactions\nThis will synchronize blocks, transactions & contracts to Ethernal\nThe CLI will connect to the URL set on the workspace you used last.\n```bash\nethernal listen\n```\nFor blocks & transactions, the whole object returned by web3 is synchronized with Ethernal.\n\n__Options__\n\n### -w\nConnect to the specified workspace. You can also set it with the env variable `ETHERNAL_WORKSPACE`.\n```bash\nethernal listen -w workspace\n```\n\n### -d\nSpecifiy which directory to watch (one or more, separated by a comma)\n```bash\nethernal listen -d ~/solidity/project,~/solidity/project2\n```\n\n### -s\nOnly listen to transactions, do not watch artifacts for changes. Useful if your blockchain is not on your local environment.\nWill be ignore if the ```-l``` flag is passed\n```bash\nethernal listen -s\n```\n\n### -l\nOnly watch artifact changes, do not listen to transactions. Useful if you ran the ```ethernal listen -s``` somewhere else.\n```bash\nethernal listen -l\n```\n\n### -h\nDisplay help\n```bash\nethernal listen -h\n```\n\n### Artifacts Uploading\nRunning the ```listen``` command in a Truffle or Brownie project will automatically watch your artifacts, and upload the data everytime it changes.\nYou can also pass a path to watch with the ```-d``` flag.\n```bash\nethernal listen -d ~/solidity/my-project\n```\nWatch multiple directories at once:\n```bash\nethernal listen -d ~/solidity/my-project,~/solidity/other-project\n```\n\nBy default, only the name and the ABI of the contract are going to be uploaded. If you want to use the \"Storage\" tab of contracts page, you'll need to have the AST uploaded as well. To do so, pass the --astUpload flag as a parameter.\nethernal listen ```--astUpload``` (this will upload the ast field, as well as the source field).\n\nFor Brownie projects, the flag ```dev_deployment_artifacts``` needs to be set to ```true``` in ```brownie-config.yaml```.\n\n### Syncing a range of blocks\n\nThis will sync all blocks in a range (start and end of the range included), and their transactions. It takes two mandatory parameters: ```-f``` or ```--from``` is the first block to be synchronized, and ```-t``` or ```--to``` which is the last block.\n```bash\nethernal sync -f 1 -t 10\n```\n\n### Resetting a workspace\n\nThis will delete all accounts/blocks/transactions/contracts from a specific workspace\n```bash\nethernal reset [workspace]\n```\n\n### [Public Explorer] Verifying a contract\n\nIt is possible to verify a contract deployed on a public explorer using `ethernal verify` with the parameters described below.\nContracts are verified using partial matches, meaning that metadata are stripped before doing the verification.\n\n| Argument               | Shorthand | description                                                                                                                                          | Type    | Required |\n|------------------------|-----------|------------------------------------------------------------------------------------------------------------------------------------------------------|---------|----------|\n| --slug                 | -s        | Slug of the explorer to connect to                                                                                                                   | string  | Yes      |\n| --address              | -a        | Address of the contract to verify                                                                                                                    | string  | Yes      |\n| --compiler             | -c        | Solidity compiler version to use (See list here https://raw.githubusercontent.com/ethereum/solc-bin/gh-pages/bin/list.json, use \"longVersion\" field) | string  | Yes      |\n| --name                 | -n        | Name of the contract to verify                                                                                                                       | string  | Yes      |\n| --path                 | -p        | Path to the file containing the contract to verify                                                                                                   | string  | Yes      |\n| --libraries            | -l        | Link external library. Format path/to/library.sol:Library1=0x1234,path/to/library.sol:Library2=0x12345                                               | string  | No       |\n| --constructorArguments | -g        | Specify constructor arguments (ABI encoded)                                                                                                          | string  | No       |\n| --evmVersion           | -e        | Specify EVM version (see https://docs.soliditylang.org/en/v0.8.16/using-the-compiler.html#target-options for valid options). Default to latest       | string  | No       |\n| --optimizer            | -o        | Enable optimizer. Default to false                                                                                                                   | boolean | No       |\n| --runs                 | -r        | Number of runs if optimizer is enabled                                                                                                               | number  | no       |\n\nExample:\n```bash\nethernal verify \\\n    --address=\"0xa4c190681d2b5cc3d86e62379e0bc94afe2282e7\" \\\n    --slug=\"ethernal\" \\\n    --path=\"contracts/ExampleERC20.sol\" \\\n    --compiler=\"v0.8.0+commitc7dfd78e\" \\\n    --name=\"ExampleERC20\" \\\n    --optimizer=true \\\n    --runs=1000 \\\n    --evmVersion=\"byzantium\" \\\n    --constructorArguments=\"000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000024869000000000000000000000000000000000000000000000000000000000000\"\n```"
  },
  "tryethernal/ethernal": {
    "fetchedAt": "2025-11-12T22:46:05.006Z",
    "content": " # Ethernal\n\n**Ethernal** is a powerful, open-source block explorer for EVM-based chains. Effortlessly explore, search, and analyze blockchain data‚Äîwhether you use our hosted service or run your own private instance.\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n---\n\n## üöÄ Quick Start\n\n### Hosted Version\n\n- **Try Ethernal instantly:** [app.tryethernal.com](https://app.tryethernal.com)\n- **Create a demo explorer:** [app.tryethernal.com/demo](https://app.tryethernal.com/demo)\n\n---\n\n## üè† Self-Hosting Ethernal\n\n> ‚ö†Ô∏è **Beta Notice:**\n> \n> The self-hosted version of Ethernal is currently in **beta**. Some features may not work as expected or may be incomplete. If you encounter any issues, please consider [opening an issue](https://github.com/tryethernal/ethernal/issues) to help us improve the project. Your feedback is greatly appreciated!\n\nRun your own Ethernal instance on your infrastructure, with full control over your data and configuration.\n\n### Prerequisites\n\n- [Docker](https://www.docker.com/) & [Docker Compose](https://docs.docker.com/compose/)\n- [OpenSSL](https://www.openssl.org/) (for environment file generation)\n- A domain name or server IP\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/tryethernal/ethernal.git\ncd ethernal\ngit checkout $(git describe --tags --abbrev=0) # Makes sure that you are using the latest stable version \n```\n\n### 2. Start Ethernal (Automatic Setup)\n\nJust run:\n\n```bash\nmake start\n```\n\n- On first run, this will prompt you for your domain/IP and port, then generate all secrets and config files using `generate-env-files.sh`.\n- On subsequent runs, it will skip generation and simply start the services.\n- If you ever want to regenerate your environment/config files, you can run `bash ./generate-env-files.sh` manually.\n\n> **Tip:** All generated secrets and config files are automatically added to `.gitignore` for your safety.\n\n### 3. Access Your Instance\n\nAfter setup, you'll see a summary like:\n\n```\n==================== Ethernal Installation Complete! ====================\n\nüåê  DNS Setup Reminder:\n    Make sure to add an A record in your DNS provider:\n    your-domain.com -> <your-server-ip-address>\n\nüîó  Start here to setup your instance:\n    http://your-domain-or-ip/setup\n\nüêò  PostgreSQL Connection String:\n    postgresql://<user>:<password>@<host>:<port>/<db>\n\nüìä  Bullboard Access (background jobs):\n    http://your-domain-or-ip/bull\n    Username: ethernal\n    Password: <auto-generated>\n=======================================================================\n```\n\n**üëâ Next step:**\n\n- Open the setup link shown above in your browser.\n- This guided setup will help you **create your admin user account** and **set up your first explorer** quickly and easily.\n- Once complete, you'll be ready to start using Ethernal!\n\n> **üåê DNS Setup Reminder:**\n> \n> If you are using a custom domain (not an IP address), make sure to add an **A record** in your DNS provider:\n> \n>     your-domain.com -> <your-server-ip-address>\n> \n> Replace `<your-server-ip-address>` with the actual public IP of your server. This is required for your domain to resolve correctly to your Ethernal instance.\n\n---\n\n## üì° API\n\nEthernal exposes a powerful API for programmatic access to your blockchain data and explorer features.\n\n- **API Documentation:**\n  - Full list of endpoints and usage examples: [Ethernal API Reference](https://documenter.getpostman.com/view/12141908/2s83zfQ5Tf)\n  - **Note:** Replace all instances of `api.tryethernal.com` in the documentation with your own server's domain or IP address.\n\nYou can use this API to:\n- Query blocks, transactions, contracts, logs, and more\n- Integrate Ethernal data into your own dashboards or tools\n- Automate explorer management (add/delete explorer, customise them, etc...)\n\nIf you need additional endpoints or have suggestions for improvements, **pull requests and issues are welcome!**\n\n---\n\n## üõ†Ô∏è Useful Makefile Commands\n\n- `make start` ‚Äì Start or restart Ethernal (with env/config generation)\n- `make stop` ‚Äì Stop and clean up all containers and networks\n- `make update` ‚Äì Pull latest images and apply migrations/seeds\n- `make nuke` ‚Äì Remove all containers, volumes, and generated config files (all data will be list)\n\n---\n\n## ‚öôÔ∏è Configuration\n\n**All configuration files and environment variables are generated automatically during setup. For a default installation, you should not need to change any of these values.**\nIf you want to customize advanced settings, you can edit the relevant files after the initial setup.\n\nBelow are the main configuration files and the variables they contain:\n\n---\n\n### Frontend Environment Variables (`.env.prod`)\n\n| Variable                  | Description                              | Default                |\n|---------------------------|------------------------------------------|------------------------|\n| VITE_VERSION              | Version of the application               | -                      |\n| VITE_API_ROOT             | Root URL for API endpoints               | https://api.example.com|\n| VITE_MAIN_DOMAIN          | Main domain for the application          | example.com            |\n| VITE_PUSHER_KEY           | Pusher API key for real-time updates     | -                      |\n| VITE_SOKETI_HOST          | Soketi server host for WebSocket         | -                      |\n| VITE_SOKETI_PORT          | Soketi server port                       | -                      |\n| VITE_SOKETI_FORCE_TLS     | Force TLS for Soketi                     | -                      |\n| VITE_POSTHOG_API_KEY      | PostHog API key for analytics            | -                      |\n| VITE_POSTHOG_API_HOST     | PostHog API host                         | -                      |\n| VITE_ENABLE_ANALYTICS     | Enable/disable analytics features        | false                  |\n| VITE_ENABLE_DEMO          | Enable/disable demo features             | false                  |\n| VITE_ENABLE_BILLING       | Enable/disable billing features          | false                  |\n| VITE_ENABLE_MARKETING     | Enable/disable marketing features        | false                  |\n| VITE_SENTRY_DSN_SECRET    | Sentry DSN secret for error tracking     | -                      |\n| VITE_SENTRY_DSN_PROJECT_ID| Sentry project ID                        | -                      |\n| VITE_FEEDBACK_FIN_ENDPOINT| Endpoint for feedback collection         | -                      |\n\n---\n\n### Backend Environment Variables (`run/.env.prod`)\n\n| Variable           | Description                        | Default     |\n|--------------------|------------------------------------|-------------|\n| ENCRYPTION_KEY     | Key used for data encryption       | -           |\n| ENCRYPTION_JWT_SECRET | Secret for JWT token encryption | -           |\n| SECRET             | Application secret key             | -           |\n| CORS_DOMAIN        | CORS allowed domains               | *           |\n| NODE_ENV           | Node environment                   | production  |\n| REDIS_URL          | Redis connection string            | redis://redis:6379 |\n| DB_USER            | PostgreSQL username                | postgres    |\n| DB_PASSWORD        | PostgreSQL password                | (random)    |\n| DB_NAME            | PostgreSQL database name           | ethernal    |\n| DB_HOST            | PostgreSQL host (via pgbouncer)    | pgbouncer   |\n| DB_PORT            | PostgreSQL port (via pgbouncer)    | 5433        |\n| SOKETI_DEFAULT_APP_ID | Soketi app id                   | default-app |\n| SOKETI_DEFAULT_APP_KEY| Soketi app key                  | app-key     |\n| SOKETI_DEFAULT_APP_SECRET| Soketi app secret            | (random)    |\n| SOKETI_HOST        | Soketi host                        | soketi      |\n| SOKETI_PORT        | Soketi port                        | 6001        |\n| PM2_HOST           | PM2 dashboard host                 | pm2:9090    |\n| PM2_SECRET         | PM2 dashboard secret               | (random\n\n[... truncated ...]"
  },
  "tryethernal/hardhat-ethernal": {
    "fetchedAt": "2025-11-12T22:46:05.448Z",
    "content": "# Hardhat plugin for Ethernal\n\n[Ethernal](https://www.tryethernal.com) is a block explorer for EVM-based chains. You can use it with your local chains (the Hardhat network for example), or for chains deployed on remote servers.\n\nIt allows you to interact with contracts by automatically generating an UI for all read/write methods. You can also read contract variables in any blocks.\n\nTo use Ethernal, you need to synchronize blocks, transactions & artifacts with the dashboard. This plugin allows you to easily do that instead of having to run the CLI separately.\n\nIf you are looking for more detailed doc about Ethernal: https://doc.tryethernal.com\n\n## Installation\n\nAdd ```hardhat-ethernal``` to your ```package.json```, and run ```npm install``` or ```yarn```\n\n\nIn your ```hardhat-config.js```file, require the plugin:\n```js\nrequire('hardhat-ethernal');\n````\n\nTo authenticate, you need to set `ETHERNAL_API_TOKEN` in your env variables. You can find the token by logging in at https://app.tryethernal.com > Settings > Account\nYou can also set them in the config object:\n```js\nmodule.exports = {\n    ethernal: {\n        apiToken: process.env.ETHERNAL_API_TOKEN\n    }\n};\n```\n\n## Synchronize blocks & transactions\n\nOnce you've installed the plugin and authenticated, the plugin will automatically sync blocks and transactions going through your node.\nBy default, it will synchronize to the latest workspace you've used in the dashboard. See next section to learn how to set the workspace manually.\n\n## Options\n\nAll options need to be under the optional `ethernal` key in the Hardhat config object, default values are shown below:\n```js\nmodule.exports = {\n    ethernal: {\n        disableSync: false, // If set to true, plugin will not sync blocks & txs\n        workspace: undefined, // Set the workspace to use, will default to the default workspace (latest one used in the dashboard). It is also possible to set it through the ETHERNAL_WORKSPACE env variable\n        uploadAst: false, // If set to true, plugin will upload AST, and you'll be able to use the storage feature (longer sync time though)\n        disabled: false, // If set to true, the plugin will be disabled, nohting will be synced, ethernal.push won't do anything either\n        resetOnStart: undefined, // Pass a workspace name to reset it automatically when restarting the node, note that if the workspace doesn't exist it won't error\n        serverSync: false, // Only available on public explorer plans - If set to true, blocks & txs will be synced by the server. For this to work, your chain needs to be accessible from the internet.\n        skipFirstBlock: false, // If set to true, the first block will be skipped. This is mostly useful to avoid having the first block synced with its tx when starting a mainnet fork\n        verbose: false // If set to true, will display this config object on start and the full error object\n    }\n};\n```\n\n## Synchronize artifacts\n\nIn your deploy script, first require the plugin:\n```js\nconst ethernal = require('hardhat-ethernal');\n```\nThen, push your artifacts to Ethernal, after deploying your contract:\n\n/!\\ The name parameter needs to match the name of the contract\n```js\nconst Greeter = await hre.ethers.getContractFactory(\"Greeter\");\nconst greeter = await Greeter.deploy(\"Hello, Hardhat!\");\nawait hre.ethernal.push({\n    name: 'Greeter',\n    address: greeter.address,\n    workspace: 'hardhat' // Optional, will override the workspace set in hardhat.config for this call only\n});\n```\n\nBy default, the push function is not going to upload AST to Ethernal. If you want to use \"Storage\" tab on contracts pages, you'll need to activate it. To do so, set the ```hre.ethernalUploadAst = true``` flag in your Hardhat config file (this will upload the ast field, as well as the source field).\n\n## Reset a workspace programmatically\n\nYou can reset a workspace programmatically by calling: `hre.ethernal.resetWorkspace(workspaceName)` (async function). All accounts/blocks/transactions/contracts will be deleted.\n"
  },
  "Nerd3Lab/superUI": {
    "fetchedAt": "2025-11-12T22:46:13.631Z",
    "content": "<p align=\"center\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://framerusercontent.com/images/3gXLrq3gkm5rm9OY8JD6Ccau28.svg\">\n      <img src=\"https://framerusercontent.com/images/3gXLrq3gkm5rm9OY8JD6Ccau28.svg\" height=\"50\">\n    </picture>\n</p>\n\n<a href=\"https://framerusercontent.com/images/Uwfs6ift9dP0BWm3UYVTSiFJ1Qs.png\"><img src=\"https://framerusercontent.com/images/Uwfs6ift9dP0BWm3UYVTSiFJ1Qs.png\" alt=\"Imgur-Magic\" border=\"0\"></a>\n\n## About SuperUI\n\nüöÄ The Ultimate Ethereum & Superchain Development Playground\n\n### Introduction\nSuperUI is an UI for Supersim that can simulate and run local chain or fork chain designed to make building on Superchain easier. We provide a user-friendly interface for testing, simulating, and debugging OP Stack applications. With SuperUI, you can fork networks, deploy smart contracts, and inspect chain state‚Äîall without relying solely on CLI commands. Our goal is to simplify the development process and support builders in creating seamless Superchain applications.\n\n- **Fork Any Superchain L2** Clone OP Mainnet, Base, and more for testing.\n- **Layer 2 Devnet** Deploy new chains in seconds, no RPC setup required.\n- **Pre-funded Test Accounts** Skip the faucet; start testing immediately.\n- **Developer tools built-in** Compatible\n- **Deploy Contract** Simple contract deployment on local test network.\n- **Contract Management** view and call contract functions. with abi import.\n- **Transaction History** Track all your transactions.\n\n## Who is this for?\n\n- üë©üèª‚Äçüíª Smart Contract Devs ‚Äì Test deployments instantly.\n- üßëüèª‚Äçüé® Frontend Devs ‚Äì Build UIs with real data.\n- üßëüèª‚Äçüî¨ Rollup Builders ‚Äì Fine-tune network configurations.\n- üßëüèª‚ÄçüöÄ Dapp Builders ‚Äì Test your app on a real network.\n- üßëüèª‚Äçüíº Hackers & Experimenters ‚Äì Play around without limits.\n\n## Installation via build from source\n\n1. Clone the repository\n\n```bash\ngit clone https://github.com/Nerd3Lab/superUI\n```\n\n2. Install dependencies\n\n```bash\ncd superUI\nyarn install\n```\n\n3. Build App\n\n```bash\nyarn package:all\n```\n\n4. open app from /release/build\n\n- On macOs (Intel chip), **mac** folder (SuperUI)\n- On macOs (Apple chip), **mac-arm64** folder (SuperUI)\n- On Windows x32, **win-ia32-unpacked** folder (superui.exe)\n- On Windows x64, **win-unpacked** folder (superui.exe)\n\n## Download\n\n- On macOs (Apple chip), install superUI with download link [here](https://github.com/Nerd3Lab/superUI/releases/download/v1.2.6/SuperUI-1.2.6-arm64.dmg)\n- On macOs (Intel chip), install superUI with download link [here](https://github.com/Nerd3Lab/superUI/releases/download/v1.2.6/SuperUI-1.2.6.dmg)\n- On Windows x64, install superUI with download link [here](https://github.com/Nerd3Lab/superUI/releases/download/v1.2.6/SuperUI-1.2.6-win.zip)\n- On Windows x32, install superUI with download link [here](https://github.com/Nerd3Lab/superUI/releases/download/v1.2.6/SuperUI-1.2.6-ia32-win.zip)\n"
  },
  "solodit/solodit_content": {
    "fetchedAt": "2025-11-12T22:46:20.896Z",
    "content": "# Solodit Content Repository\n\nWelcome to the Solodit Content Repository, the auxiliary hub for content and resources related to the Solodit platform.\nOur mission is to foster an open and collaborative community where sharing knowledge and resources empowers everyone.\nWe highly value contributions from our community and encourage active participation.\n\n## Contributing to the Repository\n\nWe believe in the power of open-source and community-driven development.\nIf you have suggestions, corrections, or new content to add, please feel free to open Pull Requests for all files in this repo.\nYour contributions help make Solodit better for everyone.\n\n### Guidelines for Contribution\n- Ensure your contributions are well-documented and easy to understand.\n- Follow the existing file and directory structure for consistency.\n- Please adhere to our code of conduct and respect the community guidelines.\n\n## Repository Contents\n\n### [Categories of Protocol](./protocol_categories.md)\nOur platform utilizes these categories to enhance user experience by enabling efficient filtering of findings, bug bounties, and audits. These categories are inspired by and initially derived from [DefiLlama](https://defillama.com/categories).\n\n### [Fork Information for Protocols](./forked_protocols.md)\nUnderstanding the lineage of protocols is essential. We provide detailed information about legacy protocols and their forks, aiding in the nuanced filtering of findings. This information is based on data from [DefiLlama](https://defillama.com/forks).\n\n### [Tags for Reports](./report_tags.md)\nTo streamline the process of filtering security review findings, we use a comprehensive set of tags. Many of these tags were initially curated and appended by [Hans](https://github.com/hans-cyfrin).\n\n### [Custom Bug Bounties](./bug_bounties/custom.md)\nAlongside the bug bounties available on external platforms, we also compile a list of custom bug bounties offered directly by protocols. Contributions to expanding this list are highly appreciated, especially for bounties not yet listed on Solodit.\n\n### [Custom Audit Reports](./reports/README.md)\nWhile the Solodit team has worked on automating the process of importing audit reports from numerous audit firms, we also welcome contributions from the community.\nIf you have an audit report that is not yet listed on Solodit, please feel free to submit a pull request.\n\n## Community and Support\n\n- [GitHub Discussions](https://github.com/orgs/solodit/discussions)\n- [Telegram Group](https://t.me/+SEZ0HWPBWn80ODI8)\n- [Email](mailto:support@solodit.xyz)\n\n## Stay Updated\n\nFollow us on [X](https://twitter.com/SoloditOfficial) for the latest updates and announcements.\n\n---\n\nWe're excited to have you as part of the Solodit community! Together, we're building a more secure, transparent, and collaborative world."
  },
  "verifereum/verifereum": {
    "fetchedAt": "2025-11-12T22:46:33.395Z",
    "content": "# Verifereum\n\nProve functional correctness of Ethereum smart contracts in higher-order logic.\n\nSee [https://verifereum.org](https://verifereum.org).\n\n## Getting Started\n\nVerifereum is developed in the [HOL](https://hol-theorem-prover.org) Theorem\nProver (a.k.a. HOL4), which itself is written in Standard ML.\n\nThese instructions guide you in installing [Poly/ML](https://polyml.org), which\nis a Standard ML implementation, and then building HOL4 with it.\n\nIn case you would rather not build the project from source, you can use Docker\nas described [here](docs/run-with-docker.md).\n\n1.  Install and build Poly/ML from source (you may prefer to use a packaged version if available)\n\n    i. Download the source code from the Poly/ML GitHub repository\n\n    ```bash\n    curl -L https://github.com/polyml/polyml/archive/refs/heads/master.zip | bsdtar -xf -\n    ```\n\n    ii.\n\n    ```bash\n    cd polyml-master\n    ./configure --enable-intinf-as-int\n    make -j4\n    make install\n    cd ..\n    rm -r polyml-master\n    ```\n\n2.  Install and build HOL4\n\n    i. Download the source code from the HOL GitHub repository\n\n    ```bash\n    git clone https://github.com/HOL-Theorem-Prover/HOL\n    cd HOL\n    poly --script tools/smart-configure.sml\n    bin/build\n    ```\n\n    ii. Export paths: add the following to your `.bashrc` file\n\n    ```bash\n    export HOLDIR=<path-to-HOL>/HOL\n    export PATH=$HOLDIR/bin:$PATH\n    ```\n\n    For other tips checkout [this FAQ](https://hol-theorem-prover.org/faq.html).\n\n3. Clone the Verifereum repo itself ahead of the build e.g., `git clone https://github.com/verifereum/verifereum` or alternative method\n\n4. Run `Holmake` in the `tests` directory, then `./runtests.exe` to build Verifereum and run the tests.\n\n    ```bash\n    Holmake\n    # Scanned 16 directories\n    # Finished $(HOLDIR)/examples/json                               (0.000s)\n    # vfmTypesTheory                    Documents/Code/verifereum (26s)     OK\n    # vfmTransactionTheory              Documents/Code/verifereum  (2s)     OK\n    # recursiveLengthPrefixTheory       Documents/Code/verifereum  (6s)     OK\n    # ...\n    ```\n\n## Links\n\n* The files in this repository are intended for use with [the HOL theorem prover](https://hol-theorem-prover.org).\n* An official executable specification of the Ethereum virtual machine can be found [here](https://github.com/ethereum/execution-specs).\n* Another useful resources on the EVM is [evm.codes](https://evm.codes).\n\n## Plan\n\n* Define the machine\n* Pass existing [test](https://github.com/ethereum/tests) [suites](https://github.com/ethereum/execution-spec-tests)\n* Define a program logic (for use with [decompilation into logic](https://www.cse.chalmers.se/~myreen/decompilation.html))\n* Specify and verify some simple one-contract protocols ([WETH](https://etherscan.io/address/0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2#code), [RocketSplit](https://github.com/xrchz/rocketsplit), etc.)\n* ...\n"
  },
  "psychemist/deo-ai": {
    "fetchedAt": "2025-11-12T22:46:41.578Z",
    "content": "# DEOAI - Your AI-Powered ENS Development Assistant\n\nDEOAI is an AI-powered assistant designed to help developers build on Ethereum and the Ethereum Name Service (ENS) by providing real-time debugging support, ENS documentation insights, and smart contract development guidance. It is trained on Ethereum historical data, Solidity references, ENS documentation, development best practices, and common debugging scenarios to streamline development.\n\n## üöÄ Features\n- **Smart Contract Debugging** ‚Äì Identify and resolve issues related to ENS-based Solidity contracts.\n- **AI-Powered ENS Assistance** ‚Äì Get instant answers on ENS concepts, deployment, and troubleshooting.\n- **Retrieval-Augmented Generation (RAG)** ‚Äì DEOAI fetches the most relevant ENS documentation before responding.\n- **Integration with Developer Tools** ‚Äì Use DEOAI in CLI, VS Code, or as a Telegram/Discord bot.\n- **Open Source & Community Driven** ‚Äì Contributions are welcome!\n\n## üìñ Getting Started\n### 1Ô∏è‚É£ Clone the Repository\n```sh\ngit clone https://github.com/yourusername/deoai.git\ncd deoai\n```\n\n\n## üõ† Developer Tools Integration\n- **VS Code Extension** ‚Äì (Coming Soon)\n- **Hardhat/Foundry Debugging Plugin** ‚Äì (Planned)\n- **Telegram/Discord Bot** ‚Äì (Planned)\n\n## üèó Contributing\nWe welcome contributions! To contribute:\n1. Fork the repo & create a new branch.\n2. Implement your changes & ensure code quality.\n3. Submit a pull request.\n\n## üìú License\nThis project is licensed under the MIT License.\n\n\n---\n\nüí° **Built for ENS developers, by ENS developers!**\n"
  },
  "meldsun0/samba": {
    "fetchedAt": "2025-11-12T22:46:48.947Z",
    "content": "# Samba\n\n[![GitHub License](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)]()\n[![Discord](https://img.shields.io/badge/Chat-on%20Discord-%235865F2?logo=discord&logoColor=white)](https://discord.com/channels/890617081744220180/1301231225276465152)\n\n\nSamba is an [Ethereum portal client](https://github.com/ethereum/portal-network-specs) written in Java language based\non [Teku](https://github.com/Consensys/teku) and [Besu](https://github.com/hyperledger/besu).\nThe name is inspired by the shortened name of of rescue dog named Sambayon that is the Spanish translation of an Italian dessert.\n\n> **Note:** Samba is still **under heavy development** and is not yet ready for production use.\n\n## Build Instructions\n\n### Install Prerequisites\n\n* Java 21+\n\nBuilding on a more recent version of Java is supported, but the resulting build will not work on earlier versions of Java.\n\n\n### Build and Dist\n\nTo create a ready to run distribution:\n\n```shell script\ngit clone https://github.com/meldsun0/samba\ncd samba && ./gradlew\n\n```\n\nThis produces:\n- Fully packaged distribution in `build/distributions`\n### Build and Test\n\nTo build, clone this repo and run with `gradle`:\n\n```shell script\ngit clone https://github.com/meldsun0/samba\ncd samba && ./gradlew\n\n```\nAdd environment variables:\n\n```shell script\nexport GITHUB_ACTOR=\nexport GITHUB_TOKEN=\n\n```\n\nAfter a successful build, distribution packages are available in `build/distributions`.\n\n### Other Useful Gradle Targets\n\n| Target             | Builds                                                  |\n|--------------------|---------------------------------------------------------|\n| distTar            | Full distribution in build/distributions (as `.tar.gz`) |\n| distZip            | Full distribution in build/distributions (as `.zip`)    |\n| distDocker         | The `meldsun/samba` docker image                        |\n| fatJarAllPlatforms | It creates fatJars for multiple platforms               |\n| dockerUpload       | Push imges to Docker Hub                                |\n| runContainer       | A docker container running                              |\n\n## Code Style\n\nWe use Google's Java coding conventions for the project. To reformat code, run:\n\n```shell script\n./gradlew spotlessApply\n```\n\nCode style is checked automatically during a build.\n\n## Testing\n\nAll the unit tests are run as part of the build, but can be explicitly triggered with:\n\n```shell script\n./gradlew test\n```\n\n## Docker\n\nTo run Samba inside docker you should:\n\n```shell script\n./gradlew distDocker \n```\n```shell script\ndocker -p 8545:8545 -p 5051:5051 -p 8008:8008 -p 9000:9000/udp {imageName} --p2p-advertised-ip==$(curl -s ifconfig.me)\n```\n## Running Hive locally\n\nTo run Hive locally against Samba you should follow these instructions: \n\nClone Hive:\n```shell script\ngit clone https://github.com/ethereum/hive\ncd hive\ngo build .\ngo build ./cmd/hiveview  \n```\n\nBuild a local Docker image from Samba:\n```shell script\n./gradlew build         \n./gradlew distDocker  \n```\n\n* Copy ~/samba/hive/samba folder to ~/hive/clients\n* Change ~/hive/clients/samba/Dockerfile. Replace the values for ARG `baseimage` and ARG `tag` with the values for the recently created image. \n\nRun Hive tests:\n```shell script\n./hive -sim portal -client samba,trin -sim.limit history \n```\n\n```shell script\n./hive  --sim devp2p --sim.limit discv5 --client samba --docker.output \n```\n\nIf you get the following error on macOS: `can't get docker version: Get \"http://unix.sock/v1.25/version\": dial unix /var/run/docker.sock: connect: no such file or directory`, you \nneed to enable `Allow the default Docker socket to be used (requires password)` in `Settings` -> `Advanced`\n\nView logs output and results:\n```shell script\n./hiveview --serve --logdir ./workspace/logs\n```\n## [JSON-RPC API (23)](https://samba-portal-node.postman.co/workspace/Samba-Portal-Node-Workspace~8bf54719-5e6d-4476-8b33-6434dc57d833/request/33150235-eb63c4bf-82ff-477e-a17d-616657e9cdbc?action=share&creator=33150235&ctx=documentation&active-environment=33150235-5c222146-bd60-431b-bb15-f3f9dc8fc9cc)\n\n#### History (15)\n- portal_historyAddEnr\n- portal_historyDeleteEnr\n- portal_historyFindContent\n- portal_historyFindNodes\n- portal_historyGetContent\n- portal_historyGetEnr\n- portal_historyLocalContent\n- portal_historyLookupEnr\n- portal_historyOffer\n- portal_historyPing\n- portal_historyStore\n- portal_historyPutContent\n- portal_historyRoutingTableInfo\n- portal_historyRecursiveFindNodes\n- portal_historyTraceGetContent\n\n#### Discv5 (8)\n- discv5_getEnr,\n- discv5_nodeInfo, \n- discv5_updateNodeInfo\n- discv5_talkReq\n- discv5_findNode\n- discv5_routingTableInfo\n- discv5_addEnr\n- discv5_deleteEnr\n\n#### Beacon\n  - portal_beaconStore\n\n##### Pending\n- discv5_ping: In order to implement it there is a refactor to be made on the library we are using:\n    - [Discord conversation](https://discord.com/channels/697535391594446898/1050616638497640548/1381765398889758931)\n    - [Issue](https://github.com/Consensys/discovery/issues/195)\n- discv5_lookupEnr: Soon\n- discv5_recursiveFindNodes: Soon\n\nWhen running against Hive:\n```shell script\n./hive -sim portal -client samba,shisui -sim.limit history\n```\nYou should be getting: \n\n![Tests](https://github.com/user-attachments/assets/daa19e4e-b6b3-4547-8de4-2536d5dad59a)\n\n## CLI options\n\n| Command Line Argument        | Default Value   |\n|------------------------------|-----------------|\n| `--unsafe-private-key=`      |                 |\n| `--portal-subnetworks=`      | history-network |\n| `--use-default-bootnodes=`   | true            |\n| `--p2p-ip=`                  | 0.0.0.0         |\n| `--jsonrpc-port=`            | 8545            |\n| `--jsonrpc-host=`            | 127.0.0.1       |\n| `--disable-json-rpc-server=` | false           |\n| `-disable-rest--server=`     | false           |\n| `--p2p-advertised-ip=`       | 0.0.0.0         |\n| `--logging=`                 | INFO            |\n| `--data-path=`               | ./build/samba   |\n\n\n\n\n## Hardware Requirements\n\nMinimum:\n\nRecommended:\n\nTO-DO\n\n## Setup\n\n- Besu or Samba:\n  - Mount volume:\n    - sudo mkfs.xfs /dev/nvme2n1\n    - sudo mkdir -p /mnt/ebs1\n    - sudo mount /dev/nvme2n1 /mnt/ebs1\n  - Provide correct access:\n    - sudo chown -R 1000:1000 /mnt/ebs1\n  - Relocating Docker's Data Directory to a Custom Path (e.g., EBS Volume):\n    - sudo mkdir -p /etc/docker \n    - sudo nano /etc/docker/daemon.json \n    {\n      \"data-root\": \"/mnt/ebs1/docker\"\n      } \n    - sudo mv /var/lib/docker /mnt/ebs1/docker \n    - sudo systemctl daemon-reexec \n    - sudo systemctl restart docker \n    - docker info | grep \"Docker Root Dir\"\n  - If you are running samba standalone:\n    - mkdir /mnt/ebs1/samba\n    -  docker run -p 8545:8545 -p 5051:5051 -p 8008:8008 -p 9000:9000/udp  -v /mnt/ebs1/samba:/opt/samba meldsun/instances:samba-standalone-arm64 --p2p-advertised-ip=$(curl -s ifconfig.me)\n  - Run Besu:\n    - docker run -e HOST_IP=$(curl -s ifconfig.me) -d --name besu --user 1000 -p 8545:8545 -p 9545:9545 -p 9000:9000/udp -v /mnt/ebs1:/data  meldsun/instances:besu-with-samba-arm64 \n### Running instances\n\nIf you want to run Samba using docker compose with Prometheus and Grafana:\n\n```shell script\nHOST_IP=$(curl -s ifconfig.me) SAMBA_DATA_PATH={dataPath}  SAMBA_LOG_PATH={logPath} docker compose up -d\n```\n\n| Service        | URL                                            | Notes                              |\n| -------------- | ---------------------------------------------- | ---------------------------------- |\n| **Prometheus** | [http://localhost:9091](http://localhost:9091) | Confirm `samba:8008/metrcis` is UP |\n| **Grafana**    | [http://localhost:3000](http://localhost:3000) | Login: `admin` / `admin`           |\n\nIf you want to run it using just the docker image:\n\n```shell script\ndocker run -p 8545:8545 -p 5051:5051 -p 8008:8008 -p 9000:9000/udp  -v /mnt/ebs1/samba:/data -d  meldsun/instances:samba-standalone-arm64 --p2p-advertised-ip=$(curl -s ifconfig.me)\n```\n\n\n\n### Useful\n\n[... truncated ...]"
  },
  "TitanLayer/contracts": {
    "fetchedAt": "2025-11-12T22:46:57.019Z",
    "content": "# Hyperlane\n\n[![GitHub Actions][gha-badge]][gha] [![codecov](https://codecov.io/gh/hyperlane-xyz/hyperlane-monorepo/branch/main/graph/badge.svg?token=APC7C3Q2GS)](https://codecov.io/gh/hyperlane-xyz/hyperlane-monorepo) [![Foundry][foundry-badge]][foundry] [![License: MIT][license-badge]][license]\n\n[gha]: https://github.com/hyperlane-xyz/hyperlane-monorepo/actions\n[gha-badge]: https://github.com/PaulRBerg/prb-math/actions/workflows/ci.yml/badge.svg\n[codecov-badge]: https://img.shields.io/codecov/c/github/hyperlane-xyz/hyperlane-monorepo\n[foundry]: https://getfoundry.sh/\n[foundry-badge]: https://img.shields.io/badge/Built%20with-Foundry-FFDB1C.svg\n[license]: https://www.apache.org/licenses/LICENSE-2.0\n[license-badge]: https://img.shields.io/badge/License-Apache-blue.svg\n\n## Versioning\n\nNote this is the branch for Hyperlane v3.\n\nV2 is deprecated in favor of V3. The code for V2 can be found in the [v2](https://github.com/hyperlane-xyz/hyperlane-monorepo/tree/v2) branch. For V1 code, refer to the [v1](https://github.com/hyperlane-xyz/hyperlane-monorepo/tree/v1) branch.\n\n## Overview\n\nHyperlane is an interchain messaging protocol that allows applications to communicate between blockchains.\n\nDevelopers can use Hyperlane to share state between blockchains, allowing them to build interchain applications that live natively across multiple chains.\n\nTo read more about interchain applications, how the protocol works, and how to integrate with Hyperlane, please see the [documentation](https://docs.hyperlane.xyz).\n\n## Working on Hyperlane\n\n### Prerequisites\n\n#### Install `jq`\n\nYou need `jq` installed on your machine. You can download it from [official page](https://jqlang.github.io/jq/download/) or use a package manager of your choice.\n\n#### Foundry\n\nFirst ensure you have Foundry installed on your machine.\n\nRun the following to install `foundryup`:\n\n```bash\ncurl -L https://foundry.paradigm.xyz | bash\n```\n\nThen run `foundryup` to install `forge`, `cast`, `anvil` and `chisel`.\n\n```bash\nfoundryup\n```\n\nCheck out the [Foundry Book](https://book.getfoundry.sh/getting-started/installation) for more information.\n\n#### Node\n\nThis repository targets v20 of node. We recommend using [nvm](https://github.com/nvm-sh/nvm) to manage your node version.\n\nTo install nvm\n\n```bash\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n```\n\nTo install version 20\n\n```bash\nnvm install 20\nnvm use 20\n```\n\nYou should change versions automatically with the `.nvmrc` file.\n\n### Workspaces\n\nThis monorepo uses [Yarn Workspaces](https://yarnpkg.com/features/workspaces). Installing dependencies, building, testing, and running prettier for all packages can be done from the root directory of the repository.\n\n- Installing dependencies\n\n  ```bash\n  yarn install\n  ```\n\n- Building\n\n  ```bash\n  yarn build\n  ```\n\nIf you are using [VSCode](https://code.visualstudio.com/), you can launch the [multi-root workspace](https://code.visualstudio.com/docs/editor/multi-root-workspaces) with `code mono.code-workspace`, install the recommended workspace extensions, and use the editor settings.\n\n### Logging\n\nThe typescript tooling uses [Pino](https://github.com/pinojs/pino) based logging, which outputs structured JSON logs by default.\nThe verbosity level and style can be configured with environment variables:\n\n```sh\nLOG_LEVEL=DEBUG|INFO|WARN|ERROR|OFF\nLOG_FORMAT=PRETTY|JSON\n```\n\n### Rust\n\nSee [`rust/README.md`](rust/README.md)\n\n### Release Agents\n\n- Tag the commit with the current date in the format `agents-yyyy-mm-dd`; e.g. `agents-2023-03-28`.\n- [Create a Github Release](https://github.com/hyperlane-xyz/hyperlane-monorepo/releases/new) with a changelog against the previous version titled `Agents MMMM DD, YYYY`, e.g. `Agents March 28, 2023`.\n- Include the agent docker image tag in the description of the release\n- Create a summary of change highlights\n- Create a \"breaking changes\" section with any changes required\n- Deploy agents with the new image tag (if it makes sense to)\n\n### Releasing packages to NPM\n\nWe use [changesets](https://github.com/changesets/changesets) to release to NPM. You can use the `release` script in `package.json` to publish.\n\nFor an alpha or beta version, follow the directions [here](https://github.com/changesets/changesets/blob/main/docs/prereleases.md).\n"
  },
  "scaffold-eth/create-eth": {
    "fetchedAt": "2025-11-12T22:47:05.214Z",
    "content": "# üèó create-eth\n\nCLI to create decentralized applications (dapps) using Scaffold-ETH 2.\n\n<h4 align=\"center\">\n  <a href=\"https://docs.scaffoldeth.io\">SE-2 Documentation</a> |\n  <a href=\"https://scaffoldeth.io\">SE-2 Website</a>\n</h4>\n\n## Requirements\n\nBefore you begin, you need to install the following tools:\n\n- [Node (>= v20.18.3)](https://nodejs.org/en/download/)\n- Yarn ([v1](https://classic.yarnpkg.com/en/docs/install/) or [v2+](https://yarnpkg.com/getting-started/install))\n- [Git](https://git-scm.com/downloads)\n\n## Quickstart\n\nTo get started with Scaffold-ETH 2, follow the steps below:\n\n1. Install the latest version of Scaffold-ETH 2\n\n```\nnpx create-eth@latest\n```\n\nThis command will install all the necessary packages and dependencies, so it might take a while.\n\n> [!NOTE]\n> You can also initialize your project with one of our extensions to add specific features or starter-kits. Learn more in our [extensions documentation](https://docs.scaffoldeth.io/extensions/).\n\n2. Run a local network in the first terminal:\n\n```\nyarn chain\n```\n\nThis command starts a local Ethereum network that runs on your local machine and can be used for testing and development. Learn how to [customize your network configuration](https://docs.scaffoldeth.io/quick-start/environment#1-initialize-a-local-blockchain).\n\n3. On a second terminal, deploy the test contract:\n\n```\nyarn deploy\n```\n\nThis command deploys a test smart contract to the local network. You can find more information about how to customize your contract and deployment script in our [documentation](https://docs.scaffoldeth.io/quick-start/environment#2-deploy-your-smart-contract).\n\n4. On a third terminal, start your NextJS app:\n\n```\nyarn start\n```\n\nVisit your app on: `http://localhost:3000`. You can interact with your smart contract using the `Debug Contracts` page. You can tweak the app config in `packages/nextjs/scaffold.config.ts`.\n\n**What's next**:\n\nVisit the [What's next section of our docs](https://docs.scaffoldeth.io/quick-start/environment#whats-next) to learn how to customize your contracts, frontend, and more.\n\n## Documentation\n\nVisit our [docs](https://docs.scaffoldeth.io) to learn all the technical details and guides of Scaffold-ETH 2.\n\nTo know more about its features, check out our [website](https://scaffoldeth.io).\n\nWatch [BG Labs](https://youtube.com/playlist?list=PLJz1HruEnenD77QAsqnk7KG8rSOMk0B99&si=JXZRn78_NBcvJJoZ) - our video series on building with Scaffold-ETH 2.\n\n## Contributing\n\nBuilt by [BuidlGuidl](https://buidlguidl.com) builders, we welcome contributions to create-eth!\n\nFor more information and guidelines for contributing, please see [CONTRIBUTING.MD](https://github.com/scaffold-eth/create-eth/blob/main/CONTRIBUTING.md)\n\n## Community\n\n<h4 align=\"center\">\n  <a href=\"https://x.com/buidlguidl\">Buidlguidl X</a> |\n  <a href=\"https://x.com/ScaffoldETH\">SE-2 X</a> |\n  <a href=\"https://t.me/joinchat/F7nCRK3kI93PoCOk\">SE-2 developers chat</a>\n</h4>\n"
  },
  "BuidlGuidl/SpeedRunEthereum-v2": {
    "fetchedAt": "2025-11-12T22:47:05.524Z",
    "content": "# Speedrun Ethereum\n\n![SRE Thumbnail](./packages/nextjs/public/thumbnail.png)\n\nNew version of [Speedrun Ethereum](https://github.com/BuidlGuidl/SpeedRunEthereum) built with [Scaffold-ETH 2](https://github.com/scaffold-eth/scaffold-eth-2). An expanded experience for builders where you'll be able to unlock your builder profile after completing a few challenges. This will open the gates to:\n\n- Interact with other BuidlGuidl curriculums like [ETH Tech Tree](https://www.ethtechtree.com/) and [BuidlGuidl CTF](https://ctf.buidlguidl.com/)\n- Share your builds and discover what other builders are up to\n- Earn badges\n\nYou can find the repository containing the challenges [here](https://github.com/scaffold-eth/se-2-challenges).\n\n## Requirements\n\nBefore you begin, you need to install the following tools:\n\n- [Node (>= v22.18.0)](https://nodejs.org/en/download/)\n- Yarn ([v1](https://classic.yarnpkg.com/en/docs/install/) or [v2+](https://yarnpkg.com/getting-started/install))\n- [Git](https://git-scm.com/downloads)\n- [Docker Engine](https://docs.docker.com/engine/install/)\n\n## Development Quickstart\n\n1. Install dependencies\n\n```\nyarn install\n```\n\n2. Spin up the Postgres database service + create database + seed\n\n```\ndocker compose up -d\nyarn drizzle-kit migrate\nyarn db:seed\n```\n\n3. Start your NextJS app:\n\n```\nyarn start\n```\n\nVisit your app on: `http://localhost:3000`.\n\n4. You can explore the database with:\n\n```\nyarn drizzle-kit studio\n```\n\n### Database Information\n\nWe are using Drizzle with Postgres for database management. You can run `drizzle-kit` commands from the root with `yarn drizzle-kit`.\n\n### Database Migration\n\nAnytime we update the schema in `packages/nextjs/services/database/config/schema.ts`, we can generate a migration with:\n\n```\nyarn drizzle-kit generate\n```\n\nThen we can apply the migration with:\n\n```\nyarn drizzle-kit migrate\n```\n\nWe also need to make sure we commit the migration to the repo.\n\n### Database (dev info)\n\nTo iterate fast on the database locally:\n\n- Tweak the schema in `schema.ts`\n- Run `yarn drizzle-kit push` to apply the changes.\n- Copy `seed.data.example.ts` to `seed.data.ts`, tweak as needed and run `yarn db:seed` (will delete existing data)\n\n### Firebase image upload\n\n1. In the Firebase Console, go to \"Project settings\" (the gear icon)\n2. Navigate to the \"Service accounts\" tab\n3. Click \"Generate new private key\" for the Firebase Admin SDK\n4. Save the JSON file securely\n\n5. In `.env.local` file in the `packages/nextjs` directory, add the following variables:\n\n```\nFIREBASE_SERVICE_ACCOUNT_KEY='{\n  \"type\": \"service_account\",\n  \"project_id\": \"your-project-id\",\n  ...,\n}'\n\nFIREBASE_STORAGE_BUCKET=your-project-id.appspot.com\n```\n\nReplace the content of `FIREBASE_SERVICE_ACCOUNT_KEY` with the JSON content from your service account key file (wrap the json in single quotes).\n\nThe `FIREBASE_STORAGE_BUCKET` should be set to your Firebase Storage bucket name, typically in the format `your-project-id.appspot.com`.\n\n## Testing\n\nThis project uses [Playwright](https://playwright.dev/) with [Synpress](https://github.com/Synthetixio/synpress) for end-to-end testing with MetaMask integration.\n\n### Running Tests\n\nTo run tests locally, you have two options:\n\n#### 1. Run tests in headless mode:\n\n```bash\nyarn next:test\n```\n\n#### 2. Run tests with UI (interactive mode):\n\n```bash\nyarn next:test-ui\n```\n\n### Test Setup Requirements\n\nBefore running tests, ensure you have:\n\n1. **Install Playwright browsers** (only needed the first time):\n\n   ```bash\n   yarn next:playwright-install\n   ```\n\n2. **Build wallet cache**: Set up the Synpress cache for MetaMask integration\n\n   ```bash\n   yarn next:cache-synpress\n   ```\n\n3. **Database running**: Make sure your Postgres database is up and seeded\n   ```bash\n   docker compose up -d\n   yarn drizzle-kit migrate\n   yarn db:seed\n   ```\n\n> **Note**: The tests will automatically start the dev server, so you don't need to run it manually.\n\n### Troubleshooting\n\n#### Cache Issues\n\nIf you encounter an error like `Error: Cache for 08a20e3c7fc77e6ae298 does not exist. Create it first!`, you need to rename your cache folder:\n\n1. Navigate to `packages/nextjs/.cache-synpress/`\n2. Rename the existing cache folder to match the error message (e.g., rename `532f685e346606c2a803` to `08a20e3c7fc77e6ae298`), or use this command from the root folder:\n\n```\nmv packages/nextjs/.cache-synpress/532f685e346606c2a803 packages/nextjs/.cache-synpress/08a20e3c7fc77e6ae298\n```\n\n#### User Registration Issues\n\nSince tests register a test user, you may need to reset the database between test runs:\n\n```bash\nyarn db:seed\n```\n\nThis will clear existing data and reseed the database with fresh test data.\n"
  },
  "scaffold-eth/scaffoldeth.io": {
    "fetchedAt": "2025-11-12T22:47:05.820Z",
    "content": "# üèó Scaffold-ETH 2 website\n\nWork in progress.\n\n## Requirements\n\nBefore you begin, you need to install the following tools:\n\n- [Node (>= v22.18.0)](https://nodejs.org/en/download/)\n- Yarn ([v1](https://classic.yarnpkg.com/en/docs/install/) or [v2+](https://yarnpkg.com/getting-started/install))\n- [Git](https://git-scm.com/downloads)\n\n## Quickstart\n\n1. Clone this repo & install dependencies\n\n```\ngit clone https://github.com/scaffold-eth/scaffoldeth.io.git\ncd scaffoldeth.io\nyarn install\n```\n\n4. Start your NextJS app:\n\n```\nyarn start\n```\n\nVisit your app on: `http://localhost:3000`.\n"
  },
  "scaffold-eth/se-2-docs": {
    "fetchedAt": "2025-11-12T22:47:06.151Z",
    "content": "# Scaffold-ETH 2 Docs\n\nThis website contains Scaffold-ETH 2 Documentation and is built using [Docusaurus 2](https://docusaurus.io/).\n\n## Requirements\n\nTo run the Documentation site locally, but first ensure you have [Node](https://nodejs.org/en/download/) and [Git](https://git-scm.com/downloads) installed.\n\n## Installation\n\nClone the repository, install all dependencies as well as build all local packages, and then start Docusaurus.\n\n```\ngit clone https://github.com/scaffold-eth/se2-docs.git\ncd se2-docs\nnpm install\nnpm run start\n```\n\n### Run docs with search feature enabled\n\nInstead of `npm run start`, you'll need to:\n\n```bash\nnpm run docusaurus build\nnpm run docusaurus serve\n```\n\nIf you change the [search configuration](/docusaurus.config.js#L27), you'll need to run `npm run docusaurus build` and then `npm run docusaurus serve` again to refresh with the changes.\n\n## Contribution Guidelines\n\nThank you for your interest in contributing to improve the documentation!\n\nThere are two types of contributions you can make:\n\n- Fix errors or add new pages to the current documentation content.\n- Fix bugs or introduce new features to the documentation website (within the Docusaurus codebase).\n\n## Content contributions\n\nThe documentation content is written in Markdown format and is located in the `docs` folder. If you‚Äôre not familiar with Markdown, please check this [guide](https://guides.github.com/features/mastering-markdown/) or this [cheat sheet](https://www.markdownguide.org/cheat-sheet/) to get started.\n\nMDX files are also present, they combine Markdown with React. You can learn more about MDX files in [Docusaurus docs](https://docusaurus.io/docs/markdown-features/react).\n\n### Existing content\n\nIf you find anything that is confusing or can be improved in an existing document, you can click **\"Edit this page\" at the bottom of the page**, which will redirect to the GitHub edit form of that document. Make your changes and submit a pull request (PR).\n\n### New content\n\nWhen **adding a new page**, you need to fork the repository, create a new branch, and make all changes necessary in your repository. Once you are done with your changes, create a PR to Scaffold-ETH 2 Documentation repository.\n\nAdd the new pages to the `docs` folder, placing them in the specific directory where you want the page to be shown.\n**Sidebar** link will get **autogenerated** under your specific folder, in the **position** that you specify in your document header. Example:\n\n```markdown\n---\nsidebar_position: 2\n---\n```\n\nIf you want to **create a new folder** to the Document structure, you'll need to add the new folder and a markdown document with the same name of that folder, which will be displayed when the users click on the sidebar link.\n\n<!---\nTODO: Explain how to upload/link images to the docs. Currently there are none.\n-->\n\n<!---\nTODO: Explain _category_.json\n-->\n\n## Website contributions\n\nFor contributions to the Website Code, we follow the [\"fork-and-pull\" Git workflow](https://github.com/susam/gitpr).\n\nFork the repository, create a new branch, and make all changes necessary in your repository. Once you are done with your changes, create a PR to Scaffold-ETH 2 Documentation repository.\n\n### Configuration\n\n- `docusaurus.config.js` - This file contains the Docusaurus configuration. Here you can manage site metadata, links in the header and footer, and theme configuration. You can visit [Docusaurus docs](https://docusaurus.io/docs/configuration) to learn more about the Docusaurus settings.\n\n### Sidebars\n\n- `sidebars.js` - This specifies the sidebars for your documentation. You'll see that we currently have `type: 'autogenerated'` configured for the sidebar. This will generate sidebar menu links based on the folder structure and positions defined in each document.\n\n  The full documentation for this file is available on the [Docusaurus website](https://docusaurus.io/docs/sidebar).\n\n### Styles\n\n- `src/css/custom.css` - This file contains our custom modifications on top of the Docusaurus 'classic' theme. For in-depth understanding of [Docusaurus Styling and Layout](https://docusaurus.io/docs/styling-layout) you can visit their docs, where you will find the Theme Class Names in order to modify them in our `custom.css`.\n\nIf there's something overlooked in this `README.md` or if any instructions are unclear, remember you can also contribute to improve it. **Fork, modify and PR to our repository!**\n\nAll contributions are welcome!\n"
  },
  "BuidlGuidl/SpeedRunEthereum": {
    "fetchedAt": "2025-11-12T22:47:06.536Z",
    "content": "# üèÉ‚Äç‚ôÄÔ∏è Speed Run Ethereum\n\n> [!WARNING]  \n> This is the codebase for SpeedRunEthereum v1 (live until April 2025) Visit https://github.com/BuidlGuidl/SpeedRunEthereum-v2/ for the new & live version.\n\n![SRE Thumbnail](./packages/react-app/public/thumbnail.png)\n\nSpeed Run Ethereum aims to provide a structured learning path for onboarding developers to Ethereum.\n\n[üèÉ‚Äç‚ôÄÔ∏èEthereum Dev Speed Run](https://medium.com/@austin_48503/%EF%B8%8Fethereum-dev-speed-run-bd72bcba6a4c) with a framework for submitting challenges, get feedback from ethereum builders, and in the process unlocking new challenges and proof of completion.\n\n---\n\n## Project setup\n\nGet the project code:\n\n```bash\ngit clone git@github.com:BuidlGuidl/SpeedRunEthereum.git\n\ncd SpeedRunEthereum\n```\n\nInstall dependencies:\n\n```bash\nyarn install\n```\n\nStart the backend service:\n\n```bash\nyarn backend\n```\n\nIn a new terminal, start the frontend:\n\n```bash\nyarn start\n```\n\nAt this point, you should have the app available at <http://localhost:3000>. By default, a locale JSON file (`packages/backend/local_database/local_db.json`) is used as the database. This is intended for testing and demo usage. In order to set it up for production usage, we provide a Firebase database adaptor. You can also easily create your own database adapter (check `packages/backend/services/db.js`).\n\n---\n\n## Firebase Setup (optional)\n\nIf you want to use Firebase (firestore) for data storage, you'll need to create a Firebase project and download the service account key configuration. You can generate and download the service account file at <https://console.cloud.google.com/> by 1.) select your Firebase project, 2.) go to IAM & Admin > Service Accounts, 3.) create a service account or click one that is already created, 4.) go to keys of that account, and 5.) Add Key > Create key and select a JSON key type.\n\nThen you will have to create a `.env` file in `packages/backend/` with `DATABASE_SERVICE=firebase` and add the full path to the service account file in `GOOGLE_APPLICATION_CREDENTIALS` (see a sample here `packages/backend/.env.sample`).\n\nThen re-run:\n\n```bash\nyarn backend\n```\n"
  },
  "scaffold-eth/create-eth-extensions": {
    "fetchedAt": "2025-11-12T22:47:06.852Z",
    "content": "# üîå create-eth Extensions\n\nThis repository holds all the BG curated extensions for [create-eth](https://github.com/scaffold-eth/create-eth), so you can extend the functionality of your Scaffold-ETH project.\n\n## Usage\n\nYou can install any of the extensions in this repository by running the following command:\n\n```bash\nnpx create-eth@latest -e <extension-name>\n```\n\n## Available Extensions\n\nExplore our curated (by BuidlGuidl) and community-contributed extensions for Scaffold-ETH 2 at: https://scaffoldeth.io/extensions\n\n## Create your own extension\n\nExtend Scaffold-ETH by building and publishing your own extension. For a step-by-step guide, see the [official documentation](https://docs.scaffoldeth.io/extensions/createExtensions).\n"
  },
  "scaffold-eth/scaffold-eth-2": {
    "fetchedAt": "2025-11-12T22:47:07.146Z",
    "content": "# üèó Scaffold-ETH 2\n\n<h4 align=\"center\">\n  <a href=\"https://docs.scaffoldeth.io\">Documentation</a> |\n  <a href=\"https://scaffoldeth.io\">Website</a>\n</h4>\n\nüß™ An open-source, up-to-date toolkit for building decentralized applications (dapps) on the Ethereum blockchain. It's designed to make it easier for developers to create and deploy smart contracts and build user interfaces that interact with those contracts.\n\n‚öôÔ∏è Built using NextJS, RainbowKit, Foundry/Hardhat, Wagmi, Viem, and Typescript.\n\n- ‚úÖ **Contract Hot Reload**: Your frontend auto-adapts to your smart contract as you edit it.\n- ü™ù **[Custom hooks](https://docs.scaffoldeth.io/hooks/)**: Collection of React hooks wrapper around [wagmi](https://wagmi.sh/) to simplify interactions with smart contracts with typescript autocompletion.\n- üß± [**Components**](https://docs.scaffoldeth.io/components/): Collection of common web3 components to quickly build your frontend.\n- üî• **Burner Wallet & Local Faucet**: Quickly test your application with a burner wallet and local faucet.\n- üîê **Integration with Wallet Providers**: Connect to different wallet providers and interact with the Ethereum network.\n\n![Debug Contracts tab](https://github.com/scaffold-eth/scaffold-eth-2/assets/55535804/b237af0c-5027-4849-a5c1-2e31495cccb1)\n\n## Requirements\n\nBefore you begin, you need to install the following tools:\n\n- [Node (>= v20.18.3)](https://nodejs.org/en/download/)\n- Yarn ([v1](https://classic.yarnpkg.com/en/docs/install/) or [v2+](https://yarnpkg.com/getting-started/install))\n- [Git](https://git-scm.com/downloads)\n\n## Quickstart\n\nTo get started with Scaffold-ETH 2, follow the steps below:\n\n1. Install the latest version of Scaffold-ETH 2\n\n```\nnpx create-eth@latest\n```\n\nThis command will install all the necessary packages and dependencies, so it might take a while.\n\n> [!NOTE]\n> You can also initialize your project with one of our extensions to add specific features or starter-kits. Learn more in our [extensions documentation](https://docs.scaffoldeth.io/extensions/).\n\n2. Run a local network in the first terminal:\n\n```\nyarn chain\n```\n\nThis command starts a local Ethereum network that runs on your local machine and can be used for testing and development. Learn how to [customize your network configuration](https://docs.scaffoldeth.io/quick-start/environment#1-initialize-a-local-blockchain).\n\n3. On a second terminal, deploy the test contract:\n\n```\nyarn deploy\n```\n\nThis command deploys a test smart contract to the local network. You can find more information about how to customize your contract and deployment script in our [documentation](https://docs.scaffoldeth.io/quick-start/environment#2-deploy-your-smart-contract).\n\n4. On a third terminal, start your NextJS app:\n\n```\nyarn start\n```\n\nVisit your app on: `http://localhost:3000`. You can interact with your smart contract using the `Debug Contracts` page. You can tweak the app config in `packages/nextjs/scaffold.config.ts`.\n\n**What's next**:\n\nVisit the [What's next section of our docs](https://docs.scaffoldeth.io/quick-start/environment#whats-next) to learn how to:\n\n- Edit your smart contracts\n- Edit your deployment scripts\n- Customize your frontend\n- Edit the app config\n- Writing and running tests\n- [Setting up external services and API keys](https://docs.scaffoldeth.io/deploying/deploy-smart-contracts#configuration-of-third-party-services-for-production-grade-apps)\n\n## Documentation\n\nVisit our [docs](https://docs.scaffoldeth.io) to learn all the technical details and guides of Scaffold-ETH 2.\n\nTo know more about its features, check out our [website](https://scaffoldeth.io).\n\n## Contributing to Scaffold-ETH 2\n\nWe welcome contributions to Scaffold-ETH 2!\n\nPlease see [CONTRIBUTING.MD](https://github.com/scaffold-eth/scaffold-eth-2/blob/main/CONTRIBUTING.md) for more information and guidelines for contributing to Scaffold-ETH 2.\n"
  },
  "scaffold-eth/se-2-challenges": {
    "fetchedAt": "2025-11-12T22:47:07.556Z",
    "content": "# üèó Scaffold-ETH 2 Challenges\n\n**Learn how to use üèó Scaffold-ETH 2 to create decentralized applications on Ethereum. üöÄ**\n\n---\n\n## üö© Challenge: üéü Tokenization\n\nüé´ Create a unique token to learn the basics of üèóÔ∏è Scaffold-ETH 2. You'll use üë∑‚Äç‚ôÄÔ∏è HardHat to compile and deploy smart contracts. Then, you'll use a template React app full of important Ethereum components and hooks. Finally, you'll deploy an NFT to a public network to share with friends! üöÄ\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-tokenization)\n\n---\n\n## üö© Challenge: üîè Decentralized Staking App\n\nü¶∏ A superpower of Ethereum is allowing you, the builder, to create a simple set of rules that an adversarial group of players can use to work together. In this challenge, you create a decentralized application where users can coordinate a group funding effort. If the users cooperate, the money is collected in a second smart contract. If they defect, the worst that can happen is everyone gets their money back. The users only have to trust the code.\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-decentralized-staking)\n\n---\n\n## üö© Challenge: üèµ Token Vendor\n\nü§ñ Smart contracts are kind of like \"always on\" vending machines that anyone can access. Let's make a decentralized, digital currency. Then, let's build an unstoppable vending machine that will buy and sell the currency. We'll learn about the \"approve\" pattern for ERC20s and how contract to contract interactions work.\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-token-vendor)\n\n---\n\n## üö© Challenge: üé≤ Dice Game\n\nüé∞ Randomness is tricky on a public deterministic blockchain. In this challenge you will explore creating random numbers using block hash and how that may be exploitable. Attack the dice game with your own contract by predicting the randomness ahead of time to always roll a winner!\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-dice-game)\n\n---\n\n## üö© Challenge: ‚öñÔ∏è Build a DEX Challenge\n\nüíµ Build an exchange that swaps ETH to tokens and tokens to ETH. üí∞ This is possible because the smart contract holds reserves of both assets and has a price function based on the ratio of the reserves. Liquidity providers are issued a token that represents their share of the reserves and fees...\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-dex)\n\n---\n\n## üéâ Checkpoint: Onboarding batches\n\nDive into end-to-end dApp development, receive mentorship from BuidlGuidl members, and learn how to collaborate with fellow developers in open‚Äësource projects.\n\n---\n\n## üö© Challenge: üåΩ Over-Collateralized Lending\n\nüí≥ Build your own lending and borrowing platform. Let's write a contract that takes collateral and lets you borrow other assets against the value of the collateral. What happens when the collateral changes in value? We will be able to borrow more if it is higher, or if it is lower, we will also build a system for liquidating the debt position.\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-over-collateralized-lending)\n\n---\n\n## üö© Challenge: üìà Prediction Markets\n\nüîÆ Build a prediction market where users can create questions about future outcomes for others to bet on. Users can also participate in existing markets to speculate on event results. üìä Outcome shares can be traded, with prices adjusting dynamically based on market belief. This is possible because the smart contract acts as an automated market maker (like in the DEX challenge) and adjusts odds based on supply and demand.\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-prediction-markets)\n\n---\n\n## üö© Challenge: ‚ö° Deploy to Layer 2\n\nüöÄ Ethereum L2s make blockchain apps fast and cheap, bringing us closer to mainstream adoption! Most L2s are EVM compatible, meaning your app should work seamlessly across them with little to no changes‚Äîjust deploy and go! In this challenge, you will deploy an app across multiple chains, including Optimism, Base, and Arbitrum, and experience the snappy, low-cost transactions while exploring how they make building scalable apps and games easier than ever.\n\nComing soon...\n\n---\n\n## üö© Challenge: Multisig Wallet\n\nüë©‚Äçüë©‚Äçüëß‚Äçüëß Using a smart contract as a wallet we can secure assets by requiring multiple accounts to \"vote\" on transactions. The contract will keep track of transactions in an array of structs and owners will confirm or reject each one. Any transaction with enough confirmations can \"execute\".\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-multisig)\n\n---\n\n## üö© Challenge: SVG NFT\n\nüé® Create a dynamic SVG NFT using a smart contract. Your contract will generate on-chain SVG images and allow users to mint their unique NFTs. ‚ú® Customize your SVG graphics and metadata directly within the smart contract. üöÄ Share the minting URL once your project is live!\n\n[Challenge Extension](https://github.com/scaffold-eth/se-2-challenges/tree/challenge-svg-nft)\n\n---\n\n## üí° Contributing: Guide and Hints to create New Challenges\n\n### 1. Learn about SE-2 Extensions\n\nGo to [SE-2 Extensions Documentation](https://docs.scaffoldeth.io/extensions/createExtensions) and familiarize yourself with the way extensions work by watching the video and reading the overview.\n\n### 2. Follow the steps to create an extension\n\n1. Clone the [create-eth repo](https://github.com/scaffold-eth/create-eth) and cd into it.\n\n```bash\n    git clone https://github.com/scaffold-eth/create-eth\n    cd create-eth\n```\n\n#### Setting up things in externalExtensions:\n\n2. cd into `externalExtensions` (if it's not present `mkdir externalExtensions && cd externalExtensions`)\n\n3. Clone the base-challenge-template with name of your extension inside `externalExtensions`:\n\n```bash\n    git clone -b base-challenge-template https://github.com/scaffold-eth/se-2-challenges.git <my-challenge-name>\n```\n\n4. cd into `<my-challenge-name>` dir and create a branch with your challenge name.\n\n```bash\n    cd <my-challenge-name> && git switch -c <my-challenge-name>\n```\n\n5. Find all the file comments marked `// CHALLENGE-TODO:` and follow the instructions to prepare your challenge.\n\n6. Commit those changes as an initial commit: `git add . && git commit -m \"fill template\"`.\n\n#### Commands to be run in create-eth repo:\n\n1. Build the create-eth cli\n\n```bash\n    yarn build:dev\n```\n\n2. Create an instance with same name as the challenge name directory which was created inside `externalExtensions`:\n\n```bash\n    yarn cli ../<my-challenge-name> -e <my-challenge-name> --dev\n```\n\n3. This will create the full instance outside of create-eth repo with <my-challenge-name>\n\n4. Tinker in that instance, adding any new files your challenge will use and then committing those changes\n\n5. Run this in create-eth to copy all the changes to you extension:\n\n```bash\n    yarn create-extension ../<my-challenge-name>\n```\n\n### 3. Testing your extension\n\nNow that you ran the `create-extension` command you should see in the terminal all files that were created and any missing template files. Add any missing template files and continue to follow the instructions in the [local testing](https://docs.scaffoldeth.io/extensions/createExtensions#local-testing) section!\n\nDon't forget to add a README.md to the top level of your extension. It should match what you put in the `extraContents` variable in `extension/README.md.args.mjs`.\n\nIterate as necessary, repeating the steps, to get it just right.\n\n### 4. Submit a PR\n\nOnce you have iterated your challenge to perfection, you can ask a maintainer to add a branch for your challenge and then submit a pull request to that branch. Expect to make a few passes of revisions as we test these challenges extensively.\n"
  },
  "scaffold-eth/burner-connector": {
    "fetchedAt": "2025-11-12T22:47:07.963Z",
    "content": "# üî• Burner Connector\n\n## Requirements\n\nBefore you begin, you need to install the following tools:\n\n- [Node (>= v18.17)](https://nodejs.org/en/download/)\n- [pnpm](https://pnpm.io/installation#using-corepack)\n- [Git](https://git-scm.com/downloads)\n\n## Quickstart\n\n1. Install the dependencies:\n\n```bash\nnpm install burner-connector\n\nor\n\nyarn add burner-connector\n\nor\n\npnpm add burner-connector\n```\n\n2. Using wagmi `burner` connector:\n\n```ts\nimport { burner } from \"burner-connector\";\nimport { mainnet, base } from \"viem/chains\";\n\n// Configuration options:\n// - `useSessionStorage` (optional) : false (default) to persist wallet across browser tabs\n//                       true to create a new wallet for each browser tab\n// - `rpcUrls` (optional) : custom RPC URLs for specific chain IDs\n\n// Basic usage without options\nexport const config = createConfig({\n  chains: [mainnet, base],\n  connectors: [burner()],\n  transports: {\n    [mainnet.id]: http(),\n    [base.id]: http(),\n  },\n});\n\n// Example with all options\nexport const config = createConfig({\n  chains: [mainnet, base],\n  connectors: [\n    burner({\n      useSessionStorage: true,\n      rpcUrls: {\n        1: \"https://eth-mainnet.g.alchemy.com/v2/YOUR_API_KEY\",\n        8453: \"https://base-mainnet.g.alchemy.com/v2/YOUR_API_KEY\",\n      },\n    }),\n  ],\n  transports: {\n    [mainnet.id]: http(),\n    [base.id]: http(),\n  },\n});\n```\n\n3. Integrate with rainbowkit:\n\n```ts\nimport { connectorsForWallets } from \"@rainbow-me/rainbowkit\";\nimport { metaMaskWallet } from \"@rainbow-me/rainbowkit/wallets\";\nimport { rainbowkitBurnerWallet } from \"burner-connector\";\nimport { mainnet, base } from \"viem/chains\";\n\n// Configure burner wallet options\n// Storage configuration:\n// - useSessionStorage: false (default) to persist wallet across browser tabs\n//                     true to create a new wallet for each browser tab\nrainbowkitBurnerWallet.useSessionStorage = true;\n\n// Custom RPC URLs configuration (optional):\nrainbowkitBurnerWallet.rpcUrls = {\n  1: \"https://eth-mainnet.g.alchemy.com/v2/YOUR_API_KEY\",\n  8453: \"https://base-mainnet.g.alchemy.com/v2/YOUR_API_KEY\",\n};\n\nconst wallets = [metaMaskWallet, rainbowkitBurnerWallet];\n\nconst wagmiConnectors = connectorsForWallets(\n  [\n    {\n      groupName: \"Supported Wallets\",\n      wallets,\n    },\n  ],\n  {\n    appName: \"scaffold-eth-2\",\n    projectId: \"YOUR_WALLET_CONNECT_PROJECT_ID\",\n  },\n);\n\nconst wagmiConfig = createConfig({\n  chains: [mainnet, base],\n  connectors: wagmiConnectors,\n  ssr: true,\n  transports: {\n    [mainnet.id]: http(),\n    [base.id]: http(),\n  },\n});\n```\n\n## Configuration Options\n\n### Burner Connector Options\n\n| Option                         | Type                     | Default     | Description                                                                                     |\n| ------------------------------ | ------------------------ | ----------- | ----------------------------------------------------------------------------------------------- |\n| `useSessionStorage` (optional) | `boolean`                | `false`     | When true, creates a new wallet for each browser tab. When false, persists wallet across tabs.  |\n| `rpcUrls` (optional)           | `Record<number, string>` | `undefined` | Optional custom RPC URLs for specific chain IDs. Falls back to chain's default if not provided. |\n\n---\n\nCheckout [CONTRIBUTING.md](/CONTRIBUTING.md) for more details on how to set it up locally.\n"
  },
  "wevm/wagmi": {
    "fetchedAt": "2025-11-12T22:47:23.184Z",
    "content": "<!-- > [!IMPORTANT] -->\n<!-- > Wagmi is participating in Gitcoin Grants round 21. Consider <a href=\"https://explorer.gitcoin.co/#/round/42161/389/74\">supporting the project</a>. Thank you. üôè -->\n\n<br>\n\n<p align=\"center\">\n  <a href=\"https://wagmi.sh\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/wagmi/main/.github/logo-dark.svg\">\n      <img alt=\"wagmi logo\" src=\"https://raw.githubusercontent.com/wevm/wagmi/main/.github/logo-light.svg\" width=\"auto\" height=\"60\">\n    </picture>\n  </a>\n</p>\n\n<p align=\"center\">\n  Reactive primitives for Ethereum apps\n<p>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/wagmi\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/npm/v/wagmi?colorA=21262d&colorB=21262d\">\n      <img src=\"https://img.shields.io/npm/v/wagmi?colorA=f6f8fa&colorB=f6f8fa\" alt=\"Version\">\n    </picture>\n  </a>\n  <a href=\"https://scorecard.dev/viewer/?uri=github.com/ossf/scorecard\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/ossf-scorecard/github.com/wevm/wagmi?label=openssf+scorecard&style=flat&color=21262d&labelColor=21262d\">\n      <img src=\"https://img.shields.io/ossf-scorecard/github.com/wevm/wagmi?label=openssf+scorecard&style=flat&color=f6f8fa&labelColor=f6f8fa\" alt=\"OpenSSF Best Practices\">\n    </picture>\n  </a>\n  <a href=\"https://www.bestpractices.dev/en/projects/11233\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/badge/openssf_best_practices-passing-21262d?labelColor=21262d\">\n      <img src=\"https://img.shields.io/badge/openssf_best_practices-passing-f6f8fa?labelColor=f6f8fa\" alt=\"OpenSSF Best Practices\">\n    </picture>\n  </a>\n  <br />\n  <a href=\"https://github.com/wevm/wagmi/blob/main/LICENSE\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/npm/l/wagmi?colorA=21262d&colorB=21262d\">\n      <img src=\"https://img.shields.io/npm/l/wagmi?colorA=f6f8fa&colorB=f6f8fa\" alt=\"MIT License\">\n    </picture>\n  </a>\n  <a href=\"https://www.npmjs.com/package/wagmi\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/npm/dm/@wagmi/core?colorA=21262d&colorB=21262d\">\n      <img src=\"https://img.shields.io/npm/dm/@wagmi/core?colorA=f6f8fa&colorB=f6f8fa\" alt=\"Downloads per month\">\n    </picture>\n  </a>\n  <a href=\"https://bestofjs.org/projects/wagmi\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/endpoint?colorA=21262d&colorB=21262d&url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=wevm%2Fviem%26since=daily\">\n      <img src=\"https://img.shields.io/endpoint?colorA=f6f8fa&colorB=f6f8fa&url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=wevm%2Fviem%26since=daily\" alt=\"Best of JS\">\n    </picture>\n  </a>\n  <a href=\"https://app.codecov.io/gh/wevm/wagmi\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/codecov/c/github/wevm/wagmi?colorA=21262d&colorB=21262d\">\n      <img src=\"https://img.shields.io/codecov/c/github/wevm/wagmi?colorA=f6f8fa&colorB=f6f8fa\" alt=\"Code coverage\">\n    </picture>\n  </a>\n</p>\n\n---\n\n## Documentation\n\nFor documentation and guides, visit [wagmi.sh](https://wagmi.sh).\n\n## Community\n\nFor help, discussion about best practices, or any other conversation that would benefit from being searchable:\n\n[Discuss Wagmi on GitHub](https://github.com/wevm/wagmi/discussions)\n\nFor casual chit-chat with others using the framework:\n\n[Join the Wagmi Discord](https://discord.gg/SghfWBKexF)\n\n## Contributing\n\nContributions to Wagmi are greatly appreciated! If you're interested in contributing to Wagmi, please read the [Contributing Guide](https://wagmi.sh/dev/contributing) **before submitting a pull request**.\n\n## Sponsors\n\nIf you find Wagmi useful or use it for work, please consider [sponsoring Wagmi](https://github.com/sponsors/wevm?metadata_campaign=gh_readme_support). Thank you üôè\n\n<p>\n  <a href=\"https://paradigm.xyz\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/paradigm-dark.svg\">\n      <img alt=\"paradigm logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/paradigm-light.svg\" width=\"auto\" height=\"70\">\n    </picture>\n  </a>\n  <a href=\"https://ithaca.xyz\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/ithaca-dark.svg\">\n      <img alt=\"ithaca logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/ithaca-light.svg\" width=\"auto\" height=\"70\">\n    </picture>\n  </a>\n</p>\n\n<p>\n  <a href=\"https://twitter.com/family\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/family-dark.svg\">\n      <img alt=\"family logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/family-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://twitter.com/context\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/context-dark.svg\">\n      <img alt=\"context logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/context-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://walletconnect.com\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/walletconnect-dark.svg\">\n      <img alt=\"WalletConnect logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/walletconnect-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://twitter.com/prtyDAO\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/partydao-dark.svg\">\n      <img alt=\"PartyDAO logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/partydao-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://dynamic.xyz\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/dynamic-dark.svg\">\n      <img alt=\"Dynamic logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/dynamic-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://sushi.com\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/sushi-dark.svg\">\n      <img alt=\"Sushi logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/sushi-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://stripe.com\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/stripe-dark.svg\">\n      <img alt=\"Stripe logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/stripe-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://www.privy.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/privy-dark.svg\">\n      <img alt=\"Privy logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/privy-light.svg\" width=\"auto\" height=\"50\">\n    </picture>\n  </a>\n  <a href=\"https://pancakeswap.finance/\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/pancake-dark.svg\">\n      <img alt=\"panc\n\n[... truncated ...]"
  },
  "protofire/solhint": {
    "fetchedAt": "2025-11-12T22:47:30.079Z",
    "content": "<p align=\"center\">\n  <a href=\"https://protofire.io/solhint\" target=\"_blank\"><img src=\"solhint.png\"></a>\n</p>\n<p align=\"center\">\n  By <a href=\"https://protofire.io/\" target=\"_blank\">Protofire</a>\n</p>\n\n[![](https://img.shields.io/badge/Solhint%20Website-cyan)](https://protofire.io/solhint)\n[![](https://img.shields.io/badge/Join%20Our%20Discord-magenta)](https://discord.gg/4TYGq3zpjs)\n[![Donate with Ethereum](https://img.shields.io/badge/Donate-ETH-blue)](https://etherscan.io/address/0xA81705c8C247C413a19A244938ae7f4A0393944e)\n[![NPM version](https://badge.fury.io/js/solhint.svg)](https://npmjs.org/package/solhint)\n[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/protofire/solhint/master/LICENSE)\n\nThis is an open source project for linting [Solidity](http://solidity.readthedocs.io/en/develop/) code. This project\nprovides both **Security** and **Style Guide** validations.\n<br>\n[VISIT OUR WEBSITE](https://protofire.io/solhint)<br>\n[JOIN OUR DISCORD SERVER](https://discord.gg/4TYGq3zpjs)\n<br>\n## Installation\n\nYou can install Solhint using **npm**:\n\n```sh\nnpm install -g solhint\n\n# verify that it was installed correctly\nsolhint --version\n```\n\n## Usage\n\nFirst initialize a configuration file, if you don't have one:\n\n```sh\nsolhint --init\n```\n\nThis will create a `.solhint.json` file with the recommended rules enabled. Then run Solhint with one or more [Globs](https://en.wikipedia.org/wiki/Glob_(programming)) as arguments. For example, to lint all files inside `contracts` directory, you can do:\n\n```sh\nsolhint 'contracts/**/*.sol'\n```\n\nTo lint a single file:\n\n```sh\nsolhint contracts/MyToken.sol\n```\n\nRun `solhint` without arguments to get more information:\n\n```text\nUsage: solhint [options] <file> [...other_files]\n\nLinter for Solidity programming language\n\nOptions:\n\n  -V, --version                           output the version number\n  -f, --formatter [name]                  report formatter name (stylish, table, tap, unix, json, compact, sarif)\n  -w, --max-warnings [maxWarningsNumber]  number of allowed warnings, works in quiet mode as well\n  -c, --config [file_name]                file to use as your rules configuration file (not compatible with multiple configs)\n  -q, --quiet                             report errors only - default: false\n  --ignore-path [file_name]               file to use as your .solhintignore\n  --fix                                   automatically fix problems and show report\n  --cache                                 only lint files that changed since last run\n  --cache-location                        path to the cache file\n  --noPrompt                              do not suggest to backup files when any `fix` option is selected\n  --init                                  create configuration file for solhint\n  --disc                                  do not check for solhint updates\n  --save                                  save report to file on current folder\n  --noPoster                              remove discord poster\n  -h, --help                              output usage information\n\nCommands:\n\n  stdin [options]                         linting of source code data provided to STDIN\n  list-rules                              display covered rules of current .solhint.json\n```\n### New Versions\n- Solhint checks if there are newer versions. The `--disc`  option avoids that check.\n- `--save` option will create a file named as `YYYYMMDDHHMMSS_solhintReport.txt` on current folder with default or specified format \n\n### Fix\nThis option currently works on:\n- avoid-throw\n- avoid-sha3\n- no-console\n- explicit-types\n- private-vars-underscore\n- payable-fallback\n- quotes\n- contract-name-capwords\n- avoid-suicide\n<br><br>\n\n## Configuration\nYou can use a `.solhint.json` file to configure Solhint for the whole project.\n\nTo generate a new sample `.solhint.json` file in current folder you can do:\n\n```sh\nsolhint --init \n```\n\nThis file has the following format:\n### Default \n```json\n{\n  \"extends\": \"solhint:recommended\"\n}\n```\n\nThe `solhint:default` configuration contains only two rules: max-line-length & no-console\nIt is now deprecated since version 5.1.0\n<br>\n\n### Multiple Configs\nMultiple configs files can be used at once. All config files should be named `.solhint.json`.\nIf not done like this, multiple hierarchy configuration will not work.\nSolhint will go though all config files automatically.\n\nGiven this structure:\n```\nProject ROOT =>\n/contracts\n---> RootAndContractRules.sol\n---> .solhint.json\n\n/src\n--->RootRules.sol\n--->interfaces/\n------->InterfaceRules.sol\n------->solhint.json  \n\n.solhint.json  \n```\n- Solhint config located on `root` will be the main one.\n- When analyzing `RootRules.sol`, `root` file config will be used that file.\n- `InterfaceRules.sol` will be using the one inside its own folder taking precedence over the `root` folder one.\n- Rules not present in `interfaces/` folder and present in `root` will be active.\n- Rules not present in `root` folder and present in `interfaces/` folder will be active.\n- If rule is present in both files, the closest to the analyzed file will take precedence. Meaning when analyzing `InterfaceRules.sol` the config file located in `Interfaces/` will be used with the remaining rules of the `root` one.\n<br><br>\n\n\n### Sample of simple config with recommended rules\n```json\n  {\n    \"extends\": \"solhint:recommended\",\n    \"plugins\": [],\n    \"rules\": {\n      \"avoid-suicide\": \"error\",\n      \"avoid-sha3\": \"warn\"\n    }\n  }\n```\nA full list of all supported rules can be found [here](docs/rules.md).\n<br><br>\n\n### Ignore Configuration\nYou can exclude files from linting using a `.solhintignore` file (name by default) or `--ignore-path` followed by a custom name. \nIt uses the same syntax as `.gitignore`, including support for negation with !.\n\nExample:\n\n```\ncontracts/**\n!contracts/utils/\n!contracts/utils/SafeMath.sol\n```\n\nThis will:\n  - Ignore everything inside contracts/\n  - Except the folder contracts/utils/\n  - And the file SafeMath.sol inside it\n\nTip: To unignore a file, you must also unignore its parent folders.\n<br><br>\n\n### Cache\nSolhint supports a caching mechanism using the `--cache` flag to avoid re-linting files that haven't changed. \nWhen enabled, Solhint stores a hash of each file's content and effective configuration, skipping analysis if neither has changed. \nBy default, the cache is saved in `.solhintcache.json` in the current working directory. \nYou can customize this location using the `--cache-location option`. If no location is specified, the file will be stored in:\n`node_modules/.cache/solhint/.solhint-cache.json`\n\nWarning:\nWhen using `cache` flag. If a file was analyzed with not error for a certain config, the hash will be stored. If the file is not changed but the config file (`.solhint.json`) has some new rules, the file will not be analyzed. \nTo analyze it again, remove `cache` option.\n\nExample:\n```\nsolhint contracts/**/*.sol --cache\nsolhint Foo.sol --cache --cache-location tmp/my-cache.json\n```\n<br><br>\n\n### Extendable rulesets\n\nThe rulesets provided by solhint are the following:\n\n+ solhint:default (deprecated since version v5.1.0)\n+ solhint:recommended\n\nUse one of these as the value for the \"extends\" property in your configuration file.\n\n### Configure the linter with comments\n\nYou can use comments in the source code to configure solhint in a given line or file.\n\nFor example, to disable all validations in the line following a comment:\n\n```solidity\n  // solhint-disable-next-line\n  uint[] a;\n```\n\nYou can disable specific rules on a given line. For example:\n\n```solidity\n  // solhint-disable-next-line not-rely-on-time, not-rely-on-block-hash\n  uint pseudoRand = uint(keccak256(abi.encodePacked(now, blockhash(block.number))));\n```\n\nDisable validation on current line:\n\n```solidity\n  uint pseudoRand = uint(keccak256(abi.encodePacked(now, blockhash(block.number)))); // solhint-disable-line\n```\n\nDisable specific rules on current line:\n\n```solidity\n   uint pseudoRand \n\n[... truncated ...]"
  },
  "vyperlang/titanoboa": {
    "fetchedAt": "2025-11-12T22:47:37.669Z",
    "content": "# Titanoboa\n\nA [Vyper](https://github.com/vyperlang/vyper) interpreter with pretty tracebacks, forking, debugging features and more! Titanoboa's goal is to provide a modern, advanced and integrated development experience for vyper users.\n\n## Architecture\n\nTitanoboa achieves feature parity with the vyper compiler while providing an interpreted experience. How does it do this? Internally, titanoboa uses vyper as a library to compile source code to bytecode, and then runs the bytecode using [py-evm](https://github.com/ethereum/py-evm), adding instrumenting hooks to provide introspection. The use of `py-evm` means that the entire experience is highly configurable, down to the ability to patch opcodes and precompiles at the EVM level.\n\n## Documentation\n\nUsage and quickstart are [below](#usage-quick-start). For more detailed documentation, please see the [documentation](https://titanoboa.readthedocs.io/en/latest/index.html).\n\n## Installation\n```\npip install titanoboa\n```\n\nFor latest dev version:\n```\npip install git+https://github.com/vyperlang/titanoboa\n```\n\n\nIf you are installing titanoboa from git alongside brownie, you may have to manually install titanoboa *after* installing brownie\n\n```\npip install brownie\npip install git+https://github.com/vyperlang/titanoboa\n```\n\nSometimes, using [pypy](https://www.pypy.org/download.html) can result in a substantial performance improvement for computation heavy contracts. `Pypy` can usually be used as a drop-in replacement for `CPython`.\n\nTo get a performance boost for mainnet forking, install with the `forking-recommended` extra (`pip install \"git+https://github.com/vyperlang/titanoboa#egg=titanoboa[forking-recommended]\"`, or `pip install titanoboa[forking-recommended]`). This installs `requests-cache` to cache certain HTTP requests between sessions, and `ujson` which improves json performance.\n\nIf you are running titanoboa on a local [Vyper](https://github.com/vyperlang/vyper) project folder, you might need to run `python setup.py install` on your [Vyper](https://github.com/vyperlang/vyper) project if you encounter errors such as `ModuleNotFoundError: No module named 'vyper.version'`\n\n## Background\n\nTitanoboa ([/Àåta…™t…ôn…ôÀàbo ä…ô/](https://en.wikipedia.org/wiki/Help:IPA/English); lit.‚Äâ'titanic boa') is an [extinct](https://en.wikipedia.org/wiki/Extinction) [genus](https://en.wikipedia.org/wiki/Genus) of giant [boid](https://en.wikipedia.org/wiki/Boidae) (the family that includes all boas and [anacondas](https://en.wikipedia.org/wiki/Anaconda)) snake that lived during the [middle](https://en.wikipedia.org/wiki/Selandian) and [late](https://en.wikipedia.org/wiki/Thanetian) [Paleocene](https://en.wikipedia.org/wiki/Paleocene). Titanoboa was first discovered in the early 2000s by the [Smithsonian Tropical Research Institute](https://en.wikipedia.org/wiki/Smithsonian_Tropical_Research_Institute) who, along with students from the [University of Florida](https://en.wikipedia.org/wiki/University_of_Florida), recovered 186 fossils of Titanoboa from [La Guajira](https://en.wikipedia.org/wiki/La_Guajira) in northeastern [Colombia](https://en.wikipedia.org/wiki/Colombia). It was named and described in 2009 as Titanoboa cerrejonensis, the largest snake ever found at that time. It was originally known only from thoracic vertebrae and ribs, but later expeditions collected parts of the skull and teeth. Titanoboa is in the subfamily [Boinae](https://en.wikipedia.org/wiki/Boinae), being most closely related to other extant boines from Madagascar and the Pacific.\n\nTitanoboa could grow up to 12.8 m (42 ft) long, perhaps even up to 14.3 m (47 ft) long, and weigh around 730‚Äì1,135 kg (1,610‚Äì2,500 lb). The discovery of Titanoboa cerrejonensis supplanted the previous record holder, [Gigantophis garstini](https://en.wikipedia.org/wiki/Gigantophis), which is known from the [Eocene](https://en.wikipedia.org/wiki/Eocene) of [Egypt](https://en.wikipedia.org/wiki/Egypt). Titanoboa evolved following the extinction of all non-avian [dinosaurs](https://en.wikipedia.org/wiki/Dinosaur), being one of the largest reptiles to evolve after the [Cretaceous‚ÄìPaleogene extinction event](https://en.wikipedia.org/wiki/Cretaceous%E2%80%93Paleogene_extinction_event). Its vertebrae are very robust and wide, with a pentagonal shape in anterior view, as in other members of Boinae. Although originally thought to be an [apex predator](https://en.wikipedia.org/wiki/Apex_predator), the discovery of skull bones revealed that it was more than likely specialized in [preying on fish](https://en.wikipedia.org/wiki/Piscivore).\n\n## Usage / Quick Start\n\n### Hello, world\n\n```python\nimport boa\nboa.eval(\"empty(uint256)\")\n```\n\n### Basic\n```vyper\n# simple.vy\n@external\ndef foo() -> uint256:\n    x: uint256 = 1\n    return x + 7\n```\n\n```python\n>>> import boa\n\n>>> simple = boa.load(\"examples/simple.vy\")\n>>> simple.foo()\n    8\n>>> simple.foo()._vyper_type\n    uint256\n```\n\n\n### Passing `__init__`\n\n```python\n>>> import boa\n\n>>> erc20 = boa.load(\"examples/ERC20.vy\", 'titanoboa', 'boa', 18, 1)\n>>> erc20.name()\n    titanoboa\n>>> erc20.symbol()\n    boa\n>>> erc20.balanceOf(erc20.address)\n    0\n>>> erc20.totalSupply()\n    1000000000000000000\n```\n\n### As a blueprint\n\n```python\n>>> import boa\n>>> s = boa.load_partial(\"examples/ERC20.vy\")\n>>> blueprint = s.deploy_as_blueprint()\n>>> deployer = boa.load(\"examples/deployer.vy\", blueprint)\n>>> token = s.at(deployer.create_new_erc20(\"token\", \"TKN\", 18, 10**18))\n>>> token.totalSupply()\n>>> 1000000000000000000000000000000000000\n```\n\n### Expecting BoaErrors / handling reverts\n```python\n>>> import boa\n>>> erc20 = boa.load(\"examples/ERC20.vy\", \"titanoboa\", \"boa\", 18, 0)\n>>> with boa.env.prank(boa.env.generate_address()):\n...     with boa.reverts():\n...         erc20.mint(boa.env.eoa, 100)  # non-minter cannot mint\n...\n>>> with boa.env.prank(boa.env.generate_address()):\n...     # you can be more specific about the failure reason\n...     with boa.reverts(rekt=\"non-minter tried to mint\"):\n...         erc20.mint(boa.env.eoa, 100)\n```\n\n### From within IPython\n\n```python\nIn [1]: %load_ext boa.ipython\n        import boa\n        boa.interpret.set_cache_dir()  # cache source compilations across sessions\n\nIn [2]: %vyper msg.sender  # evaluate a vyper expression directly\nOut[2]: '0x0000000000000000000000000000000000000065'\n\nIn [3]: %%vyper\n   ...:\n   ...: MY_IMMUTABLE: immutable(uint256)\n   ...:\n   ...: @external\n   ...: def __init__(some_number: uint256):\n   ...:     MY_IMMUTABLE = some_number * 2\n   ...:\n   ...: @external\n   ...: def foo() -> uint256:\n   ...:     return MY_IMMUTABLE\n   ...:\nOut[3]: <boa.vyper.contract.VyperDeployer at 0x7f3496187190>\n\nIn [4]: d = _\n\nIn [4]: c = d.deploy(5)\n\nIn [5]: c.foo()\nOut[5]: 10\n```\n\n### Evaluating arbitrary code\n\n```python\n>>> erc20 = boa.load(\"examples/ERC20.vy\", 'titanoboa', 'boa', 18, 1)\n>>> erc20.balanceOf(erc20.address)\n    0\n>>> erc20.totalSupply()\n    1000000000000000000\n>>> erc20.eval(\"self.totalSupply += 10\")  # manually mess with total supply\n>>> erc20.totalSupply()\n1000000000000000010\n>>> erc20.eval(\"self.totalSupply\")  # same result when eval'ed\n1000000000000000010\n>>> erc20.eval(\"self.balanceOf[msg.sender] += 101\")  # manually mess with balance\n>>> erc20.balanceOf(boa.env.eoa)\n1000000000000000101\n>>> erc20.eval(\"self.balanceOf[msg.sender]\")  # same result when eval'ed\n1000000000000000101\n```\n\nNote that in `eval()` mode, titanoboa uses slightly different optimization settings, so gas usage may not be the same as using the external interface.\n\n### Forking\nCreate a fork of mainnet given rpc.\n```python\nIn [1]: import boa; boa.env.fork(url=\"<rpc server address>\")\n\nIn [2]: %load_ext boa.ipython\n\nIn [3]: %%vyper Test\n   ...: interface HasName:\n   ...:     def name() -> String[32]: view\n   ...:\n   ...: @external\n   ...: def get_name_of(addr: HasName) -> String[32]:\n   ...:     return addr.name()\nOut[3]: <boa.vyper.contract.VyperDeployer at 0x7f3496187190>\n\nIn [4]: c = Test.deploy()\n\nIn [5]: c.get_name_of(\"0xD533a949740bb330\n\n[... truncated ...]"
  },
  "otterscan/otterscan": {
    "fetchedAt": "2025-11-12T22:47:45.597Z",
    "content": "# Otterscan\n\nAn open-source, fast, local, laptop-friendly Ethereum block explorer.\n\nhttps://user-images.githubusercontent.com/28685/124196700-4fe71200-daa3-11eb-912c-b66494fe4b23.mov\n\n## Documentation\n\n> üí° For install instructions and a lot more, please take a look at our official documentation: [The Otterscan Book](https://docs.otterscan.io/)!\n\n## What?\n\nThis is an Ethereum block explorer designed to be run locally with an archive node companion, [Erigon](https://github.com/erigontech/erigon).\n\nThis approach brings many advantages, as follows.\n\n### Privacy\n\nYou are querying your own node, so you are not sending your IP address or queries to an external, third-party node.\n\n### Fast\n\nSince you are querying your local archive node, everything is fast. No network roundtrips are necessary.\n\n### Actually, very fast\n\nThis software was designed to be a companion of Erigon, a blazingly fast archive node.\n\n### Really, it is even faster\n\nThe standard web3 JSON-RPC methods are quite verbose and generic requiring many calls to gather many pieces of information at client side.\n\nWe've implemented some custom methods at the client level, so less information needs to be JSON-marshalled and transmitted over the network.\n\n## Why?\n\nCurrent offerings are either closed source or lack many features the most famous Ethereum block explorer has, or simply have high requirements like having an archive node + additional indexers.\n\nOtterscan requires only a mainline Erigon execution node and Otterscan itself (a simple React app), which makes it a laptop-friendly block explorer.\n\n## Why the name?\n\n3 reasons:\n\n- It is heavily based on Erigon, whose mascot is an otter (Erigon, the otter), think about an otter scanning your transactions inside blocks.\n- It is an homage to the most popular Ethereum block explorer.\n- The author loves wordplays and bad puns.\n\n## Kudos (in no particular order)\n\nWe make use of open-source software and integrate many public data sources, mainly:\n\nTo the [Geth](https://geth.ethereum.org/) team whose code Erigon is based on.\n\nTo the [Erigon](https://github.com/erigontech/erigon) team that made it possible for regular humans to run an archive node on a retail laptop. Also, they have been very helpful explaining Erigon's internals which made the Otterscan modifications possible.\n\nTo the [Test in Prod](https://www.testinprod.io/) team that made OP-Erigon. Their effort made it possible to run Otterscan against any Optimism Superchain.\n\nTo the [mdbx](https://github.com/erthink/libmdbx) team which created the blazingly fast database that empowers Erigon.\n\nTo [Trust Wallet](https://github.com/trustwallet/assets) who sponsors and makes available their icons under a permissive license.\n\nTo the owners of the [4bytes repository](https://github.com/ethereum-lists/4bytes) that we import and use to translate method selectors to human-friendly strings.\n\nTo [Sourcify](https://sourcify.dev/), a public, decentralized source code and metadata verification service.\n\nTo [Ethers](https://github.com/ethers-io/ethers.js/), which is the client library we used to interact with the Erigon node. It is high-level enough to hide most JSON-RPC particularities but flexible enough to allow for easy interaction with custom methods.\n\n## License\n\nThis software itself is MIT licensed and redistributes MIT-compatible dependencies.\n\nThe Otterscan API is implemented inside Erigon and follow its own license (LPGL-3).\n\n## Getting in touch\n\n### Erigon Discord server\n\nOur Discord server: https://discord.gg/5xM2q2eqDz\n\nOtterscan also has a community channel under the \"ecosystem\" section of [Erigon's Discord](https://github.com/erigontech/erigon#erigon-discord-server) (invite should be requested).\n\n### X/Twitter\n\nOfficial X/Twitter account: ([@otterscan](https://x.com/otterscan)).\n\nFollow the creator on X/Twitter for more updates ([@wmitsuda](https://x.com/wmitsuda)).\n\n### Donation address\n\nIf you like this project, feel free to send donations to `otterscan.eth` on any EVM chain (it's an EOA).\n\nWe also participate regularly on Gitcoin Grants rounds.\n"
  },
  "Cyfrin/moccasin": {
    "fetchedAt": "2025-11-12T22:47:52.955Z",
    "content": "> This tool is in beta, use at your own risk\n\n<p align=\"center\">\n    <br />\n        <img src=\"./docs/source/_static/gh_banner.png\" width=\"100%\" alt=\"\"/></a>\n    <br />\n</p>\n\n\n# Moccasin\n\nA fast, pythonic, Vyper smart contract testing and development framework.\n\n[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)\n[![moccasin](https://img.shields.io/pypi/v/moccasin.svg)](https://pypi.org/project/moccasin/)\n[![license](https://img.shields.io/pypi/l/moccasin.svg)](https://pypi.python.org/pypi/moccasin)\n[![python-versions](https://img.shields.io/pypi/pyversions/moccasin.svg)](https://pypi.python.org/pypi/moccasin)\n\n> The smaller bar is better, it means it's faster\n\n<p align=\"center\">\n  <picture align=\"center\">\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"./docs/source/_static/stats-dark.png\" width=70%>\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"./docs/source/_static/stats-light.png\" width=70%>\n    <img alt=\"Shows a bar chart with benchmark results.\" src=\"./docs/source/_static/stats-default.png\" width=70%>\n  </picture>\n</p>\n\n_You can see how we conducted these tests from the [benchmarking repo](https://github.com/PatrickAlphaC/benchmarking-frameworks)._\n\nFast to install, test, and run python commands on your smart contracts.\n\n# Highlights\n\n- üêç Pythonic start to finish, built on top of Vyper's [titanoboa](https://titanoboa.readthedocs.io/en/latest/)\n- üîê ZKsync built-in support\n- üìë Named Contracts allow you to define smart contract addresses without scaffolding anything yourself\n- üß™ Custom staging pytest markers so you can run tests anywhere, anyhow\n- ü¶ä Support for encrypting wallets, no private keys in `.env` files! \n- üß≥ GitHub and Python smart contract dependency installation \n\n# Quickstart\n\nHead over to [the moccasin installation documentation](https://cyfrin.github.io/moccasin/installing_moccasin.html) for other install methodologies and getting started.\n\n## This README Quickstart\n\nTo install the moccasin `mox` command, we recommend the [uv](https://docs.astral.sh/uv/) tool.\n\n```bash\nuv tool install moccasin\n```\n\nThen, see a list of commands with:\n\n```bash\nmox --help\n```\n\n# Documentation\n\nYou can view the documentation [here](https://cyfrin.github.io/moccasin/).\n\n# Contributing\n\nIf you're interested in helping build moccasin, please see the [contributing guide](./CONTRIBUTING.md).\n\n# Help output\n\n```bash\nmox --help\nusage: Moccasin CLI [-h] [-d] [-q]\n                    {init,compile,build,test,run,script,deploy,wallet,console,install,purge,config,explorer,inspect,deployments,utils,u,util}\n                    ...\n\nüêç Pythonic Smart Contract Development Framework\n\npositional arguments:\n  {init,compile,build,test,run,script,deploy,wallet,console,install,purge,config,explorer,inspect,deployments,utils,u,util}\n    init                Initialize a new project.\n    compile (build)     Compiles the project.\n    test                Runs all tests in the project.\n    run (script)        Runs a script with the project's context.\n    deploy              Deploys a contract named in the config with a deploy script.\n    wallet              Wallet management utilities.\n    console             BETA, USE AT YOUR OWN RISK: Interact with the network in a python shell.\n    install             Installs the project's dependencies.\n    purge               Purge a given dependency\n    config              View the Moccasin configuration.\n    explorer            Work with block explorers to get data.\n    inspect             Inspect compiler data of a contract.\n    deployments         View deployments of the project from your DB.\n    utils (u, util)     Helpful utilities - right now it's just the one.\n\noptions:\n  -h, --help            show this help message and exit\n  -d, --debug           Run in debug mode\n  -q, --quiet           Suppress all output except errors\n```\n\n# Acknowledgements \n\n- [brownie](https://github.com/eth-brownie/brownie)\n- [vyper](https://github.com/vyperlang/vyper)\n- [boa](https://github.com/vyperlang/titanoboa)\n\n## Background\n\n> Agkistrodon piscivorus is a species of venomous snake, a pit viper in the subfamily Crotalinae of the family Viperidae. The generic name is derived from the Greek words ·ºÑŒ≥Œ∫ŒπœÉœÑœÅŒøŒΩ agkistron \"fish-hook, hook\" and ·ΩÄŒ¥œéŒΩ odon \"tooth\", and the specific name comes from the Latin piscis 'fish' and voro '(I) eat greedily, devour'; thus, the scientific name translates to \"hook-toothed fish-eater\". Common names include cottonmouth, northern cottonmouth, water moccasin, swamp moccasin, black moccasin, and simply viper.\n\n# More Stats\n\n<p align=\"center\">\n    <br />\n    <a href=\"https://cyfrin.io/\">\n        <img src=\"./docs/source/_static/speed-comparisons.png\" width=\"70%\" alt=\"\"/></a>\n    <br />\n</p>\n\n# License \n\nmoccasin is licensed under either of:\n\n- Apache License, Version 2.0, (LICENSE-APACHE or https://www.apache.org/licenses/LICENSE-2.0)\n- MIT license (LICENSE-MIT or https://opensource.org/licenses/MIT)\n\nat your option.\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in moccasin by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.\n"
  },
  "pcaversaccio/create2deployer": {
    "fetchedAt": "2025-11-12T22:47:59.476Z",
    "content": "# `CREATE2` Deployer\n\n[![üïµÔ∏è‚Äç‚ôÇÔ∏è Test smart contracts](https://github.com/pcaversaccio/create2deployer/actions/workflows/test-contracts.yml/badge.svg)](https://github.com/pcaversaccio/create2deployer/actions/workflows/test-contracts.yml)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/license/mit)\n\n> [!TIP]\n> I have built a versatile, trustless, and stateless successor to `Create2Deployer`: [`CreateX`](https://github.com/pcaversaccio/createx). Check it out! ü´°\n\nHelper smart contract to make easier and safer usage of the [`CREATE2`](https://eips.ethereum.org/EIPS/eip-1014) Ethereum Virtual Machine (EVM) opcode. `CREATE2` can be used to compute in advance the address where a smart contract will be deployed, which allows for interesting new mechanisms known as _counterfactual interactions_.\n\n<div align=\"center\">\n  <img src=\"assets/img/distribution.jpg\" alt=\"A very fancy meme\" width=\"80%\" />\n</div>\n\n## Unit Tests\n\nSince [Hardhat](https://hardhat.org) implements great features for Solidity debugging like Solidity stack traces, `console.log`, and explicit error messages when transactions fail, we leverage [Hardhat](https://hardhat.org) for testing:\n\n```console\npnpm run test\n```\n\n### Test Coverage\n\nThis project repository implements a test coverage [plugin](https://github.com/sc-forks/solidity-coverage). Simply run:\n\n```console\npnpm run coverage\n```\n\nThe written tests available in the file [`Create2Deployer.test.ts`](./test/Create2Deployer.test.ts) achieve a test coverage of 100%:\n\n```console\n--------------------------------|----------|----------|----------|----------|----------------|\nFile                            |  % Stmts | % Branch |  % Funcs |  % Lines |Uncovered Lines |\n--------------------------------|----------|----------|----------|----------|----------------|\n contracts\\                     |      100 |      100 |      100 |      100 |                |\n  Create2Deployer.sol           |      100 |      100 |      100 |      100 |                |\n  Create2DeployerDeprecated.sol |      100 |      100 |      100 |      100 |                |\n--------------------------------|----------|----------|----------|----------|----------------|\nAll files                       |      100 |      100 |      100 |      100 |                |\n--------------------------------|----------|----------|----------|----------|----------------|\n```\n\n> [!NOTE]\n> A test coverage of 100% does not mean that there are no vulnerabilities. What really counts is the quality and spectrum of the tests themselves!\n\n## Deployments [`Create2Deployer`](./contracts/Create2Deployer.sol)\n\n> [!IMPORTANT]\n> As of 8 December 2023, all non-deprecated [`Create2Deployer`](./contracts/Create2Deployer.sol) deployments are _permissionless_ as I have renounced the ownership accordingly.\n\n- **EVM-Based Production Networks:**\n  - Ethereum: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://etherscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - BNB Smart Chain: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://bscscan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - OP (Optimism): [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://optimistic.etherscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Arbitrum One: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://arbiscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Arbitrum Nova: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://nova.arbiscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Polygon: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://polygonscan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Polygon zkEVM: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://zkevm.polygonscan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Heco: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://hecoscan.io/#/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Fantom: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.fantom.network/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Avalanche: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://snowtrace.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Gnosis Chain: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://gnosisscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Moonriver: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://moonriver.moonscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Moonbeam: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://moonscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Celo: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://celoscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Aurora: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.mainnet.aurora.dev/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Harmony: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.harmony.one/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Autobahn (‚ö†Ô∏è Deprecated): [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.autobahn.network/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Fuse Network: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.fuse.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Cronos: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://cronoscan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Evmos: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://www.mintscan.io/evmos/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Boba Network: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://bobascan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Canto: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://tuber.build/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Base: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://basescan.org/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Mantle: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://mantlescan.xyz/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Scroll: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://scrollscan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Linea: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://lineascan.build/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Zora: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.zora.energy/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - LUKSO: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.execution.mainnet.lukso.network/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Manta Pacific: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://pacific-explorer.manta.network/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Kroma: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://kroscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Kava: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://kavascan.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - X Layer: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://www.oklink.com/x-layer/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Core: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://scan.coredao.org/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Telos: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://www.teloscan.io/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Rootstock: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://rootstock.blockscout.com/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Arthera: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://explorer.arthera.net/address/0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2)\n  - Metis Andromeda: [`0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2`](https://andromeda-explorer.metis.io/addre\n\n[... truncated ...]"
  },
  "pcaversaccio/xdeployer": {
    "fetchedAt": "2025-11-12T22:48:06.090Z",
    "content": "# xdeployer üí•\n\n[![Test xdeploy](https://github.com/pcaversaccio/xdeployer/actions/workflows/test.yml/badge.svg)](https://github.com/pcaversaccio/xdeployer/actions/workflows/test.yml)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/license/mit)\n[![npm package](https://img.shields.io/npm/v/xdeployer.svg)](https://www.npmjs.com/package/xdeployer)\n\n[Hardhat](https://hardhat.org) plugin to deploy your smart contracts across multiple Ethereum Virtual Machine (EVM) chains with the same deterministic address.\n\n> [!TIP]\n> It is pronounced _cross_-deployer.\n\n## What\n\nThis plugin will help you make easier and safer usage of the [`CREATE2`](https://eips.ethereum.org/EIPS/eip-1014) EVM opcode. [`CREATE2`](https://eips.ethereum.org/EIPS/eip-1014) can be used to compute in advance the address where a smart contract will be deployed, which allows for interesting new mechanisms known as _counterfactual interactions_.\n\n## Installation\n\nWith `npm` versions `>=7`:\n\n```console\n# based on ethers v6\nnpm install --save-dev xdeployer\n```\n\nWith `npm` version `6`:\n\n```console\n# based on ethers v6\nnpm install --save-dev xdeployer @nomicfoundation/hardhat-ethers ethers\n```\n\n<details>\n<summary> Using <code>ethers</code> version <code>5</code> </summary>\n\nWith `npm` versions `>=7`:\n\n```console\n# based on ethers v5\nnpm install --save-dev 'xdeployer@^1.2.7'\n```\n\nWith `npm` version `6`:\n\n```console\n# based on ethers v5\nnpm install --save-dev 'xdeployer@^1.2.7' @nomiclabs/hardhat-ethers 'ethers@^5.7.2' '@openzeppelin/contracts@^4.9.0'\n```\n\n</details>\n\nOr if you are using [Yarn](https://classic.yarnpkg.com):\n\n```console\n# based on ethers v6\nyarn add --dev xdeployer @nomicfoundation/hardhat-ethers ethers\n```\n\n<details>\n<summary> Using <code>ethers</code> version <code>5</code> </summary>\n\n```console\n# based on ethers v5\nyarn add --dev 'xdeployer@^1.2.7' @nomiclabs/hardhat-ethers 'ethers@^5.7.2' '@openzeppelin/contracts@^4.9.0'\n```\n\n</details>\n\nIn case you are using [pnpm](https://pnpm.io), invoke:\n\n```console\n# based on ethers v6\npnpm add --save-dev xdeployer\n```\n\n<details>\n<summary> Using <code>ethers</code> version <code>5</code> </summary>\n\n```console\n# based on ethers v5\npnpm add --save-dev 'xdeployer@^1.2.7'\n```\n\n</details>\n\n> [!NOTE]\n> This plugin uses the optional chaining operator (`?.`). Optional chaining is _not_ supported in [Node.js](https://nodejs.org/en) `v13` and below.\n\nImport the plugin in your `hardhat.config.js`:\n\n```js\nrequire(\"xdeployer\");\n```\n\nOr if you are using TypeScript, in your `hardhat.config.ts`:\n\n```ts\nimport \"xdeployer\";\n```\n\n## Required Plugins\n\n- [`@nomicfoundation/hardhat-ethers`](https://www.npmjs.com/package/@nomicfoundation/hardhat-ethers)\n- [`ethers`](https://www.npmjs.com/package/ethers)\n\n## Tasks\n\nThis plugin provides the `xdeploy` task, which allows you to deploy your smart contracts across multiple EVM chains with the same deterministic address:\n\n```console\nnpx hardhat xdeploy\n```\n\n## Environment Extensions\n\nThis plugin does not extend the environment.\n\n## Configuration\n\nYou need to add the following configurations to your `hardhat.config.js` file:\n\n```js\nmodule.exports = {\n  networks: {\n    mainnet: { ... }\n  },\n  xdeploy: {\n    contract: \"YOUR_CONTRACT_NAME_TO_BE_DEPLOYED\",\n    constructorArgsPath: \"PATH_TO_CONSTRUCTOR_ARGS\", // optional; default value is `undefined`\n    salt: \"YOUR_SALT_MESSAGE\",\n    signer: \"SIGNER_PRIVATE_KEY\",\n    networks: [\"LIST_OF_NETWORKS\"],\n    rpcUrls: [\"LIST_OF_RPCURLS\"],\n    gasLimit: 1_500_000, // optional; default value is `1.5e6`\n  },\n};\n```\n\nOr if you are using TypeScript, in your `hardhat.config.ts`:\n\n```ts\nconst config: HardhatUserConfig = {\n  networks: {\n    mainnet: { ... }\n  },\n  xdeploy: {\n    contract: \"YOUR_CONTRACT_NAME_TO_BE_DEPLOYED\",\n    constructorArgsPath: \"PATH_TO_CONSTRUCTOR_ARGS\", // optional; default value is `undefined`\n    salt: \"YOUR_SALT_MESSAGE\",\n    signer: \"SIGNER_PRIVATE_KEY\",\n    networks: [\"LIST_OF_NETWORKS\"],\n    rpcUrls: [\"LIST_OF_RPCURLS\"],\n    gasLimit: 1_500_000, // optional; default value is `1.5e6`\n  },\n};\n```\n\nThe parameters `constructorArgsPath` and `gasLimit` are _optional_. The `salt` parameter is a random string value used to create the contract address. If you have previously deployed the same contract with the identical `salt`, the contract creation transaction will fail due to [EIP-684](https://eips.ethereum.org/EIPS/eip-684). For more details, see also [here](#a-note-on-selfdestruct).\n\n> [!IMPORTANT]\n> Please note that `xdeployer` computes the UTF-8 byte representation of the specified `salt` and calculates the `keccak256` hash, which represents the 32-byte `salt` value that is passed to [`CREATE2`](https://eips.ethereum.org/EIPS/eip-1014).\n\n_Example:_\n\n```ts\nxdeploy: {\n    contract: \"ERC20Mock\",\n    constructorArgsPath: \"./deploy-args.ts\",\n    salt: \"WAGMI\",\n    signer: vars.get(\"PRIVATE_KEY\", \"\"),\n    networks: [\"hardhat\", \"sepolia\", \"hoodi\"],\n    rpcUrls: [\n      \"hardhat\",\n      vars.get(\"ETH_SEPOLIA_TESTNET_URL\", \"https://rpc.sepolia.org\"),\n      vars.get(\"ETH_HOODI_TESTNET_URL\", \"https://0xrpc.io/hoodi\"),\n    ],\n    gasLimit: 1.2 * 10 ** 6,\n},\n```\n\n> [!NOTE]\n> We recommend using [Hardhat configuration variables](https://v2.hardhat.org/hardhat-runner/docs/guides/configuration-variables) introduced in Hardhat version [`2.19.0`](https://github.com/NomicFoundation/hardhat/releases/tag/hardhat%402.19.0) to set the private key of your signer.\n\nThe current available networks are:\n\n> [!TIP]\n> To display the complete list of supported networks with the corresponding block explorer links and chain IDs, run `npx hardhat xdeploy --list-networks`.\n\n- **Local:**\n  - `localhost`\n  - `hardhat`\n- **EVM-Based Test Networks:**\n  - `sepolia`\n  - `hoodi`\n  - `bscTestnet`\n  - `optimismSepolia`\n  - `arbitrumSepolia`\n  - `amoy`\n  - `polygonZkEVMTestnet`\n  - `fantomTestnet`\n  - `fuji`\n  - `chiado`\n  - `moonbaseAlpha`\n  - `celoTestnet`\n  - `auroraTestnet`\n  - `harmonyTestnet`\n  - `spark`\n  - `cronosTestnet`\n  - `evmosTestnet`\n  - `bobaTestnet`\n  - `cantoTestnet`\n  - `baseSepolia`\n  - `mantleTestnet`\n  - `filecoinTestnet`\n  - `scrollSepolia`\n  - `lineaTestnet`\n  - `zoraSepolia`\n  - `luksoTestnet`\n  - `mantaTestnet`\n  - `blastTestnet`\n  - `dosTestnet`\n  - `fraxtalTestnet`\n  - `metisTestnet`\n  - `modeTestnet`\n  - `seiArcticDevnet`\n  - `seiAtlanticTestnet`\n  - `xlayerTestnet`\n  - `bobTestnet`\n  - `coreTestnet`\n  - `telosTestnet`\n  - `rootstockTestnet`\n  - `chilizTestnet`\n  - `taraxaTestnet`\n  - `taikoTestnet`\n  - `zetaChainTestnet`\n  - `5ireChainTestnet`\n  - `sapphireTestnet`\n  - `worldChainTestnet`\n  - `plumeTestnet`\n  - `unichainTestnet`\n  - `xdcTestnet`\n  - `sxTestnet`\n  - `liskTestnet`\n  - `metalL2Testnet`\n  - `superseedTestnet`\n  - `storyTestnet`\n  - `sonicTestnet`\n  - `flowTestnet`\n  - `inkTestnet`\n  - `morphTestnet`\n  - `shapeTestnet`\n  - `etherlinkTestnet`\n  - `soneiumTestnet`\n  - `swellTestnet`\n  - `hemiTestnet`\n  - `berachainTestnet`\n  - `monadTestnet`\n  - `cornTestnet`\n  - `arenazTestnet`\n  - `iotexTestnet`\n  - `hychainTestnet`\n  - `zircuitTestnet`\n  - `megaETHTestnet`\n  - `bitlayerTestnet`\n  - `roninTestnet`\n  - `zkSyncTestnet`\n  - `immutableZkEVMTestnet`\n  - `abstractTestnet`\n  - `hyperevmTestnet`\n  - `apeChainTestnet`\n  - `botanixTestnet`\n  - `tacTestnet`\n  - `plasmaTestnet`\n  - `sophonTestnet`\n  - `jovayTestnet`\n  - `intuitionTestnet`\n- **EVM-Based Production Networks:**\n  - `ethMain`\n  - `bscMain`\n  - `optimismMain`\n  - `arbitrumOne`\n  - `arbitrumNova`\n  - `polygon`\n  - `polygonZkEVMMain`\n  - `fantomMain`\n  - `avalanche`\n  - `gnosis`\n  - `moonriver`\n  - `moonbeam`\n  - `celo`\n  - `auroraMain`\n  - `harmonyMain`\n  - `fuse`\n  - `cronosMain`\n  - `evmosMain`\n  - `bobaMain`\n  - `cantoMain`\n  - `baseMain`\n  - `mantleMain`\n  - `filecoinMain`\n  - `scrollMain`\n  - `lineaMain`\n  - `zoraMain`\n  - `luksoMain`\n  - `mantaMain`\n  - `blastMain`\n  - `dosMain`\n  - `fraxtalMain`\n  - `enduranceMain`\n  - `kavaMain`\n  - `metisMain`\n  - `modeMain`\n  - `s\n\n[... truncated ...]"
  },
  "rotki/rotki": {
    "fetchedAt": "2025-11-12T22:48:13.170Z",
    "content": "<div id=\"top\"></div>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/rotki/rotki/develop/frontend/app/public/assets/images/rotkehlchen_no_text.png\" alt=\"rotki Logo\" width=\"250\">\n</p>\n\n<h1 align=\"center\">rotki: The Opensource, Self-Hosted Portfolio Manager</h1>\n\n<p align=\"center\">\n  <strong>A privacy-focused portfolio manager, accounting, and analytics tool.</strong>\n</p>\n\n<div align=\"center\">\n\n[![GitHub release](https://img.shields.io/github/release/rotki/rotki.svg)](https://GitHub.com/rotki/rotki/releases/)\n[![Docker Image Version](https://img.shields.io/docker/v/rotki/rotki/latest?label=Docker)](https://hub.docker.com/r/rotki/rotki)\n[![GitHub commits](https://img.shields.io/github/commits-since/rotki/rotki/latest.svg)](https://GitHub.com/rotki/rotki/commit/)\n[![GitHub contributors](https://img.shields.io/github/contributors/rotki/rotki.svg?style=flat)](https://github.com/rotki/rotki/graphs/contributors)\n[![Visitors](https://api.visitorbadge.io/api/visitors?path=rotki%2Frotki%20&countColor=%23263759&style=flat)](https://rotki.com/)\n[![GitHub forks](https://img.shields.io/github/forks/rotki/rotki)](https://github.com/rotki/rotki/forks)\n[![GitHub stars](https://img.shields.io/github/stars/rotki/rotki)](https://github.com/rotki/rotki/stargazers)\n[![GitHub last commit](https://img.shields.io/github/last-commit/rotki/rotki)](https://github.com/rotki/rotki/commits/master)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/rotki/rotki/badge)](https://www.gitpoap.io/gh/rotki/rotki)\n[![Github downloads](https://img.shields.io/github/downloads/rotki/rotki/total.svg)](https://GitHub.com/rotki/rotki/releases/)\n[![Hiring](https://img.shields.io/badge/Hiring-Open-brightgreen)](https://rotki.com/jobs/)\n[![X Follow](https://img.shields.io/twitter/follow/rotkiapp)](https://twitter.com/rotkiapp)\n[![Discord](https://img.shields.io/discord/657906918408585217.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.rotki.com/)\n\n</div>\n\n---\n\n## üìå **Table of Contents**\n- [üìñ Overview](#overview)\n- [‚ú® Features](#features)\n- [üîß Requirements](#requirements)\n- [üöÄ Installation](#installation)\n- [üìò Usage](#usage)\n- [üìú Changelog](#changelog)\n- [ü§ù Contribute](#contribute)\n- [üì¢ Get in Touch](#get-in-touch)\n- [üí∞ Donations](#donations)\n- [üìÑ License](#license)\n\n---\n\n<div id=\"overview\"></div>\n\n## üìñ **Overview**\n[rotki](https://rotki.com/) is an opensource self-hosted portfolio management tool that puts privacy first. Unlike most competitors, which are closed-source SaaS platforms requiring you to hand over sensitive financial data, rotki keeps your data encrypted and stored locally‚Äîensuring you stay in control. Our mission is to bring transparency to the crypto and financial sectors through opensource software, empowering users with a secure, self-sovereign alternative to cloud-based tracking services.\n\nüîπ **Why choose rotki?**\n- **Open-source & Transparent** üìñ  \n- **Self-hosted** üè†  \n- **Privacy-Focused** üîí  \n- **Multi-Platform Support** üñ•  \n- **Powerful Analytics & Reporting** üìä  \n\nFor **advanced features**, check out the [Pro Version](https://rotki.com/products/) or explore the [Feature Coverage Page](https://rotki.com/products/details).\n\n---\n\n<div id=\"features\"></div>\n\n## ‚ú® **Features**\n‚úÖ **Portfolio Overview**: Track balances across multiple platforms, blockchains, and exchanges.  \n‚úÖ **Graphical Insights**: Historical data visualization for better financial decision-making.  \n‚úÖ **Transaction Decoding**: Readable breakdown of blockchain transactions, exchange events and other history.  \n‚úÖ **Data Customization**: Personalize UI, main currency, language, and more.  \n‚úÖ **PnL Reports**: Perform detailed profit/loss analysis using customizable accounting settings.  \n\n---\n\n<div id=\"requirements\"></div>\n\n## üîß **Requirements**\nBefore installing rotki, ensure you have the following dependencies:\n\nüìå **Required Software**:\n- `Node.js`\n- `npm` (Node Package Manager)\n- `Python 3.11`\n- `uv` (Python Package Manager)\n- `Docker`\n\n---\n\n<div id=\"installation\"></div>\n\n## üöÄ **Installation**\nrotki supports **Windows, macOS, and Linux**.\n\nüìå **Recommended Installation Method**:\n- [Download Pre-Packaged Binaries](https://docs.rotki.com/requirement-and-installation/packaged-binaries.html)\n\nüìå **Advanced Installation** (for developers):\n- [Build from Source](https://docs.rotki.com/requirement-and-installation/build-from-source.html)\n\n---\n\n<div id=\"usage\"></div>\n\n## üìò **Usage**\nFor **detailed setup and usage guides**, visit our [documentation](https://docs.rotki.com/).\n\nüìå **Quick Start**:\n- Follow the [usage guide](https://docs.rotki.com/usage-guides/).\n- Configure settings & import your addresses.\n- Start managing and analyzing your portfolio! üöÄ\n\n---\n\n<div id=\"changelog\"></div>\n\n## üìú **Changelog**\nStay up to date with rotki's latest features and improvements:\n\nüìå **[Full Changelog](https://rotki.readthedocs.io/en/latest/changelog.html)**  \nüìå **[Release Notes](https://github.com/rotki/rotki/releases)**  \n\n---\n\n<div id=\"contribute\"></div>\n\n## ü§ù **Contribute**\nWe welcome contributions from the community! üéâ\n\nüîπ **Getting Started**:\n- Read the [Contribution Guide](CONTRIBUTING.md)\n- Explore the [Developer Guide](https://docs.rotki.com/contribution-guides/)\n- Check out [Open Issues](https://github.com/rotki/rotki/issues)\n\nüìå **Claim Your Contributor Badge!**  \nContributors receive a **GitPOAP Badge** for each year they contribute! üéñ [Claim yours here](https://www.gitpoap.io/rp/62).\n\n---\n\n### Contributors\n\nWe are thankful to all the people who have contributed to rotki.\n\n<a href=\"https://github.com/rotki/rotki/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=rotki/rotki&max=999&anon=1&columns=12\" />\n</a>\n\n---\n\n<div id=\"get-in-touch\"></div>\n\n## üì¢ **Get in Touch**\nNeed help or want to discuss features? Connect with us!\n\n### üí¨ **Community & Support**\n[![Discord](https://img.shields.io/badge/Join%20our%20Discord-5865F2?logo=discord&logoColor=white&style=for-the-badge)](https://discord.rotki.com)\n[![GitHub Discussions](https://img.shields.io/badge/GitHub%20Discussions-181717?logo=github&logoColor=white&style=for-the-badge)](https://github.com/rotki/rotki/discussions)\n[![GitHub Issues](https://img.shields.io/badge/Report%20an%20Issue-F05032?logo=github&logoColor=white&style=for-the-badge)](https://github.com/rotki/rotki/issues)  \n\n### üìå **Follow Us for Updates**\n[![Website](https://img.shields.io/badge/Visit%20rotki-1E90FF?logoColor=white&style=for-the-badge)](https://rotki.com)\n[![Docs](https://img.shields.io/badge/Read%20the%20Docs-FF4500?logo=read-the-docs&logoColor=white&style=for-the-badge)](https://docs.rotki.com/)\n[![X (Twitter)](https://img.shields.io/badge/Follow%20on%20X-000000?logo=x&logoColor=white&style=for-the-badge)](https://twitter.com/rotkiapp)\n[![LinkedIn](https://img.shields.io/badge/Connect%20on%20LinkedIn-0077B5?logo=linkedin&logoColor=white&style=for-the-badge)](https://www.linkedin.com/company/rotki)  \n\n---\n\n<div id=\"donations\"></div>\n\n## üí∞ **Donations**\nIf you find rotki helpful, don't want to purchase a subscription and would like to support its development, you can make a donation using the following cryptocurrency addresses üöÄ\n\nüìå **Bitcoin (BTC)**: `1PfvkW8MC7Ns2y8zn6CE2P2t5f19KF8XiW`  \nüìå **Ethereum (ETH)**: `rotki.eth` (`0x9531c059098e3d194ff87febb587ab07b30b1306`)  \n\nüí° Your contribution will go directly towards enhancing the project, covering development costs, and supporting ongoing maintenance.\n\nWe appreciate every donation, no matter the size. It helps to ensure the project's sustainability and motivates us to continue delivering valuable updates and improvements.\n\nThank you for considering a donation to support our work!\n\n---\n\n<div id=\"license\"></div>\n\n## üìÑ **License**\nrotki is open-source and distributed under the **AGPLv3 License**.\n\nüìú **[Read the Full License](https://github.com/rotki/rotki/blob/develop/LICENSE.md)**\n\n<p align=\"right\">(<a href=\"#top\">üîº Back to top</a>)</p>\n\n\n[... truncated ...]"
  },
  "hyperledger-web3j/web3j-cli": {
    "fetchedAt": "2025-11-12T22:48:20.414Z",
    "content": "web3j-cli: Web3j Command Line Tools\n===================================\n\n.. image:: https://api.travis-ci.org/web3j/web3j-docs.svg?branch=master\n   :target: https://docs.web3j.io\n   :alt: Documentation Status\n\n.. image:: https://travis-ci.org/web3j/web3j-cli.svg?branch=master\n   :target: https://travis-ci.org/web3j/web3j-cli\n   :alt: Build Status\n\n.. image:: https://codecov.io/gh/web3j/web3j-cli/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/web3j/web3j-cli\n   :alt: codecov\n\n.. image:: https://badges.gitter.im/web3j/web3j.svg\n   :target: https://gitter.im/web3j/web3j\n   :alt: Join the chat at https://gitter.im/web3j/web3j\n\nAbout\n=====\nThe Web3j command line tools enable developers to interact with blockchains more easily. The Web3j command line tools allow allow you to use some of the key functionality of web3j from your terminal, including:\n\n* New project creation\n* Project creation from existing Solidity code\n* Wallet creation\n* Wallet password management\n* Ether transfer from one wallet to another\n* Generation of Solidity smart contract wrappers\n* Smart contract auditing\n\n**N.B.** For version prior to 4.5.7 go to web3j/web3j `releases <https://github.com/web3j/web3j/releases>`_\n\nInstallation\n=====\nOn Linux/macOS, in a terminal, run the following command:\n\n.. code-block:: bash\n\n\tcurl -L get.web3j.io | sh\n\nThis script will not work if Web3j has been installed using Homebrew on macOS.\n\nOn Windows, in PowerShell, run the following command:\n\n.. code-block:: bash\n\n\tSet-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/web3j/web3j-installer/master/installer.ps1'))\n   \nDocs\n=====\n\nhttps://docs.web3j.io/latest/command_line_tools/\n\n\nCredits\n=====\n\nSmart contract auditing functionality is provided by `SmartCheck <https://github.com/smartdec/smartcheck>`_\n"
  },
  "hyperledger-web3j/web3j-docs": {
    "fetchedAt": "2025-11-12T22:48:21.749Z",
    "content": "# web3j-docs\nWeb3j Documentation repository.\n\n[docs.web3j.io](http://docs.web3j.io)\n\n## Project setup\n\nMake sure you have [Pipenv](https://docs.pipenv.org/en/latest/) installed.\n\nThen run the following to get up and running:\n\n```bash\ngit clone https://github.com/web3j/web3j-docs.git\ncd web3j-docs\npipenv install\n```\n\n## Build instructions\nInstall mkdocs material theme:\n```bash\npip install mkdocs-material\n```\nInstall [mike](https://github.com/jimporter/mike)\n```bash\npip install mike\n```\nRun locally using:\n\n```bash\nmike serve\n```\n\nTo build and push to web3j-docs:\n\n```bash\nmike deploy VERSION ALIAS -p\n```\n\nSet default version to latest\n\n```bash\nmike set-default VERSION or ALIAS -p\n```\n\nTo update the versions of the dependencies simply change them in the `mkdocs.yml` file under the extra tag\n\n"
  },
  "hyperledger-web3j/web3j-maven-plugin": {
    "fetchedAt": "2025-11-12T22:48:22.463Z",
    "content": "# web3j-maven-plugin\n[![build status](https://github.com/web3j/web3j-maven-plugin/actions/workflows/maven.yml/badge.svg)](https://github.com/web3j/web3j-maven-plugin/actions/workflows/maven.yml)\n[![codecov](https://codecov.io/gh/web3j/web3j-maven-plugin/branch/master/graph/badge.svg?token=Ar7tgwmUEz)](https://codecov.io/gh/web3j/web3j-maven-plugin)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nweb3j maven plugin is used to create java classes based on the solidity contract files.\n\n## Usage\nThe base configuration for the plugin will take the solidity files from `src/main/resources` and generates \nthe java classes into the folder `src/main/java`.\n\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.web3j</groupId>\n            <artifactId>web3j-maven-plugin</artifactId>\n            <version>4.14.0</version>\n            <configuration>\n                <soliditySourceFiles/>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\nto run the plugin execute the goal `generate-sources`\n```bash\nmvn web3j:generate-sources\n```\n\n\n## Configuration\nThe are several variable to select the solidity source files, define a source destination path or change the package name.\n\n| Name                   | Format                                                                                 | Default value                   |\n| -----------------------|----------------------------------------------------------------------------------------| --------------------------------|\n| `<packageName/>`       | valid java package name                                                                | `org.web3j.model`               |\n| `<outputDirectory><java/></outputDirectory>` | relative or absolute path of the generated for 'Java files       | value in `<sourceDestination/>` |\n| `<outputDirectory><bin/></outputDirectory>`  | relative or absolute path of the generated for 'Bin' files       | value in `<sourceDestination/>` |\n| `<outputDirectory><abi/></outputDirectory>`  | relative or absolute path of the generated for 'ABI' files       | value in `<sourceDestination/>` |\n| `<sourceDestination/>` | relative or absolute path of the generated files (java, bin, abi)                      | `src/main/java`                 |\n| `<outputFormat/>`      | generate Java Classes(`java`), ABI(`abi`) and/or BIN (`bin`) Files (comma separated)   | `java`                          |\n| `<nativeJavaType/>`    | Creates Java Native Types (instead of Solidity Types)                                  | `true`                          |\n| `<outputJavaParentContractClassName/>` | Sets custom(? extends org.web3j.tx.Contract) class as a parent for java generated code | `org.web3j.tx.Contract` |\n| `<soliditySourceFiles>`| Standard maven [fileset](https://maven.apache.org/shared/file-management/fileset.html) | `<soliditySourceFiles>`<br>`  <directory>src/main/resources</directory>`<br>`  <includes>`<br>`    <include>**/*.sol</include>`<br>`  </includes>`<br>`</soliditySourceFiles>`  |\n| `<abiSourceFiles>`     | Standard maven [fileset](https://maven.apache.org/shared/file-management/fileset.html) | `<abiSourceFiles>`<br>`  <directory>src/main/resources</directory>`<br>`  <includes>`<br>`    <include>**/*.json</include>`<br>`  </includes>`<br>`</abiSourceFiles>`           |\n| `<contract>`           | Filter (`<include>` or `<exclude>`) contracts based on the name.                       | `<contract>`<br>`  <includes>`<br>`    <include>greeter</include>`<br>`  </includes>`<br>`  <excludes>`<br>`    <exclude>mortal</exclude>`<br>`  <excludes>`<br>`</contracts>`  |\n| `<pathPrefixes>`       | A list (`<pathPrefixe>`) of replacements of dependency replacements inside Solidity contract.  |  |\n\nConfiguration of `outputDirectory` has priority over `sourceDestination`\n\n\n## Getting Started\n\nCreate a standard java maven project. Add following `<plugin>` - configuration into the `pom.xml` file:\n\n```xml\n<plugin>\n    <groupId>org.web3j</groupId>\n    <artifactId>web3j-maven-plugin</artifactId>\n    <version>4.14.0</version>\n    <configuration>\n        <packageName>com.zuehlke.blockchain.model</packageName>\n        <sourceDestination>src/main/java/generated</sourceDestination>\n        <nativeJavaType>true</nativeJavaType>\n        <outputFormat>java,bin</outputFormat>\n        <soliditySourceFiles>\n            <directory>src/main/resources</directory>\n            <includes>\n                <include>**/*.sol</include>\n            </includes>\n        </soliditySourceFiles>\n        <abiSourceFiles>\n            <directory>src/main/resources</directory>\n            <includes>\n                <include>**/*.json</include>\n            </includes>\n        </abiSourceFiles>\n        <outputDirectory>\n            <java>src/java/generated</java>\n            <bin>src/bin/generated</bin>\n            <abi>src/abi/generated</abi>\n        </outputDirectory>\n        <contract>\n            <includes>\n                <include>greeter</include>\n            </includes>\n            <excludes>\n                <exclude>mortal</exclude>\n            </excludes>\n        </contract>\n        <pathPrefixes>\n            <pathPrefix>dep=../dependencies</pathPrefix>\n        </pathPrefixes>\n    </configuration>\n</plugin>\n```\n\nAdd your solidity contract files into the folder `src/main/resources`. Make sure that the solidity files \nends with `.sol`.\n\n\nStart the generating process:\n\n\n```\n> mvn web3j:generate-sources\n\n[INFO] --- web3j-maven-plugin:4.3.0:generate-sources (default-cli) @ hotel-showcase ---\n[INFO] process 'HotelShowCaseProxy.sol'\n[INFO] \tBuilt Class for contract 'HotelShowCaseProxy'\n[INFO] \tBuilt Class for contract 'HotelShowCaseV2'\n[INFO] \tBuilt Class for contract 'Owned'\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 4.681 s\n[INFO] Finished at: 2017-06-13T07:07:04+02:00\n[INFO] Final Memory: 14M/187M\n[INFO] ------------------------------------------------------------------------\n\nProcess finished with exit code 0\n```\n\nYou find the generated java classes inside the directory `src/main/java/generated/`.\n\nNext step is to interact with the smart contract. See for that \n[deploying and interacting with smart contracts](https://web3j.readthedocs.io/en/latest/smart_contracts.html#deploying-and-interacting-with-smart-contracts) \nin the official web3j documentation.\n\nFor a multi module project configuration see following [post](https://github.com/web3j/web3j-maven-plugin/issues/14) \nfrom [@fcorneli](https://github.com/fcorneli). In short:  For pick up the generated java source \nfiles, you need the build-helper-maven-plugin configuration. Also, `${basedir}` prefix is required \nwithin a multi-module project.\n"
  },
  "hyperledger-web3j/web3j-unit": {
    "fetchedAt": "2025-11-12T22:48:23.182Z",
    "content": "# Web3j-unit [![Build Status](https://github.com/web3j/web3j-unit/actions/workflows/build.yml/badge.svg)](https://github.com/web3j/web3j-unit/actions/workflows/build.yml)\n\nWeb3j-unit is a [Junit 5](https://junit.org/junit5/docs/current/user-guide/) extension to streamline the creation of Ethereum contract tests.\n\nMultiple Ethereum implementations are supported including Geth and Besu. To run tests built using Web3j-unit, **docker is required** on the host.\n\nInstances of `Web3j`, `TransactionManager` and `GasProvider` are injected into the Junit runner.\n\nYou can find a sample [here](https://github.com/web3j/web3j-unitexample).\n\nYou can find an example using docker-compose [here](https://github.com/web3j/web3j-unit-docker-compose-example). This spins up VMWare Concord nodes using a docker-compose file. \n\n### Getting Started\n\n1. Add dependency to gradle.\n\n```groovy\n   repositories {\n      mavenCentral()\n      maven { url \"https://hyperledger.jfrog.io/artifactory/besu-maven/\" }\n      maven { url \"https://artifacts.consensys.net/public/maven/maven/\" }\n      maven { url \"https://splunk.jfrog.io/splunk/ext-releases-local\" }\n      maven { url \"https://dl.cloudsmith.io/public/consensys/quorum-mainnet-launcher/maven/\" }\n   }\n\n   implementation \"org.web3j:core:4.14.0\"\n   testCompile \"org.web3j:web3j-unit:4.14.0\"\n```\n\n2. Create a new test with the `@EVMTest` annotation. An embedded EVM is used by default. To use Geth or Besu pass the node type into the annotation: `@EVMTest(NodeType.GETH)` or `@EVMTest(NodeType.BESU)`\n\n```kotlin\n@EVMTest\nclass GreeterTest {\n\n}\n```\n\n3. Inject instance of `Web3j` `TransactionManager` and `ContractGasProvider` in your test method.\n\n```kotlin\n@EVMTest\nclass GreeterTest {\n\n    @Test\n    fun greeterDeploys(\n        web3j: Web3j,\n        transactionManager: TransactionManager,\n        gasProvider: ContractGasProvider\n    ) {}\n\n}\n```\n\n4. Deploy your contract in the test.\n\n```kotlin\n@EVMTest\nclass GreeterTest {\n\n    @Test\n    fun greeterDeploys(\n        web3j: Web3j,\n        transactionManager: TransactionManager,\n        gasProvider: ContractGasProvider\n    ) {\n        val greeter = Greeter.deploy(web3j, transactionManager, gasProvider, \"Hello EVM\").send()\n        val greeting = greeter.greet().send()\n        assertEquals(\"Hello EVM\", greeting)\n    }\n\n}\n```\n\n5. Run the test!\n\n### Using a custom docker-compose file\n\n1. Add dependency to gradle.\n   \n```groovy\n  repositories {\n     mavenCentral()\n  }\n\n  implementation \"org.web3j:core:4.14.0\"\n  testCompile \"org.web3j:web3j-unit:4.14.0\"\n```\n\n2. Create a new test with the `@EVMComposeTest` annotation.\nBy default, uses `test.yml` file in the project home, and runs `web3j` on service name `node1` exposing the port `8545`. \nCan be customised to use specific docker-compose file, service name and port by `@EVMComposeTest(\"src/test/resources/geth.yml\", \"ethnode1\", 8080)`\nHere, we connect to the service named `ethnode1` in the `src/test/resources/geth.yml` docker-compose file which exposes the port `8080` for `web3j` to connect to. \n\n```kotlin\n@EVMComposeTest(\"src/test/resources/geth.yml\", \"ethnode1\", 8080)\nclass GreeterTest {\n\n}\n```\n\n3. Inject instance of `Web3j` `TransactionManager` and `ContractGasProvider` in your test method.\n\n```kotlin\n@EVMComposeTest(\"src/test/resources/geth.yml\", \"ethnode1\", 8080)\nclass GreeterTest {\n\n    @Test\n    fun greeterDeploys(\n        web3j: Web3j,\n        transactionManager: TransactionManager,\n        gasProvider: ContractGasProvider\n    ) {}\n\n}\n```\n\n4. Deploy your contract in the test.\n\n```kotlin\n@EVMComposeTest(\"src/test/resources/geth.yml\", \"ethnode1\", 8080)\nclass GreeterTest {\n\n    @Test\n    fun greeterDeploys(\n        web3j: Web3j,\n        transactionManager: TransactionManager,\n        gasProvider: ContractGasProvider\n    ) {\n        val greeter = Greeter.deploy(web3j, transactionManager, gasProvider, \"Hello EVM\").send()\n        val greeting = greeter.greet().send()\n        assertEquals(\"Hello EVM\", greeting)\n    }\n\n}\n```\n\n5. Run the test!\n"
  },
  "hyperledger-web3j/web3j-solidity-gradle-plugin": {
    "fetchedAt": "2025-11-12T22:48:24.015Z",
    "content": "Web3j Solidity Gradle Plugin\n======================\n\nSimple Gradle plugin used by the [Web3j plugin](https://github.com/web3j/web3j-gradle-plugin) \nto compile Solidity contracts, but it can be used in any standalone project for this purpose.\n\n## Plugin configuration\n\nTo configure the Solidity Gradle Plugin using the plugins DSL or the legacy plugin application, \ncheck the [plugin page](https://plugins.gradle.org/plugin/org.web3j.solidity). \nThe minimum Gradle version to run the plugin is `7.+`.\n\nThen run this command from your project containing Solidity contracts:\n\n```\n./gradlew build\n```\n\nAfter the task execution, the base directory for compiled code (by default \n`$buildDir/resources/solidity`) will contain a directory for each source set \n(by default `main` and `test`), and each of those a directory with the compiled code.\n\n\n## Code generation\n\nThe `solidity` DSL allows to configure the generated code, e.g.:\n\n```groovy\nsolidity {\n    outputComponents = [BIN, ABI, ASM_JSON]\n    optimizeRuns = 500\n}\n```\n\nThe properties accepted by the DSL are listed in the following table:\n\n|  Name                      | Type                        | Default value                                     | Description                                                     |\n|----------------------------|:---------------------------:|:-------------------------------------------------:|-----------------------------------------------------------------|\n| `executable`               | `String`                    | `null` (bundled with the plugin)                  | Solidity compiler path.                                         |\n| `version`                  | `String`                    | `null` (defined by contract's pragma)             | Solidity compiler version.                                      |\n| `overwrite`                | `Boolean`                   | `true`                                            | Overwrite existing files.                                       |\n| `resolvePackages`          | `Boolean`                   | `true`                                            | Resolve third-party contract packages.                          |           \n| `optimize`                 | `Boolean`                   | `true`                                            | Enable byte code optimizer.                                     |\n| `optimizeRuns`             | `Integer`                   | `200`                                             | Set for how many contract runs to optimize.                     |\n| `prettyJson`               | `Boolean`                   | `false`                                           | Output JSON in pretty format. Enables the combined JSON output. |\n| `ignoreMissing`            | `Boolean`                   | `false`                                           | Ignore missing files.                                           |\n| `allowPaths`               | `List<String>`              | `['src/main/solidity', 'src/test/solidity', ...]` | Allow a given path for imports.                                 |\n| `pathRemappings`           | `Map<String, String>`        | `[ : ]`                                           | Remaps contract imports to target path.                         |\n| `evmVersion`               | `EVMVersion`                | `BYZANTIUM`                                       | Select desired EVM version.                                     |\n| `outputComponents`         | `OutputComponent[]`         | `[BIN, ABI]`                                      | List of output components to produce.                           |\n| `combinedOutputComponents` | `CombinedOutputComponent[]` | `[BIN, BIN_RUNTIME, SRCMAP, SRCMAP_RUNTIME]`      | List of output components in combined JSON output.              |\n\n**Notes:**\n\n  * Setting the `executable` property will disable the bundled `solc` and use your local or containerized executable:\n  \n```groovy\nsolidity {\n    executable = \"docker run --rm -v $projectDir/src:/src -v $projectDir/build:/build ethereum/solc:0.6.4-alpine\"\n    version = '0.4.15'\n}\n```\n\n  * Use `version` to change the bundled Solidity version. \n    Check the [Solidity releases](https://github.com/ethereum/solidity/releases) \n    for all available versions.\n  * `allowPaths` contains all project's Solidity source sets by default.\n\n## Source sets\n\nBy default, all `.sol` files in `$projectDir/src/main/solidity` and `$projectDir/src/test/solidity` will be processed by\nthe plugin. To specify and add different source sets, use the `sourceSets` DSL. You can also set your preferred output\ndirectory for compiled code.\n\n```groovy\nsourceSets {\n    main {\n        solidity {\n            srcDir {\n                \"my/custom/path/to/solidity\"\n             }\n             output.resourcesDir = file('out/bin/compiledSol') \n        }\n    }\n}\n```\n\nNow with solidity gradle plugin version 0.4.2, you can set different solidity versions, evmVersions, optimize flag, optimizeRuns and ignoreMissing \nflag values for different sourceSets.\n\n```groovy\nsourceSets {\n    main {\n        solidity {\n            srcDir {\n                \"my/custom/path/to/solidity\"\n            }\n            output.resourcesDir = file('out/bin/compiledSol')\n            setEvmVersion('ISTANBUL')\n            setOptimize(true)\n            setOptimizeRuns(200)\n            setVersion('0.8.12')\n        }\n    }\n}\n```\n\n## Gradle Node Plugin\n\nThe plugin makes use of the [Node plugin](https://github.com/node-gradle/gradle-node-plugin) to resolve third-party\ncontract dependencies. It currently supports [Open Zeppelin](https://www.npmjs.com/package/@openzeppelin/contracts)\nand [Uniswap](https://www.npmjs.com/package/@uniswap/lib).\n\nWhen importing libraries from `@openzeppelin/contracts` in your Solidity contract, the plugin will use the\ntask `resolveSolidity` to generate a `package.json` file required by\nthe [Node plugin](https://github.com/node-gradle/gradle-node-plugin).\n\nBy default, `package.json` will be generated under the `build/` directory. If you wish to change the directory for the\nNode plugin, add the following snippet to your `build.gradle` file:\n\n```\nnode {\n    nodeProjectDir = file(\"my/custom/node/directory\")\n}\n```\n\nIf it already exists, the plugin will keep the `package.json` file in that directory and will also download the node\nmodules under the same directory.\n\n**Note:** In case of problems with the `package.json` file, you can delete it, and it will be regenerated with the\nlatest versions.\n\n## Plugin tasks\n\nThe [Java Plugin](https://docs.gradle.org/current/userguide/java_plugin.html)\nadds tasks to your project build using a naming convention on a per source set basis\n(i.e. `compileJava`, `compileTestJava`).\n\nSimilarly, the Solidity plugin will add the tasks:\n\n* `resolveSolidity` task for all project Solidity sources.\n* `compileSolidity` task for the project `main` source set.\n* `compile<SourceSet>Solidity` for each remaining source set. (e.g. `compileTestSolidity` for the `test` source set,\n  etc.).\n\nTo obtain a list and description of all added tasks, run the command:\n\n```\n./gradlew tasks --all\n```\n"
  },
  "hyperledger-web3j/web3j-openapi": {
    "fetchedAt": "2025-11-12T22:48:24.695Z",
    "content": "Web3j Open API\n==============\n\n[![Build Status](https://travis-ci.org/web3j/web3j-openapi.svg?branch=master)](https://travis-ci.org/web3j/web3j-openapi)\n\nWeb3j-OpenAPI is a [OpenAPI](https://swagger.io/specification/) client and server generator from \n[Solidity](https://solidity.readthedocs.io/) smart contracts. it provides a way to interact with the Ethereum blockchain via simple and intuitive \nHTTP requests, abstracting the coding layer. These interactions can be done using :\n- Plain HTTP requests\n- Via the `Swagger-UI`, which is generated with every project\n- A client application using the [`webj3-openapi-client`](/client) implementation\n\nThe workflow can be summed in the following steps:\n- Writing a Solidity smart contract\n- Generating the corresponding **OpenAPI** project using **Web3j-OpenAPI**\n- Running the generated project as a standalone server\n- Sending HTTP requests using `Swagger-UI`, client application or `Curl` request.\n\n# Getting started with Web3j-OpenAPI\nTo generate an OpenAPI project using the [Web3j-OpenAPI](https://github.com/hyperledger/web3j-openapi) generator, \nyou need to have the [Web3j-CLI](https://docs.web3j.io/latest/command_line_tools/) installed on your machine. \nIt‚Äôs easy to do (for Windows instructions head [here](https://github.com/hyperledger/web3j-cli/)):\n\t\n```ssh\n$ curl -L get.web3j.io | sh\n```\n\n### Create a Hello World project\nTo create a base OpenAPI project using a `Hello World` contract, run the following :\n\n```ssh\n$ web3j openapi new\n```\n\nYou can also generate a `Web3j-OpenAPI` project using the [Web3j-OpenAPI-gradle-plugin](https://github.com/web3j/web3j-openapi-gradle-plugin).\n\n### Configure the project\nAfter having the generated project, you can configure your application with the following environment variables:\n\n```ssh\n$ export WEB3J_ENDPOINT=<link_to_your_Ethereum_node>\n$ export WEB3J_PRIVATE_KEY=<your_private_key>\n$ export WEB3J_OPENAPI_HOST=localhost\n$ export WEB3J_OPENAPI_PORT=9090\n```\n\n### Run the project\nIf you aren't using the Web3j-CLI you may run the project using the following Gradle target:\n\n```ssh\n$ cd <project_folder>\n$ ./gradlew run\n```\n\nThen, you should be seeing the server logs.\n\n### Interact with the project\n\n#### SwaggerUI\nThe easiest way to interact with the generated project is via the generated `Swagger-UI` which can be found on `http://<host>:<port>/swagger-ui`.\n\n![image](https://github.com/web3j/web3j-docs/blob/master/docs/img/Web3j-OpenAPI/SwaggerUI_1.png)\n\n#### Web3j-OpenAPI client\nAlso, you can use our client implementation via adding the following dependency to your project:\n```groovy\ndependencies {\n    implementation \"org.web3j.openapi:web3j-openapi-client:4.14.0\"\n}\n```\n\nThen, within the application:\n\n```kotlin\nval service = ClientService(\"http://localhost:9090\")\nval app = ClientFactory.create(<AppNameApi>::class.java, service)\n\n// Then you have access to all the API resources\nval receipt = app.contracts.contractName.deploy()\n\nprintln(\"Deployment receipt: ${receipt.contractAddress}\")\n\n// ...\n```\n\n#### **For more information**, please refer to the [documentation](https://docs.web3j.io/web3j_openapi).\n"
  },
  "hyperledger-web3j/web3j-openapi-gradle-plugin": {
    "fetchedAt": "2025-11-12T22:48:25.333Z",
    "content": "Web3j OpenAPI Gradle Plugin\n============================\n\nGradle plugin that generates [Web3j-OpenAPI](https://github.com/web3j/web3j-openapi) \nproject from Solidity smart contracts.\nIt smoothly integrates with your project's build lifecycle by adding specific tasks that can be also\nrun independently.\n\n## Plugin configuration\n\nTo configure the Web3j Gradle Plugin using the plugins DSL or the legacy plugin application, \ncheck the [plugin page](https://plugins.gradle.org/plugin/org.web3j). \nThe minimum Gradle version to run the plugin is `5.+`.\n\nYou *should not* add the Kotlin plugin to your project build. It already comes with the `web3j-openapi-gradle-plugin`\nand applying it again may cause issues.\n\nThen run your project containing Solidity contracts:\n```\n./gradlew build\n```\n\nAfter applying the plugin, the base directory for generated code (by default \n`$buildDir/generated/sources/web3j`) will contain a directory containing the generated\nproject for all the contracts specified in the configuration.\n\n## Code generation\n\nThe `web3j` DSL allows to configure the generated code, e.g.:\n\n```groovy\nweb3j {\n    generatedPackageName = 'com.mycompany'\n    generatedFilesBaseDir = \"$buildDir/custom/destination\"\n    excludedContracts = ['Ownable']\n    openapi {\n        contextPath = \"api\"\n    }\n}\n```\n\nThe properties accepted by the `openapi` DSL are listed in the following table: \n\n|  Name                   | Type       | Default value                       | Description |\n|-------------------------|:----------:|:-----------------------------------:|-------------|\n| `projectName`           | `String`   | `${rootProject.name}` or `OpenAPI`  | Generated Web3j-OpenAPI project name. |\n| `contextPath`           | `String`   | `$projectName`                      | Generated Web3j-OpenAPI context path `/{contextPath}/...`. |\n| `generateServer`        | `Boolean`  | `true`                              | Whether to generate the API implementation and contract wrappers or only the interfaces |\n\nCheck the [web3j-gradle-plugin](https://github.com/web3j/web3j-gradle-plugin#code-generation) \nfor the options accepted by the `web3j` DSL.\n\nThe `generatedPackageName` is a `.` separated list of words. It will be converted to lower case during the generation.\n\nThe default value for the `generatePackageName` is : `org.web3j.openapi`\n\n**The `.{0}` is not accepted in the case we are generating an `OpenAPI` project**.\n\n## Source sets\n\nBy default, all `.sol` files in `$projectDir/src/main/solidity` will be processed by the plugin.\nTo specify and add different source sets, use the `sourceSets` DSL:\n\n```groovy\nsourceSets {\n    main {\n        solidity {\n            srcDir { \n                \"my/custom/path/to/solidity\" \n             }\n        }\n    }\n}\n```\n\nCheck the [Solidity Plugin](https://github.com/web3j/solidity-gradle-plugin)\ndocumentation to configure the smart contracts source code directories.\n\nOutput directories for generated Web3j-OpenAPI project\nwill be added to your build automatically.\n\n## Swagger UI\n\nThe Swagger UI page will be found on : `http://{host}:{port}/swagger-ui`, after running the project `./gradlew run` and specifying the [Web3j-OpenAPI](https://github.com/web3j/web3j-openapi) runtime configuration.\n\n## Plugin tasks\n\nThe `Web3j-OpenAPI` Gradle plugin adds tasks to your project build using \na naming convention on a per source set basis\n(i.e. `generateWeb3jOpenApi`, `generate[SourceSet]Web3jOpenApi`).\n\nTo obtain a list and description of all added tasks, run the command:\n\n```\n./gradlew tasks --all\n```\n\n[web3j]: https://web3j.io/\n\n"
  },
  "hyperledger-web3j/web3j-gradle-plugin": {
    "fetchedAt": "2025-11-12T22:48:25.995Z",
    "content": "Web3j Gradle Plugin\n===================\n\nGradle plugin that generates [Web3j][web3j] Java wrappers from Solidity smart contracts.\nIt smoothly integrates with your project's build lifecycle by adding specific tasks that can be also\nrun independently.\n\n## Plugin configuration\n\nTo configure the Web3j Gradle Plugin using the plugins DSL or the legacy plugin application, \ncheck the [plugin page](https://plugins.gradle.org/plugin/org.web3j). \nThe minimum Gradle version to run the plugin is `7.+`.\n\nThen run your project containing Solidity contracts:\n\n```\n./gradlew build\n```\n\nAfter applying the plugin, the base directory for generated code (by default \n`$buildDir/generated/sources/web3j`) will contain a directory for each source set \n(by default `main` and `test`) containing the smart contract wrappers Java classes.\n\n## Code generation\n\nThe `web3j` DSL allows to configure the generated code, e.g.:\n\n```groovy\nweb3j {\n    generatedPackageName = 'com.mycompany.{0}'\n    generatedFilesBaseDir = \"$buildDir/custom/destination\"\n    excludedContracts = ['Ownable']\n    useNativeJavaTypes = false\n}\n```\n\nThe properties accepted by the DSL are listed in the following table: \n\n|  Name                   | Type       | Default value                       | Description |\n|-------------------------|:----------:|:-----------------------------------:|-------------|\n| `generatedPackageName`  | `String`   | `${group}.web3j` or `org.web3j.{0}` | Generated contract wrappers package. |\n| `generatedFilesBaseDir` | `String`   | `$buildDir/generated/sources/web3j`  | Generated Java code output directory. |\n| `excludedContracts`     | `String[]` | `[]`                                | Excluded contract names from wrapper generation. |\n| `includedContracts`     | `String[]` | `[]`                                | Included contract names from wrapper generation. Has preference over `excludedContracts`. |\n| `useNativeJavaTypes`    | `Boolean`  | `true`                              | Generate smart contract wrappers using native Java types. |\n| `addressBitLength`      | `int`      | `160`                               | Supported address length in bits, by default Ethereum addresses. |\n\nThe `generatedPackageName` is evaluated as a [message format](https://docs.oracle.com/javase/6/docs/api/index.html?java/text/MessageFormat.html) \nstring accepting a single parameter between curly brackets (`{0}`),\nallowing to format the generated value using the contract name. For convenience,\nwhen applied to a Java package name it will be converted to lower case. \n\nFor instance, a `generatedPackageName` set to `${group}.{0}` in a project with group \n`com.mycompany`, a Solidity contract named `MyToken.sol` will be generated in the package\n`com.mycompany.mytoken`.\n\nAlso, the default value contains the `${group}` property, which corresponds to your project artifact \ngroup (e.g. `com.mycompany`). If the project does not define a `group` property, the generated package\nname will be `org.web3j.{0}`.\n\nNote that message format parameters are not Gradle properties and should not be preceded by `$`.\n\n## Source sets\n\nBy default, all `.sol` files in `$projectDir/src/main/solidity` will be processed by the plugin.\nTo specify and add different source sets, use the `sourceSets` DSL:\n\n```groovy\nsourceSets {\n    main {\n        solidity {\n            srcDir 'my/custom/path/to/solidity'\n        }\n    }\n}\n```\n\nCheck the [Solidity Plugin](https://github.com/web3j/solidity-gradle-plugin)\ndocumentation to configure the smart contracts source code directories.\n\nOutput directories for generated smart contract wrappers Java code \nwill be added to your build automatically.\n\n## Plugin tasks\n\nThe [Java Plugin](https://docs.gradle.org/current/userguide/java_plugin.html)\nadds tasks to your project build using a naming convention on a per source set basis\n(i.e. `compileJava`, `compileTestJava`).\n\nSimilarly, the Solidity plugin will add the `generateContractWrappers` task for the project `main`\nsource set, and a `generate[SourceSet]ContractWrappers` for each remaining source set (e.g. `test`). \n\nTo obtain a list and description of all added tasks, run the command:\n\n```\n./gradlew tasks --all\n```\n\n[web3j]: https://web3j.io/"
  },
  "hyperledger-web3j/web3j-sokt": {
    "fetchedAt": "2025-11-12T22:48:26.761Z",
    "content": "# Sokt\n\nSokt is a Kotlin wrapper for the Solidity compiler (solc). Given a solidity file, it can identify the ideal compiler version to use from the pragma statement at the top of the file. It can then download, install and invoke the compiler. Rather than using Dockerized versions of Solc, Sokt uses native builds and is compatible with Mac, Windows and Linux (x86/64 only)<sup>*</sup>. This means that the only dependency is a Java installation. Sokt also plays nicely with GraalVM, eliminating the Java dependency if necessary. \n \nSokt is currently under active development. You can use it in one of your own projects by adding the following dependency to your `build.gradle`:\n\n```groovy\ndependencies {\n    compile group: 'org.web3j', name: 'web3j-sokt', version: '0.5.0'\n}\n```\nFor other build systems, see [here](https://mvnrepository.com/artifact/org.web3j/web3j-sokt/0.2.1).\n\nExample usage:\n```kotlin\nval fileName = filePath.substringAfterLast(\"/\")\nprintln(\"sokt Processing $fileName\")\nval solidityFile = SolidityFile(filePath)\n\nprintln(\"Resolving compiler version for $fileName\")\nval compilerInstance = solidityFile.getCompilerInstance()\n\nprintln(\"Resolved ${compilerInstance.solcRelease.version} for $fileName\")\n\nval result = compilerInstance.execute(\n    SolcArguments.OUTPUT_DIR.param { \"/tmp\" },\n    SolcArguments.BIN,\n    SolcArguments.OVERWRITE\n)\n\nprintln(\"Solc exited with code: ${result.exitCode}\")\nprintln(\"Solc standard output:\\n${result.stdOut}\")\nprintln(\"Solc standard error:\\n${result.stdErr}\")\n\n```\n\n<sup>*</sup>Note: Solc is not officially released for Linux arm machines, You can build it from source and copy the bin file to `{$USER}/.web3j/solc/<solc-version>/`\n\nHow to build from source, see [here](https://docs.soliditylang.org/en/latest/installing-solidity.html#building-from-source)."
  },
  "hyperledger-web3j/web3j": {
    "fetchedAt": "2025-11-12T22:48:27.384Z",
    "content": "Web3j: Web3 Java Ethereum Dapp API\n==================================\n\n[![Documentation Status](https://readthedocs.org/projects/web3j-docs/badge/?version=latest)](https://docs.web3j.io)\n[![build status](https://github.com/web3j/web3j/actions/workflows/build.yml/badge.svg)](https://github.com/web3j/web3j/actions/workflows/build.yml)\n[![codecov](https://codecov.io/gh/LFDT-web3j/web3j/branch/main/graph/badge.svg?token=a4G9ITI6CU)](https://codecov.io/gh/web3j/web3j)\n[![Discord](https://img.shields.io/discord/779382027614158919?label=discord)](https://discord.gg/A9UXfPF2tS)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Web3j%20Guru-006BFF)](https://gurubase.io/g/web3j)\n\n\nWeb3j is a lightweight, highly modular, reactive, type safe Java and\nAndroid library for working with Smart Contracts and integrating with\nclients (nodes) on the Ethereum network:\n\n![image](https://github.com/LFDT-web3j/web3j-docs/blob/main/docs/img/web3j_network.png)\n\nThis allows you to work with the [Ethereum](https://www.ethereum.org/)\nblockchain, without the additional overhead of having to write your own\nintegration code for the platform.\n\nThe [Java and the Blockchain](https://www.youtube.com/watch?v=ea3miXs_P6Y) talk provides\nan overview of blockchain, Ethereum and Web3j.\n\nNEW! Get involved!\n--------\nSince Web3J moved under Hyperledger we started to do Web3J Contributors calls every 2 weeks!\nSubscribe to our community page and to see check our call schedule.\nYour contribution matters!\n- [Community Link](https://lists.hyperledger.org/g/web3j) - Check our last updates! \n- [Calendar Invite](https://lists.hyperledger.org/g/web3j/ics/invite.ics?repeatid=57401) - Add the contributor call to your calendar!\n\nFeatures\n--------\n\n-   Complete implementation of Ethereum's\n    [JSON-RPC](https://ethereum.org/en/developers/docs/apis/json-rpc/) client\n    API over HTTP and IPC\n-   Ethereum wallet support\n-   Auto-generation of Java smart contract wrappers to create, deploy,\n    transact with and call smart contracts from native Java code\n    ([Solidity](http://solidity.readthedocs.io/en/latest/using-the-compiler.html#using-the-commandline-compiler)\n    and\n    [Truffle](https://github.com/trufflesuite/truffle-contract-schema)\n    definition formats supported)\n-   Reactive-functional API for working with filters\n-   [Ethereum Name Service (ENS)](https://ens.domains/) support\n-   Support for Parity's\n    [Personal](https://github.com/paritytech/parity/wiki/JSONRPC-personal-module),\n    and Geth's\n    [Personal](https://github.com/ethereum/go-ethereum/wiki/Management-APIs#personal)\n    client APIs\n-   Support for [Alchemy](https://docs.alchemyapi.io/alchemy/guides/getting-started#web-3-j) and [Infura](https://infura.io/), so you don't have to run\n    an Ethereum client yourself\n-   Comprehensive integration tests demonstrating a number of the above\n    scenarios\n-   Command line tools\n-   Android compatible\n-   Support for JP Morgan's Quorum via\n    [web3j-quorum](https://github.com/web3j/quorum)\n-   Support for [EEA Privacy features as described in EEA\n    documentation](https://entethalliance.org/technical-documents/) and\n    implemented in [Hyperledger\n    Besu](https://besu.hyperledger.org/private-networks/reference/api#eea-methods).\n\nIt has five runtime dependencies:\n\n-   [RxJava](https://github.com/ReactiveX/RxJava) for its\n    reactive-functional API\n-   [OKHttp](https://square.github.io/okhttp/)\n    for HTTP connections\n-   [Jackson Core](https://github.com/FasterXML/jackson-core) for fast\n    JSON serialisation/deserialization\n-   [Bouncy Castle](https://www.bouncycastle.org/) for\n    crypto\n-   [Jnr-unixsocket](https://github.com/jnr/jnr-unixsocket) for \\*nix\n    IPC (not available on Android)\n-   [Java-WebSocket](https://github.com/TooTallNate/Java-WebSocket)\n\nIt also uses [JavaPoet](https://github.com/square/javapoet) for\ngenerating smart contract wrappers.\n\nQuickStart\n---------\nThe simplest way to start your journey with Web3j is to create a project.\nWe provide this functionality using the [Web3j CLI](http://docs.web3j.io/latest/command_line_tools/). This latter can be installed as follows:\n\nFor Unix:\n\n```shell script\ncurl -L get.web3j.io | sh && source ~/.web3j/source.sh\n```\n\nFor Windows, in Powershell:\n\n```shell script\nSet-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/hyperledger/web3j-installer/main/installer.ps1'))\n```\n\nCreate a new project by running:\n\n```shell script\n$ web3j new \n```\n\nOr use our [Maven](https://github.com/web3j/web3j-maven-plugin) or \n[Gradle](https://github.com/web3j/web3j-gradle-plugin) plugins to \ngenerate java files from Solidity contracts.\n\n\n#### Please head to the [Web3j Documentation](https://docs.web3j.io) for further instructions on using Web3j.\n\nMaven\n-----\n\nJava:\n\n```xml\n<dependency>\n  <groupId>org.web3j</groupId>\n  <artifactId>core</artifactId>\n  <version>4.14.0</version>\n</dependency>\n```\n\n**Note:** The Web3j Java binaries are compiled using Java 21. Java 21 or a more recent version is required to use Web3j\n as a dependency.\n\nAndroid:\n\n```xml\n<dependency>\n  <groupId>org.web3j</groupId>\n  <artifactId>core</artifactId>\n  <version>4.12.3-android</version>\n</dependency>\n```\n\nGradle\n------\n\nJava:\n\n```groovy\nimplementation ('org.web3j:core:5.0.1')\n```\n\nAndroid:\n\n```groovy\nimplementation ('org.web3j:core:4.12.3-android')\n```\n\nBuild instructions\n------------------\n\nWeb3j includes integration tests for running against a live Ethereum\nclient. If you do not have a client running, you can exclude their\nexecution as per the below instructions.\n\nTo run a full build (excluding integration tests):\n\n``` {.sourceCode .bash}\n$ ./gradlew check\n```\n\nTo run the integration tests, you will need to set up these variables in order to pull the Docker \nimages from the Docker Hub registry:\n\n- `registry.username`\n- `registry.password`\n\nThen run the following command:\n\n``` {.sourceCode .bash}\n$ ./gradlew -Pintegration-tests=true :integration-tests:test\n```\n\nIf you do not want the integration test to run:\n\n``` {.sourceCode .bash}\n$ ./gradlew -Pintegration-tests=false :test\n```\n\nCheck the [Docker client API](https://github.com/docker-java/docker-java/blob/master/docs/getting_started.md#instantiating-a-dockerclientconfig)\nfor more information on configuration options.\n\n\nProjects using Web3j\n------------------\n\n<a href=\"https://alphawallet.com/\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/alphawallet-dark.svg\">\n    <img alt=\"Alphawallet logo\" src=\"static-imgs/alphawallet-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n\n<a href=\"https://linea.build\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/linea-dark.svg\">\n    <img alt=\"Linea logo\" src=\"static-imgs/linea-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n\n<a href=\"https://consensys.io/\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/consensys-dark.svg\">\n    <img alt=\"ConsenSys logo\" src=\"static-imgs/consensys-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n\n<a href=\"https://ens.domains\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/ens-dark.svg\">\n    <img alt=\"ENS logo\" src=\"static-imgs/ens-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n\n<a href=\"https://github.com/hyperledger/besu\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/hyperledger-besu-dark.svg\">\n    <img alt=\"Hyperledger Besu logo\" src=\"static-imgs/hyperledger-besu-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n\n<a href=\"https://web3auth.io\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/web3auth_dark.svg\">\n    <img alt=\"Web3Auth logo\" src=\"static-imgs/web3auth_light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n\n<a href=\"https://hedera.com\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"static-imgs/\n\n[... truncated ...]"
  },
  "juanfranblanco/vscode-solidity": {
    "fetchedAt": "2025-11-12T22:48:34.843Z",
    "content": "# Solidity support for Visual Studio code\n[![Version](https://vsmarketplacebadges.dev/version/juanblanco.solidity.png)](https://marketplace.visualstudio.com/items?itemName=juanblanco.solidity)  [![Downloads](https://vsmarketplacebadges.dev/downloads-short/juanblanco.solidity.png)](https://marketplace.visualstudio.com/items?itemName=juanblanco.solidity) [![Installs](https://vsmarketplacebadges.dev/installs-short/juanblanco.solidity.png)](https://marketplace.visualstudio.com/items?itemName=juanblanco.solidity) [![Rating](https://vsmarketplacebadges.dev/rating-short/juanblanco.solidity.png)](https://marketplace.visualstudio.com/items?itemName=juanblanco.solidity#review-details)\n\nNOTE: BE CAREFUL WITH EXTENSIONS IMPERSONATIONS, CHECK THE PUBLISHING HISTORY. VSCODE MARKETPLACE 10 YEARS OPENVSX 5 YEARS.\n\n[Solidity](https://soliditylang.org/) is the language used in Ethereum to create smart contracts, this extension provides: \n\n* Syntax highlighting\n* Snippets\n* Compilation of the current contract (Press <kbd>F1</kbd> Solidity : Compile Current Solidity Contract), or <kbd>F5</kbd>\n* Compilation of all the contracts (Press <kbd>F1</kbd> Solidity : Compile all Solidity Contracts), or <kbd>Ctrl</kbd> + <kbd>F5</kbd> or <kbd>Cmd</kbd> + <kbd>F5</kbd>\n* Code completion for all contracts / libraries in the current file and all referenced imports\n* Goto definition\n* Find all references in project\n* Hover information\n* Code actions / quick fixes (change compiler, format address, add sdpx license.. )\n* Mono repo support (identifies the project by finding the files: remappings.txt, foundry.toml, brownie-config.yaml, truffle-config.js, hardhat.config.js, hardhat.config.ts)\n* Default project structure (solidity files needs to be in the `src/` directory, and libraries in the `lib/` directory). Libraries will follow the same structure.\n* Compilation supporting EIP82 (dappfile and dependency packages)\n* Support for different solidity versions (Remote and local)\n* Download source code and Abi from Etherscan\n* Code generation using [Nethereum](https://github.com/Nethereum/Nethereum), it includes currently the default template for Nethereum service, dtos generation. \n  (Open 'contractName.json' after compilation from the bin folder. Press <kbd>F1</kbd> and press Solidity: Code generate from compilation output..)\n  Auto generation of Nethereum files on compilation\n* Linting using [Solhint](https://github.com/protofire/solhint) or [Ethlint](https://github.com/duaraghav8/Ethlint)\n\nIt is also available as a standalone LSP:\n```sh\nnpm install -g vscode-solidity-server\nvscode-solidity-server --stdio\n```\n\n# Instructions\n\n\n## Using a different version of the solidity compiler\n\nSometimes you may want to use a different compiler than the one provided. You can find all the different versions in the solc-bin repository https://binaries.soliditylang.org/,\nusing the context menu within the extension, or included in the extension github repository [Solidity versions](solidity-versions.txt).\n\nCurrently we support four ways supported to use a different version of the solidity compiler. Remote, Local, NodeModule and Embedded\n\nYou can change the compiler, in your user settings or workspace settings.\n\n![image](https://user-images.githubusercontent.com/562371/112019635-85d13d80-8b27-11eb-9e91-dc74dcf9e2fa.png)\n\n\n\n### Remote download\nWhen selecting remote download the compiler gets downloaded from the solc-bin repository. \n\nYou will need to change the following user setting, with the version required, for example `'latest'` or `'v0.8.18+commit.87f61d96'`, for your workspace user setting (current project) or global user setting (all projects)\n\n```\n\"solidity.compileUsingRemoteVersion\" : \"latest\"\n```\n![Screenshot](screenshots/change-compiler-version-gui-setting.png)\n\nYou can simply change this setting using the context menu:\n\n![Screenshot](screenshots/change-compiler-version-contextmenu.png) \n\n![Screenshot](screenshots/change-compiler-version-selectversion.png) \n\n#### Using a code action\nIf your code is targetting a specific version for solidity, and see the issue highlighted you can also trigger the menu directly from the import.\n\n![Screenshot](screenshots/solidity-change-workspacecompiler-codeaction.gif)\n\n### Using a Local file\n\nIf you want to keep a compiler version locally, you can download the compiler from https://binaries.soliditylang.org/ and change your user settings to use this.\n\n```\n\"solidity.compileUsingLocalVersion\" : \"C:\\\\Users\\\\JuanFran\\\\Downloads\\\\soljson-v0.8.18%2Bcommit.87f61d96.js\"\n```\n\nThe simplest way to download a compiler is to use the context menu, this will download your desired version at the root of the project and configure your workspace accordingly.\n\n![image](https://user-images.githubusercontent.com/562371/112136733-435f3d80-8bc7-11eb-91e5-e1d04a51cd72.png)\n\n### Npm / node installation\nAnother option, is to use the solc npm package in your project, if this is enabled it will try to find the compiler in your configured node_modules at root.\n\nYou can install solc using npm at the root of your project as follows.\n```\nnpm install solc \n```\n\nThe default module package is \"solc\", but you may want to use other node module containing a compiler, this can be configured in the settings:\n![image](https://user-images.githubusercontent.com/562371/112137067-b668b400-8bc7-11eb-90bc-73e972da98d6.png)\n\n\n### Compiling a specific contract using a different compiler than the default one.\n\nThere might be scenarios, that you want to use a different compiler for a specific file, using one of the other configured compilers. \n\n![image](https://user-images.githubusercontent.com/562371/112020727-7f8f9100-8b28-11eb-91ca-0a43ef491e57.png)\n\n![image](https://user-images.githubusercontent.com/562371/112020877-a3eb6d80-8b28-11eb-895d-bbee7665e38d.png)\n\n\n\n## ERC, ERC drafts and Smart contracts snippets / reference\n\nIt is pretty hard sometimes to find interfaces or information about an EIP (ERC) or specific libraries to simply get started working with Solidity. \nThe solidity extension now includes ERC approved and most drafts (wip) to help get you started.\n\nJust type ```erc``` and select the erc example or interface you want.\n\n![Screenshot](screenshots/ercautocomplete1.png)\n![Screenshot](screenshots/ercautocomplete2.png)\n\n### Smart contract project interfaces \nIn a similar to way to ERCs and as we work towards to more interoperable smart contracts, being able to quickly examine those interfaces that you want to integrate is a time saver.\n\nThe current release includes the interfaces for Uniswap V2 (to get started), just type ```uni``` to list them all.\n![Screenshot](screenshots/unigen1.png) \n![Screenshot](screenshots/unigen2.png)\n\nNote: If an ERC or your project is not included, please create a pull request. Note: Only established projets will be included.\n\n## Compiler optimization\nOptimize for how many times you intend to run the code. Lower values will optimize more for initial deployment cost, higher values will optimize more for high-frequency usage. The default value is **200**.\n```\"solidity.compilerOptimization\": 200``` \n\n## Project structure and Remappings\n\n## Mono repo support\nMono repo support enables having different projects in the same workspace as opposed to different open workspaces in the same window.\n\nTo provide mono repo support, idenfify the project by finding one of the files used by different tools, for example remappings.txt, foundry.toml, brownie-config.yaml, truffle-config.js, hardhat.config.js. Solidity does not have a standard project file yet, or many not have it ever, so this is the best solution.\n\nThe settings enable Mono repo support by default, but if wanted can be disabled.\n\n### Dependencies for both \"Node_modules\" and \"Lib\" (Default)\n\nIf you're using a library like [`@openzeppelin/contracts`](https://github.com/OpenZeppelin/openzeppelin-contracts), the OpenZeppelin Contracts will be found in your node_modules folder, or you might be using a library like [`Solmate`](https:\n\n[... truncated ...]"
  },
  "ethers-io/ethers.js": {
    "fetchedAt": "2025-11-12T22:48:41.499Z",
    "content": "The Ethers Project\n==================\n\n[![npm (tag)](https://img.shields.io/npm/v/ethers)](https://www.npmjs.com/package/ethers)\n[![CI Tests](https://github.com/ethers-io/ethers.js/actions/workflows/test-ci.yml/badge.svg?branch=main)](https://github.com/ethers-io/ethers.js/actions/workflows/test-ci.yml)\n![npm bundle size (version)](https://img.shields.io/bundlephobia/minzip/ethers)\n![npm (downloads)](https://img.shields.io/npm/dm/ethers)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/ethers-io/ethers.js/badge)](https://www.gitpoap.io/gh/ethers-io/ethers.js)\n[![Twitter Follow](https://img.shields.io/twitter/follow/ricmoo?style=social)](https://twitter.com/ricmoo)\n\n-----\n\nA complete, compact and simple library for Ethereum and ilk, written\nin [TypeScript](https://www.typescriptlang.org).\n\n**Features**\n\n- Keep your private keys in your client, **safe** and sound\n- Import and export **JSON wallets** (Geth, Parity and crowdsale)\n- Import and export BIP 39 **mnemonic phrases** (12 word backup phrases) and **HD Wallets** (English as well as Czech, French, Italian, Japanese, Korean, Simplified Chinese, Spanish, Traditional Chinese)\n- Meta-classes create JavaScript objects from any contract ABI, including **ABIv2** and **Human-Readable ABI**\n- Connect to Ethereum nodes over [JSON-RPC](https://github.com/ethereum/wiki/wiki/JSON-RPC), [INFURA](https://infura.io), [Etherscan](https://etherscan.io), [Alchemy](https://alchemyapi.io), [Ankr](https://ankr.com) or [MetaMask](https://metamask.io)\n- **ENS names** are first-class citizens; they can be used anywhere an Ethereum addresses can be used\n- **Small** (~144kb compressed; 460kb uncompressed)\n- **Tree-shaking** focused; include only what you need during bundling\n- **Complete** functionality for all your Ethereum desires\n- Extensive [documentation](https://docs.ethers.org/v6/)\n- Large collection of **test cases** which are maintained and added to\n- Fully written in **TypeScript**, with strict types for security and safety\n- **MIT License** (including ALL dependencies); completely open source to do with as you please\n\n\nKeep Updated\n------------\n\nFor advisories and important notices, follow [@ethersproject](https://twitter.com/ethersproject)\non Twitter (low-traffic, non-marketing, important information only) as well as watch this GitHub project.\n\nFor more general news, discussions, and feedback, follow or DM me,\n[@ricmoo](https://twitter.com/ricmoo) on Twitter or on the\n[Ethers Discord](https://discord.gg/qYtSscGYYc).\n\n\nFor the latest changes, see the\n[CHANGELOG](https://github.com/ethers-io/ethers.js/blob/main/CHANGELOG.md).\n\n\n**Summaries**\n\n- [August 2023](https://blog.ricmoo.com/highlights-ethers-js-august-2023-fb68354c576c)\n- [September 2022](https://blog.ricmoo.com/highlights-ethers-js-september-2022-d7bda0fc37ed)\n- [June 2022](https://blog.ricmoo.com/highlights-ethers-js-june-2022-f5328932e35d)\n- [March 2022](https://blog.ricmoo.com/highlights-ethers-js-march-2022-f511fe1e88a1)\n- [December 2021](https://blog.ricmoo.com/highlights-ethers-js-december-2021-dc1adb779d1a)\n- [September 2021](https://blog.ricmoo.com/highlights-ethers-js-september-2021-1bf7cb47d348)\n- [May 2021](https://blog.ricmoo.com/highlights-ethers-js-may-2021-2826e858277d)\n- [March 2021](https://blog.ricmoo.com/highlights-ethers-js-march-2021-173d3a545b8d)\n- [December 2020](https://blog.ricmoo.com/highlights-ethers-js-december-2020-2e2db8bc800a)\n\n\n\nInstalling\n----------\n\n**NodeJS**\n\n```\n/home/ricmoo/some_project> npm install ethers\n```\n\n**Browser (ESM)**\n\nThe bundled library is available in the `./dist/` folder in this repo.\n\n```\n<script type=\"module\">\n    import { ethers } from \"./dist/ethers.min.js\";\n</script>\n```\n\n\nDocumentation\n-------------\n\nBrowse the [documentation](https://docs.ethers.org) online:\n\n- [Getting Started](https://docs.ethers.org/v6/getting-started/)\n- [Full API Documentation](https://docs.ethers.org/v6/api/)\n- [Various Ethereum Articles](https://blog.ricmoo.com/)\n\n\n\nProviders\n---------\n\nEthers works closely with an ever-growing list of third-party providers\nto ensure getting started is quick and easy, by providing default keys\nto each service.\n\nThese built-in keys mean you can use `ethers.getDefaultProvider()` and\nstart developing right away.\n\nHowever, the API keys provided to ethers are also shared and are\nintentionally throttled to encourage developers to eventually get\ntheir own keys, which unlock many other features, such as faster\nresponses, more capacity, analytics and other features like archival\ndata.\n\nWhen you are ready to sign up and start using for your own keys, please\ncheck out the [Provider API Keys](https://docs.ethers.org/v5/api-keys/) in\nthe documentation.\n\nA special thanks to these services for providing community resources:\n\n- [Ankr](https://www.ankr.com/)\n- [QuickNode](https://www.quicknode.com/)\n- [Etherscan](https://etherscan.io/)\n- [INFURA](https://infura.io/)\n- [Alchemy](https://dashboard.alchemyapi.io/signup?referral=55a35117-028e-4b7c-9e47-e275ad0acc6d)\n\n\nExtension Packages\n------------------\n\nThe `ethers` package only includes the most common and most core\nfunctionality to interact with Ethereum. There are many other\npackages designed to further enhance the functionality and experience.\n\n- [MulticallProvider](https://github.com/ethers-io/ext-provider-multicall) - A Provider which bundles multiple call requests into a single `call` to reduce latency and backend request capacity\n- [MulticoinPlugin](https://github.com/ethers-io/ext-provider-plugin-multicoin) - A Provider plugin to expand the support of ENS coin types\n- [GanaceProvider](https://github.com/ethers-io/ext-provider-ganache) - A Provider for in-memory node instances, for fast debugging, testing and simulating blockchain operations\n- [Optimism Utilities](https://github.com/ethers-io/ext-utils-optimism) - A collection of Optimism utilities\n- [LedgerSigner](https://github.com/ethers-io/ext-signer-ledger) - A Signer to interact directly with Ledger Hardware Wallets\n\n\nLicense\n-------\n\nMIT License (including **all** dependencies).\n\n"
  },
  "sc-forks/solidity-coverage": {
    "fetchedAt": "2025-11-12T22:48:48.941Z",
    "content": "# solidity-coverage\n\n[![Gitter chat](https://badges.gitter.im/sc-forks/solidity-coverage.svg)][18]\n![npm (tag)](https://img.shields.io/npm/v/solidity-coverage/latest)\n[![CircleCI](https://circleci.com/gh/sc-forks/solidity-coverage.svg?style=svg)][20]\n[![codecov](https://codecov.io/gh/sc-forks/solidity-coverage/branch/master/graph/badge.svg)][21]\n[![Hardhat](https://hardhat.org/buidler-plugin-badge.svg?1)][26]\n\n\n## Code coverage for Solidity testing\n![coverage example][22]\n\n+ For more details about what this is, how it works and potential limitations,\n  see [the accompanying article][16].\n+ `solidity-coverage` is [Solcover][17]\n\n## Requirements\n\n+ Hardhat >= 2.11.0\n\n## Install\n```\n$ yarn add solidity-coverage --dev\n```\n\n**Require** the plugin in `hardhat.config.js` ([Hardhat docs][26])\n```javascript\nrequire('solidity-coverage')\n```\n\nOr, if you are using TypeScript, add this to your hardhat.config.ts:\n```ts\nimport 'solidity-coverage'\n```\n\n**Resources**:\n+ [0.8.0 release notes][31]\n\n## Run\n```\nnpx hardhat coverage [command-options]\n```\n\n### Trouble shooting\n\n**Missing or unexpected coverage?** Make sure you're using the latest plugin version and run:\n```sh\n$ npx hardhat clean\n$ npx hardhat compile\n$ npx hardhat coverage\n```\n\n**Typescript compilation errors?**\n```sh\n$ npx hardhat compile\n$ TS_NODE_TRANSPILE_ONLY=true npx hardhat coverage\n```\n\n**Weird test failures or plugin conflicts?**\n\n```sh\n# Setting the `SOLIDITY_COVERAGE` env variable tells the coverage plugin to configure the provider\n# early in the hardhat task cycle, minimizing conflicts with other plugins or `extendEnvironment` hooks\n\n$ SOLIDITY_COVERAGE=true npx hardhat coverage\n```\n\n**Additional Help**\n+ [FAQ][1007]\n+ [Advanced Topics][1005]\n\n\n## Command Options\n| Option <img width=200/> | Example <img width=750/>| Description <img width=1000/> |\n|--------------|------------------------------------|--------------------------------|\n| testfiles  | `--testfiles \"test/registry/*.ts\"` | Test file(s) to run. (Globs must be enclosed by quotes and use [globby matching patterns][38])|\n| sources | `--sources myFolder` or `--sources myFile.sol` | Path to *single* folder or file to target for coverage. Path is relative to Hardhat's `paths.sources` (usually `contracts/`) |\n| solcoverjs | `--solcoverjs ./../.solcover.js` | Relative path from working directory to config. Useful for monorepo packages that share settings. (Path must be \"./\" prefixed) |\n| matrix   | `--matrix` | Generate a JSON object that maps which mocha tests hit which lines of code. (Useful as an input for some fuzzing, mutation testing and fault-localization algorithms.) [More...][39]|\n\n[<sup>*</sup> Advanced use][14]\n\n## Config Options\n\nAdditional options can be specified in a `.solcover.js` config file located in the root directory\nof your project.\n\n**Example:**\n```javascript\nmodule.exports = {\n  skipFiles: ['Routers/EtherRouter.sol']\n};\n```\n\n| Option <img width=200/>| Type <img width=200/> | Default <img width=1000/> | Description <img width=1000/> |\n| ------ | ---- | ------- | ----------- |\n| skipFiles | *Array* | `[]` | Array of contracts or folders (with paths expressed relative to the `contracts` directory) that should be skipped when doing instrumentation.(ex: `[ \"Routers\", \"Networks/Polygon.sol\"]`) :warning: **RUN THE HARDHAT CLEAN COMMAND AFTER UPDATING THIS**  |\n| irMinimum | *Boolean* | `false` | Speeds up test execution times when solc is run in `viaIR` mode. If your project successfully compiles while generating coverage with this option turned on (it may not!) it's worth using |\n| modifierWhitelist | *String[]* | `[]` | List of modifier names (ex: `onlyOwner`) to exclude from branch measurement. (Useful for modifiers which prepare something instead of acting as a gate.)) |\n| mocha | *Object* | `{ }` | [Mocha options][3] to merge into existing mocha config. `grep` and `invert` are useful for skipping certain tests under coverage using tags in the test descriptions. [More...][24]|\n| measureStatementCoverage | *boolean* | `true` | Computes statement (in addition to line) coverage. [More...][34] |\n| measureFunctionCoverage | *boolean* | `true` | Computes function coverage. [More...][34] |\n| measureModifierCoverage | *boolean* | `true` | Computes each modifier invocation as a code branch. [More...][34] |\n| **:printer:    OUTPUT** |  | |  |\n| matrixOutputPath | *String* | `./testMatrix.json` | Relative path to write test matrix JSON object to. [More...][39]|\n| mochaJsonOutputPath | *String* | `./mochaOutput.json` | Relative path to write mocha JSON reporter object to. [More...][39]|\n| abiOutputPath | *String* | `./humanReadableAbis.json` | Relative path to write diff-able ABI data to |\n| istanbulFolder | *String* | `./coverage` |  Folder location for Istanbul coverage reports. |\n| istanbulReporter | *Array* | `['html', 'lcov', 'text', 'json']` | [Istanbul coverage reporters][2]  |\n| silent | *Boolean* | false | Suppress logging output |\n| **:recycle:    WORKFLOW HOOKS** |  | |  |\n| onServerReady[<sup>*</sup>][14] | *Function* |   | Hook run *after* server is launched, *before* the tests execute. Useful if you need to use the Oraclize bridge or have setup scripts which rely on the server's availability. [More...][23] |\n| onPreCompile[<sup>*</sup>][14] | *Function* |   | Hook run *after* instrumentation is performed, *before* the compiler is run. Can be used with the other hooks to be able to generate coverage reports on non-standard / customized directory structures, as well as contracts with absolute import paths. [More...][23] |\n| onCompileComplete[<sup>*</sup>][14] | *Function* |  | Hook run *after* compilation completes, *before* tests are run. Useful if you have secondary compilation steps or need to modify built artifacts. [More...][23]|\n| onTestsComplete[<sup>*</sup>][14] | *Function* |  | Hook run *after* the tests complete, *before* Istanbul reports are generated. [More...][23]|\n| onIstanbulComplete[<sup>*</sup>][14] | *Function* |  | Hook run *after* the Istanbul reports are generated, *before* the coverage task completes. Useful if you need to clean resources up. [More...][23]|\n| **:warning:    LOW LEVEL** |  | |  |\n| configureYulOptimizer | *Boolean* | false | Setting to `true` lets you specify optimizer details (see next option). If no details are defined it defaults to turning on the yul optimizer and enabling stack allocation |\n| solcOptimizerDetails | *Object* | `undefined` |Must be used in combination with `configureYulOptimizer`. Allows you to configure solc's [optimizer details][1001]. (See [FAQ: Running out of stack][1002] ). |\n\n\n[<sup>*</sup> Advanced use][14]\n\n## Viewing the reports:\n+ You can find the Istanbul reports written to the `./coverage/` folder generated in your root directory.\n\n## API\n\nSolidity-coverage's core methods and many utilities are available as an API.\n\n```javascript\nconst CoverageAPI = require('solidity-coverage/api');\n```\n\n[Documentation available here][28].\n\n## Detecting solidity-coverage from another task\n\nIf you're writing another plugin or task, it can be helpful to detect whether coverage is running or not.\nThe coverage plugin sets a boolean variable on the globally injected hardhat environment object for this purpose.\n\n```\nhre.__SOLIDITY_COVERAGE_RUNNING === true\n```\n\n## Example reports\n+ [openzeppelin-contracts][10] (Codecov)\n\n## Funding\n\nYou can help fund solidity-coverage development through [DRIPS][1008]. It's a public goods protocol which helps distribute money to packages in your dependency tree. (It's great, check it out.)\n\n## Contribution Guidelines\n\nContributions are welcome! If you're opening a PR that adds features or options *please consider\nwriting full [unit tests][11] for them*. (We've built simple fixtures for almost everything\nand are happy to add some for your case if necessary).\n\n\nSet up the development environment with:\n```\n$ git clone https://github.com/sc-forks/solidity-coverage.git\n$ yarn\n```\n\n[2]: https://istanbul.js.org/docs/advanced/alternative-reporters\n\n[... truncated ...]"
  },
  "adraffy/blocksmith.js": {
    "fetchedAt": "2025-11-12T22:48:56.544Z",
    "content": "# blocksmith.js\n\n‚ö†Ô∏è This repo is under active development!\n\n`npm i @adraffy/blocksmith` [&check;](https://www.npmjs.com/package/@adraffy/blocksmith)\n\n* see [**types**](./dist/index.d.mts) / designed for [Foundry](https://github.com/foundry-rs/foundry) + [ethers](https://github.com/ethers-io/ethers.js).\n* compatible with any async test runner, including [node:test](https://nodejs.org/api/test.html)\n* designed for complex [EIP-3668](https://eips.ethereum.org/EIPS/eip-3668) contracts \n* reads directly from [`foundry.toml`](https://book.getfoundry.sh/reference/config/overview)\n* deploy inline contracts with string templates\n\n![Screenshot](./test/deploy/screenshot.png)\n\n### Instructions\n\n1. [`foundryup`](https://book.getfoundry.sh/getting-started/installation)\n1. `npm i`\n1. `npm run start` &rarr; runs deploy example: [`js`](./test/deploy/test.js) + [`sol`](./test/Deploy.sol)\n\n### Examples\n\n* [./test/deploy/](./test/deploy/)\n* [./test/ens-encoded-dns/](./test/ens-encoded-dns/)\n* [./test/extlib/](./test/ens-encoded-dns/)\n* [resolverworks/**TheOffchainResolver.sol**](https://github.com/resolverworks/TheOffchainResolver.sol/blob/main/test/test.js)\n* [resolverworks/**XCTENS.sol**](https://github.com/resolverworks/XCTENS.sol/blob/main/test/test.js)\n* [resolverworks/**OffchainNext.sol**](https://github.com/resolverworks/OffchainNext.sol/blob/main/test/test.js)\n* [unruggable-labs/**unruggable-gateways**](https://github.com/unruggable-labs/unruggable-gateways/)\n* [unruggable-labs/**Storage.sol**](https://github.com/unruggable-labs/Storage.sol)\n* [adraffy/**CCIPRewriter.sol**](https://github.com/adraffy/CCIPRewriter.sol)\n* [adraffy/**punycode.sol**](https://github.com/adraffy/punycode.sol)\n\n### Additional Tooling\n\n* [`Node`](./src/Node.js) is client-side scaffolding to manage name/label/namehash/labelhash which simplifies many ENS-related functions that require a variety of inputs.\n* [`Resolver`](./src/Resolver.js) is a [**TOR**](https://github.com/resolverworks/TheOffchainResolver.sol)-aware [ENSIP-10](https://docs.ens.domains/ensip/10) resolver implementation.\n\n### Funding Support\n\n* Received [GG20 ENS Retro Grant](https://discuss.ens.domains/t/gg20-ens-identity-round-conclusion/19301) from Arbitrum DAO, Gitcoin, SpruceID, and ThankARB\n* [GG22 OSS - Developer Tooling and Libraries](https://builder.gitcoin.co/#/chains/8453/registry/0x/projects/0xf1082b71aa913e5749b81b0c1f9c0be7fc94b60c1d34a9d668575a0b141e59e6)\n* [GG23 OSS - Developer Tooling and Libraries](https://builder.gitcoin.co/#/chains/42161/registry/0x/projects/0x2b9be3c545fd71f47c0bc1c17c04baeb8f3d4c350b777b1aeff5a093216e47a3)\n"
  },
  "OpenZeppelin/openzeppelin-contracts": {
    "fetchedAt": "2025-11-12T22:49:03.947Z",
    "content": "# <img src=\"logo.svg\" alt=\"OpenZeppelin\" height=\"40px\">\n\n[![Github Release](https://img.shields.io/github/v/tag/OpenZeppelin/openzeppelin-contracts.svg?filter=v*&sort=semver&label=github)](https://github.com/OpenZeppelin/openzeppelin-contracts/releases/latest)\n[![NPM Package](https://img.shields.io/npm/v/@openzeppelin/contracts.svg)](https://www.npmjs.org/package/@openzeppelin/contracts)\n[![Coverage Status](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg)](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![GitPOAPs](https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge)](https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-yellow)](https://docs.openzeppelin.com/contracts)\n[![Forum](https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow)](https://forum.openzeppelin.com/)\n\n**A library for secure smart contract development.** Build on a solid foundation of community-vetted code.\n\n * Implementations of standards like [ERC20](https://docs.openzeppelin.com/contracts/erc20) and [ERC721](https://docs.openzeppelin.com/contracts/erc721).\n * Flexible [role-based permissioning](https://docs.openzeppelin.com/contracts/access-control) scheme.\n * Reusable [Solidity components](https://docs.openzeppelin.com/contracts/utilities) to build custom contracts and complex decentralized systems.\n\n:mage: **Not sure how to get started?** Check out [Contracts Wizard](https://wizard.openzeppelin.com/) ‚Äî an interactive smart contract generator.\n\n> [!IMPORTANT]\n> OpenZeppelin Contracts uses semantic versioning to communicate backwards compatibility of its API and storage layout. For upgradeable contracts, the storage layout of different major versions should be assumed incompatible, for example, it is unsafe to upgrade from 4.9.3 to 5.0.0. Learn more at [Backwards Compatibility](https://docs.openzeppelin.com/contracts/backwards-compatibility).\n\n## Overview\n\n### Release tags\n\nWe use NPM tags to clearly distinguish between audited and non-audited versions of our package:\n\n| Tag        | Purpose                  | Description                                                                                                                                                                   |\n| :--------- | :----------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **latest** | ‚úÖ Audited releases      | Stable, audited versions of the package. This is the **default** version installed when users run `npm install @openzeppelin/contracts`.                                      |\n| **dev**    | üß™ Final but not audited | Versions that are finalized and feature-complete but have **not yet been audited**. This version is fully tested, can be used in production and is covered by the bug bounty. |\n| **next**   | üöß Release candidates    | Pre-release versions that are **not final**. Used for testing and validation before the version becomes a final `dev` or `latest` release.                                    |\n\n### Installation\n\n#### Hardhat (npm)\n\n```\n$ npm install @openzeppelin/contracts\n```\n‚Üí Installs the latest audited release (`latest`).\n\n```\n$ npm install @openzeppelin/contracts@dev\n```\n‚Üí Installs the latest unaudited release (`dev`).\n\n#### Foundry (git)\n\n> [!WARNING]\n> When installing via git, it is a common error to use the `master` branch. This is a development branch that should be avoided in favor of tagged releases. The release process involves security measures that the `master` branch does not guarantee.\n\n> [!WARNING]\n> Foundry installs the latest version initially, but subsequent `forge update` commands will use the `master` branch.\n\n```\n$ forge install OpenZeppelin/openzeppelin-contracts\n```\n\nAdd `@openzeppelin/contracts/=lib/openzeppelin-contracts/contracts/` in `remappings.txt`.\n\n### Usage\n\nOnce installed, you can use the contracts in the library by importing them:\n\n```solidity\npragma solidity ^0.8.20;\n\nimport {ERC721} from \"@openzeppelin/contracts/token/ERC721/ERC721.sol\";\n\ncontract MyCollectible is ERC721 {\n    constructor() ERC721(\"MyCollectible\", \"MCO\") {\n    }\n}\n```\n\n_If you're new to smart contract development, head to [Developing Smart Contracts](https://docs.openzeppelin.com/learn/developing-smart-contracts) to learn about creating a new project and compiling your contracts._\n\nTo keep your system secure, you should **always** use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.\n\n## Learn More\n\nThe guides in the [documentation site](https://docs.openzeppelin.com/contracts) will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:\n\n* [Access Control](https://docs.openzeppelin.com/contracts/access-control): decide who can perform each of the actions on your system.\n* [Tokens](https://docs.openzeppelin.com/contracts/tokens): create tradeable assets or collectibles for popular ERC standards like ERC-20, ERC-721, ERC-1155, and ERC-6909.\n* [Utilities](https://docs.openzeppelin.com/contracts/utilities): generic useful tools including non-overflowing math, signature verification, and trustless paying systems.\n\nThe [full API](https://docs.openzeppelin.com/contracts/api/token/ERC20) is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts' development in the [community forum](https://forum.openzeppelin.com).\n\nFinally, you may want to take a look at the [guides on our blog](https://blog.openzeppelin.com/), which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.\n\n* [The Hitchhiker‚Äôs Guide to Smart Contracts in Ethereum](https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05) will help you get an overview of the various tools available for smart contract development, and help you set up your environment.\n* [A Gentle Introduction to Ethereum Programming, Part 1](https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094) provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.\n* For a more in-depth dive, you may read the guide [Designing the Architecture for Your Ethereum Application](https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317), which discusses how to better structure your application and its relationship to the real world.\n\n## Security\n\nThis project is maintained by [OpenZeppelin](https://openzeppelin.com) with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.\n\nThe [OpenZeppelin Contracts Security Center](https://contracts.openzeppelin.com/security) contains more details about the secure development process.\n\nThe security policy is detailed in [`SECURITY.md`](./SECURITY.md) as well, and specifies how you can report security vulnerabilities, which versions will receive security patches, and how to stay informed about them. We run a [bug bounty program on Immunefi](https://immunefi.com/bounty/openzeppelin) to reward the responsible disclosure of vulnerabilities.\n\nThe engineering guidelines we follow to promote project quality can be found \n\n[... truncated ...]"
  },
  "OpenZeppelin/contracts-wizard": {
    "fetchedAt": "2025-11-12T22:49:04.222Z",
    "content": "# [OpenZeppelin Contracts Wizard](https://wizard.openzeppelin.com)\n\n[![Solidity NPM Package](https://img.shields.io/npm/v/@openzeppelin/wizard?color=%234e5de4&label=%40openzeppelin%2Fwizard)](https://www.npmjs.com/package/@openzeppelin/wizard)\n[![Cairo NPM Package](https://img.shields.io/npm/v/@openzeppelin/wizard-cairo?color=%23e55233&label=%40openzeppelin%2Fwizard-cairo)](https://www.npmjs.com/package/@openzeppelin/wizard-cairo)\n[![Stellar NPM Package](https://img.shields.io/npm/v/@openzeppelin/wizard-stellar?color=%23e55233&label=%40openzeppelin%2Fwizard-stellar)](https://www.npmjs.com/package/@openzeppelin/wizard-stellar)\n[![Stylus NPM Package](https://img.shields.io/npm/v/@openzeppelin/wizard-stylus?color=%23e55233&label=%40openzeppelin%2Fwizard-stylus)](https://www.npmjs.com/package/@openzeppelin/wizard-stylus)\n[![Contracts MCP NPM Package](https://img.shields.io/npm/v/@openzeppelin/contracts-mcp?label=%40openzeppelin%2Fcontracts-mcp)](https://www.npmjs.com/package/@openzeppelin/contracts-mcp)\n[![Netlify Status](https://api.netlify.com/api/v1/badges/ca9b53e1-44eb-410d-aac7-31b2f5399b68/deploy-status)](https://app.netlify.com/sites/openzeppelin-contracts-wizard/deploys)\n\nContracts Wizard is a web application to interactively build a contract out of components from OpenZeppelin Contracts. Select the kind of contract that you want, set your parameters and desired features, and the Wizard will generate all of the code necessary. The resulting code is ready to be compiled and deployed, or it can serve as a starting point and customized further with application specific logic.\n\n[![](./screenshot.png)](https://wizard.openzeppelin.com)\n\n## Usage\n\nUse the Contracts Wizard at https://wizard.openzeppelin.com\n\n## MCP Servers\n\nMCP Servers allow AI agents to generate smart contracts with the same options as the Contracts Wizard.\n\nFor local installation, see the [Contracts MCP Server](packages/mcp/README.md) package.  \nFor a hosted version, see [OpenZeppelin MCP Servers](https://mcp.openzeppelin.com).\n\n## TypeScript API\n\nYou can use the programmatic TypeScript API to generate contracts from your own applications.\n\nView the API documentation for each smart contract language:\n- [Solidity](packages/core/solidity/README.md)\n- [Cairo](packages/core/cairo/README.md)\n- [Stellar](packages/core/stellar/README.md)\n- [Stylus](packages/core/stylus/README.md)\n\n## Embedding\n\nTo embed Contracts Wizard on your site, first include the script tag:\n\n```html\n<script async src=\"https://wizard.openzeppelin.com/build/embed.js\"></script>\n```\n\nThen place `<oz-wizard></oz-wizard>` in the body where you want Contracts Wizard to load.\n\nOptionally focus on specific tab with the `data-tab` attribute as in `<oz-wizard data-tab=\"ERC721\"></oz-wizard>`.\n\nFor languages other than Solidity, use the `data-lang` attribute, for example: `<oz-wizard data-lang=\"cairo\"></oz-wizard>`.\n\n## Contributing\n\nWe welcome contributions from the community! Here's how you can get involved:\n\n1. Fork the repository\n2. Create your feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\nIf you are looking for a good place to start, find a good first issue [here](https://github.com/openzeppelin/contracts-wizard/issues?q=is%3Aissue%20is%3Aopen%20label%3A%22good%20first%20issue%22), or [open an issue](https://github.com/OpenZeppelin/contracts-wizard/issues/new) for a bug report or feature request.\n\nYou can find more details in our [Contributing](CONTRIBUTING.md) guide.\n\n## License\n\nThis project is licensed under the GNU Affero General Public License v3.0 - see the [LICENSE](LICENSE) file for details.\n"
  },
  "OpenZeppelin/openzeppelin-contracts-upgradeable": {
    "fetchedAt": "2025-11-12T22:49:04.497Z",
    "content": "# <img src=\"logo.svg\" alt=\"OpenZeppelin\" height=\"40px\">\n\n[![Github Release](https://img.shields.io/github/v/tag/OpenZeppelin/openzeppelin-contracts.svg?filter=v*&sort=semver&label=github)](https://github.com/OpenZeppelin/openzeppelin-contracts/releases/latest)\n[![NPM Package](https://img.shields.io/npm/v/@openzeppelin/contracts.svg)](https://www.npmjs.org/package/@openzeppelin/contracts)\n[![Coverage Status](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts/graph/badge.svg)](https://codecov.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![GitPOAPs](https://public-api.gitpoap.io/v1/repo/OpenZeppelin/openzeppelin-contracts/badge)](https://www.gitpoap.io/gh/OpenZeppelin/openzeppelin-contracts)\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-yellow)](https://docs.openzeppelin.com/contracts)\n[![Forum](https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow)](https://forum.openzeppelin.com/)\n\n**A library for secure smart contract development.** Build on a solid foundation of community-vetted code.\n\n * Implementations of standards like [ERC20](https://docs.openzeppelin.com/contracts/erc20) and [ERC721](https://docs.openzeppelin.com/contracts/erc721).\n * Flexible [role-based permissioning](https://docs.openzeppelin.com/contracts/access-control) scheme.\n * Reusable [Solidity components](https://docs.openzeppelin.com/contracts/utilities) to build custom contracts and complex decentralized systems.\n\n:mage: **Not sure how to get started?** Check out [Contracts Wizard](https://wizard.openzeppelin.com/) ‚Äî an interactive smart contract generator.\n\n> [!IMPORTANT]\n> OpenZeppelin Contracts uses semantic versioning to communicate backwards compatibility of its API and storage layout. For upgradeable contracts, the storage layout of different major versions should be assumed incompatible, for example, it is unsafe to upgrade from 4.9.3 to 5.0.0. Learn more at [Backwards Compatibility](https://docs.openzeppelin.com/contracts/backwards-compatibility).\n\n+> [!NOTE]\n+> You are looking at the upgradeable variant of OpenZeppelin Contracts. Be sure to review the documentation on [Using OpenZeppelin Contracts with Upgrades](https://docs.openzeppelin.com/contracts/upgradeable).\n+\n## Overview\n\n### Release tags\n\nWe use NPM tags to clearly distinguish between audited and non-audited versions of our package:\n\n| Tag        | Purpose                  | Description                                                                                                                                                                   |\n| :--------- | :----------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **latest** | ‚úÖ Audited releases      | Stable, audited versions of the package. This is the **default** version installed when users run `npm install @openzeppelin/contracts`.                                      |\n| **dev**    | üß™ Final but not audited | Versions that are finalized and feature-complete but have **not yet been audited**. This version is fully tested, can be used in production and is covered by the bug bounty. |\n| **next**   | üöß Release candidates    | Pre-release versions that are **not final**. Used for testing and validation before the version becomes a final `dev` or `latest` release.                                    |\n\n### Installation\n\n#### Hardhat (npm)\n\n```\n$ npm install @openzeppelin/contracts-upgradeable\n```\n‚Üí Installs the latest audited release (`latest`).\n\n```\n$ npm install @openzeppelin/contracts-upgradeable@dev\n```\n‚Üí Installs the latest unaudited release (`dev`).\n\n#### Foundry (git)\n\n> [!WARNING]\n> When installing via git, it is a common error to use the `master` branch. This is a development branch that should be avoided in favor of tagged releases. The release process involves security measures that the `master` branch does not guarantee.\n\n> [!WARNING]\n> Foundry installs the latest version initially, but subsequent `forge update` commands will use the `master` branch.\n\n```\n$ forge install OpenZeppelin/openzeppelin-contracts-upgradeable\n```\n\nAdd `@openzeppelin/contracts-upgradeable/=lib/openzeppelin-contracts-upgradeable/contracts/` in `remappings.txt`.\n\n### Usage\n\nOnce installed, you can use the contracts in the library by importing them:\n\n```solidity\npragma solidity ^0.8.20;\n\nimport {ERC721Upgradeable} from \"@openzeppelin/contracts-upgradeable/token/ERC721/ERC721Upgradeable.sol\";\n\ncontract MyCollectible is ERC721Upgradeable {\n    function initialize() initializer public {\n        __ERC721_init(\"MyCollectible\", \"MCO\");\n    }\n}\n```\n\n_If you're new to smart contract development, head to [Developing Smart Contracts](https://docs.openzeppelin.com/learn/developing-smart-contracts) to learn about creating a new project and compiling your contracts._\n\nTo keep your system secure, you should **always** use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.\n\n## Learn More\n\nThe guides in the [documentation site](https://docs.openzeppelin.com/contracts) will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:\n\n* [Access Control](https://docs.openzeppelin.com/contracts/access-control): decide who can perform each of the actions on your system.\n* [Tokens](https://docs.openzeppelin.com/contracts/tokens): create tradeable assets or collectibles for popular ERC standards like ERC-20, ERC-721, ERC-1155, and ERC-6909.\n* [Utilities](https://docs.openzeppelin.com/contracts/utilities): generic useful tools including non-overflowing math, signature verification, and trustless paying systems.\n\nThe [full API](https://docs.openzeppelin.com/contracts/api/token/ERC20) is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts' development in the [community forum](https://forum.openzeppelin.com).\n\nFinally, you may want to take a look at the [guides on our blog](https://blog.openzeppelin.com/), which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.\n\n* [The Hitchhiker‚Äôs Guide to Smart Contracts in Ethereum](https://blog.openzeppelin.com/the-hitchhikers-guide-to-smart-contracts-in-ethereum-848f08001f05) will help you get an overview of the various tools available for smart contract development, and help you set up your environment.\n* [A Gentle Introduction to Ethereum Programming, Part 1](https://blog.openzeppelin.com/a-gentle-introduction-to-ethereum-programming-part-1-783cc7796094) provides very useful information on an introductory level, including many basic concepts from the Ethereum platform.\n* For a more in-depth dive, you may read the guide [Designing the Architecture for Your Ethereum Application](https://blog.openzeppelin.com/designing-the-architecture-for-your-ethereum-application-9cec086f8317), which discusses how to better structure your application and its relationship to the real world.\n\n## Security\n\nThis project is maintained by [OpenZeppelin](https://openzeppelin.com) with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.\n\nThe [OpenZeppelin Contracts Security Center](https://contracts.openzeppelin.com/security) contains more details about the secure development process.\n\nThe security policy is detailed in [`SECURITY.md`](./SECURITY.md\n\n[... truncated ...]"
  },
  "OpenZeppelin/openzeppelin-upgrades": {
    "fetchedAt": "2025-11-12T22:49:04.840Z",
    "content": "# <img src=\"assets/banner.svg\" alt=\"OpenZeppelin Upgrades\" height=\"40px\">\n\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-blue)](https://docs.openzeppelin.com/upgrades-plugins)\n[![Coverage Status](https://codecov.io/gh/OpenZeppelin/openzeppelin-upgrades/graph/badge.svg)](https://codecov.io/gh/OpenZeppelin/openzeppelin-upgrades)\n[![Checks](https://github.com/OpenZeppelin/openzeppelin-upgrades/actions/workflows/checks.yml/badge.svg)](https://github.com/OpenZeppelin/openzeppelin-upgrades/actions/workflows/checks.yml)\n[![License](https://img.shields.io/github/license/OpenZeppelin/openzeppelin-upgrades)](https://github.com/OpenZeppelin/openzeppelin-upgrades/blob/master/LICENSE)\n\n**Integrate upgrades into your existing workflow.** Plugins for [Hardhat](https://hardhat.org/) and [Foundry](https://book.getfoundry.sh/) to deploy and manage upgradeable contracts on Ethereum.\n\n- Deploy upgradeable contracts.\n- Upgrade deployed contracts.\n- Manage proxy admin rights.\n- Easily use in tests.\n\n## Installation and Usage\n\nSee the documentation for each plugin:\n\n| [<img src=\"assets/hardhat.svg\" height=\"20px\" width=\"30px\" alt=\"\">Hardhat](./packages/plugin-hardhat/README.md)| [<img src=\"https://avatars.githubusercontent.com/u/99892494?s=20&v=4\" height=\"20px\" width=\"20px\" alt=\"\"> Foundry](https://github.com/OpenZeppelin/openzeppelin-foundry-upgrades) |\n|-|-|\n\n## How do the plugins work?\n\nThe plugins provide functions which take care of managing upgradeable deployments of your contracts.\n\nFor example, `deployProxy` does the following:\n\n1. Validates that the implementation is [upgrade safe](https://docs.openzeppelin.com/upgrades-plugins/faq#what-does-it-mean-for-a-contract-to-be-upgrade-safe).\n\n2. Deploys the [implementation contract](https://docs.openzeppelin.com/upgrades-plugins/faq#what-is-an-implementation-contract). Note that the Hardhat plugin first checks if there is an implementation contract deployed with the same bytecode, and skips this step if one is already deployed.\n\n3. Creates and initializes the proxy contract, along with a [proxy admin](https://docs.openzeppelin.com/upgrades-plugins/faq#what-is-a-proxy-admin) (if needed).\n\nAnd when you call `upgradeProxy`:\n\n1. Validates that the new implementation is [upgrade safe](https://docs.openzeppelin.com/upgrades-plugins/faq#what-does-it-mean-for-a-contract-to-be-upgrade-safe) and is [compatible](https://docs.openzeppelin.com/upgrades-plugins/faq#what-does-it-mean-for-an-implementation-to-be-compatible) with the previous one.\n\n2. Deploys the new [implementation contract](https://docs.openzeppelin.com/upgrades-plugins/faq#what-is-an-implementation-contract). Note that the Hardhat plugin first checks if there is an implementation contract deployed with the same bytecode, and skips this step if one is already deployed.\n\n3. Upgrades the proxy to use the new implementation contract.\n\nThe Hardhat plugin keeps track of all the implementation contracts you have deployed in an `.openzeppelin` folder in the project root. You will find one file per network there. It is advised that you commit to source control the files for all networks except the development ones (you may see them as `.openzeppelin/unknown-*.json`).\n\nThe Foundry plugin does not keep track of implementation contracts, but requires you to [define reference contracts](https://github.com/OpenZeppelin/openzeppelin-foundry-upgrades?tab=readme-ov-file#before-running) in order to validate new versions of implementations for upgrade safety.\n\n## Proxy patterns\n\nThe plugins support the UUPS, transparent, and beacon proxy patterns. UUPS and transparent proxies are upgraded individually, whereas any number of beacon proxies can be upgraded atomically at the same time by upgrading the beacon that they point to. For more details on the different proxy patterns available, see the documentation for [Proxies](https://docs.openzeppelin.com/contracts/api/proxy).\n\nFor UUPS and transparent proxies, use `deployProxy` and `upgradeProxy`. For beacon proxies, use `deployBeacon`, `deployBeaconProxy`, and `upgradeBeacon`. See the documentation for [Hardhat Upgrades](./packages/plugin-hardhat/README.md) and [Foundry Upgrades](https://github.com/OpenZeppelin/openzeppelin-foundry-upgrades) for examples.\n\n## Managing ownership\n\nTransparent proxies have an _admin_ address which has the rights to upgrade them. By default, the admin is a [proxy admin contract](https://docs.openzeppelin.com/upgrades-plugins/faq#what-is-a-proxy-admin) deployed behind the scenes. Keep in mind that the _admin_ of a proxy can only upgrade it, but not interact with the implementation contract. Read [here](https://docs.openzeppelin.com/upgrades-plugins/proxies#transparent-proxies-and-function-clashes) for more info on this restriction.\n\nThe proxy admin contract also defines an _owner_ address which has the rights to operate it. By default, the proxy admin's owner is the `initialOwner` address used during deployment of the transparent proxy if provided, otherwise it is the externally owned account used during deployment. You can change the proxy admin owner by calling the `admin.transferProxyAdminOwnership` function in the Hardhat plugin, or the `transferOwnership` function of the proxy admin contract if using Foundry.\n\n> [!WARNING]\n> Do not reuse an already deployed `ProxyAdmin`. Before `@openzeppelin/contracts` version 5.x, the address provided to transparent proxies was an `initialAdmin` as opposed to an `initialOwner` of a newly deployed `ProxyAdmin`. Reusing a `ProxyAdmin` will disable upgradeability in your contract.\n\nUUPS and beacon proxies do not use admin addresses. UUPS proxies rely on an [`_authorizeUpgrade`](https://docs.openzeppelin.com/contracts/api/proxy#UUPSUpgradeable-_authorizeUpgrade-address-) function to be overridden to include access restriction to the upgrade mechanism, whereas beacon proxies are upgradable only by the owner of their corresponding beacon.\n\nOnce you have transferred the rights to upgrade a proxy or beacon to another address, you can still use your local setup to validate and deploy the implementation contract. The plugins include a `prepareUpgrade` function that will validate that the new implementation is upgrade-safe and compatible with the previous one, and deploy it using your local Ethereum account. You can then execute the upgrade itself from the admin or owner address. You can also use the `defender.proposeUpgrade` or `defender.proposeUpgradeWithApproval` functions to automatically set up the upgrade in [OpenZeppelin Defender](https://docs.openzeppelin.com/defender/).\n\n## Community\n\nJoin the [OpenZeppelin forum](https://forum.openzeppelin.com/) to ask questions or discuss about these plugins, smart contracts upgrades, or anything related to Ethereum development!\n\n## License\n\nOpenZeppelin Upgrade plugins are released under the [MIT License](LICENSE).\n"
  },
  "OpenZeppelin/openzeppelin-foundry-upgrades": {
    "fetchedAt": "2025-11-12T22:49:05.146Z",
    "content": "# OpenZeppelin Foundry Upgrades\n\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-blue)](https://docs.openzeppelin.com/upgrades-plugins/foundry-upgrades)\n\nFoundry library for deploying and managing upgradeable contracts, which includes upgrade safety validations.\n\n## Installing\n\nFollow one of the sections below depending on which version of OpenZeppelin Contracts you are using. OpenZeppelin Contracts v5 is required for new deployments.\n\n### Using OpenZeppelin Contracts v5\n\nRun these commands:\n```console\nforge install foundry-rs/forge-std\nforge install OpenZeppelin/openzeppelin-foundry-upgrades\nforge install OpenZeppelin/openzeppelin-contracts-upgradeable\n```\n\nSet the following in `remappings.txt`, replacing any previous definitions of these remappings:\n```\n@openzeppelin/contracts/=lib/openzeppelin-contracts-upgradeable/lib/openzeppelin-contracts/contracts/\n@openzeppelin/contracts-upgradeable/=lib/openzeppelin-contracts-upgradeable/contracts/\n```\n\n> **Note**\n> The above remappings mean that both `@openzeppelin/contracts/` (including proxy contracts deployed by this library) and `@openzeppelin/contracts-upgradeable/` come from your installation of the `openzeppelin-contracts-upgradeable` submodule and its subdirectories, which includes its own transitive copy of `openzeppelin-contracts` of the same release version number. This format is needed for Etherscan verification to work. Particularly, any copies of `openzeppelin-contracts` that you install separately are NOT used.\n\n### Using OpenZeppelin Contracts v4\n\nRun these commands, replacing `v4.9.6` with the specific version of OpenZeppelin Contracts that you are using:\n```console\nforge install foundry-rs/forge-std\nforge install OpenZeppelin/openzeppelin-foundry-upgrades\nforge install OpenZeppelin/openzeppelin-contracts@v4.9.6\nforge install OpenZeppelin/openzeppelin-contracts-upgradeable@v4.9.6\n```\n\nSet the following in `remappings.txt`:\n```\n@openzeppelin/contracts/=lib/openzeppelin-contracts/contracts/\n@openzeppelin/contracts-upgradeable/=lib/openzeppelin-contracts-upgradeable/contracts/\n```\n\n> **Note**\n> Use [LegacyUpgrades.sol](src/LegacyUpgrades.sol) instead of `Upgrades.sol` to upgrade existing deployments that were created with OpenZeppelin Contracts v4.\n\n### Optional: Alternative installation methods\n\n#### NPM\n\nFollow the steps above, but instead of running `forge install OpenZeppelin/openzeppelin-foundry-upgrades`, use this command instead:\n```\nnpm install @openzeppelin/foundry-upgrades\n```\n\nThen add the following additional line to `remappings.txt`, in addition to the ones described above:\n```\nopenzeppelin-foundry-upgrades/=node_modules/@openzeppelin/foundry-upgrades/src/\n```\n\n#### Soldeer\n\nFollow the steps above, but instead of running `forge install OpenZeppelin/openzeppelin-foundry-upgrades`, use one of the install commands described in https://soldeer.xyz/project/openzeppelin-foundry-upgrades\n\nThen add the following additional line to `remappings.txt`, in addition to the ones described above (replace `0.3.6` with the version of the plugin that you installed):\n```\nopenzeppelin-foundry-upgrades/=dependencies/openzeppelin-foundry-upgrades-0.3.6/src/\n```\n\n## OpenZeppelin Defender integration\n\nSee [DEFENDER.md](DEFENDER.md)\n\n## Foundry Requirements\n\nThis library requires [forge-std](https://github.com/foundry-rs/forge-std) version 1.9.5 or higher.\n\n## Before Running\n\nThis library uses the [OpenZeppelin Upgrades CLI](https://docs.openzeppelin.com/upgrades-plugins/api-core) for upgrade safety validations, which are run by default during deployments and upgrades.\n\nIf you want to be able to run upgrade safety validations, the following are needed:\n1. Install [Node.js](https://nodejs.org/).\n2. Configure your `foundry.toml` to enable ffi, ast, build info and storage layout:\n```toml\n[profile.default]\nffi = true\nast = true\nbuild_info = true\nextra_output = [\"storageLayout\"]\n```\n3. If you are upgrading your contract from a previous version, add the `@custom:oz-upgrades-from <reference>` annotation to the new version of your contract according to [Define Reference Contracts](https://docs.openzeppelin.com/upgrades-plugins/api-core#define-reference-contracts) or specify the `referenceContract` option when calling the library's functions.\n4. Run `forge clean` before running your Foundry script or tests, or include the `--force` option when running `forge script` or `forge test`.\n\nIf you do not want to run upgrade safety validations, you can skip the above steps and use the [`unsafeSkipAllChecks` option](src/Options.sol) when calling the `Upgrades` library's functions, or use the `UnsafeUpgrades` library instead. Note that these are dangerous options meant to be used as a last resort.\n\n### Optional: Custom output directory\n\nBy default, this library assumes your Foundry output directory is set to \"out\".\n\nIf you want to use a custom output directory, set it in your `foundry.toml` and provide read permissions for the directory. For example (replace `my-output-dir` with the directory that you want to use):\n```toml\n[profile.default]\nout = \"my-output-dir\"\nfs_permissions = [{ access = \"read\", path = \"my-output-dir\" }]\n```\nThen in a `.env` at your project root, set the `FOUNDRY_OUT` environment variable to match the custom output directory, for example:\n```env\nFOUNDRY_OUT=my-output-dir\n```\n\n### Windows environments\n\nIf you are using Windows, set the `OPENZEPPELIN_BASH_PATH` environment variable to the fully qualified path of the `bash` executable.\nFor example, if you are using [Git for Windows](https://gitforwindows.org/), add the following line in the `.env` file of your project (using forward slashes):\n```env\nOPENZEPPELIN_BASH_PATH=\"C:/Program Files/Git/bin/bash\"\n```\n\n## Usage\n\nDepending on which major version of OpenZeppelin Contracts you are using, and whether you want to run upgrade safety validations and/or use OpenZeppelin Defender, use the table below to determine which library to import:\n\n|     | OpenZeppelin Contracts v5 | OpenZeppelin Contracts v4 |\n| --- | --- | --- |\n| **Runs validations, supports Defender** | `import {Upgrades} from \"openzeppelin-foundry-upgrades/Upgrades.sol\";` | `import {Upgrades} from \"openzeppelin-foundry-upgrades/LegacyUpgrades.sol\";` |\n| **No validations, does not support Defender** | `import {UnsafeUpgrades} from \"openzeppelin-foundry-upgrades/Upgrades.sol\";` | `import {UnsafeUpgrades} from \"openzeppelin-foundry-upgrades/LegacyUpgrades.sol\";` |\n\n\nImport one of the above libraries in your Foundry scripts or tests, for example:\n```solidity\nimport {Upgrades} from \"openzeppelin-foundry-upgrades/Upgrades.sol\";\n```\n\nAlso import the implementation contract that you want to validate, deploy, or upgrade to, for example:\n```solidity\nimport {MyToken} from \"src/MyToken.sol\";\n```\n\nThen call functions from the imported library to run validations, deployments, or upgrades.\n\n## Examples\n\nThe following examples assume you are using OpenZeppelin Contracts v5 and want to run upgrade safety validations.\n\n### Deploy a proxy\n\nDeploy a UUPS proxy:\n```solidity\naddress proxy = Upgrades.deployUUPSProxy(\n    \"MyContract.sol\",\n    abi.encodeCall(MyContract.initialize, (\"arguments for the initialize function\"))\n);\n```\n\nDeploy a transparent proxy:\n```solidity\naddress proxy = Upgrades.deployTransparentProxy(\n    \"MyContract.sol\",\n    INITIAL_OWNER_ADDRESS_FOR_PROXY_ADMIN,\n    abi.encodeCall(MyContract.initialize, (\"arguments for the initialize function\"))\n);\n```\n\nDeploy an upgradeable beacon and a beacon proxy:\n```solidity\naddress beacon = Upgrades.deployBeacon(\"MyContract.sol\", INITIAL_OWNER_ADDRESS_FOR_BEACON);\n\naddress proxy = Upgrades.deployBeaconProxy(\n    beacon,\n    abi.encodeCall(MyContract.initialize, (\"arguments for the initialize function\"))\n);\n```\n\n### Use your contract\n\nCall your contract's functions as normal, but remember to always use the proxy address:\n```solidity\nMyContract instance = MyContract(proxy);\ninstance.myFunction();\n```\n\n### Upgrade a proxy or beacon\n\nUpgrade a transparent or\n\n[... truncated ...]"
  },
  "openzeppelin/openzeppelin-community-contracts": {
    "fetchedAt": "2025-11-12T22:49:05.449Z",
    "content": "# <img src=\"logo.svg\" alt=\"OpenZeppelin\" height=\"40px\">\n\n[![Coverage Status](https://codecov.io/gh/OpenZeppelin/openzeppelin-community-contracts/graph/badge.svg)](https://codecov.io/gh/OpenZeppelin/openzeppelin-community-contracts)\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%9A-blue)](https://docs.openzeppelin.com/community-contracts)\n[![Forum](https://img.shields.io/badge/forum-%F0%9F%92%AC-yellow)](https://forum.openzeppelin.com)\n\n> [!IMPORTANT]\n> This repository includes community-curated and experimental code that has not been audited and may introduce breaking changes at any time. We recommend\n> reviewing the [Security](#security) section before using any code from this repository.\n\n## Overview\n\nThis repository contains contracts and libraries in the following categories:\n\n- Extensions and modules compatible with contracts in the [@openzeppelin/contracts](https://github.com/OpenZeppelin/openzeppelin-contracts) package\n- Alternative implementation of interfaces defined in the [@openzeppelin/contracts](https://github.com/OpenZeppelin/openzeppelin-contracts) package\n- Contracts with third-party integrations\n- Contracts built by community members, that align with OpenZeppelin offerings\n- General prototypes and experiments\n\nCode is provided by the OpenZeppelin Contracts team, as well as by community contributors, for other developers to review, discuss, iterate on, and potentially use.\n\n## Security\n\nContracts and libraries in this repository are provided as is, with no particular guarantees. In particular:\n\n- Code in this repository is not audited. Maintainers will review the code to the extend that the is no obviously malicious code published, but bugs may be present in this code that may lead to privilege escalation or loss of funds. Any code taken from this repository should be audited before being used in production.\n\n- Code in this repository is NOT covered by the [OpenZeppelin bug bounty on Immunefi](https://immunefi.com/bug-bounty/openzeppelin/) unless explicitly specified otherwise.\n\n- Code in this repository comes with no backward compatibility guarantees. Updates may change internal or external interfaces without notice. Dependencies updates may also break code present in this repository.\n\n- Code in this repository may depend on un-audited and un-released features from the [OpenZeppelin Contracts repository](https://github.com/OpenZeppelin/openzeppelin-contracts). In some cases, having a versioned dependency on the OpenZeppelin contracts library may not be enough.\n\n- Code in this repository is not versioned nor formally released.\n\n- Bugs affecting code in this repository may not be notified through a CVE.\n\n## Contribute\n\nOpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the [contribution guide](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/CONTRIBUTING.md)!\n\n### CODEOWNERS\n\nContributions to this repository require approval from a code owner (see [CODEOWNERS](./.github/CODEOWNERS)). They are responsible for reviewing contributions to their respective areas of the codebase and ensuring that they meet the project's standards for quality and security.\n\n## License\n\nEach contract file should have their own licence specified. In the absence of any specific licence information, file is released under the [MIT License](LICENSE).\n\n## Legal\n\nYour use of this Project is governed by the terms found at www.openzeppelin.com/tos (the \"Terms\").\n"
  },
  "OpenZeppelin/merkle-tree": {
    "fetchedAt": "2025-11-12T22:49:05.709Z",
    "content": "# `@openzeppelin/merkle-tree`\n\n**A JavaScript library to generate merkle trees and merkle proofs.**\n\nWell suited for airdrops and similar mechanisms in combination with OpenZeppelin Contracts [`MerkleProof`] utilities.\n\n[`MerkleProof`]: https://docs.openzeppelin.com/contracts/4.x/api/utils#MerkleProof\n\n[![NPM Package](https://img.shields.io/npm/v/@openzeppelin/merkle-tree.svg)](https://www.npmjs.org/package/@openzeppelin/merkle-tree)\n[![Coverage](https://codecov.io/github/OpenZeppelin/merkle-tree/branch/master/graph/badge.svg?token=1JMTIEYRZK)](https://codecov.io/github/OpenZeppelin/merkle-tree)\n\n## Quick Start\n\n```\nnpm install @openzeppelin/merkle-tree\n```\n\n### Building a Tree\n\n```js\nimport { StandardMerkleTree } from \"@openzeppelin/merkle-tree\";\nimport fs from \"fs\";\n\n// (1)\nconst values = [\n  [\"0x1111111111111111111111111111111111111111\", \"5000000000000000000\"],\n  [\"0x2222222222222222222222222222222222222222\", \"2500000000000000000\"]\n];\n\n// (2)\nconst tree = StandardMerkleTree.of(values, [\"address\", \"uint256\"]);\n\n// (3)\nconsole.log('Merkle Root:', tree.root);\n\n// (4)\nfs.writeFileSync(\"tree.json\", JSON.stringify(tree.dump()));\n```\n\n1. Get the values to include in the tree. (Note: Consider reading them from a file.)\n2. Build the merkle tree. Set the encoding to match the values.\n3. Print the merkle root. You will probably publish this value on chain in a smart contract.\n4. Write a file that describes the tree. You will distribute this to users so they can generate proofs for values in the tree.\n\n### Obtaining a Proof\n\nAssume we're looking to generate a proof for the entry that corresponds to address `0x11...11`.\n\n```js\nimport { StandardMerkleTree } from \"@openzeppelin/merkle-tree\";\nimport fs from \"fs\";\n\n// (1)\nconst tree = StandardMerkleTree.load(JSON.parse(fs.readFileSync(\"tree.json\", \"utf8\")));\n\n// (2)\nfor (const [i, v] of tree.entries()) {\n  if (v[0] === '0x1111111111111111111111111111111111111111') {\n    // (3)\n    const proof = tree.getProof(i);\n    console.log('Value:', v);\n    console.log('Proof:', proof);\n  }\n}\n```\n\n1. Load the tree from the description that was generated previously.\n2. Loop through the entries to find the one you're interested in.\n3. Generate the proof using the index of the entry.\n\nIn practice this might be done in a frontend application prior to submitting the proof on-chain, with the address looked up being that of the connected wallet.\n\n### Validating a Proof in Solidity\n\nOnce the proof has been generated, it can be validated in Solidity using [`MerkleProof`] as in the following example:\n\n```solidity\npragma solidity ^0.8.4;\n\nimport \"@openzeppelin/contracts/utils/cryptography/MerkleProof.sol\";\n\ncontract Verifier {\n    bytes32 private root;\n\n    constructor(bytes32 _root) {\n        // (1)\n        root = _root;\n    }\n\n    function verify(\n        bytes32[] memory proof,\n        address addr,\n        uint256 amount\n    ) public {\n        // (2)\n        bytes32 leaf = keccak256(bytes.concat(keccak256(abi.encode(addr, amount))));\n        // (3)\n        require(MerkleProof.verify(proof, root, leaf), \"Invalid proof\");\n        // (4)\n        // ...\n    }\n}\n```\n\n1. Store the tree root in your contract.\n2. Compute the [leaf hash](#leaf-hash) for the provided `addr` and `amount` ABI encoded values.\n3. Verify it using [`MerkleProof`]'s `verify` function.\n4. Use the verification to make further operations on the contract. (Consider you may want to add a mechanism to prevent reuse of a leaf).\n\n## Standard Merkle Trees\n\nThis library works on \"standard\" merkle trees designed for Ethereum smart contracts. We have defined them with a few characteristics that make them secure and good for on-chain verification.\n\n- The tree is shaped as a [complete binary tree](https://xlinux.nist.gov/dads/HTML/completeBinaryTree.html).\n- The leaves are sorted.\n- The leaves are the result of ABI encoding a series of values.\n- The hash used is Keccak256.\n- The leaves are double-hashed[^1] to prevent [second preimage attacks].\n\n[second preimage attacks]: https://flawed.net.nz/2018/02/21/attacking-merkle-trees-with-a-second-preimage-attack/\n\n## Simple Merkle Trees\n\nThe library also supports \"simple\" merkle trees, which are a simplified version of the standard ones. They are designed to be more flexible and accept arbitrary `bytes32` data as leaves. It keeps the same tree shape and internal pair hashing algorithm.\n\nAs opposed to standard trees, leaves are not double-hashed. Instead they are ABI encoded to `bytes32` and hashed in pairs inside the tree. This is useful to override the leaf hashing algorithm and use a different one prior to building the tree.\n\nUsers of tooling that produced trees without double leaf hashing can use this feature to build a representation of the tree in JavaScript. We recommend this approach exclusively for trees that are already built on-chain. Otherwise the standard tree may be a better fit.\n\n```typescript\nimport { SimpleMerkleTree } from '@openzeppelin/merkle-tree';\nimport keccak256 from '@ethersproject/keccak256';\n\n// (1)\nconst tree = SimpleMerkleTree.of([keccak256('Value 1'), keccak256('Value 2')]);\n\n// (2)\n// ...\n```\n\n1. Use a custom leaf hashing algorithm to produce `bytes32` values for the tree.\n2. The Simple Merkle Tree share the same API as Standard Merkle Tree.\n\n## Advanced usage\n\n### Leaf Hash\n\nThe Standard Merkle Tree uses an opinionated double leaf hashing algorithm. For example, a leaf in the tree with value `[addr, amount]` can be computed in Solidity as follows:\n\n```solidity\nbytes32 leaf = keccak256(bytes.concat(keccak256(abi.encode(addr, amount))));\n```\n\nThis is an opinionated design that we believe will offer the best out of the box experience for most users. However, there are advanced use case where a different leaf hashing algorithm may be needed. For those, the `SimpleMerkleTree` can be used to build a tree with custom leaf hashing.\n\n### Leaf ordering\n\nEach leaf of a merkle tree can be proven individually. The relative ordering of leaves is mostly irrelevant when the only objective is to prove the inclusion of individual leaves in the tree. Proving multiple leaves at once is however a little bit more difficult.\n\nThis library proposes a mechanism to prove (and verify) that sets of leaves are included in the tree. These \"multiproofs\" can also be verified onchain using the implementation available in `@openzeppelin/contracts`. This mechanism requires the leaves to be ordered respective to their position in the tree. For example, if the tree leaves are (in hex form) `[ 0xAA...AA, 0xBB...BB, 0xCC...CC, 0xDD...DD]`, then you'd be able to prove `[0xBB...BB, 0xDD...DD]` as a subset of the leaves, but not `[0xDD...DD, 0xBB...BB]`.\n\nSince this library knows the entire tree, you can generate a multiproof with the requested leaves in any order. The library will re-order them so that they appear inside the proof in the correct order. The `MultiProof` object returned by `tree.getMultiProof(...)` will have the leaves ordered according to their position in the tree, and not in the order in which you provided them.\n\nBy default, the library orders the leaves according to their hash when building the tree. This is so that a smart contract can build the hashes of a set of leaves and order them correctly without any knowledge of the tree itself. Said differently, it is simpler for a smart contract to process a multiproof for leaves that it rebuilt itself if the corresponding tree is ordered.\n\nHowever, some trees are constructed iteratively from unsorted data, causing the leaves to be unsorted as well. For this library to be able to represent such trees, the call to `StandardMerkleTree.of` includes an option to disable sorting. Using that option, the leaves are kept in the order in which they were provided. Note that this option has no effect on your ability to generate and verify proofs and multiproofs in JavaScript, but that it may introduce challenges when verifying multiproofs onchain. We recommend only using it for building a re\n\n[... truncated ...]"
  },
  "OpenZeppelin/openzeppelin-subgraphs": {
    "fetchedAt": "2025-11-12T22:49:06.166Z",
    "content": "# OpenZeppelin Subgraphs\n\n## Introduction\n\nThis repo contains subgraph schema and templates to index the activity of OpenZeppelin Contracts. For each of the supported OpenZeppelin modules `x`, this repo provides:\n\n- **Primitives to generate a graphql schema:** `src/datasource/x.gql.json`\n\n  In order to allow composability, the schema are not defined in the graphql format but rather in a dedicated json format which can be assembled and compiled to graphql using the `graph-compiler` tool from `@amxx/graphprotocol-utils`. Graphql version for each module is also available in `generated/x.schema.graphql`\n\n- **Template to generate a subgraph manifest:** `src/datasource/x.yaml`\n\n  This file lists all the events that the datasources should listen to, and links that to the corresponding indexing logic. Similarly to the schema, the manifest can be generated procedurally from a JSON app description.\n\n- **Indexing logic:** `src/datasources/x.ts` and (optionally) `src/fetch/x.ts`\n\n  This is the core logic that processes the events and to index the onchain activity.\n\n## Suported modules\n\n- AccessControl\n- ERC20\n- ERC721\n- ERC1155\n- ERC1967Upgrade\n- Governor\n- Ownable\n- Pausable\n- Timelock\n\n<!--\nPaymentSplitter\nERC20Snapshot\nERC20Votes\nERC777\nEscrow\n-->\n\n## Usage\n\nTo use OpenZeppelin Subgraphs, install them in your local project directory and follow the steps outlined in __How to build my app's subgraph__:\n\n```sh\nnpm install @openzeppelin/subgraphs\n```\n\n## How to build my app's subgraph\n\nIn order to build your subgraph, the first step is to create a JSON file listing the modules you want to index. Examples of such config can be found in the `config` folder.\n\nFor example, `configs/sample.json` describes an app with 4 contracts, the first one is an `ERC20` with `AccessControl`, while the 3 others are `ERC721` registries.\n\n```\n{\n  \"output\": \"generated/sample.\",\n  \"chain\": \"mainnet\",\n  \"datasources\": [\n    { \"address\": \"0xA3B26327482312f70E077aAba62336f7643e41E1\", \"startBlock\": 11633151, \"module\": [ \"erc20\", \"accesscontrol\" ] },\n    { \"address\": \"0xB1C52075b276f87b1834919167312221d50c9D16\", \"startBlock\":  9917641, \"module\": \"erc721\" },\n    { \"address\": \"0x799DAa22654128d0C64d5b79eac9283008158730\", \"startBlock\":  9917642, \"module\": \"erc721\" },\n    { \"address\": \"0xC76A18c78B7e530A165c5683CB1aB134E21938B4\", \"startBlock\":  9917639, \"module\": \"erc721\" }\n  ]\n}\n```\n\nIt can be compiled by doing\n\n```\nnpx graph-compiler \\\n  --config configs/sample.json \\\n  --include node_modules/@openzeppelin/subgraphs/src/datasources \\\n  --export-schema \\\n  --export-subgraph\n```\n\nThis will create two files: `generated/sample.schema.graphql` and `generated/sample.subgraph.yaml` that can be used to build and deploy the corresponding subgraph.\n\nNote: `startBlock` is optional but will improve your subgraph initial indexing speed.\n\n\n## Live deployments\n\n### Admin (Access Control + Ownable + ERC1967)\n\n| Network | Config                                                                 | Queries (HTTP)                                                                                                                         | Subscriptions (WS)                                                                                                                 |\n|---------|------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n| Mainnet | [configs/live/mainnet/admin.json](configs/live/mainnet/admin.json)     | [https://api.thegraph.com/subgraphs/name/amxx/access-control](https://api.thegraph.com/subgraphs/name/amxx/access-control)             | [wss://api.thegraph.com/subgraphs/name/amxx/access-control](wss://api.thegraph.com/subgraphs/name/amxx/access-control)             |\n| BSC     | [configs/live/bsc/admin.json](configs/live/bsc/admin.json)             | [https://api.thegraph.com/subgraphs/name/amxx/access-control-bsc](https://api.thegraph.com/subgraphs/name/amxx/access-control-bsc)     | [wss://api.thegraph.com/subgraphs/name/amxx/access-control-bsc](wss://api.thegraph.com/subgraphs/name/amxx/access-control-bsc)     |\n| Matic   | [configs/live/matic/admin.json](configs/live/matic/admin.json)         | [https://api.thegraph.com/subgraphs/name/amxx/access-control-matic](https://api.thegraph.com/subgraphs/name/amxx/access-control-matic) | [wss://api.thegraph.com/subgraphs/name/amxx/access-control-matic](wss://api.thegraph.com/subgraphs/name/amxx/access-control-matic) |\n| XDai    | [configs/live/xdai/admin.json](configs/live/xdai/admin.json)           | [https://api.thegraph.com/subgraphs/name/amxx/access-control-xdai](https://api.thegraph.com/subgraphs/name/amxx/access-control-xdai)   | [wss://api.thegraph.com/subgraphs/name/amxx/access-control-xdai](wss://api.thegraph.com/subgraphs/name/amxx/access-control-xdai)   |\n\n### NFTs (ERC721 + ERC1155)\n\n| Network | Config                                                                 | Queries (HTTP)                                                                                                                         | Subscriptions (WS)                                                                                                                 |\n|---------|------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n| Mainnet | [configs/live/mainnet/nfts.json](configs/live/mainnet/nfts.json)       | [https://api.thegraph.com/subgraphs/name/amxx/nft-mainnet](https://api.thegraph.com/subgraphs/name/amxx/nft-mainnet)                   | [wss://api.thegraph.com/subgraphs/name/amxx/nft-mainnet](wss://api.thegraph.com/subgraphs/name/amxx/nft-mainnet)                   |\n| BSC     | [configs/live/bsc/nfts.json](configs/live/bsc/nfts.json)               | [https://api.thegraph.com/subgraphs/name/amxx/nft-bsc](https://api.thegraph.com/subgraphs/name/amxx/nft-bsc)                           | [wss://api.thegraph.com/subgraphs/name/amxx/nft-bsc](wss://api.thegraph.com/subgraphs/name/amxx/nft-bsc)                           |\n| Matic   | [configs/live/matic/nfts.json](configs/live/matic/nfts.json)           | [https://api.thegraph.com/subgraphs/name/amxx/nft-matic](https://api.thegraph.com/subgraphs/name/amxx/nft-matic)                       | [wss://api.thegraph.com/subgraphs/name/amxx/nft-matic](wss://api.thegraph.com/subgraphs/name/amxx/nft-matic)                       |\n| XDai    | [configs/live/xdai/nfts.json](configs/live/xdai/nfts.json)             | [https://api.thegraph.com/subgraphs/name/amxx/nft-xdai](https://api.thegraph.com/subgraphs/name/amxx/nft-xdai)                         | [wss://api.thegraph.com/subgraphs/name/amxx/nft-xdai](wss://api.thegraph.com/subgraphs/name/amxx/nft-xdai)                         |\n\n### ERC721 only\n\n| Network | Config                                                                 | Queries (HTTP)                                                                                                                         | Subscriptions (WS)                                                                                                                 |\n|---------|------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n| Mainnet | [configs/live/mainnet/eip721.json](configs/live/mainnet/eip721.jso\n\n[... truncated ...]"
  },
  "blockscout/blockscout": {
    "fetchedAt": "2025-11-12T22:49:17.596Z",
    "content": "<h1 align=\"center\">Blockscout</h1>\n<p align=\"center\">Blockchain Explorer for inspecting and analyzing EVM Chains.</p>\n<div align=\"center\">\n\n[![Blockscout](https://github.com/blockscout/blockscout/actions/workflows/config.yml/badge.svg)](https://github.com/blockscout/blockscout/actions)\n[![Discord](https://img.shields.io/badge/chat-Blockscout-green.svg)](https://discord.gg/blockscout)\n\n</div>\n\n\nBlockscout provides a comprehensive, easy-to-use interface for users to view, confirm, and inspect transactions on EVM (Ethereum Virtual Machine) blockchains. This includes Ethereum Mainnet, Ethereum Classic, Optimism, Gnosis Chain and many other **Ethereum testnets, private networks, L2s and sidechains**.\n\nSee our [project documentation](https://docs.blockscout.com/) for detailed information and setup instructions.\n\nFor questions, comments and feature requests see the [discussions section](https://github.com/blockscout/blockscout/discussions) or via [Discord](https://discord.com/invite/blockscout).\n\n## About Blockscout\n\nBlockscout allows users to search transactions, view accounts and balances, verify and interact with smart contracts and view and interact with applications on the Ethereum network including many forks, sidechains, L2s and testnets.\n\nBlockscout is an open-source alternative to centralized, closed source block explorers such as Etherscan, Etherchain and others.  As Ethereum sidechains and L2s continue to proliferate in both private and public settings, transparent, open-source tools are needed to analyze and validate all transactions.\n\n## Supported Projects\n\nBlockscout currently supports several hundred chains and rollups throughout the greater blockchain ecosystem. Ethereum, Cosmos, Polkadot, Avalanche, Near and many others include Blockscout integrations. A comprehensive list is available at [chains.blockscout.com](https://chains.blockscout.com). If your project is not listed, contact the team in [Discord](https://discord.com/invite/blockscout).\n\n## Getting Started\n\nSee the [project documentation](https://docs.blockscout.com/) for instructions:\n\n- [Manual deployment](https://docs.blockscout.com/for-developers/deployment/manual-deployment-guide)\n- [Docker-compose deployment](https://docs.blockscout.com/for-developers/deployment/docker-compose-deployment)\n- [Kubernetes deployment](https://docs.blockscout.com/for-developers/deployment/kubernetes-deployment)\n- [Manual deployment (backend + old UI)](https://docs.blockscout.com/for-developers/deployment/manual-old-ui)\n- [Ansible deployment](https://docs.blockscout.com/for-developers/ansible-deployment)\n- [ENV variables](https://docs.blockscout.com/setup/env-variables)\n- [Configuration options](https://docs.blockscout.com/for-developers/configuration-options)\n\n## Acknowledgements\n\nWe would like to thank the EthPrize foundation for their funding support.\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for contribution and pull request protocol. We expect contributors to follow our [code of conduct](CODE_OF_CONDUCT.md) when submitting code or comments.\n\n## License\n\n[![License: GPL v3.0](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\nThis project is licensed under the GNU General Public License v3.0. See the [LICENSE](LICENSE) file for details.\n"
  },
  "Recon-Fuzz/chimera": {
    "fetchedAt": "2025-11-12T22:49:25.727Z",
    "content": "## Chimera\n\nChimera is a smart contract property-based testing framework. Write once, run everywhere.\n\n <a href=\"https://github.com/Recon-Fuzz/chimera/assets/3029017/65828e54-8c55-4292-9467-4efe94dc6347\"><img src=\"https://github.com/Recon-Fuzz/chimera/assets/3029017/65828e54-8c55-4292-9467-4efe94dc6347\" width=\"300\"/></a>\n \n### Installation\n\n```bash\nforge install Recon-Fuzz/chimera\n```\n\n### Motivation\n\nWhen writing property-based tests, developers commonly face several issues: \n- the amount of boilerplate code required\n- the challenge of switching tools after the initial setup\n- the difficulty in sharing results between different tools\n\nWriting invariant tests that work seamlessly with Foundry, Echidna, Medusa, and Halmos is not straightforward. \n\nChimera addresses this problem by enabling a \"write once, run everywhere\" approach.\n\n### Limitations\n\nChimera currently only supports cheatcodes implemented by [HEVM](https://hevm.dev/std-test-tutorial.html#supported-cheat-codes). \n\nFoundry has extended these and offers functionality not supported by the HEVM cheatcodes, subsequently these must be accounted for when adding Chimera to a Foundry project as they will cause issues when running Echidna and Medusa. If adding Chimera to an existing Foundry project ensure that there are no cheatcodes implemented that aren't supported by HEVM as they will throw the following error: `VM failed for unhandled reason, BadCheatCode <cheatcode hash>`.  \n\nWhile **medusa** supports `etch`, echidna does not support it yet. Please note when using `etch` in an echidna environment it will not work as expected.\n\n### Features\n\n- [x] Boilerplate contracts for Foundry, Echidna, Medusa, Halmos and Kontrol tests\n\n### Help\n\nJoin the Recon Discord: https://getrecon.xyz/discord\n"
  },
  "Recon-Fuzz/recon-extension": {
    "fetchedAt": "2025-11-12T22:49:26.050Z",
    "content": "# Recon - Smart Contract Fuzzing Extension\n\n<p align=\"center\">\n  <img src=\"https://avatars.githubusercontent.com/u/152159338?s=200&v=4\" alt=\"Recon Logo\" width=\"128\" height=\"128\">\n</p>\n\n<p align=\"center\">\n  <strong>Scaffold and run Invariant Tests with Medusa, Echidna and Halmos, automatically debug broken properties with Foundry</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"#features\">Features</a> ‚Ä¢\n  <a href=\"#installation\">Installation</a> ‚Ä¢\n  <a href=\"#getting-started\">Getting Started</a> ‚Ä¢\n  <a href=\"#usage\">Usage</a> ‚Ä¢\n  <a href=\"#configuration\">Configuration</a> ‚Ä¢\n  <a href=\"#troubleshooting\">Troubleshooting</a> ‚Ä¢\n  <a href=\"#license\">License</a>\n</p>\n\n---\n\n## Features\n\nThe Recon extension is a VS Code extension that streamlines smart contract testing by providing:\n\n- **One-click setup**: Automatically install and configure [Chimera](https://github.com/Recon-Fuzz/chimera) templates\n- **Integrated fuzzing**: Run [Echidna](https://github.com/crytic/echidna), [Medusa](https://github.com/crytic/medusa) and [Halmos](https://github.com/a16z/halmos) directly from VS Code\n- **Contract explorer**: Browse and select target contracts and functions\n- **Fuzzer integration**: Quick access to fuzzing tools directly through the extension\n- **Coverage visualization**: View and analyze code coverage from fuzzers\n- **Test generation**: Generate Foundry unit tests from call sequences that break properties found by the fuzzer\n- **Log to Foundry Repro converter**: Convert Echidna and Medusa logs to Foundry test reproductions with customizable VM options\n- **Link Libraries (Experimental)**: Automatically detect and configure library dependencies for Echidna and Medusa\n- **Mock/TargetFunctions generation**: Easily create mock contracts and target functions for testing\n- **CodeLens integration**: Run tests and modify function behaviors directly in the editor\n\n## Installation\n\n### Prerequisites\n\n- Visual Studio Code 1.88.0 or higher\n- Foundry toolchain (forge, cast, anvil)\n- Echidna (optional)\n- Medusa (optional)\n- Halmos (optional)\n\n### Install from VS Code Marketplace\n\nOfficial Link: https://marketplace.visualstudio.com/items?itemName=Recon-Fuzz.recon\n\n1. Open VS Code\n2. Go to Extensions (Ctrl+Shift+X)\n3. Search for \"Recon\"\n4. Click \"Install\"\n\n### Manual Installation\n\n1. Download the `.vsix` file from the [latest release](https://github.com/Recon-Fuzz/recon-extension/releases/latest)\n2. In VS Code, go to Extensions\n3. Click the \"...\" menu and select \"Install from VSIX...\"\n4. Select the downloaded file\n\n## Getting Started\n\n1. Open a Foundry project in VS Code\n2. Click on the Recon icon in the activity bar\n3. In the Cockpit view, click \"Scaffold\" to set up a project using the [create-chimera-app](https://github.com/Recon-Fuzz/create-chimera-app/tree/main) template\n4. Select target contracts and functions in the Contracts view\n5. Run Echidna or Medusa from the status bar or Cockpit view\n\n## Usage\n\nFor a comprehensive overview of how to use the extension for your fuzzing workflows see the [Recon Book](https://book.getrecon.xyz/free_recon_tools/recon_extension.html).\n\n### Scaffolding a Project\n\nThe \"Scaffold\" button in the Recon Cockpit view will:\n\n- Install Chimera as a Foundry submodule dependency\n- Update `remappings.txt` with the necessary dependency remappings\n- Create template files in the test/recon directory\n- Configure your project for fuzzing\n\n### Selecting Target Contracts and Functions\n\nIn the Contracts view you can:\n\n1. Enable the contracts you want to test\n2. For each contract, select the functions to include in the generated [`TargetFunctions`](https://book.getrecon.xyz/tutorial/chimera_framework.html#targetfunctions) contract\n3. Configure function properties:\n   - Actor: Regular user or admin\n   - Mode: Normal execution, expected failure, or catch exceptions\n\n### Running Fuzzers\n\n- Use the status bar buttons for quick access to Echidna and Medusa\n- Set the default fuzzer and configuration in the Cockpit view\n- View live fuzzing progress in the output panel\n\n### Viewing Coverage\n\nAfter running a fuzzer with coverage enabled:\n\n1. Go to the Coverage Reports view\n2. Select a coverage report to view\n3. Click the external icon to open the report in a browser view\n4. Use the \"Clean up Coverage Report\" command for better readability\n\n### Generating Mocks\n\nRight-click on a contract's JSON artifact (located in the `out/` directory by default) or Solidity file and select \"Generate Solidity Mock\" to create a mock implementation of the contract.\n\n### Converting Logs to Foundry Tests\n\nThe Log to Foundry converter helps you create reproducible Foundry tests from fuzzer outputs:\n\n1. In the Recon Cockpit view, click \"Tools\" and select \"Log to Foundry\"\n2. Select your fuzzer (Echidna or Medusa)\n3. Paste the fuzzer log output into the text area\n4. Click \"Convert\" to process the log\n5. For each broken property found:\n   - Toggle VM options (vm.prank, vm.roll, vm.warp) independently\n   - View the generated Foundry test code with syntax highlighting\n   - Copy individual properties or all properties at once\n   - View the original trace if needed\n\n## Configuration\n\nRecon can be configured through VS Code settings:\n\n### General Settings\n\n- `recon.defaultFuzzer`: Choose between Echidna and Medusa\n- `recon.showAllFiles`: Show or hide test and library files in the Contracts view\n- `recon.foundryConfigPath`: Path to foundry.toml (relative to workspace root)\n\n### Echidna Settings\n\n- `recon.echidna.mode`: Configure [testing mode](https://secure-contracts.com/program-analysis/echidna/configuration.html#testmode) (assertion, property, etc.)\n- `recon.echidna.testLimit`: Maximum number of test cases to run\n- `recon.echidna.workers`: Number of parallel workers\n\n### Medusa Settings\n\n- `recon.medusa.testLimit`: Maximum number of test cases to run\n- `recon.medusa.workers`: Number of parallel workers\n\n### Forge Settings\n\n- `recon.forge.buildArgs`: Additional arguments for forge build\n- `recon.forge.testVerbosity`: Verbosity level for forge test output\n\n## Troubleshooting\n\n### Common Issues\n\n- **Fuzzer not found**: Ensure Echidna/Medusa are installed and in your PATH\n- **Compilation errors**: Run `forge build` manually to identify issues\n- **No contracts showing**: Check if `out/` directory exists with compiled contracts\n- Halmos log parser may have a few bugs\n- The Vyper/foundry compiler integration doesn't have paths, so you have to fix them\n\n## License\n\nhttps://www.gnu.org/licenses/old-licenses/gpl-2.0.txt\n"
  },
  "Recon-Fuzz/setup-helpers": {
    "fetchedAt": "2025-11-12T22:49:26.448Z",
    "content": "# Setup Helpers\nThese contracts were created with the intention of speeding up the setup process for an invariant testing suite.\n\nFor an example implementation of these contracts in use see the [create-chimera-app](https://github.com/Recon-Fuzz/create-chimera-app) repo. \n\n## [ActorManager](https://github.com/Recon-Fuzz/setup-helpers/blob/main/src/ActorManager.sol)\nThe `ActorManager` contract serves as the source of truth for actors that are being used in the fuzzing suite setup. \n\nThe primary functions of interest when setting up a suite are:\n- `_addActor` - allows adding a new address as an actor that can be tracked\n- `_switchActor` - this should be exposed in a target function that can be called by the fuzzer to randomly switch between actors\n\nTo use the actors stored in the ActorManager, add the `asActor` modifier on all of your target function handlers which pranks as the currently set actor. \n\nFor privileged functions you can use the `asAdmin` modifier which calls the target functions as the tester contract (`address(this)`). The tester contract is typically set as the default admin address by convention. \n\n## [AssetManager](https://github.com/Recon-Fuzz/setup-helpers/blob/main/src/AssetManager.sol)\n\nThe `AssetManager` allows tracking all assets being used in the fuzz suite setup. \nSimilar to the `ActorManager` this serves as the source of truth for all assets used in the test suite and therefore no target function should be called that may transfer an asset not tracked in the `AssetManager`. \n\nThe primary functions of interest when setting up a suite are: \n- `_newAsset` - deploys an instance of the `MockERC20 `contract and adds it to tracking so it can be accessed as needed\n- `_getAsset` - used to clamp values used for tokens in calls to target functions\n- `_finalizeAssetDeployment` - a utility for minting tokens added via `_newAsset` to all actors that have been setup and approving it to all contracts in the the system that may need to call `transferFrom` on it\n\n## [Utils](https://github.com/Recon-Fuzz/setup-helpers/blob/main/src/Utils.sol)\nProvides utilities for invariant testing\n- `checkError` - allows checking if a revert reason from a function call is equivalent to the reason passed in as the `expected` argument\n\n## [Panic](https://github.com/Recon-Fuzz/setup-helpers/blob/main/src/Panic.sol)\nA library that provides named variables corresponding to compiler panic messages. Used to more easily access these messages when using the `checkError` utility.\n\n```solidity\nlibrary Panic {\n    // compiler panics\n    string constant assertionPanic = \"Panic(1)\";\n    string constant arithmeticPanic = \"Panic(17)\";\n    string constant divisionPanic = \"Panic(18)\";\n    string constant enumPanic = \"Panic(33)\";\n    string constant arrayPanic = \"Panic(34)\";\n    string constant emptyArrayPanic = \"Panic(49)\";\n    string constant outOfBoundsPanic = \"Panic(50)\";\n    string constant memoryPanic = \"Panic(65)\";\n    string constant functionPanic = \"Panic(81)\";\n}\n```\n\n## [MockERC20](https://github.com/Recon-Fuzz/setup-helpers/blob/main/src/MockERC20.sol)\nA minimal `MockERC20` contract that lets you mock any standard ERC20 tokens that will be interacting with the system without requiring external dependencies. \n"
  },
  "Recon-Fuzz/log-parser": {
    "fetchedAt": "2025-11-12T22:49:26.901Z",
    "content": "# Log Parser\n\nA TypeScript utility for parsing Medusa, Echidna, and Halmos fuzzing / symbolic execution logs.\n\n## Web\n\nUsed in:\n\n- Recon VSCode Extension\n- https://getrecon.xyz/tools/medusa\n- https://getrecon.xyz/tools/echidna\n- https://getrecon.xyz/tools/halmos\n\n## NPM\n\nhttps://www.npmjs.com/package/@recon-fuzz/log-parser\n\n## Installation\n\n```bash\nyarn add @recon-fuzz/log-parser\n```\n\n\n## Usage\n\n```typescript\nimport { processLogs, Fuzzer } from '@recon-fuzz/log-parser';\n\n// Process Medusa logs\nconst medusaResults = processLogs(medusaLogContent, Fuzzer.MEDUSA);\n\n// Process Echidna logs\nconst echidnaResults = processLogs(echidnaLogContent, Fuzzer.ECHIDNA);\n\n// Process Halmos logs\nconst halmosResults = processLogs(halmosLogContent, Fuzzer.HALMOS);\n```\n\n## API Reference\n\n### `processLogs(logs: string, tool: Fuzzer): FuzzingResults`\n\nProcesses fuzzing logs and returns structured results.\n\n#### Parameters\n- `logs: string` - The raw log content as a string\n- `tool: Fuzzer` - The tool used (Fuzzer.MEDUSA | Fuzzer.ECHIDNA | Fuzzer.HALMOS)\n\n#### Returns: `FuzzingResults`\n```typescript\ninterface FuzzingResults {\n  duration: string;\n  coverage: number;\n  failed: number;\n  passed: number;\n  results: any[];\n  traces: any[];\n  brokenProperties: any[];\n  numberOfTests: number;\n}\n```\n\n## Converting Logs to Foundry Tests\n\nMedusa, Echidna and Halmos logs can be converted into Foundry test cases using the provided utility functions.\n\n### Medusa & Echidna\n\n```typescript\n// Echidna -> Foundry test functions\nimport { echidnaLogsToFunctions } from '@recon-fuzz/log-parser';\n\nconst echidnaFoundryTests = echidnaLogsToFunctions(\n  echidnaLogs,\n  \"test_identifier\",\n  \"brokenProperty\",           // the property name that failed\n  { roll: true, time: true, prank: true } // vm helpers configuration\n);\n\n// Medusa -> Foundry test functions\nimport { medusaLogsToFunctions } from '@recon-fuzz/log-parser';\n\nconst medusaFoundryTests = medusaLogsToFunctions(\n  medusaLogs,\n  \"test_identifier\",\n  { roll: true, time: true, prank: true }\n);\n```\n\n### Halmos\n\nHalmos produces counterexamples consisting of parameter assignments and a symbolic execution call sequence. These can be transformed into Foundry tests.\n\n```typescript\nimport { halmosLogsToFunctions } from '@recon-fuzz/log-parser';\n\n// Convert all broken properties (if any) to test functions\nconst halmosFoundryTests = halmosLogsToFunctions(halmosLogs, \"test_identifier\");\n```\n\nThe conversion handles:\n- VM state manipulation (block numbers, timestamps)\n- Actor simulation (pranks for different senders)\n- Function call sequences / symbolic traces\n- Parameter reconstruction for Halmos counterexamples\n- Special data types (addresses, bytes)\n\nGenerated tests include the exact sequence of calls that triggered the property violation, making it easy to reproduce and debug issues found during fuzzing or symbolic exploration.\n\n## Development\n\n### Requirements\n\n- Node.js (>= 14.x)\n- yarn or npm\n\n### Setup\n\n1. Clone the repository\n2. Install dependencies:\n```bash\nyarn install\n```\n\n### Scripts\n\n- `yarn build` - Build the package\n- `yarn test` - Run tests\n- `yarn lint` - Run linting\n\n## License\n\nhttps://www.gnu.org/licenses/old-licenses/gpl-2.0.txt\n"
  },
  "Recon-Fuzz/create-chimera-app": {
    "fetchedAt": "2025-11-12T22:49:27.241Z",
    "content": "## Create Chimera App\n\nWe've synthesized everything you need for invariant testing (tutorials, best practices, videos, and an invariant testing bootcamp) using this template in the [Recon Book](https://book.getrecon.xyz/).\n\n## Table of Contents\n\n- [Prerequisites](#prerequisites)\n- [How it Works](#how-it-works)\n- [Example Projects](#example-projects)\n- [Usage](#usage)\n  - [Build](#build)\n  - [Property Testing](#echidna-property-testing)\n  - [Foundry Testing](#foundry-testing)\n- [Expanding Target Functions](#expanding-target-functions)\n- [Uploading Fuzz Job To Recon](#uploading-fuzz-job-to-recon)\n- [Credits](#credits)\n- [Help](#help)\n\n  \nThis Foundry template allows you to bootstrap an invariant fuzz testing suite using a scaffolding provided by the Recon [Handler Builder](https://getrecon.xyz/tools/builder) tool. You can generate a similar scaffolding for any existing project using the Handler Builder or the [Recon Extension](https://book.getrecon.xyz/free_recon_tools/recon_extension.html).\n\nIt extends the default Foundry template used when running `forge init` to include example property tests supported by [Echidna](https://github.com/crytic/echidna) and [Medusa](https://github.com/crytic/medusa).\n\n## Prerequisites\nTo use this template you'll need to have Foundry and at least one fuzzer (Echidna or Medusa) or a symbolic testing tool (Halmos) installed:\n- [Foundry](https://book.getfoundry.sh/getting-started/installation)\n- [Echidna](https://github.com/crytic/echidna?tab=readme-ov-file#installation)\n- [Medusa](https://github.com/crytic/medusa?tab=readme-ov-file#install)\n- [Halmos](https://github.com/a16z/halmos?tab=readme-ov-file#installation)\n\n## How it Works\n\nFor a full explainer of the different contracts that make up the Chimera Framework and are used in this template, checkout [this section](https://book.getrecon.xyz/writing_invariant_tests/chimera_framework.html) of the Recon Book.\n\nFor an in-depth explanation of the configuration options that come with this template and how to use it, see [this section](https://book.getrecon.xyz/writing_invariant_tests/create_chimera_app.html) of the Recon Book.\n\n## Example Projects \nTo see an end-to-end example of how to use this template to define properties on a contract and debug them when they break, checkout the [example project](https://book.getrecon.xyz/writing_invariant_tests/example_project.html) in the Recon Book. \n\n## Usage\nTo initialize a new Foundry repo using this template run the following command in the terminal.\n\n```shell\nforge init --template https://github.com/Recon-Fuzz/create-chimera-app\n```\n\n### Build\nThis template is configured to use Foundry as its build system for [Echidna](https://github.com/Recon-Fuzz/create-chimera-app-2/blob/271c3506a040b30011accfc15ba253cf99a4e6f1/echidna.yaml#L9) and [Medusa](https://github.com/Recon-Fuzz/create-chimera-app-2/blob/271c3506a040b30011accfc15ba253cf99a4e6f1/medusa.json#L73-L83) so after making any changes the project must successfully compile using the following command before running either fuzzer:\n\n```shell\nforge build\n```\n\n### Property Testing\nThis template comes with property tests defined for the `Counter` contract in the [`Properties`](https://github.com/Recon-Fuzz/create-chimera-app-2/blob/main/test/recon/Properties.sol) contract and in the function handlers in the [`TargetFunctions`](https://github.com/Recon-Fuzz/create-chimera-app-2/blob/14f651389623f23880723f01936c546b6d0234a1/test/recon/TargetFunctions.sol#L23-L51) contract.\n\nSee [this section](https://book.getrecon.xyz/writing_invariant_tests/implementing_properties.html) of the Recon Book to learn more about implementing properties.\n\n#### Echidna Property Testing\nTo locally test properties using Echidna, run the following command in your terminal:\n```shell\nechidna . --contract CryticTester --config echidna.yaml\n```\n\n#### Medusa Property Testing\nTo locally test properties using Medusa, run the following command in your terminal:\n\n```shell\nmedusa fuzz\n```\n\n### Foundry Testing\nBroken properties found when running Echidna and/or Medusa can be turned into unit tests for easier debugging with Recon ([for Echidna](https://getrecon.xyz/tools/echidna)/[for Medusa](https://getrecon.xyz/tools/medusa)) and added to the `CryticToFoundry` contract (you can also do this directly in your editor using the [Recon VS Code extension](https://book.getrecon.xyz/free_recon_tools/recon_extension.html#reproducer-generation)).\n\n```shell\nforge test --match-contract CryticToFoundry -vv\n```\n\nYou can then use optimization mode to increase the severity of findings as we've described [here](https://book.getrecon.xyz/writing_invariant_tests/optimizing_broken_properties.html).\n\n#### Foundry Invariant Testing\nTo run invariant tests directly in Foundry using the built-in invariant testing framework, use the `invariants` profile:\n\n```shell\nFOUNDRY_PROFILE=invariants forge test --match-contract CryticToFoundry -vv\n```\n\nThe number of test runs can be modified by the `runs` parameter in the `[profile.invariants.invariant]` section of `foundry.toml`.\n\n### Halmos Invariant Testing\nThis template works out of the box for invariant testing with Halmos.\n\nTo run Halmos for invariant testing, run the `halmos` command in your terminal while in the root of this repository .\n\n## Expanding Target Functions\nAfter you've added new contracts in the `src` directory, they can then be deployed in the `Setup` contract.\n\nThe ABIs of these contracts can be taken from the `out` directory and added to Recon's [Handler Builder](https://book.getrecon.xyz/free_recon_tools/builder.html). The target functions that the builder generates can then be added to the existing `TargetFunctions` contract. \n\n## Uploading Fuzzing Job To Recon\n\nYou can offload your fuzzing job to Recon to run long duration jobs and share test results with collaborators using the [jobs page](https://book.getrecon.xyz/using_recon/running_jobs.html).\n\n## Credits\nThis template implements the [`EnumerableSet`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/structs/EnumerableSet.sol) contract from OpenZeppelin and the [`ERC20`](https://github.com/transmissions11/solmate/blob/main/src/tokens/ERC20.sol) contract from Solmate to reduce the number of dependencies and make it simpler to get started.\n\n## Limitations\n\n- Echidna `contractAddr` must be hardcoded due to how Echidna works\n- Medusa uses `deployerAddress` to deploy libraries, burning nonces, as a sidestep we use a random `deployerAddress` and set¬†`CryticTester` address in `predeployedContracts` \n\n## Help\n\nIf you need help using the template or have question about any of our tools, join the [Recon Discord](https://getrecon.xyz/discord).\n"
  },
  "Synthetixio/synpress": {
    "fetchedAt": "2025-11-12T22:49:34.999Z",
    "content": "# Synpress\n\n[![npm version](https://badge.fury.io/js/%40synthetixio%2Fsynpress.svg)](https://badge.fury.io/js/%40synthetixio%2Fsynpress)\n[![Discord](https://img.shields.io/discord/1103781993394733136.svg?color=768AD4&label=discord&logo=https%3A%2F%2Fdiscordapp.com%2Fassets%2F8c9701b98ad4372b58f13fd9f65f966e.svg)](https://discord.gg/XhZKSRGtWc)\n[![Twitter Follow](https://img.shields.io/twitter/follow/synpress_.svg?label=synpress&style=social)](https://twitter.com/synpress_)\n\n![Synpress CI](https://github.com/Synthetixio/synpress/workflows/Synpress%20CI/badge.svg?branch=master)\n[![CodeQL](https://github.com/Synthetixio/synpress/actions/workflows/codeql.yml/badge.svg?branch=master)](https://github.com/Synthetixio/synpress/actions/workflows/codeql.yml)\n[![synpress](https://img.shields.io/endpoint?url=https://dashboard.cypress.io/badge/count/ohpeaz/master&style=flat&logo=cypress)](https://dashboard.cypress.io/projects/ohpeaz/runs)\n\n> **We're Hiring üéâ** ‚Äî Think you have what it takes? See open positions [here](https://mirror.xyz/synpress.eth/FXhd5-7e7wBmYYtfmqkF0h7FhDBRUGuGF6j-D7jPpvM).\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Synthetixio/synpress/dev/images/synpress-logo.png\" height=\"200\" alt=\"Synpress Logo\" />\n  <p align=\"center\">\n    Synpress is a powerful and developer-friendly E2E testing library for Web3 dapps, built on top of <a href=\"https://www.cypress.io/\">Cypress</a> and <a href=\"https://playwright.dev/\">Playwright</a>.  It simplifies testing interactions with wallets like <a href=\"https://metamask.io/\">MetaMask</a> and other blockchain-specific operations.\n  </p>\n</p>\n\n<p align=\"center\">\n    <i>Sponsored by: </i> <br/> <br/>\n    <a href=\"https://github.com/ethereum-optimism\"><img src=\"https://raw.githubusercontent.com/Synthetixio/synpress/dev/images/optimism-logo.png\" height=\"100\" alt=\"Optimism Logo\" /></a>\n</p>\n\n## ‚ú® Features\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Synthetixio/synpress/dev/images/demo.gif\" title=\"Synpress Demo\" alt=\"Synpress Demo\" style=\"margin-bottom: 10px;\">\n</p>\n\n- **Playwright and Cypress Support**: Use either Playwright or Cypress as your testing framework, leveraging all their existing features and functionalities with Synpress.\n- **One-Time Browser Setup & Caching:** Define your dApps wallet setup once, and let Synpress cache the browser state. This dramatically speeds up test execution and unlocks the full potential of Playwright and Cypress, including parallel testing.\n- **Built-in Wallet and Blockchain Agnostic System**: Synpress core is designed to be wallet and blockchain agnostic, offering flexibility for future integrations and broader dApp support.\n- **MetaMask Integration**: Deep integration with MetaMask for seamless testing of common dApp interactions.\n- **TypeScript Support**: Enhanced TypeScript support for improved type safety and developer experience.\n- **Anvil Support**: Easily spin up a local Anvil node with just one line of code for fast and isolated testing.\n- **Blazing Fast Performance**: Synpress is optimized for speed, rivalling native Web2 testing framework performance.\n- **Improved Debugging**: Detailed error handling, combined with the debugging tools of Playwright and Cypress, makes pinpointing and resolving issues simple.\n\n## üßë‚Äçüíª Installation\n\n```bash\npnpm add -D @synthetixio/synpress@latest\n```\n\n## üìù Documentation\n\nFor comprehensive guides, API references, and examples, refer to our [official documentation](https://docs.synpress.io/docs/introduction).\n\n## üßë‚Äçü§ù‚Äçüßë Community\n\nJoin our vibrant community for support, discussions, and updates:\n\n## How to Contribute\n\nWe welcome contributions from the community! Please refer to our [contributing guidelines](https://docs.synpress.io/docs/contribution).\n\n- [Discord](https://discord.gg/XhZKSRGtWc)\n- [X (formerly Twitter)](https://twitter.com/Synpress_)\n"
  },
  "synpress-io/docs": {
    "fetchedAt": "2025-11-12T22:49:35.428Z",
    "content": "# Mintlify Starter Kit\n\nClick on `Use this template` to copy the Mintlify starter kit. The starter kit contains examples including\n\n- Guide pages\n- Navigation\n- Customizations\n- API Reference pages\n- Use of popular components\n\n### Development\n\nInstall the [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview the documentation changes locally. To install, use the following command\n\n```\nnpm i -g mintlify\n```\n\nRun the following command at the root of your documentation (where mint.json is)\n\n```\nmintlify dev\n```\n\n### Publishing Changes\n\nInstall our Github App to auto propagate changes from your repo to your deployment. Changes will be deployed to production automatically after pushing to the default branch. Find the link to install on your dashboard. \n\n#### Troubleshooting\n\n- Mintlify dev isn't running - Run `mintlify install` it'll re-install dependencies.\n- Page loads as a 404 - Make sure you are running in a folder with `mint.json`\n"
  },
  "shazow/callthis": {
    "fetchedAt": "2025-11-12T22:49:43.438Z",
    "content": "# callthis.link\n\n**Build a transaction and send it as a link for someone else to execute.**\n\n<img src=\"https://github.com/shazow/callthis/assets/6292/41f04548-2d39-4fb7-87c2-c55bce1e42cb\" alt=\"Screenshot of callthis.link\" width=\"484.5\" />\n\n---\n\nLatest version is available on [callthis.link](https://callthis.link) and on IPFS via [callthis.eth](https://callthis.eth.limo).\n\n‚ú® Automagic proxy resolving and ABI detection is powered by [WhatsABI](https://github.com/shazow/whatsabi)!\n\n## Developing\n\nIf you're a fellow Nix-user, run `nix develop`. Otherwise, make sure you have nodejs and pnpm installed.\n\nRun `make run` to serve locally, `make build` to build a ready-to-deploy static site.\n\n## License\n\nMIT\n"
  },
  "candidelabs/candide-contracts": {
    "fetchedAt": "2025-11-12T22:49:51.110Z",
    "content": "<div align=\"center\">\n  <h1 align=\"center\">Candide Contracts</h1>\n</div>\n\n![atelier-meta-web](https://github.com/candidelabs/.github/assets/7014833/5090c8d1-31ad-4daf-9efd-adae4c350c35)\n\n# About\n\nCandide Wallet is a smart contract wallet for Ethereum Mainnet and EVM compatible rollups.<br/>\nThis repo includes the smart contracts used by Candide Labs.\n\n# Features\n\n- <a href=\"https://eips.ethereum.org/EIPS/eip-4337\">EIP-4337: Account Abstraction via Entry Point Contract</a>\n- Account Recovery\n- Pay gas with ERC-20 using a Paymaster\n\n# Account Recovery\n\n_In this section, we highlight and explain the [SocialRecoveryModule.sol](./contracts/modules/social_recovery/SocialRecoveryModule.sol) contract._\n\nThe Account Recovery module is designed to work for both a single-owner account and an n-m multi-sig account. In the case of the single-owner account, the signer key is typically stored on the user's device. More specifically, owners can add recovery addresses (also known as Guardians) to change the ownership of the account, in case their signer key is lost or compromised.\n\nRecovery methods are typical Ethereum accounts. They can be:\n\n- Family & Friends' contacts\n- Hardware wallets\n- Institutions\n- Custodial services that offer cloud-based wallets\n\nNormal operations of the Account do not require the approval of added Guardians in the module.\n\nOwners of the account decide the threshold for the number of guardians needed for recovery, as well as the number of guardians. A typical single-owner account can have 3 guardians with a threshold of 2. This decreases the likelihood that a single guardian can overtake the account.\n\nOwners are encouraged to ask their guardians to provide fresh addresses. This makes them private and eliminates the possibility of malicious guardians cooperating against an owner. By design, a guardian does not need to necessarily store value in their account to maintain their duties, even during a recovery process.\n\nOnce the recovery is initiated, the owners have until the `delayPeriod` to cancel the recovery, if the initiation was done with malicious intent. Once the `delayPeriod` is over, anyone can finalize the recovery to update the ownership of that particular Safe Wallet.\n\nAccount Recovery interfaces can be built with or without a backend service:\n\n- An interface without a backend service can simply let each guardian submit their signatures separately. Once the threshold is met, anyone can call execute recovery to start the recovery period.\n\n- An interface that leverages a backend service can aggregate guardians' signatures so that only the last guardian executes the transaction and pay gas fees. This is similar to how Safe's interface works when multiple owners for a multi-sig sign transactions before submitting them.\n\n## High-Level specs of methods\n\nWe assume that the signer key belongs to its real owner. The probability of the signer key being in control of someone else should be close to zero. Under this model, we can build a simple yet highly secure non-custodial wallet. To enable that model to evolve if needed, upgrading the wallet to a new implementation requires the approval of only the owner of the account.\n\n| Method                        | Owner | Guardians | Anyone | Comment                                                                                                           |\n| ----------------------------- | ----- | --------- | ------ | ----------------------------------------------------------------------------------------------------------------- |\n| `addGuardianWithThreshold`    | X     |           |        | Owner can add a guardian with a new threshold                                                                     |\n| `revokeGuardianWithThreshold` | X     |           |        | Owner can remove a guardian from its list of guardians                                                            |\n| `confirmRecovery`             |       | X         |        | Lets a single guardian approve the execution of the recovery request                                              |\n| `multiConfirmRecovery`        |       | X         |        | Lets multiple guardians approve the execution of the recovery request                                             |\n| `cancelRecovery`              | X     |           |        | Lets an owner cancel an ongoing recovery request                                                                  |\n| `finalizeRecovery`            |       |           | X      | Finalizes an ongoing recovery request if the recovery period is over. The method is public and callable by anyone |\n\n## Audit\n\n- [For version 0.0.1 by Ackee Blockchain](./audit/ackee-blockchain-candide-social-recovery-report.pdf)\n\n# Development\n\n### Install dependencies\n\n```\nyarn install\n```\n\n### Add required .env variables\n\n```\ncp .env.example .env\n```\n\n## Run tests\n\n```\nyarn build\nyarn test\n```\n\n## Run FV\n\n```\ncertoraRun certora/conf/SocialRecoveryModule.conf\ncertoraRun certora/conf/GuardianStorage.conf\ncertoraRun certora/conf/RecoveryConfirmationSignatureValidity.conf\n```\n\nNote: You will need to install Certora CLI and a valid Certora Key for running FV. To provide a custom `solc` path, use `--solc` flag.\n\n<!-- LICENSE -->\n\n## License\n\nGNU General Public License v3.0\n\n<!-- ACKNOWLEDGMENTS -->\n\n## Acknowledgments\n\n- <a href='https://github.com/eth-infinitism/account-abstraction'>eth-infinitism/account-abstraction</a>\n- <a href='https://github.com/safe-global/safe-contracts'>Gnosis Safe Contracts</a>\n- <a href='https://eips.ethereum.org/EIPS/eip-4337'>EIP-4337: Account Abstraction via Entry Point Contract specification </a>\n"
  },
  "candidelabs/abstractionkit": {
    "fetchedAt": "2025-11-12T22:49:58.514Z",
    "content": "<!-- PROJECT LOGO -->\n<div align=\"center\">\n<img src=\"https://github.com/user-attachments/assets/ad202256-d3c2-40d3-ac70-c458f9ab0c1c\">\n</div>\n\nA Typescript Library to easily build standard Ethereum Smart Wallets, with first class support for Safe Accounts.\n\nAbstractionKit is agnostic of:\n- **Ethereum interface libraries**: ethers, web3.js, viem/wagmi\n- **Bundlers**: Plug and play a Bundler URL from any provider, or self-host your own\n- **Paymasters**: Candide Paymaster is supported , but you can use any 3rd party paymaster to sponsor gas\n- **Accounts**: The Safe Account is first class supported, but you can use use Bundlers and Paymasters with any account\n\n## Examples\n<a href=\"https://github.com/candidelabs/abstractionkit-examples\">Abstractionkit Example Projects</a>\n\n\n## Features\n### Safe Accounts\n- Built on ERC-4337 account abstraction\n- Passkeys Authentication for secure, passwordless access\n- Social Recovery to regain access easily\n- Multisig Support\n- Allowance Management for controlled spending limits\n\n### Gas Abstraction with Paymasters\n- Full Gas Sponsorship for a seamless user experience\n- Support for ERC-20 Tokens as gas payment options\n\n### Bundler Support\n- Compatibility with standard ERC-4337 Bundler Methods\n\n### UserOperation Utilities\n- A complete toolkit to construct, sign, and send UserOperations, enabling smooth integration\n\n## Docs\n\nFor full detailed documentation visit our [docs page](https://docs.candide.dev/wallet/abstractionkit/introduction). \n\n## Installation\n\n```bash\nnpm install abstractionkit\n```\n\n## Quickstart\n\n### Safe Account\n\nAbstractionKit features the Safe Account. It uses the original Safe Singleton and adds ERC-4337 functionality using a fallback handler module. The contracts have been developed by the Safe Team. It has been audited by Ackee Blockchain. To learn more about the contracts and audits, visit [safe-global/safe-modules](https://github.com/safe-global/safe-modules/tree/main/modules/4337).\n\n\n```typescript\nimport { SafeAccountV0_3_0 as SafeAccount } from \"abstractionkit\";\n\nconst ownerPublicAddress = \"0xBdbc5FBC9cA8C3F514D073eC3de840Ac84FC6D31\";\nconst smartAccount = SafeAccount.initializeNewAccount([ownerPublicAddress]);\n\n```\nThen you can consume accout methods:\n```typescript\nconst safeAddress = smartAccount.accountAddress;\n```\n\n### Bundler\n\nInitialize a Bundler with your desired bundler RPC url. Get a bundler endpoint from the [dashboard](https://dashboard.candide.dev)\n```typescript\nimport { Bundler } from \"abstractionkit\";\n\nconst bundlerRPC = \"https://api.candide.dev/bundler/version/network/YOUR_API_KEY\";\n\nconst bundler: Bundler = new Bundler(bundlerRPC);\n```\nThen you can consume Bundler methods:\n\n```typescript\nconst entrypointAddresses = await bundler.supportedEntryPoints();\n```\n\n### Paymaster\nInitialize a Candide Paymaster with your RPC url. Get one from the [dashboard](https://dashboard.candide.dev).\n```typescript\nimport { CandidePaymaster } from \"abstractionkit\";\n\nconst paymasterRpc = \"https://api.candide.dev/paymaster/$version/$network/$apikey\";\n\nconst paymaster: CandidePaymaster = new CandidePaymaster(paymasterRPC);\n```\nThen you can consume Paymaster methods:\n\n```typescript\nconst supportedERC20TokensAndPaymasterMetadata = await paymaster.fetchSupportedERC20TokensAndPaymasterMetadata();\n```\n\n## Guides\n| Title | Description\n| -----------------------------------------------------------------------------------------| -------------------------------------------------------------------------------- |\n| [Send your first user operation](https://docs.candide.dev/wallet/guides/getting-started) | Learn how to create a smart wallet and to send your first user operation         |\n| [Send a Gasless Transaction](https://docs.candide.dev/wallet/guides/send-gasless-tx)     | Learn how to send gasless transactions using a paymaster                         |\n| [Pay Gas in ERC-20](https://docs.candide.dev/wallet/guides/pay-gas-in-erc20)             | Learn how to offer the ability for users to pay gas in ERC-20s using a Paymaster |\n\n## npm package\n<a href=\"https://www.npmjs.com/package/abstractionkit\">npm</a>\n\n<!-- LICENSE -->\n## License\n\nMIT\n\n<!-- ACKNOWLEDGMENTS -->\n## Acknowledgments\n\n* <a href='https://eips.ethereum.org/EIPS/eip-4337'>EIP-4337: Account Abstraction via Entry Point Contract specification </a>\n* <a href='https://safe.global/'>Safe Accounts, Modules, and SGP</a>\n"
  },
  "usecannon/cannon": {
    "fetchedAt": "2025-11-12T22:50:05.319Z",
    "content": "# Cannon\n\nCannon is a DevOps tool for EVM chains. It's a tool for testing, deploying, and publishing of smart contracts.\n\nThis is the monorepo for Cannon. If you're just interested in using the project, [visit the website](https://usecannon.com/learn).\n\n**‚ö†Ô∏è Cannon is under active development. While the interface and functionality are generally stable, use the tool with caution when conducting high-risk deployments.**\n\nFor more information, please see documentation in the modules listed below:\n\n- [`api`](packages/api): Backend for the website.\n- [`cli`](packages/cli): The command-line interface. Run `npx @usecannon/cli --help` for usage information.\n- [`builder`](packages/builder): Builds chain data from cannonfiles. (This is used by the CLI.)\n- [`hardhat-cannon`](packages/hardhat-cannon): Code for the Hardhat plug-in, which wraps the CLI functionality with defaults pulled from a Hardhat project configuration.\n- [`indexer`](packages/indexer): Processes all data for cannon into a Redis database. Used on the website.\n- [`registry`](packages/registry): The smart contract for the package registry.\n- [`repo`](packages/repo): Backend for our homegrown IPFS hosting service.\n- [`website`](packages/website): The website, hosted at https://usecannon.com.\n\nUsage Examples:\n\n- [`router-architecture`](examples/router-architecture): Project demonstrating how to setup an upgradable [Router Architecture](https://www.npmjs.com/package/@synthetixio/router).\n- [`sample-hardhat-project`](examples/sample-hardhat-project): Hardhat project that demonstrates the core functionality of the `hardhat-cannon` module\n- [`sample-foundry-project`](examples/sample-hardhat-project): Foundry project that demonstrates the core functionality of the `cli` module\n\nCannon is 100% open-source, from the dev tooling to our hosted infrastructure.\n\n## Development\n\nCommunity contributions to Cannon are greatly appreciated. Please open pull requests, issues, and discussions in the GitHub repository.\n\nTo load a development version of Cannon, first start by making sure you have the correct node and [pnpm](https://pnpm.io/installation) versions installed.\n\nThen, install the dependencies from the root directory:\n\n```\npnpm i\n```\n\nAfter making changes, rebuild the project:\n\n```\npnpm build\n```\n\nUse the development version of the CLI:\n\n```\ncd ./packages/cli && pnpm start -- <package:version>\n```\n\nTest changes to the Hardhat plug-in in the sample project:\n\n```\ncd ./examples/sample-hardhat-project && pnpm hardhat cannon:build\n```\n\nPreview updates to the website\n\n```\ncd ./packages/website && pnpm dev\n```\n\n### Contribution Guidelines\n\nSee [CONTRIBUTING.md](./CONTRIBUTING.md)\n\n### Version and Publish\n\nWe bump and publish manually using lerna's [version and publish](https://lerna.js.org/docs/features/version-and-publish) workflow.\n\n#### Stable Release\n\n1. To create a `stable` release, first checkout to a new branch (it should be called `release/*`)\n\n- Note, DO NOT use the version name as the branch name as this can cause conflicts with tags. (eg `v2.12.1` as a branch name is incorrect)\n\n2. Run `pnpm run version` and select one of the desired patch, minor or major versions.\n3. Create PR for the release branch\n4. From the branch, run `pnpm run publish` and follow the prompts.\n5. Create a new GitHub release here: https://github.com/usecannon/cannon/releases/new\n6. Merge release PR\n\n#### Alpha Release\n\n1. To create an `alpha` release, first checkout to a new branch (it can be called `release-alpha` or something similar)\n\n- Note, DO NOT use the version name as the branch name as this can cause conflicts with tags. (eg `v2.12.1-alpha.0` as a branch name is incorrect)\n\n1. Run `pnpm run version` to bump package versions and select one of the desired alpha versions.\n2. Create PR for the branch and merge when required tests are passing\n3. From the `main` branch, run `pnpm publish-alpha` and follow the prompts.\n\n#### Changesets\n\nWe can also use [changesets](https://github.com/changesets/changesets) to manage versions on our monorepo.\n\nCurrently our [release workflow](.github/workflows/release.yml) on our CI handles bumping package versions and publishing releases to npm through lerna.\nIt only publishes releases if any changeset PR's have been added to the commit history merged into main.\n\nTo trigger a new version bump run the following command (from the root of the repo):\n\n```\n  pnpm changeset\n```\n\n## License\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\nThis project is licensed under the terms of the GNU General Public License v3.0.\n\nCopyright (C) 2024 Taihou Technologies\n"
  },
  "Ratimon/superfuse-forge": {
    "fetchedAt": "2025-11-12T22:50:12.118Z",
    "content": "<h1>Keep Optimistic and be Superchain dApp developer!! </h1>\n\n- [What is it for](#what-is-it-for)\n- [Quickstart](#quickstart)\n- [Architecture](#architecture)\n- [Contributing](#contributing)\n- [Acknowledgement](#acknowledgement)\n\n>[!NOTE]\n> You can find our relevant examples [`here`](https://github.com/Ratimon/superfuse-contracts-examples). Geneated contract code from the Superfuse Wizard is stored here due to documentation and testing purpose.\n\n## What Is It For\n\nOne of our Swiss army knife toolset: **superfuse-forge** is a developer-friendly framework/library in solidity to build a variations of cross-chain contracts in superchain Ecosystem.\n\nThe features include:\n\n- Type-safe smart contract deployment\n- Re-usable  smart contract deployment and testing pipeline\n- Standardized framework, minimizing developer mistake and enhancing better security\n- Save deployment schemas in **json** file\n- Separatable into each of modular and customizable deploy scripts\n- Based on All-Solidity, so no context switching, no new testing syntax\n\nTogether with [`Redprint Wizard UI`](https://github.com/Ratimon/redprint-wizard), which is a code generator/ interactive playground oriented for OPStack development, it does not only help novice developers to deploy OPStack's smart contracts to deploy on OP mainnet, but also help them to use generated deployment script in their own projects.\n\n## Quickstart\n\n### Installation\n\nAdd the `superfuse-forge` using your favorite package manager, e.g., with pnpm:\n\n```bash\npnpm init\npnpm add superfuse-forge\npnpm install\n``` \n\n### Quick Guide\n\n1. Set your working environment with **foundry** : \n\n```bash\nforge init my-project\ncd my-project\n``` \n\n2.  Add the `superfuse-forge` using your favorite package manager, e.g., with pnpm or Yarn:\n\n```sh\npnpm add superfuse-forge\n```\nor\n```sh\nyarn add -D superfuse-forge\n```\n\n3. Configure permission and remapping (e.g. with txt\" for `remappings.txt`) by modifing:\n\n```diff\n[profile.default]\nsrc = \"src\"\nout = \"out\"\nlibs = [\"lib\"]\n+solc_version = '0.8.25'\n+fs_permissions = [\n+    { access = 'read-write', path = './deployments/' },\n+    { access = 'read', path = './configs' },\n+    { access = 'read', path = './test' },\n+    { access = 'write', path = './deployment.json' },\n+]\n\n+[soldeer]\n+remappings_location = \"txt\"\n```\n\nThen, add `remappings.txt` with following lines:\n\n```txt\n@superfuse-core/=node_modules/superfuse-forge/src\n@superfuse-deploy/=node_modules/superfuse-forge/script\n@superfuse-test/=node_modules/superfuse-forge/test/\n\n@forge-std-v1.9.1/=node_modules/superfuse-forge/lib/forge-std-v1.9.1/src/\n@solady-v0.0.292/=node_modules/superfuse-forge/lib/solady-v0.0.292/src/\n\n@openzeppelin-v0.4.7.3/=node_modules/superfuse-forge/lib/openzeppelin-v0.4.7.3/contracts/\n@openzeppelin-v0.5.0.2/=node_modules/superfuse-forge/lib/openzeppelin-v0.5.0.2/contracts/\n```\n\n>[!TIP]\n> We use @<Lib>-v<Lib-Version>/ as a convention to avoid any naming conflicts with your previously installed libararies ( i.e. `@solady-0.0.292/` vs `@solady/`)\n\n>[!NOTE]\n>  You can check out dependencies'versions [`here`](https://github.com/Ratimon/superfuse-forge/blob/main/package.json#L31).\n\n\n4. Copy `.env` as following.\n\n```sh\nMNEMONIC=\"test test test test test test test test test test test junk\"\n# local network 's default private key so it is still not exposed\nDEPLOYER_PRIVATE_KEY=0x59c6995e998f97a5a0044966f0945389dc9e86dae88c7a8412f4603b6b78690d\nDEPLOYER_ADDRESS=0x70997970C51812dc3A010C7d01b50e0d17dc79C8\n```\n\n>[!NOTE]\n>  The key or menemonic here must be secret and secure. you can configure it via our [Wizard](https://superfuse.ninja/), and the default values are based on above `.env`. You must choose your own secret. Otherwise, it does not mimic the production deployment environment.\n\n4. Modify  `.gitignore` as following.\n\n```diff\n# ...\n+node_modules/\n```\n\n5. Copy a set of smart contract including main contracts deploy scripts and test suites \n\n```sh\nrsync -av --exclude='interfaces/' --exclude='L2/' --exclude='libraries/' node_modules/superfuse-forge/src/ src/\n```\n\n>[!NOTE]\n>  we, for this example, also need to reconfigue the new remapping:\n\n```diff\n# ...\n+@main/=src/\n+@script/=script/\n@superfuse-core/=node_modules/superfuse-forge/src\n@superfuse-deploy/=node_modules/superfuse-forge/script\n@superfuse-test/=node_modules/superfuse-forge/test/\n\n@forge-std-v1.9.1/=node_modules/superfuse-forge/lib/forge-std-v1.9.1/src/\n@solady-v0.0.292/=node_modules/superfuse-forge/lib/solady-v0.0.292/src/\n\n@openzeppelin-v0.4.7.3/=node_modules/superfuse-forge/lib/openzeppelin-v0.4.7.3/contracts/\n@openzeppelin-v0.5.0.2/=node_modules/superfuse-forge/lib/openzeppelin-v0.5.0.2/contracts/\n```\n\n>[!TIP]\n> You may choose your own remapping convention that suites your needs best!!!\n\nFor Deploy script, we now want to exclude [`/deployer`](./script/deployer/):\n\n```sh\nrsync -av --exclude='deployer/' node_modules/superfuse-forge/script/ script/\n```\n\nNow, copy a test suite:\n\n```sh\ncp node_modules/superfuse-forge/test/* test/\n```\n\n6. Compile and run test:\n\nThis will take a while to compile:\n```sh\nforge t\n```\n\n>[!TIP]\n>Behind the scene, the test suite works by replicating the same environment as production script, because it utilizes the same deployment logic script inside `setUp()` as following:\n\n```ts\n\n/** ... */\n\n// deployment logic\nimport {DeployMyERC20VotesScript} from \"@script/000_DeployMyERC20VotesScript.s.sol\";\n\ncontract ERC20VotesTest is Test {\n\n    /** ... */\n\n    function setUp() external {\n\n         /** ... */\n\n        deployerProcedue = getDeployer();\n        deployerProcedue.setAutoBroadcast(false);\n\n        console.log(\"Setup MyERC20Votes ... \");\n\n        DeployMyERC20VotesScript myERC20VotesDeployments = new DeployMyERC20VotesScript();\n        myERC20Votes = myERC20VotesDeployments.deploy();\n\n        deployerProcedue.deactivatePrank();\n\n    }\n    /** ... */\n\n}\n```\n\n>[!NOTE]\n> You can chekout [this](https://github.com/Ratimon/redprint-forge/blob/main/script/example/000_DeployMyERC20VotesScript.s.sol)"
  },
  "Ratimon/superfuse-wizard": {
    "fetchedAt": "2025-11-12T22:50:12.565Z",
    "content": "<h1>Keep Optimistic and be Superchain dApp developer!! </h1>\n\n- [Installation](#installation)\n- [What is it for](#what-is-it-for)\n- [Acknowledgement](#acknowledgement)\n\n>[!NOTE]\n> You can find our relevant examples [`here`](https://github.com/Ratimon/superfuse-contracts-examples). Geneated contract code from the Superfuse Wizard is stored here due to documentation and testing purpose.\n\n## Installation\n\n### with npm\n\nWe assume that you already setup your own working front-end environment and `cd` into it\n\n```bash\ncd my-project;\nnvm use v22.14.0\n``` \n\nAdd the `superfuse-wizard` using your favorite package manager, e.g., with pnpm:\n\n```sh\nnpm add -D superfuse-wizard\n```\n\nAlternatively, you can fork a project and installed dependencies with `pnpm install` (or `yarn`), then start a development server:\n\n```bash\ngit clone git@github.com:Ratimon/superfuse-wizard.git\ncd superfuse-wizard;\npnpm dev\n```\n\n#what-is-it-for\n\nSuperfuse Wizard is a code generator/ interactive developer playground to develop parts of smart contract/deploy script/ test suites out of components from cross-chain specification. Select kind of contract that you want (eg. ERC7802, SuperchainERC20, and ERC20Votes).\n\n\n#acknowledgement\n\nWe embrace a culture of regenerative approach of building open-source software and we acknowledge, use, and get inspiration from these upstream software repositories :\n- [OZ 's contracts](https://github.com/OpenZeppelin/openzeppelin-contracts) by **OpenZeppelin**\n- [OZ 's Wizard](https://github.com/OpenZeppelin/contracts-wizard/) by **OpenZeppelin**\n- [OPStack monorepo](https://github.com/ethereum-optimism/optimism) by **OP Labs**\n- [superchainerc20-starter template](https://github.com/ethereum-optimism/superchainerc20-starter) by **OP Labs**\n- [foundry's forge](https://github.com/foundry-rs/foundry/tree/master/crates/forge) by **Paradigm**\n- [forge-deploy](https://github.com/wighawag/forge-deploy) by **Ronan Sandford**\n- [solady](https://github.com/Vectorized/solady) by **Vectorized**\n- [Redprint Wizard](https://github.com/Ratimon/redprint-wizard) by **Ratimon**\n- [redprint-forge](https://github.com/Ratimon/redprint-forge) by **Ratimon**\n- [superfuse-contracts-examples](https://github.com/Ratimon/superfuse-contracts-examples) by **Ratimon**\n"
  },
  "Ratimon/solid-grinder": {
    "fetchedAt": "2025-11-12T22:50:21.260Z",
    "content": "<h1>be calldata gas optimizooor!! </h1>\n\nA CLI that goes along with building blocks of smart contract. Along with our front-end snippets, this toolbox can reduce L2 gas cost by encoding calldata for dApps development to use as little bytes of calldata as possible. \n\n> [!WARNING]\n> The code is not audited yet. Please use it carefully in production.\n\n- [What is it for](#what-is-it-for)\n- [How It Works](#how-it-works)\n- [Benchmarks](#benchmarks)\n- [Installation](#installation)\n- [Quickstart](#quickstart)\n- [Contributing](#contributing)\n- [Acknowledgement](#acknowledgement)\n\n\n## What is it for ?\n\nThis dApp building block is intended to reduce L2 gas costs by a significant amount, using calldata optimization paradigm.\n\nTo learn more about **calldata optimization**, Check out this [`Technical Article`](https://www.rareskills.io/post/l2-calldata) !!\n\nWhile security is our top priority, we aim to enhance developer experience, such that the entire protocol is not required to re-written from scratch.\n\nWhat you need to do is specify how argument is packed into one single calldata, then our CLI will generate required files for you !!\n\n\n## How It Works\n\nIt works by optimizing calldata by using as little bytes of calldata as possible.\n\nSpecifically, Our novel components are as follows:\n\n1. Solidity snippets: one contract to encode call data on chain. Another to decode it. This component has following feat:\n\n   - AddressTable: to store **the mapping between addresses and indexes**, allowing:\n     - The **address** can be registered to the contract, then the index is generated.\n     - The generated id can then be used  to look up the registered address  during the compressed **call data** **decoding** process\n   - Data Serialization, allowing:\n     - The encoded calldata could be deserialized into the correct type with adequate data size.\n     - For example, if we choose to reduce the calldata by sending the time period as arguments with type of uint40 (5 bytes) instead of uint256, the calldata should be sliced at the correct offset and the result can be correctly used in the next steps.\n\n2. Front-end snippets: to atomically connect between encoding and decoding component into single call\n\n    - The demo of how to implement front-end part is here:[ `uniswap-calldata-optimization-monorepo`](https://github.com/Ratimon/uniswap-calldata-optimization-monorepo)\n\n3. CLI: to generate the above solidity snippets (including Encoder and Decoder contracts). The only task requires to do is to specify the data type to pack the calldata while ensuring security.\n\n\n## Benchmarks\n\n### Benchmarks - on Mainnet!!\n\nWe have done the benchmark by deploying and interacting the **un-optimized version** : [`/UniswapV2Router02.sol`](https://github.com/Ratimon/uniswap-calldata-optimization-monorepo/blob/main/contracts/src/UniswapV2Router02.sol) and **optimized version** [`/UniswapV2Router02_Optimized.sol`](https://github.com/Ratimon/uniswap-calldata-optimization-monorepo/blob/main/contracts/src/UniswapV2Router02_Optimized.sol).\n\nThen, we have compared the difference in gas cost in following Txs:\n\n1. [`https://optimistic.etherscan.io/tx/0x446b8d7f091ff258d16dfbac751797210ad1edeb5f856c0ac0686b80d32516a5`](https://optimistic.etherscan.io/tx/0x446b8d7f091ff258d16dfbac751797210ad1edeb5f856c0ac0686b80d32516a5)\n\nThe L2 Fees Paid is then 0.00011025.\n\n![Unoptimized](./assets/optimized.png)\n\n2. [`https://optimistic.etherscan.io/tx/0x778a6beb856540c5534d7516fa168e0b26b09086e414317748ac01c153e81f01`](https://optimistic.etherscan.io/tx/0x778a6beb856540c5534d7516fa168e0b26b09086e414317748ac01c153e81f01)\n![Optimized](./assets/unoptimized.png)\n\nThe L2 Fees Paid is then 0.00007481\n\nIt can be seen that the L1 gas has been saved by ~36% (from 0.000029 ETH to 0.000018 ETH), but the overall cost is higher. However, the gas amount saved can potentially be much higher in case of the high congestion on L1 network.\n\nFor example if L1 gas price increases to 100 Gwei and L1 Fee Scalar is adjusted to 1. The figures will be from 0.000424 ETH to 0.000263 ETH.\n\nAccording to the formula: \n\n$`\\\n\\text{Total Gas} = \\text{Gas Price}_{\\text{Layer2}} \\times \\text{Gas Used for Execution}_{\\text{Layer2}} +  \\text{Gas Price}_{\\text{Layer1}} \\times \\text{Gas Used for Data}_{\\text{Layer2}}  \\times \\text{Scalar Fee}_{\\text{Layer1}} `$\n\nThe total fee for unoptimized contract is 0.00007481 + 0.000424 = 0.0004988.\n\nThe total fee for optimized contract is 0.00011025 + 0.000263 = 0.00034325.\n\nThe gas has been saved by 31 %\n\n### Benchmarks - Behind the scene\n\nWe provide how the UniswapV2's router is optimized as follows:\n\n- The original version:[ `UniswapV2Router02.sol`](https://github.com/Ratimon/solid-grinder/blob/main/contracts/examples/uniswapv2/UniswapV2Router02.sol)\n\n```solidity\n    /** ... */\n    contract UniswapV2Router02 is IUniswapV2Router02 {\n\n        /** ... */\n\n        function addLiquidity(\n            address tokenA,\n            address tokenB,\n            uint256 amountADesired,\n            uint256 amountBDesired,\n            uint256 amountAMin,\n            uint256 amountBMin,\n            address to,\n            uint256 deadline\n        ) public virtual override ensure(deadline) returns (uint256 amountA, uint256 amountB, uint256 liquidity) {\n            /** ... */\n        }\n        /** ... */\n    }\n\n```\n\n- The optimized version: including two components. The first one is [ `UniswapV2Router02_Optimized.sol`](https://github.com/Ratimon/solid-grinder/blob/main/contracts/examples/uniswapv2/UniswapV2Router02_Optimized.sol) which inherits main functionality from [ `UniswapV2Router02_Decoder.g.sol`](https://github.com/Ratimon/solid-grinder/blob/main/contracts/examples/uniswapv2/decoder/UniswapV2Router02_Decoder.g.sol)\n\n```solidity\n\n    /** ... */\n    contract UniswapV2Router02_Optimized is UniswapV2Router02, Ownable, UniswapV2Router02_Decoder {\n\n        /** ... */\n\n        function addLiquidityCompressed(bytes calldata _payload)\n            external\n            payable\n            returns (uint256 amountA, uint256 amountB, uint256 liquidity)\n        {\n            (addLiquidityData memory addLiquidityData,) = _decode_addLiquidityData(_payload, 0);\n\n            return UniswapV2Router02.addLiquidity(\n                addLiquidityData.tokenA,\n                addLiquidityData.tokenB,\n                addLiquidityData.amountADesired,\n                addLiquidityData.amountBDesired,\n                addLiquidityData.amountAMin,\n                addLiquidityData.amountBMin,\n                addLiquidityData.to,\n                addLiquidityData.deadline\n            );\n        }\n        /** ... */\n  \n    }\n\n```\n\nThe second one is [ `UniswapV2Router02_Encoder.sol`](https://github.com/Ratimon/solid-grinder/blob/main/contracts/examples/uniswapv2/encoder/UniswapV2Router02_Encoder.g.sol)\n\n```solidity\n\n    /** ... */\n   contract UniswapV2Router02_Encoder {\n    IAddressTable public immutable addressTable;\n\n        /** ... */\n\n        function encode_addLiquidityData(\n            address tokenA,\n            address tokenB,\n            uint256 amountADesired,\n            uint256 amountBDesired,\n            uint256 amountAMin,\n            uint256 amountBMin,\n            address to,\n            uint256 deadline\n        )\n            external\n            view\n            returns (\n                bytes memory _compressedPayload\n            )\n        {\n            /** ... */\n        }\n\n        /** ... */\n\n    }\n\n```\n\nAs shown above, the various input arguments of original contract are compressed into a single calldata via **encoder**. It is then decoded to be used later in **decoder**. Thus, nearly half bytes of calldata is reduced.\n\nThis can be illustrated by following:\n\n- This command shows how solidity encodes an original function with arguments:\n\n```sh\ncast calldata \"addLiquidity(address,address,uint256,uint256,uint256,uint256,address,uint256)\" 0x106EABe0298ec286Adf962994f0Dcf250c4BB763 0xEbfc763Eb9e1d1ab09Eb2f70549b66682AfD9aa5 1200000000000000000000 2500\n\n[... truncated ...]"
  },
  "joshstevens19/ethereum-multicall": {
    "fetchedAt": "2025-11-12T22:50:28.620Z",
    "content": "[![npm version](https://badge.fury.io/js/ethereum-multicall.svg)](https://badge.fury.io/js/ethereum-multicall)\n![downloads](https://img.shields.io/npm/dw/ethereum-multicall)\n\n# ethereum-multicall\n\nethereum-multicall is a lightweight library for interacting with the [`Multicall3`](https://github.com/mds1/multicall) smart contract. \n\nMulticall allows multiple smart contract constant function calls to be grouped into a single call and the results aggregated into a single result. This reduces the number of separate JSON RPC requests that need to be sent over the network if using a remote node like Infura, and provides the guarantee that all values returned are from the same block. The latest block number is also returned along with the aggregated results.\n\nethereum-multicall is fully written in typescript so has full compile time support. The motivation of this package was to expose a super simple and easy to understand interface for you to take the full benefits of the multicalls. Also to not being opinionated on how you use it, you can use it with web3, ethers or even pass in a custom nodeUrl and we do it for you. This package takes care of the decoding for you but at the same time if you dont want it to you can turn that part off.\n\n## Supports\n\nThe below networks are supported by default, and custom networks can be supported by providing your own instance of a deployed Multicall contract.\n\n| Chain                 | Chain ID   |\n|-----------------------|------------|\n| Mainnet               | 1          |\n| Ropsten               | 3          |\n| Rinkeby               | 4          |\n| G√∂rli                 | 5          |\n| Optimism              | 10         |\n| Kovan                 | 42         |\n| Matic                 | 137        |\n| KovanOptimism         | 69         |\n| xDai                  | 100        |\n| xDaiTestnet           | 10200      |\n| GoerliOptimism        | 420        |\n| SepoliaOptimism       | 11155420   |\n| Arbitrum              | 42161      |\n| RinkebyArbitrum       | 421611     |\n| GoerliArbitrum        | 421613     |\n| SepoliaArbitrum       | 421614     |\n| Mumbai                | 80001      |\n| Sepolia               | 11155111   |\n| AvalancheMainnet      | 43114      |\n| AvalancheFuji         | 43113      |\n| FantomTestnet         | 4002       |\n| Fantom                | 250        |\n| BSC                   | 56         |\n| BSC_Testnet           | 97         |\n| Moonbeam              | 1284       |\n| Moonriver             | 1285       |\n| MoonbaseAlphaTestnet  | 1287       |\n| Harmony               | 1666600000 |\n| Cronos                | 25         |\n| Fuse                  | 122        |\n| SongbirdCanaryNetwork | 19         |\n| CostonTestnet         | 16         |\n| Boba                  | 288        |\n| Aurora                | 1313161554 |\n| Astar                 | 592        |\n| OKC                   | 66         |\n| Heco                  | 128        |\n| Metis                 | 1088       |\n| RSK                   | 30         |\n| RSKTestnet            | 31         |\n| Evmos                 | 9001       |\n| EvmosTestnet          | 9000       |\n| Thundercore           | 108        |\n| ThundercoreTestnet    | 18         |\n| Oasis                 | 26863      |\n| Celo                  | 42220      |\n| Godwoken              | 71402      |\n| GodwokenTestnet       | 71401      |\n| Klatyn                | 8217       |\n| Milkomeda             | 2001       |\n| KCC                   | 321        |\n| Etherlite             | 111        |\n| Linea Testnet         | 59140      |\n| Linea                 | 59144      |\n| Scroll                | 534352     |\n| Scroll Sepolia        | 534531     |\n| zkSync Era            | 324        |\n| zkSync Era Testnet    | 280        |\n| zkSync Era Sepolia    | 300        |\n| Sei                   | 1328       |\n| Shibarium             | 109        |\n| Mantle                | 5000       |\n| Mantle Testnet        | 5001       |\n| Base                  | 8453       |\n| Base Testnet          | 84531      |\n| Blast Sepolia         | 168587773  |\n| PolygonZkEvm          | 1101       |\n| PolygonZkEvmTestnet   | 1442       |\n| Zora                  | 7777777    |\n| Zora Testnet          | 999        |\n| Flare Mainnet         | 14         |\n| Pulsechain Mainnet    | 369        |\n| Starknet              | 300        |\n| Starknet Testnet      | 301        |\n| Blast                 | 81457      |\n| Amoy                  | 80002      |\n| Mode                  | 34443      |\n| Mode Testnet          | 919        |\n| Manta Pacific Mainnet | 169        |\n| Bob Mainnet           | 60808      |\n\n## Installation\n\n### npm:\n\n```js\n$ npm install ethereum-multicall\n```\n\n### yarn:\n\n```js\n$ yarn add ethereum-multicall\n```\n\n## Usage\n\n### Overloaded methods\n\nAs the [official docs mentions here](https://docs.ethers.io/v3/api-contract.html#prototype):\n\n> Due to signature overloading, multiple functions can have the same name. The first function specified in the ABI will be bound to its name. To access overloaded functions, use the full typed signature of the functions (e.g. contract[\"foobar(address,uint256)\"]).\n\nSo, when creating the contract call context, under the calls array property we should have that in mind and use the method signature rather than the method name. E.g.\n\n```js\nconst contractCallContext: ContractCallContext = {\n  reference: 'upV2Controller',\n  contractAddress: '0x19891DdF6F393C02E484D7a942d4BF8C0dB1d001',\n  abi: [\n    {\n      inputs: [],\n      name: 'getVirtualPrice',\n      outputs: [\n        {\n          internalType: 'uint256',\n          name: '',\n          type: 'uint256',\n        },\n      ],\n      stateMutability: 'view',\n      type: 'function',\n    },\n    {\n      inputs: [\n        {\n          internalType: 'uint256',\n          name: 'sentValue',\n          type: 'uint256',\n        },\n      ],\n      name: 'getVirtualPrice',\n      outputs: [\n        {\n          internalType: 'uint256',\n          name: '',\n          type: 'uint256',\n        },\n      ],\n      stateMutability: 'view',\n      type: 'function',\n    },\n  ],\n  calls: [\n    {\n      reference: 'getVirtualPriceWithInput',\n      methodName: 'getVirtualPrice(uint256)',\n      methodParameters: ['0xFFFFFFFFFFFFF'],\n    },\n    {\n      reference: 'getVirtualPriceWithoutInput',\n      methodName: 'getVirtualPrice()',\n      methodParameters: [],\n    },\n  ],\n};\n```\n\n### Import examples:\n\n### JavaScript (ES3)\n\n```js\nvar ethereumMulticall = require('ethereum-multicall');\n```\n\n### JavaScript (ES5 or ES6)\n\n```js\nconst ethereumMulticall = require('ethereum-multicall');\n```\n\n### JavaScript (ES6) / TypeScript\n\n```js\nimport {\n  Multicall,\n  ContractCallResults,\n  ContractCallContext,\n} from 'ethereum-multicall';\n```\n\n### ethers usage example\n\n```ts\nimport {\n  Multicall,\n  ContractCallResults,\n  ContractCallContext,\n} from 'ethereum-multicall';\nimport { ethers } from 'ethers';\n\nlet provider = ethers.getDefaultProvider();\n\n// you can use any ethers provider context here this example is\n// just shows passing in a default provider, ethers hold providers in\n// other context like wallet, signer etc all can be passed in as well.\nconst multicall = new Multicall({ ethersProvider: provider, tryAggregate: true });\n\nconst contractCallContext: ContractCallContext[] = [\n    {\n        reference: 'testContract',\n        contractAddress: '0x6795b15f3b16Cf8fB3E56499bbC07F6261e9b0C3',\n        abi: [ { name: 'foo', type: 'function', inputs: [ { name: 'example', type: 'uint256' } ], outputs: [ { name: 'amounts', type: 'uint256' }] } ],\n        calls: [{ reference: 'fooCall', methodName: 'foo', methodParameters: [42] }]\n    },\n    {\n        reference: 'testContract2',\n        contractAddress: '0x66BF8e2E890eA0392e158e77C6381b34E0771318',\n        abi: [ { name: 'fooTwo', type: 'function', inputs: [ { name: 'example', type: 'uint256' } ], outputs: [ { name: 'amounts', type: 'uint256', name: \"path\", \"type\": \"address[]\" }] } ],\n        calls: [{ reference: 'fooTwoCall', methodName: 'fooTwo', me\n\n[... truncated ...]"
  },
  "joshstevens19/ethereum-bloom-filters": {
    "fetchedAt": "2025-11-12T22:50:38.757Z",
    "content": "[![npm version](https://badge.fury.io/js/ethereum-bloom-filters.svg)](https://badge.fury.io/js/ethereum-bloom-filters)\n![downloads](https://img.shields.io/npm/dw/ethereum-bloom-filters)\n\n# ethereum-bloom-filters\n\nA lightweight bloom filter client which allows you to test ethereum blooms for fast checks of set membership.\n\nThis package only has 1 dependency which is on `@noble/hashes` which has no dependencies on at all and is funded by ethereum foundation.\n\n## Installation \n\n### npm:\n\n```js\n$ npm install ethereum-bloom-filters\n```\n\n### yarn:\n\n```js\n$ yarn add ethereum-bloom-filters\n```\n\n## Usage\n\n### JavaScript (ES3)\n\n```js\nvar ethereumBloomFilters = require('ethereum-bloom-filters');\n```\n\n### JavaScript (ES5 or ES6)\n\n```js\nconst ethereumBloomFilters = require('ethereum-bloom-filters');\n```\n\n### JavaScript (ES6) / TypeScript\n\n```js\nimport {\n  isBloom,\n  isUserEthereumAddressInBloom,\n  isContractAddressInBloom,\n  isTopic,\n  isTopicInBloom,\n  isInBloom,\n} from 'ethereum-bloom-filters';\n```\n\n### Including within a web application which doesn't use any transpiler\n\nWhen using angular, react or vuejs these frameworks handle dependencies and transpile them so they work on the web, so if you're using any of them just use the above code snippets to start using this package.\n\nIf you're using a standard web application you can go [here](https://github.com/joshstevens19/ethereum-bloom-filters/tree/master/web-scripts) to copy any of the versioned script files and then dropping it into your web application, making sure you reference it within a script tag in the head of the website.\n\nThis will expose the library as a global variable named `ethereumBloomFilters`, you can then execute the methods through this variable:\n\n```js\nethereumBloomFilters.isBloom(...)\nethereumBloomFilters.isUserEthereumAddressInBloom(...)\nethereumBloomFilters.isContractAddressInBloom(...)\nethereumBloomFilters.isTopic(...)\nethereumBloomFilters.isTopicInBloom(...)\nethereumBloomFilters.isInBloom(...)\n```\n\nYou can find out more about the functions parameters below.\n\nWe do not expose an cdn for security reasons.\n\n## What are bloom filters?\n\nA Bloom filter is a probabilistic, space-efficient data structure used for fast checks of set membership. That probably doesn‚Äôt mean much to you yet, and so let‚Äôs explore how bloom filters might be used.\n\nImagine that we have some large set of data, and we want to be able to quickly test if some element is currently in that set. The naive way of checking might be to query the set to see if our element is in there. That‚Äôs probably fine if our data set is relatively small. Unfortunately, if our data set is really big, this search might take a while. Luckily, we have tricks to speed things up in the ethereum world!\n\nA bloom filter is one of these tricks. The basic idea behind the Bloom filter is to hash each new element that goes into the data set, take certain bits from this hash, and then use those bits to fill in parts of a fixed-size bit array (e.g. set certain bits to 1). This bit array is called a bloom filter.\n\nLater, when we want to check if an element is in the set, we simply hash the element and check that the right bits are in the bloom filter. If at least one of the bits is 0, then the element definitely isn‚Äôt in our data set! If all of the bits are 1, then the element might be in the data set, but we need to actually query the database to be sure. So we might have false positives, but we‚Äôll never have false negatives. This can greatly reduce the number of database queries we have to make.\n\n## ethereum-bloom-filters benefits with an real life example\n\nA ethereum real life example in where this is useful is if you want to update a users balance on every new block so it stays as close to real time as possible. Without using a bloom filter on every new block you would have to force the balances even if that user may not of had any activity within that block. But if you use the logBlooms from the block you can test the bloom filter against the users ethereum address before you do any more slow operations, this will dramatically decrease the amount of calls you do as you will only be doing those extra operations if that ethereum address is within that block (minus the false positives outcome which will be negligible). This will be highly performant for your app.\n\n## Requirements for blooms to be queryable\n\nBlooms do not work with eth transactions (purely sending eth), eth transactions do not emit logs so do not exist in the bloom filter. This is what ethereum did purposely but it means you should query the eth balance every block to make sure it's in sync. Blooms will only work if the transaction emits an event which then ends up in the logs. The bloom filter is there to help you find logs. A contract can be written which does not emit an event and in that case, would not be queryable from a bloom filter. The erc20 token spec requires you to fire an event on `approval` and `transfer` so blooms will work for `approval` and `transfer` for ALL erc20 tokens, this will be most people's primary use-case. Saying that this can be used in any way you want with any use-case as long as events are emitted then it's queryable.\n\n## Functions\n\n### isBloom\n\n```ts\nisBloom(bloom: string): boolean;\n```\n\nReturns true if the bloom is a valid bloom.\n\n### isUserEthereumAddressInBloom\n\n```ts\nisUserEthereumAddressInBloom(bloom: string, ethereumAddress: string): boolean;\n```\n\nReturns true if the ethereum users address is part of the given bloom\nnote: false positives are possible.\n\n### isContractAddressInBloom\n\n```ts\nisContractAddressInBloom(bloom: string, contractAddress: string): boolean;\n```\n\nReturns true if the contract address is part of the given bloom\nnote: false positives are possible.\n\n### isTopic\n\n```ts\nisTopic(topic: string): boolean;\n```\n\nReturns true if the topic is valid\n\n### isTopicInBloom\n\n```ts\nisTopicInBloom(bloom: string, topic: string): boolean;\n```\n\nReturns true if the topic is part of the given bloom\nnote: false positives are possible.\n\n### isInBloom\n\nThis is the raw base method which the other bloom methods above use. You can pass in a bloom and a value which will return true if its part of the given bloom.\n\n```ts\nisInBloom(bloom: string, value: string | Uint8Array): boolean;\n```\n\nReturns true if the value is part of the given bloom\nnote: false positives are possible.\n\n## Issues\n\nPlease raise any issues in the below link.\n\nhttps://github.com/joshstevens19/ethereum-bloom-filters/issues\n\n## Contributors dev guide\n\nTo run locally firstly run:\n\n```js\n$ npm install\n```\n\nTo build:\n\n```js\n$ tsc\n```\n\nTo watch build:\n\n```js\n$ tsc --watch\n```\n\nTo run tests:\n\n```js\n$ npm test\n```\n"
  },
  "joshstevens19/rindexer": {
    "fetchedAt": "2025-11-12T22:50:45.938Z",
    "content": "# ü¶Ä rindexer ü¶Ä \n\nNote rindexer is brand new and actively under development, things will change and bugs will exist - if you find any bugs or have any\nfeature requests please open an issue on [github](https://github.com/joshstevens19/rindexer/issues).\n\nrindexer is an opensource powerful, high-speed indexing toolset developed in Rust, designed for compatibility with any EVM chain.\nThis tool allows you to index chain events using a simple YAML file, requiring no additional coding.\nFor more advanced needs, the rindexer provides foundations and advanced capabilities to build whatever you want.\nIt's highly extendable, enabling you to construct indexing pipelines with ease and focus exclusively on the logic.\nrindexer out the box also gives you a GraphQL API to query the data you have indexed instantly.\n\nYou can get to the full rindexer [documentation](https://rindexer.xyz/).\n\n## Install \n\n```bash\ncurl -L https://rindexer.xyz/install.sh | bash\n```\n\nIf you‚Äôre on Windows, you will need to install and use Git BASH or WSL, as your terminal,\nsince rindexer installation does not support Powershell or Cmd.\n\n## Use rindexer\n\nOnce installed you can run `rindexer --help` in your terminal to see all the commands available to you.\n\n```bash\nrindexer --help\n```\n\n```bash\nBlazing fast EVM indexing tool built in rust\n\nUsage: rindexer [COMMAND]\n\nCommands:\n  new           Creates a new rindexer no-code project or rust project\n  start         Start various services like indexers, GraphQL APIs or both together\n  add           Add elements such as contracts to the rindexer.yaml file\n  codegen       Generates rust code based on rindexer.yaml or graphql queries\n  delete        Delete data from the postgres database or csv files\n  phantom       Use phantom events to add your own events to contracts\n  help          Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help     Print help\n  -V, --version  Print version\n```\n\nWe have full documentation https://rindexer.xyz/docs/introduction/installation which goes into more detail on how to use \nrindexer and all the commands available to you.\n\n## Docker\n\nThere's a pre-built docker image which can be used to run `rindexer` inside your dockerized infra:\n\n- Docker image: [`ghcr.io/joshstevens19/rindexer`](https://github.com/users/joshstevens19/packages/container/package/rindexer)\n\n### Create new project\nTo create a new `no-code` project in your current directory, you can run the following:\n\n`docker run -it -v $PWD:/app/project_path ghcr.io/joshstevens19/rindexer new -p /app/project_path no-code`\n\n### Use with existing project\nTo use it with an existing project and a running postgres instance you can simply invoke:\n\n```\nexport PROJECT_PATH=/path/to/your/project\nexport DATABASE_URL=\"postgresql://user:pass@postgres/db\"\n\ndocker-compose up -d\n```\n\nThis will start all local indexing and if you have enabled the graphql endpoint, it will become exposed under:\n\nhttp://localhost:3001\n\n## Helm Chart\n\nWe also provide a Helm chart for deploying `rindexer` in Kubernetes environments. The Helm chart simplifies the deployment process and allows for easy customization of the deployment parameters.\n\nYou can find the Helm chart in the following directory:\n\n- **[rindexer Helm Chart](https://github.com/joshstevens19/rindexer/tree/master/helm/rindexer)**\n\nTo use the Helm chart, follow the instructions in the [Helm Chart README](https://github.com/joshstevens19/rindexer/tree/master/helm/rindexer/README.md) to deploy `rindexer` to your Kubernetes cluster.\n\n## What can I use rindexer for?\n\n- Hackathons: spin up a quick indexer to index events for your dApp with an API without any code needed\n- Data reporting\n- Building advanced indexers\n- Building a custom indexer for your project\n- Fast prototyping and MVP developments\n- Quick proof-of-concept projects\n- Enterprise standard indexing solutions for projects\n- Much more... \n\n## Crate.io\n\nrindexer rust project building is available on crate.io but we strongly recommend using the git repository to install it\nand use it in your project. To use the CLI please install it using the above instructions.\n\nhttps://crates.io/crates/rindexer\n\n## What networks do you support?\n\nrindexer supports any EVM chain out of the box. If you have a custom chain, you can easily add support for it by\nadding the chain's RPC URL to the YAML configuration file and defining the chain ID. No code changes are required.\n\n## Code structure\n\n### core\n\nThis is the core of rindexer, it contains all the logic for indexing and where most the code lives.\n\n### cli\n\nThis\nis the cli for rindexer, it contains all the logic for the cli and is how users interact with rindexer.\n\n### graphql\n\nThis is the express project which leverages postgraphile rindexer GraphQL, it is automatically built into a binary during the Rust build process using `pkg`.\n\n**Build Process:**\n- Automatically builds during `cargo build`\n- Detects target architecture (macOS, Linux, Windows) \n- Smart rebuilding - only rebuilds when source files change\n- Requires Node.js and npm for development/building\n\n**Development:**\n```bash\ncd graphql\nnpm install\nnpm start\n```\n\nThe binary is embedded into the Rust application and started automatically when GraphQL functionality is enabled.\n\n### documentation\n\nThis is the documentation for rindexer, it is built using [voc](https://vocs.dev/) which is an incredible\ntool to build documentation. Big shout out to `wevm` team for all the work they have done on `vocs`, `viem` and `wagmi`.\n\n### examples\n\nThis just holds some no-code examples for rindexer which is referenced in the docs or used for new users to see\nhow a project is setup.\n\n## Building\n\n### Requirements\n\n- Rust (latest stable)\n- Node.js and npm (for GraphQL server build)\n\n### Locally \n\nTo build locally you can just run `cargo build` in the root of the project. This will build everything for you as this is a workspace, including the GraphQL server binary.\n\n**Note:** The first build may take longer as it needs to:\n1. Install npm dependencies for the GraphQL server\n2. Build the GraphQL binary for your target platform\n3. Compile all Rust code\n\nSubsequent builds use smart caching and will only rebuild components that have changed.\n\n### Prod\n\nTo build for prod you can run `make prod_build` this will build everything for you and optimise it for production.\n\n## Formatting\n\nyou can run `cargo fmt` to format the code, rules have been mapped in the `rustfmt.toml` file.\n\n## Contributing\n\nAnyone is welcome to contribute to rindexer, feel free to look over the issues or open a new one if you have\nany new ideas or bugs you have found.\n\n### Playing around with the CLI locally\n\nYou can use the `make` commands to run the CLI commands locally, this is useful for testing and developing.\nThese are located in the `cli` folder > `Makefile`. It uses `CURDIR` to resolve the paths for you, so they should work\nout of the box. The examples repo has a `rindexer_demo_cli` folder which you can modify (please do not commit any changes though) \nor spin up a new no-code project using the make commands.\n\n## Release\n\nTo release a new rindexer:\n\n1. Checkout `release/x.x.x` branch depending on the next version number\n2. Push the branch to GitHub which will queue a build on the CI\n3. Once build is successful, a PR will be automatically created with updated changelog and version\n4. Review and merge the auto-generated PR - this will auto-deploy the release with binaries built from the release branch\n"
  },
  "candidelabs/voltaire": {
    "fetchedAt": "2025-11-12T22:50:54.165Z",
    "content": "<div align=\"center\">\n  <h1 align=\"center\">Voltaire</h1>\n</div>\n\n<!-- PROJECT LOGO -->\n\n<div align=\"center\">\n  <img src=\"https://github.com/user-attachments/assets/8b28b10f-495a-4cf7-8ec8-43c4cf684db8\">\n  <p>\n    <b>\n      Modular and lighting-fast Python-Rust Bundler for Ethereum EIP-4337 Account Abstraction\n    </b>\n   </p>\n</div>\n\n# Using an instance\n\nFor a quick bundler instance, use one of our [public hosted endpoints](https://docs.candide.dev/wallet/bundler/rpc-endpoints/) for your development.\n\n# Deployment\n\nDeploy Voltaire using the latest docker image\n\n```\ndocker run --net=host --rm -ti ghcr.io/candidelabs/voltaire/voltaire-bundler:latest --bundler_secret $BUNDLER_SECRET --rpc_url $RPC_URL --rpc_port $PORT --ethereum_node_url $ETHEREUM_NODE_URL --chain_id $CHAIN_ID --verbose --unsafe --disable_p2p\n```\n\n# Development\n\n## Ubuntu: Get started testing the bundler in 5 minutes \n\n### Install Poetry\n```\ncurl -sSL https://install.python-poetry.org | python3 -\n```\n### Install dependencies\n```\npoetry install\n```\n\n### Make sure you are using the right python version\n\n```\npoetry env use python3.11\n```\n\n### Install Docker\n\nFollow the installation guide to install [docker on ubuntu](https://docs.docker.com/engine/install/ubuntu/)\n\n### Post docker installation\n\nFollow the instruction for docker's [post linux instalation](https://docs.docker.com/engine/install/linux-postinstall/)  \n\n### Start geth\n```\ndocker run --rm -ti --name geth -p 8545:8545 ethereum/client-go:v1.10.26 \\\n  --miner.gaslimit 12000000 \\\n  --http --http.api personal,eth,net,web3,debug \\\n  --http.vhosts '*,localhost,host.docker.internal' --http.addr \"0.0.0.0\" \\\n  --ignore-legacy-receipts --allow-insecure-unlock --rpc.allow-unprotected-txs \\\n  --dev \\\n  --verbosity 4 \\\n  --nodiscover --maxpeers 0 --mine --miner.threads 1 \\\n  --networkid 1337\n```\n\n### Deploy the EntryPoint and fund the signer (in another terminal)\n```\ngeth --exec 'loadScript(\"scripts/deploy.js\")' attach http://0.0.0.0:8545\n```\n\n### Set env values\n```\nsource scripts/init-params \n```\n\n### Run the bundler\n```\npoetry run python3 -m voltaire_bundler --entrypoint $ENTRYPOINT --bundler_secret $BUNDLER_SECRET --chain_id 1337 --verbose\n```\n\n### Test the bundler by cloning `eth-infinitism/bundler-spec-tests`\n\nFollow the instruction in <a href='https://github.com/eth-infinitism/bundler-spec-tests'>eth-infinitism/bundler-spec-tests</a> to install dependencies and run the test\n\n## P2P rust section development\n\n### Install Rust\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n\n### Install build dependencies\n```\nsudo apt install musl-tools\nrustup target add x86_64-unknown-linux-musl\n```\n\n### Build the rust section using poetry script\n```\npoetry run build_p2p\n```\n\n## Contributions\n\nThank you for considering contributing to open-source code! We welcome contributions and are grateful for even the smallest of fixes. \n\nIf you want to contribute today or follow along with the contributor discussion, you can use our main discord to chat with us about the development of Voltaire.\n\n<!-- LICENSE -->\n## License\nLGPL\n\n<!-- ACKNOWLEDGMENTS -->\n## Acknowledgments\n\nNone of this would have been possible without the following teams and organizations below: \n\n* <a href='https://eips.ethereum.org/EIPS/eip-4337'>EIP-4337: Account Abstraction via Entry Point Contract specification </a>\n* <a href='https://github.com/eth-infinitism/bundler'>eth-infinitism/bundler</a>\n* <a href='https://github.com/sigp/lighthouse'>Lighthouse: Ethereum consensus client</a>\n* [The Ethereum Foundation](https://ethereum.foundation/) throught the Ecosystem Support Grants Program (ESP).\n"
  },
  "Elefria-Labs/evm-tools": {
    "fetchedAt": "2025-11-12T22:51:01.442Z",
    "content": "## Evm Tools - Tools for web3 and zk Dapps\n\nWebsite- [evmtools](https://evmtools.xyz)\n\nExtension- [evmtools](https://chromewebstore.google.com/detail/evm-tools/aibinghcdfagfoaajjiojfhkmnjmjmem)\n\nPreviously- [zkblock](https://zkblock.app)\n\n![](https://i.imgur.com/waxVImv.png)\n\nThis repository is part of evmtools (zkblock). If you want to request specific tools please create an issue or create a pr with the code.\n\n#### Run locally\n\n```\ngit clone https://github.com/heypran/evm-tools.git\n\ncd evm-tools\n\nnpm install\n\n```\n\nThen, you can run locally in development mode with live reload:\n\n```\nnpm run dev\n```\n\nOpen http://localhost:3000 in the browser.\n\n![](https://i.imgur.com/waxVImv.png)\n\n### Contributions\n\n> Everyone is welcome to contribute to this project.\n\n- Add more tools including testing libraries, new zk paradigms, testing, debugging tools\n- Improve the site's codebase\n- Discuss ideas in issues\n- Improve documentation\n"
  },
  "Elefria-Labs/zk-block": {
    "fetchedAt": "2025-11-12T22:51:01.884Z",
    "content": "## ZK-Block Boilerplate for ZK Dapps\n\nWebsite- [ZkBlock](https://zkblock.app)\nThe current sample zk-dapp has an age verification circuit.\n\n##### Repository for other tools [Zk-Tools](https://github.com/heypran/zk-tools)\n\n[Read boilerplate walkthrough guide on Hackernoon](https://hackernoon.com/how-to-use-a-zero-knowledge-dapp-boilerplate)\n\n![](https://i.imgur.com/waxVImv.png)\n\n### Getting started\n\n#### Pre-Requisite\n\n- Install [rust](https://www.rust-lang.org/tools/install)\n- Install [circom](https://docs.circom.io/getting-started/installation/)\n- Install [nodejs](https://nodejs.org/en/download/)\n\n#### How it Works?\n\n- Walkthrough [here](https://hackernoon.com/how-to-use-a-zero-knowledge-dapp-boilerplate)\n- Diagram [here](./ui/public/assets/images/howitworks.png)\n\n![](https://i.imgur.com/waxVImv.png)\n\n#### Frontend / UI\n\nRun the following command on your local environment:\n\n```\ngit clone https://github.com/heypran/zk-block.git\n\ncd zk-block/ui\n\nyarn install\n\n```\n\nThen, you can run locally in development mode with live reload:\n\n```\nyarn dev\n```\n\nOpen http://localhost:3000 in the browser.\n\nNow you play around with Age Verification UI, ( currently deployed on Polygon, and Harmony)\n\n![](https://i.imgur.com/waxVImv.png)\n\n### Backend ( Smart Contracts & Circuits)\n\nCreate a file `private.json` ( refer `private.example.json` ) inside `backend` folder and add your private key.\n\n##### Install deps\n\n```\ncd zk-block/backend\nyarn install\n```\n\n##### Compile contracts\n\n`yarn compile`\n\n##### Compile cicuits\n\n- Using groth16\n\n`yarn compile:circuits`\n\nPlease do not use this to compile circuits for production. Proper ceremony is required.\n\n- Using Plonk\n\n`yarn compile:pks`\n\nNote: Plonks does not require phase 2 trusted ceremony per circuit, it's enough with the powers of tau ceremony which is universal.\n\nThis repo uses [Hermez Cryptographic Setup](https://blog.hermez.io/hermez-cryptographic-setup/) with power of 14, which is more than enough for this repo purpose.\n\n##### Run tests\n\n`yarn test`\n\n##### Deploy Contract\n\nNote: Frontend already has deployed contract address configured ( inside `ui/src/config/constants`).\n\n```\nPolygon Testnet: 0xD8bfe046B2b2B66672841196E9aE3785200D5FE0\nHarmony Testnet: 0x457900273036dB9C5157Fcb1072294C0E7e720F4\n```\n\nSelect network - `chain.ts` contains network configuration. Network selected for deployment is mentioned in `hardhat.config.ts` file. Default is \"ONE\" ( HARMONY Network).\n\nRun below command to deploy\n\n`yarn deploy:agecheck --network testnet`\n\n### Contributions\n\n> Everyone is welcome to contribute to this project.\n\n- Add more beginner friendly circuits\n- Improve the site's codebase\n- Write tests\n- Discuss ideas in issues\n- Improve documentation\n"
  },
  "ethereum/remix-project": {
    "fetchedAt": "2025-11-12T22:51:10.309Z",
    "content": "<p align=\"center\">\n  <img src=\"./apps/remix-ide/src/assets/img/icon.png\" alt=\"Remix Logo\" width=\"200\"/>\n</p>\n<h3 align=\"center\">Remix Project</h3>\n    \n<div align=\"center\">\n\n\n[![CircleCI](https://img.shields.io/circleci/build/github/remix-project-org/remix-project?logo=circleci)](https://circleci.com/gh/remix-project-org/remix-project)\n[![Documentation Status](https://readthedocs.org/projects/remix-ide/badge/?version=latest)](https://remix-ide.readthedocs.io/en/latest/index.html)\n[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&logo=github)](https://github.com/remix-project-org/remix-project/blob/master/CONTRIBUTING.md)\n[![GitHub contributors](https://img.shields.io/github/contributors/remix-project-org/remix-project?style=flat&logo=github)](https://github.com/remix-project-org/remix-project/graphs/contributors)\n[![Awesome Remix](https://img.shields.io/badge/Awesome--Remix-resources-green?logo=awesomelists)](https://github.com/remix-project-org/awesome-remix)\n[![GitHub](https://img.shields.io/github/license/remix-project-org/remix-project)](https://github.com/remix-project-org/remix-project/blob/master/LICENSE)\n[![Discord](https://img.shields.io/badge/join-discord-brightgreen.svg?style=flat&logo=discord)](https://discord.gg/snsrYVU4Q7)\n[![X Follow](https://img.shields.io/twitter/follow/ethereumremix?style=flat&logo=x&color=green)](https://x.com/ethereumremix)\n\n</div>\n\n## Remix Project\n\n**Remix Project** is a rich toolset including Remix IDE, a comprehensive smart contract development tool. The Remix Project also includes Remix Plugin Engine and Remix Libraries which are low-level tools for wider use.  \n\n## Remix IDE\n**Remix IDE** is used for the entire journey of contract development by users of any knowledge level. It fosters a fast development cycle and has a rich set of plugins with intuitive GUIs. The IDE comes in 2 flavors and a VSCode extension:\n\n**Remix Online IDE**, see: [https://remix.ethereum.org](https://remix.ethereum.org)\n\n:point_right: Supported browsers: Firefox v100.0.1 & Chrome v101.0.4951.64. No support for Remix's use on tablets or smartphones or telephones.\n\n**Remix Desktop IDE**, see releases: [https://github.com/remix-project-org/remix-desktop/releases](https://github.com/remix-project-org/remix-desktop/releases)\n\n![Remix screenshot](https://github.com/remix-project-org/remix-project/raw/master/apps/remix-ide/remix-screenshot-400h.png)\n\n\n## Remix libraries \nRemix libraries are essential for Remix IDE's native plugins. Read more about libraries [here](libs/README.md)\n\n## Offline Usage\n\nThe `gh-pages` branch of [remix-live](https://github.com/remix-project-org/remix-live) always has the latest stable build of Remix. It contains a ZIP file with the entire build. Download it to use offline.\n\nNote: It contains the latest supported version of Solidity available at the time of the packaging. Other compiler versions can be used online only.\n\n\n## Setup\n\n* Install **Yarn** and **Node.js**. See [Guide for NodeJs](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm) and [Yarn install](https://classic.yarnpkg.com/lang/en/docs/install)<br/>\n*Supported versions:*\n```bash\n\"engines\": {\n    \"node\": \"^20.0.0\",\n    \"npm\": \"^6.14.15\"\n  }\n```\n* Install [Nx CLI](https://nx.dev/using-nx/nx-cli) globally to enable running **nx executable commands**.\n```bash\nyarn global add nx\n```\n* Clone the GitHub repository (`wget` need to be installed first):\n\n```bash\ngit clone https://github.com/remix-project-org/remix-project.git\n```\n* Build and Run `remix-project`:\n\n1. Move to project directory: `cd remix-project`\n2. Install dependencies: `yarn install` or simply run `yarn`\n3. Build Remix libraries: `yarn run build:libs`\n4. Build Remix project: `yarn build`\n5. Build and run project server: `yarn serve`. Optionally, run `yarn serve:hot` to enable hot module to reload for frontend updates.\n\nOpen `http://127.0.0.1:8080` in your browser to load Remix IDE locally.\n\nGo to your `text editor` and start developing. The browser will automatically refresh when files are saved.\n\n## Production Build\nTo generate react production builds for remix-project.\n```bash\nyarn run build:production\n```\nBuild can be found in `remix-project/dist/apps/remix-ide` directory.\n\n```bash\nyarn run serve:production\n```\nProduction build will be served by default to `http://localhost:8080/` or `http://127.0.0.1:8080/`\n\n## Nx Cloud caching\n\nThis repo uses Nx Cloud to speed up builds and keep CI deterministic via remote caching.\n\n- Configuration: `nx.json` uses the Nx Cloud runner and reads the token from the `NX_CLOUD_ACCESS_TOKEN` environment variable.\n- CI: CircleCI jobs automatically use `--cloud` when the token is present; for forked PRs (no secrets), they fall back to local-only caching. Build logs are stored under `logs/nx-build.log`.\n- Verifying locally: run the same target twice; the second run should print ‚ÄúNx read the output from the cache‚Äù. Example: `nx run remix-ide:build` and run it again.\n- Insights: View cache analytics and run details at https://nx.app (links appear in Nx output when the token is configured).\n\n## Docker:\n\nPrerequisites: \n* Docker (https://docs.docker.com/desktop/)\n* Docker Compose (https://docs.docker.com/compose/install/)\n\n### Run with docker\n\nIf you want to run the latest changes that are merged into the master branch then run:\n\n```\ndocker pull remixproject/remix-ide:latest\ndocker run -p 8080:80 remixproject/remix-ide:latest\n```\n\nIf you want to run the latest remix-live release run.\n```\ndocker pull remixproject/remix-ide:remix_live\ndocker run -p 8080:80 remixproject/remix-ide:remix_live\n```\n\n### Run with docker-compose:\n\nTo run locally without building you only need docker-compose.yaml file and you can run:\n\n```\ndocker-compose pull\ndocker-compose up -d\n```\n\nThen go to http://localhost:8080 and you can use your Remix instance.\n\nTo fetch the docker-compose file without cloning this repo run:\n```\ncurl https://raw.githubusercontent.com/remix-project-org/remix-project/master/docker-compose.yaml > docker-compose.yaml\n```\n\n### Troubleshooting\n\nIf you have trouble building the project, make sure that you have the correct version of `node`, `npm` and `nvm`. Also, ensure [Nx CLI](https://nx.dev/using-nx/nx-cli) is installed globally.\n\nRun:\n\n```bash\nnode --version\nnpm --version\nnvm --version\n```\n\nIn Debian-based OS such as Ubuntu 14.04LTS, you may need to run `apt-get install build-essential`. After installing `build-essential`, run `npm rebuild`.\n\n## Unit Testing\n\nRun the unit tests using library name like: `nx test <project-name>`\n\nFor example, to run unit tests of `remix-analyzer`, use `nx test remix-analyzer`\n\n## Browser Testing\n\nTo run the tests via Nightwatch:\n\n - Install webdrivers for the first time: `yarn install_webdriver`\n - Build & Serve Remix: `yarn serve`\n\n        \n**NOTE:**\n\n- **The `ballot` tests suite** requires running `ganache` locally.\n\n- **The `remixd` tests suite** requires running `remixd` locally.\n\n- **The `gist` tests suite** requires specifying a GitHub access token in **.env file**. \n```\n    gist_token = <token> // token should have permission to create a gist\n```\n\nThere is a script to allow selecting the browser and a specific test to run:\n\n```\nyarn run select_test\n```\n\nYou need to have \n\n- selenium running \n\n- the IDE running\n\n- optionally have remixd or ganache running\n\n### Splitting tests with groups\n\nGroups can be used to group tests in a test file together. The advantage is you can avoid running long test files when you want to focus on a specific set of tests within a test file.\n\nThese groups only apply to the test file, not across all test files. So for example group1 in the ballot is not related to a group1 in another test file.\n\nRunning a group only runs the tests marked as belonging to the group + all the tests in the test file that do not have a group tag. This way you can have tests that run for all groups, for example, to perform common actions.\n\nThere is no need to nu\n\n[... truncated ...]"
  },
  "remix-project-org/remix-reward": {
    "fetchedAt": "2025-11-12T22:51:10.753Z",
    "content": "# Remix Reward\n\ndeployed at 0x5d470270e889b61c08C51784cDC73442c4554011 on Optimism\n\n## Overview\n\nRemix reward is a program run by the Remix project. \nIt consists of a soulbound nft and is at the moment deployed in the Optimism chain.\n\nRemix Project rewards contributors, beta testers, and UX research participants with NFTs deployed on Optimism.\nRemix Reward holders are able to mint a second ‚ÄúRemixer‚Äù user NFT badge to any wallet address of their choice.\nThis feature is a way to reward Remix contributors to help grow our user base into a larger and more genuine open source community of practice.\n\nRemix Rewards are currently not transferable. This feature leaves open the future possibility of granting holders proportional voting power to help the community decide on new features for the IDE and/or other issues governing the development of the Remix toolset.\n\nSee the [remix reward website](https://rewards.remix.ethereum.eth.limo) for a list of already minted badges.\n\n## For Challengers\n\nThis contract allows users to publish zero knowledge proofs generated using the Remix Challenges program.\nThe Remix challenges program is run regularly by the Remix project. \nIt consists of a list of four questions.\nParticipants can generate a proof that they found the answer to the four questions without publicly revealing the answers. \nPublishing such a proof to the contract will mint a badge to the participant.\n\n## For Trainers\n\nWhen a trainer has been whitelisted in the contract (Please join our discord server and the community if you wish to be whitelisted as a trainer),\nhe/she has the ability to allow student addresses to mint a soulbound nft, within the context of a workshop, classes, etc...\n\nThe easiest way for a trainer to allow their students to mint a badge is to run the `grantRemixerMinting.ts` from the `scripts` folder.\nThen the student can either: \n    - run the `remixerMint.ts` script.\n    - or browse the [remix reward website](https://rewards.remix.ethereum.eth.limo) and go to the section `Mint a badge`\n\n"
  },
  "remix-project-org/remix-rewards-ui": {
    "fetchedAt": "2025-11-12T22:51:11.114Z",
    "content": "# üèó Scaffold-ETH\n\n> everything you need to build on Ethereum! üöÄ\n\nüß™ Quickly experiment with Solidity using a frontend that adapts to your smart contract:\n\n![image](https://user-images.githubusercontent.com/2653167/124158108-c14ca380-da56-11eb-967e-69cde37ca8eb.png)\n\n\n# üèÑ‚Äç‚ôÇÔ∏è Quick Start\n\nPrerequisites: [Node (v16 LTS)](https://nodejs.org/en/download/) plus [Yarn](https://classic.yarnpkg.com/en/docs/install/) and [Git](https://git-scm.com/downloads)\n\n> clone/fork üèó scaffold-eth:\n\n```bash\ngit clone https://github.com/scaffold-eth/scaffold-eth.git\n```\n\n> install and start your üë∑‚Äç Hardhat chain:\n\n```bash\ncd scaffold-eth\nyarn install\nyarn chain\n```\n\n> in a second terminal window, start your üì± frontend:\n\n```bash\ncd scaffold-eth\nyarn start\n```\n\n> in a third terminal window, üõ∞ deploy your contract:\n\n```bash\ncd scaffold-eth\nyarn deploy\n```\n\nüîè Edit your smart contract `YourContract.sol` in `packages/hardhat/contracts`\n\nüìù Edit your frontend `App.jsx` in `packages/react-app/src`\n\nüíº Edit your deployment scripts in `packages/hardhat/deploy`\n\nüì± Open http://localhost:3000 to see the app\n\n# üìö Documentation\n\nDocumentation, tutorials, challenges, and many more resources, visit: [docs.scaffoldeth.io](https://docs.scaffoldeth.io)\n\n# üî≠ Learning Solidity\n\nüìï Read the docs: https://docs.soliditylang.org\n\nüìö Go through each topic from [solidity by example](https://solidity-by-example.org) editing `YourContract.sol` in **üèó scaffold-eth**\n\n- [Primitive Data Types](https://solidity-by-example.org/primitives/)\n- [Mappings](https://solidity-by-example.org/mapping/)\n- [Structs](https://solidity-by-example.org/structs/)\n- [Modifiers](https://solidity-by-example.org/function-modifier/)\n- [Events](https://solidity-by-example.org/events/)\n- [Inheritance](https://solidity-by-example.org/inheritance/)\n- [Payable](https://solidity-by-example.org/payable/)\n- [Fallback](https://solidity-by-example.org/fallback/)\n\nüìß Learn the [Solidity globals and units](https://docs.soliditylang.org/en/latest/units-and-global-variables.html)\n\n# üõ† Buidl\n\nCheck out all the [active branches](https://github.com/scaffold-eth/scaffold-eth/branches/active), [open issues](https://github.com/scaffold-eth/scaffold-eth/issues), and join/fund the üè∞ [BuidlGuidl](https://BuidlGuidl.com)!\n\n  \n - üö§  [Follow the full Ethereum Speed Run](https://medium.com/@austin_48503/%EF%B8%8Fethereum-dev-speed-run-bd72bcba6a4c)\n\n\n - üéü  [Create your first NFT](https://github.com/scaffold-eth/scaffold-eth/tree/simple-nft-example)\n - ü•©  [Build a staking smart contract](https://github.com/scaffold-eth/scaffold-eth/tree/challenge-1-decentralized-staking)\n - üèµ  [Deploy a token and vendor](https://github.com/scaffold-eth/scaffold-eth/tree/challenge-2-token-vendor)\n - üé´  [Extend the NFT example to make a \"buyer mints\" marketplace](https://github.com/scaffold-eth/scaffold-eth/tree/buyer-mints-nft)\n - üé≤  [Learn about commit/reveal](https://github.com/scaffold-eth/scaffold-eth/tree/commit-reveal-with-frontend)\n - ‚úçÔ∏è  [Learn how ecrecover works](https://github.com/scaffold-eth/scaffold-eth-examples/tree/signature-recover)\n - üë©‚Äçüë©‚Äçüëß‚Äçüëß  [Build a multi-sig that uses off-chain signatures](https://github.com/scaffold-eth/scaffold-eth/tree/meta-multi-sig)\n - ‚è≥  [Extend the multi-sig to stream ETH](https://github.com/scaffold-eth/scaffold-eth/tree/streaming-meta-multi-sig)\n - ‚öñÔ∏è  [Learn how a simple DEX works](https://medium.com/@austin_48503/%EF%B8%8F-minimum-viable-exchange-d84f30bd0c90)\n - ü¶ç  [Ape into learning!](https://github.com/scaffold-eth/scaffold-eth/tree/aave-ape)\n\n# üíå P.S.\n\nüåç You need an RPC key for testnets and production deployments, create an [Alchemy](https://www.alchemy.com/) account and replace the value of `ALCHEMY_KEY = xxx` in `packages/react-app/src/constants.js` with your new key.\n\nüì£ Make sure you update the `InfuraID` before you go to production. Huge thanks to [Infura](https://infura.io/) for our special account that fields 7m req/day!\n\n# üèÉüí® Speedrun Ethereum\nRegister as a builder [here](https://speedrunethereum.com) and start on some of the challenges and build a portfolio.\n\n# üí¨ Support Chat\n\nJoin the telegram [support chat üí¨](https://t.me/joinchat/KByvmRe5wkR-8F_zz6AjpA) to ask questions and find others building with üèó scaffold-eth!\n\n---\n\nüôè Please check out our [Gitcoin grant](https://gitcoin.co/grants/2851/scaffold-eth) too!\n\n### Automated with Gitpod\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#github.com/scaffold-eth/scaffold-eth)\n"
  },
  "remix-project-org/remix-challenges": {
    "fetchedAt": "2025-11-12T22:51:11.515Z",
    "content": "## Introduction\n\n Remix Challenges is an onchain quiz that uses a zk proof.  People submitting answers won't reveal their solutions.\n\n  - Why not just code the challenge in Solidity?\n  \n All the data in the Ethereum blockchain is public and visible. This means that if the challenge is coded in Solidity, the first user who finds the solution will submit that solution in **a transaction** and thus the solution will be visible by everyone.\n\n Using zk proof, we only require the user post a **proof** that the challenge has been successfully completed.\n\n  - Is it possible to double post the same proof?\n\nThere are 2 parts to this question - can the same person (address) post the same proof?  And can a different address post the same proof?\n\nIncorporated in the proof is a special parameter named `externalNullifier` - a number generated from a timestamp. \nIf a different value is used in the nullifier, then a different proof will be generated, but it will still show that the questions were correctly answered. \n\nThe smart contract used for verifying the proof will remember the nullifier.  \n\nAn address (a user) can only submit a single proof - even if another `nullifier` is used.  And a `nullifier` can only be used once.\n\nSo even when the actual proof becomes public, it won't be possible to re-post that specific proof.  \n\n  - If a user knows how to complete a challenge, can he compute with another salt and win the game again?\n\nThe contract keeps a mapping of all the users that completed the challenge (using `msg.sender`), it is also possible to ask for a signed nullifier instead of directly using `msg.sender`\n \n ## Completing the challenge\n ### Setup\n\n - Clone the following repository in Remix `https://github.com/yann300/remix-challenges`.\n \n   - In Remix, to find the **clone** option, go to the hamburger menu at the top of the File Explorer.\n   \n - Once the cloned repo has been retrieved, open the file, **verify-solution.ts**, which is in the **scripts** folder.\n \n  ### Answering the questions\n - Starting on line 76 of **verify-solution.ts**, input the answers to the questions.\n - Run the script by either right-clicking on the script in the File Explorer or clicking on the green play button.\n - If the program executes correctly, you have successfully answered the 4 questions.\n\n - In Remix's terminal, you'll see a log of the proof. The script will save this proof in the file named **zk/proof_calldata.json**.\n \n - **If you have not answered the questions correctly**, the proof will NOT be generated and the file **zk/proof_calldata.json** will not be created.\n - This proof can be used in a **verifier** to prove that you found the 4 values. By doing so, only the proof needs to be shared, you don't need to share the 4 values, but everyone can be certain that you know these values.\n - Go to the next steps.\n\n ## Mint a Remixer Badge using the generated proof\n\n - Now that you have a proof, you can publish the proof onchain and mint a remixer badge.\n - Switch to the Optimism network. Make sure that in the Deploy & Run plugin, you are connected to Optimism and that your browser wallet (often MetaMask) is also connected there and that you have enough ETH to pay for the minting (usually about 40 cents).\n - Open the file scripts/publish-solution.ts.\n - This script will use the proof generated in the previous section **zk/proof_calldata.json** for calling the function `publishChallenge` in the Remix Rewards contract.\n - Run the transaction for publishing the solution.\n - Once the solution has been published head to https://rewards.remix.ethereum.eth.limo to see the newly created badge.\n\n\n\n\n\n\n"
  },
  "collinsadi/diamonds": {
    "fetchedAt": "2025-11-12T22:51:18.842Z",
    "content": "# diamondscaffold\n\n**diamondscaffold** is a CLI tool that helps developers scaffold an EIP-2535 diamond structure with ease. Users can choose between Hardhat or Foundry as their development environment, and they can select between templates like \"ERC20\", \"ERC721\", or a default Diamond template to kickstart their smart contract development.\n\n![Screenshot](./image.png)\n\n## Features\n\n- Scaffold **EIP-2535 Diamond** architecture.\n- Choose between **Hardhat** or **Foundry** frameworks.\n- Select from multiple templates: **ERC20**, **ERC721**, and a **default** Diamond template.\n- Option to scaffold in **JavaScript** or **TypeScript** when using Hardhat.\n- Install project dependencies automatically when using Hardhat.\n\n## Installation\n\nYou can install the package globally via npm to use it as a CLI tool.\n\n```bash\nnpm install -g diamondscaffold\n```\n\n## Usage\n\nOnce installed, use the `diamonds init` command to scaffold an EIP-2535 Diamond structure.\n\n### Basic Command\n\n```bash\ndiamonds init\n```\n\nThis command will prompt you with several questions to help set up your project. Here's the sequence of questions asked:\n\n1. **Project Name**: The name of your project (default is `my-app`).\n2. **Template**: Choose a template to scaffold: `Default`, `ERC20`, or `ERC721`.\n3. **Framework**: Choose between `Foundry` or `Hardhat`.\n4. **Language** (only for Hardhat): Choose between `JavaScript` or `TypeScript`.\n5. **Install Dependencies** (only for Hardhat): Option to install dependencies automatically, provided you have an active internet connection.\n\n### Example\n\n```bash\ndiamonds init\n```\n\nDuring the initialization, you will be prompted with questions like:\n\n```\nüìù What is the name of your project? (default: my-app)\nüìë  What Template would you like to scaffold? (choices: Default, ERC20, ERC721)\nüîß Which framework would you like to use? (choices: Foundry, Hardhat)\nüìö Which language do you want to use? (choices: JavaScript, TypeScript)\nDo you want to install project dependencies? (only for Hardhat)\n```\n\nTo scaffold a diamond project using **Hardhat**, **ERC20**, and **TypeScript** with automatic dependency installation:\n\n```bash\ndiamonds init\n```\n\n### Available Templates\n\n1. **ERC20**: A diamond contract implementing the ERC20 token standard.\n2. **ERC721**: A diamond contract implementing the ERC721 NFT standard.\n3. **Default**: A basic diamond structure with no additional functionality, providing a clean slate to start with.\n\n## Commands\n\n### Version Commands\n\n```bash\n# Check current version\ndiamonds --version\ndiamonds -v\n\n# Update to latest version\ndiamonds update\n```\n\n\n### Hardhat Commands\n\nIf you scaffold with Hardhat, these commands will be available:\n\n- Compile the project:\n\n  ```bash\n  npx hardhat compile\n  ```\n\n- Run tests:\n\n  ```bash\n  npx hardhat test\n  ```\n\n- Deploy the contract:\n  ```bash\n  npx hardhat run scripts/deploy.js\n  ```\n\n### Foundry Commands\n\nIf you scaffold with Foundry, these commands will be available:\n\n- Compile the project:\n\n  ```bash\n  forge build\n  ```\n\n- Run tests:\n\n  ```bash\n  forge test\n  ```\n\n- Deploy the contract:\n  ```bash\n  forge script <script-file> --broadcast\n  ```\n\n## Contribution\n\nContributions to **diamondscaffold** are welcome! If you'd like to contribute checkout:\n\n1. [Contribution guildlines](https://github.com/collinsadi/diamonds/blob/main/CONTRIBUTION_GUIDELINES.md)  \n2. [Git guildlines](https://github.com/collinsadi/diamonds/blob/main/GIT_GUIDELINES.md)  \n3. [Issues guildlines](https://github.com/collinsadi/diamonds/blob/main/ISSUES_GUIDELINES.md)  \n\n## License\n\nThis package is licensed under the MIT License. See the [LICENSE](./LICENSE) file for more information.\n"
  },
  "runtimeverification/simbolik-examples": {
    "fetchedAt": "2025-11-12T22:51:29.026Z",
    "content": "# Simbolik Example\n\nWelcome to the Simbolik Example repository, your gateway to exploring Simbolik - the Solidity Debugger.\n\n## Getting Started\n\nIf you haven't done so yet, follow the steps from our [Getting Started](https://docs.runtimeverification.com/simbolik/overview/getting-started) guide to set up your environment and install the Simbolik VSCode extension.\n\nOnce you're set up, open the `test/DebugCPAMM.sol` file in VSCocde.\nYou'll find a `‚ñ∑ Debug` button above to the `debugAddLiquidity` and `debugSwap` functions.\nSimply click it to start the debugging process.\n\nHappy debugging!\n\nYou can learn more about Simbolik in our [documentation](https://docs.runtimeverification.com/simbolik).\n"
  },
  "runtimeverification/simbolik-vscode": {
    "fetchedAt": "2025-11-12T22:51:29.312Z",
    "content": "# Solidity Debugger for Visual Studio Code\n\nSimbolik is a Solidity debugger for **Foundry** projects.\nIt allows you to step through your Solidity code line by line, set breakpoints and inspect variables.\n\n## Quick Start\n\nOn first use Simbolik may ask for GitHub access. Alternatively, you can provide a Simbolik API key, [read more](https://docs.runtimeverification.com/simbolik/overview/getting-started).\n\nSimbolik follows a **zero-configuration** approach where possible and falls back to **configuration-as-code** where needed.\nFor simple smart contracts, you can start debugging with just a single click on the `‚ñ∑ Debug`-button.\n\n![Zero Configuration](images/readme/zero-config.gif)\n\nFor complex smart contracts, you set up your debugging session similarly to a Foundry unit test:\nYou first define a `setUp` function to initialize your contracts, and then provide a test function.\nIf the test function is public and does not have parameters, the `‚ñ∑ Debug`-button shows up, [read more](https://docs.runtimeverification.com/simbolik/overview/starting-the-debugger#debuggable-functions).\n\n## Inspect Variables\n\n![Inspect Variables](images/readme/variables.gif)\n\n## Time Travel Debugging\n\n![Time Travel Debugging](images/readme/time-travel-debugging.gif)\n\n## EVM Level Debugging\n\n![EVM Level Debugging](images/readme/evm-debugging.gif)\n\n## Questions?\n\nDo you have questions, or need help?\n\nVisit our Documentation: https://docs.runtimeverification.com/simbolik \\\nJoin our Discord: https://discord.gg/jnvEeDxW \\\nJoin our TG group: https://t.me/rv_simbolik\n\n\n"
  },
  "shazow/whatsabi": {
    "fetchedAt": "2025-11-12T22:51:36.420Z",
    "content": "![WhatsABI](assets/logo.png)\n\n# WhatsABI\n\nGuess an ABI and detect proxies from an Ethereum bytecode, even if it's unverified.\n\nWhatsABI is perfect for building procedural frontends, embedding in wallets, block explorers, or doing bytecode analysis.\n\nü§ù Used by **Otterscan, Sourcify, Ondora, Rivet,** [and more great projects](#projects-powered-by-whatsabi).\n\n## Features\n\n**What can WhatsABI do**?\n- Return selectors from bytecode.\n- Look up function signatures from selectors.\n- Helpers for looking up ABI and signatures from public databases (like Sourcify, Etherscan, Blockscout, OpenChain, 4Byte).\n- ‚ú® Resolve proxy contracts!\n- Small bundle (less than 15 KB) that works with Ethers.js, Viem, and others.\n\n**WhatsABI is different from other EVM analysis tools in some important ways:**\n- Built in Typescript with minimal dependencies, so that it is **runnable in the browser and embeddable in wallets.**\n- Algorithms used are limited to `O(instructions)` with a small constant factor, so that **complex contracts don't cause it to time out or use unbounded memory.**\n- Does not rely on source code, so it **works with unverified contracts.**\n- Does not assume the source language, so it can work for source languages other than Solidity (Vyper, or even hand-written assembly).\n- Permissive open source (MIT-licensed), so that anyone can use it.\n\n## Usage\n\nGenerated docs: https://shazow.github.io/whatsabi/\n\nQuick start:\n\n```typescript\nimport { ethers } from \"ethers\";\nimport { whatsabi } from \"@shazow/whatsabi\";\n\n// Works with any provider (or client) library like Ethers.js, Viem, or Web3.js!\nconst provider = ethers.getDefaultProvider();\nconst address = \"0x00000000006c3852cbEf3e08E8dF289169EdE581\"; // Or your fav contract address\n\n// Quick-start:\n\nconst result = await whatsabi.autoload(address, { provider });\nconsole.log(result.abi);\n// -> [ ... ]\n```\n\nAnother quick example with Viem:\n\n```typescript\nimport { createPublicClient, http } from 'viem'\nimport { mainnet } from 'viem/chains'\nimport { whatsabi } from \"@shazow/whatsabi\";\n \nconst client = createPublicClient({ chain: mainnet, transport: http() })\nconst result = await whatsabi.autoload(address, { provider: client });\n```\n\n\nBreaking it down, here's what autoload is doing on the inside:\n\n```typescript\nconst code = await provider.getCode(address); // Load the bytecode\n\n// Get just the callable selectors\nconst selectors = whatsabi.selectorsFromBytecode(code);\nconsole.log(selectors); // -> [\"0x06fdde03\", \"0x46423aa7\", \"0x55944a42\", ...]\n\n// Get an ABI-like list of interfaces\nconst abi = whatsabi.abiFromBytecode(code);\nconsole.log(abi);\n// -> [\n//  {\"type\": \"event\", \"hash\": \"0x721c20121297512b72821b97f5326877ea8ecf4bb9948fea5bfcb6453074d37f\"},\n//  {\"type\": \"function\", \"payable\": true, \"selector\": \"0x06fdde03\", ...},\n//  {\"type\": \"function\", \"payable\": true, \"selector\": \"0x46423aa7\", ...},\n//   ...\n\n// We also have a suite of database loaders for convenience\nconst signatureLookup = new whatsabi.loaders.OpenChainSignatureLookup();\nconsole.log(await signatureLookup.loadFunctions(\"0x06fdde03\"));\n// -> [\"name()\"]);\nconsole.log(await signatureLookup.loadFunctions(\"0x46423aa7\"));\n// -> [\"getOrderStatus(bytes32)\"]);\n\n// We also have event loaders!\nconsole.log(await signatureLookup.loadEvents(\"0x721c20121297512b72821b97f5326877ea8ecf4bb9948fea5bfcb6453074d37f\"));\n// -> [\"CounterIncremented(uint256,address)\"]\n\n// There are more fancy loaders in whatsabi.loaders.*, take a look!\n\n// Here's a multiloader with an Etherscan API key, it can be used with autoload below.\n// Each source will be attempted until a result is found.\nconst loader = new whatsabi.loaders.MultiABILoader([\n  new whatsabi.loaders.SourcifyABILoader(),\n  new whatsabi.loaders.EtherscanV2ABILoader({\n    apiKey: \"...\", // Replace the value with your Etherscan API key\n  }),\n  new whatsabi.loaders.BlockscoutABILoader({\n    apiKey: \"...\", // Replace the value with your Blockscout API key\n  }),\n]);\nconst { abi, name, /* ... other metadata */ } = await loader.getContract(address));\n```\n\nSee [whatsabi.loaders](https://shazow.github.io/whatsabi/modules/loaders.html) for more examples of what our loaders can do, like loading verified contract source code and compiler settings.\n\nAll together with our do-all-the-things helper:\n\n```typescript\n...\n\nlet result = await whatsabi.autoload(address, {\n  provider: provider,\n\n  // * Optional loaders:\n  // abiLoader: whatsabi.loaders.defaultABILoader,\n  // signatureLoader: whatsabi.loaders.defaultSignatureLookup,\n\n  // There is a handy helper for adding the default loaders but with your own settings\n  ... whatsabi.loaders.defaultsWithEnv({\n    CHAIN_ID: 42161,\n    ETHERSCAN_API_KEY: \"MYSECRETAPIKEY\",\n  }),\n\n  // * Optional hooks:\n  // onProgress: (phase: string) => { ... }\n  // onError: (phase: string, context: any) => { ... }\n\n  onProgress: (phase) => console.log(\"autoload progress\", phase),\n  onError: (phase, context) => console.log(\"autoload error\", phase, context),\n\n  // * Optional overrides:\n  // addressResolver: (name: string) => Promise<string>\n\n  // * Optional settings:\n  // followProxies: false,\n  // enableExperimentalMetadata: false,\n});\n\nconsole.log(result.abi);\n\n// Detail will vary depending on whether `address` source code was available,\n// or if bytecode-loaded selector signatures were available, or\n// if WhatsABI had to guess everything from just bytecode.\n\n// We can even detect and resolve proxies!\nif (result.followProxies) {\n    console.log(\"Proxies detected:\", result.proxies);\n\n    result = await result.followProxies();\n    console.log(result.abi);\n}\n```\n\nOr we can auto-follow resolved proxies, and expand parts of the result object:\n\n```typescript\nconst { abi, address } = await whatsabi.autoload(\n    \"0x4f8AD938eBA0CD19155a835f617317a6E788c868\",\n    {\n        provider,\n        followProxies: true,\n    },\n});\n\nconsole.log(\"Resolved to:\", address);\n// -> \"0x964f84048f0d9bb24b82413413299c0a1d61ea9f\"\n```\n\n\n## See Also\n\n### Projects powered by WhatsABI\n\n* ‚≠ê [otterscan.io](https://otterscan.io/) - Open source block explorer, [contract interactions powered by WhatsABI](https://x.com/otterscan/status/1817261257994756569)\n* ‚≠ê [sourcify.dev](https://sourcify.dev/) - Verified source code API, proxy resolving powered by WhatsABI\n* ‚≠ê [rivet](https://github.com/paradigmxyz/rivet) - Developer Wallet & DevTools for Anvil\n* ‚≠ê [ondora.xyz](https://www.ondora.xyz/) - Cross-chain explorer and search engine\n* ‚≠ê [thirdweb](https://thirdweb.com/) - Web3 SDK, automatic ABI Resolution powered by WhatsABI\n* [callthis.link](https://callthis.link/) - Transaction builder powered by WhatsABI\n* [whatsabi-ui](https://0xcompose.github.io/whatsabi-ui/) - A simple UI for WhatsABI - [github.com/0xcompose/immortal-ui](https://github.com/0xcompose/whatsabi-ui)\n* [ethcmd.com](https://www.ethcmd.com/) - Contract explorer frontend, [uses WhatsABI for unverified contracts](https://github.com/verynifty/ethcmd)\n* [monobase.xyz](https://monobase.xyz) - Universal frontend, [uses WhatsABI for unverified contracts](https://twitter.com/nazar_ilamanov/status/1659648915195707392)\n* [savvy](https://svvy.sh/) - Contract explorer with in-browser devnet execution\n* [blockscout](https://www.blockscout.com/) - Open source block explorer\n* [curvegrid](https://www.curvegrid.com/) - Platform for building EVM applications\n* [tevm](https://tevm.sh/) - EVM toolkit for TypeScript\n\n### Talks & Presentations\n\n* [The Bytecode with Shafu - WhatsABI](https://www.youtube.com/watch?v=Io8bcYFjoEE) (July 2024)\n* [WhatsABI? - Seminar for Spearbit](https://www.youtube.com/watch?v=sfgassm8SKw) (April 2023)\n\n## Some Cool People Said...\n\n> Omg WhatsABI by @shazow is so good that it can solve CTFs.  \n> In one of my CTFs, students are supposed to find calldata that doesn‚Äôt revert  \n> WhatsABI just spits out the solution automaticallyüòÇ I‚Äôm impressed!üëè\n>  \n> üó£Ô∏è [Nazar Ilamanov](https://twitter.com/nazar_ilamanov/status/1661240265955495936), creator of [monobase.xyz](https://monobase.xyz/)\n\n> WhatsAB\n\n[... truncated ...]"
  },
  "alchemyplatform/rundler": {
    "fetchedAt": "2025-11-12T22:51:43.331Z",
    "content": "# Rundler\n\n[![gh_ci_badge]][gh_ci_link]\n[![tg_badge]][tg_link]\n\n[gh_ci_badge]: https://github.com/alchemyplatform/rundler/workflows/ci/badge.svg\n[gh_ci_link]: https://github.com/alchemyplatform/rundler/actions/workflows/ci.yml\n[tg_badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&url=https://mogyo.ro/quart-apis/tgmembercount?chat_id=rundler\n[tg_link]: https://t.me/rundler\n\n**High-performance, modular implementation of an ERC-4337 bundler**\n\n![Rundler Banner](./docs/images/rundler-banner.jpg)\n\n[Run](#running) | [Developer Docs](./docs)\n\nüöß *Under active development, see [status](#status) below.* üöß\n\n## Overview\n\n**Rundler** (**R**ust B**undler**) is an [ERC-4337][eip_link] bundler implementation written in Rust. Rundler is designed to achieve high-performance and high-reliability in cloud deployments via a modular architecture. \n\nBuilt, maintained, and used by [Alchemy](https://www.alchemy.com/) to push the limits of user experience on EVM chains via [Account Abstraction](https://www.alchemy.com/blog/account-abstraction).\n\n### Goals\n\nRundler is meant to power the ERC-4337 ecosystem with an implementation that users can rely on to scale to their needs while maintaining high reliability. As ERC-4337 is a nascent technology, Rundler strives to be on the bleeding edge of feature support and the team will be contributing to push the protocol forward.\n\nOur goals with Rundler:\n\n1. **ERC-4337 Specification Compliance**: Rundler strives to implement the full ERC-4337 specification and to maintain support as the specification changes and new onchain components are released. This includes new Entry Point contract support, support for the upcoming P2P mempool specification, support for alternative mempools, and more.\n2. **High Performance and Reliability**:  Rundler strives to power the most demanding workloads in cloud environments. Rust was chosen for its high performance and memory safety. Rundler's modular architecture lets providers choose to run the stateless components (RPC, builder) in a fully horizontally scalable manner connecting to the stateful components (mempool, p2p, event cache) via the network. Rundler's bundle builder is designed to be able to support the full gas throughput of the network it's building for.\n3. **Extendability/Chain Support**: ERC-4337 is designed to support any EVM chain. However, different EVM supporting networks have different rules around how they support things like gas usage, gas fees, precompiles, etc. Rundler is designed to be extendable and easily adapted to support any EVM chain.\n4. **Modularity**: Rundler is written in a modular manner, allowing its components to be run as a single integrated binary, or as a distributed system. Rundler also strives for its individual crates to be used to support future ERC-4337 tooling.\n\n## Status\n\nRundler is under active development. It is used in Alchemy's cloud to power Alchemy's Account Abstraction APIs. However, Rundler is rapidly being upgraded, features are being added, interfaces will have breaking changes, and the ERC-4337 spec is evolving from onchain learnings.\n\nThe documentation is work in progress, and we are working to improve it. Please [reach out](#help) with any questions.\n\n**Use in production at your own risk.**\n\n### ERC-4337 Entry Point Version Support\n\nRundler currently supports the following Entry Point versions:\n  * [v0.6.0](https://github.com/eth-infinitism/account-abstraction/tree/v0.6.0)\n  * [v0.7.0](https://github.com/eth-infinitism/account-abstraction/tree/v0.7.0)\n\nSee more on Entry Point support [here](docs/architecture/entry_point.md).\n\n### Chain Support\n\nRundler has been tested on the following networks and their testnets:\n\n* Ethereum\n* OP Stack\n    * Generally any OP stack chain should work.\n    * Rundler has been explicitly tested on Optimism, Base, Zora, and Frax.\n* Arbitrum Orbit\n    * Generally any Arbitrum Orbit chain should work.\n    * Rundler has been explicitly tested on Arbitrum One.\n* Polygon POS\n\n## Developers\n\n### Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n\n### Running\n\nThe easiest way to run Rundler is via a docker container. There is currently no pre-built image. See our [docker documentation](docs/docker.md) for further instructions.\n\n### Developing\n\nFor detailed instructions see [developing](docs/developing.md).\n\nInstall [prerequisites](docs/developing.md#setup).\n\nClone the repository and checkout submodules:\n```\ngit clone https://github.com/alchemyplatform/rundler\ncd rundler\ngit submodule update --init --recursive\n```\n\nRun unit tests:\n```\nmake test-unit\n```\n\nRun ERC-4337 spec tests:\n```\n# Only need to run once to install testing frameworks\ncd test/spec-tests/v0_6/bundler-spec-tests && pdm install && pdm run update-deps\ncd test/spec-tests/v0_7/bundler-spec-tests && pdm install && pdm run update-deps\n\n# Run the v0.6 and v0.7 tests\nmake test-spec-integrated\n```\n\n### Help\n\nIf you have questions regarding the Rundler codebase, please first look through our [documentation](./docs/).\n\nWith further questions:\n\n* [Github discussions](https://github.com/alchemyplatform/rundler/discussions)\n* [Telegram][tg_link]\n* [Github issues](https://github.com/alchemyplatform/rundler/issues/new/choose)\n\nIf you have questions regarding Alchemy's APIs or service, kindly refrain from discussion here. Please join the [Discord](https://discord.com/invite/alchemyplatform) or reach out to support@alchemy.com.\n\n### Security\n\nFor security concerns do not file a public ticket, please reach out to security@alchemy.com.\n\nSee [SECURITY.md](SECURITY.md) for details.\n\n## Acknowledgements\n\nThe work on this project would not have been possible without the amazing contributions from:\n\n- [ERC-4337 team](https://github.com/eth-infinitism/account-abstraction): The ERC-4337 team has pioneered the standard, and has answered countless questions during our development. They developed the [bundler reference implementation](https://github.com/eth-infinitism/bundler) and [spec tests](https://github.com/eth-infinitism/bundler-spec-tests) that were invaluable during our development process. We are excited to continue to work with this team to push ERC-4337 ahead.\n- [Reth](https://github.com/paradigmxyz/reth): Shout-out to the Reth team, from which we've taken inspiration for many of our practices in this repo (including this README). They are pushing the Ethereum Rust ecosystem forward in an open way. We thank the Reth team for their continued contributions.\n\n[eip_link]: https://eips.ethereum.org/EIPS/eip-4337\n\n## License\n\nThe Rundler library (i.e. all code outside of the `bin` directory) is licensed under the GNU Lesser General Public License v3.0, also included in our repository in the COPYING.LESSER file.\n\nThe Rundler binaries (i.e. all code inside of the `bin` directory) are licensed under the GNU General Public License v3.0, also included in our repository in the COPYING file.\n\nThe Rundler library and binaries are licensed under Unicode License v3.0, also included in the UNICODE file.\n\nCopyright 2023 Alchemy Insights, Inc.\n\nContact: Alchemy Insights, Inc., 548 Market St., PMB 49099, San Francisco, CA 94104; legal@alchemy.com\n"
  },
  "alexfertel/bulloak": {
    "fetchedAt": "2025-11-12T22:51:50.162Z",
    "content": "<p align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/036bad22-3b0d-4ea3-9338-faecd017a290\" width=\"200\"></a>\n    <br>\n    <a href=\"https://crates.io/crates/bulloak/\">\n        <img src=\"https://img.shields.io/crates/v/bulloak?style=flat&labelColor=1C2C2E&color=C96329&logo=Rust&logoColor=white\">\n    </a>\n    <a href=\"https://codecov.io/gh/alexfertel/bulloak\">\n        <img src=\"https://codecov.io/github/alexfertel/bulloak/coverage.svg?branch=main\">\n    </a>\n</p>\n\n# bulloak\n\nA Solidity test generator based on the\n[Branching Tree Technique](https://twitter.com/PaulRBerg/status/1682346315806539776).\n\n- [Installation](#installation)\n  - [VSCode](#vscode)\n- [Usage](#usage)\n  - [`bulloak scaffold`](#scaffold-solidity-files)\n  - [`bulloak check`](#check-that-your-code-and-spec-match)\n    - [Rules](#rules)\n  - [Compiler Errors](#compiler-errors)\n- [Trees](#trees)\n  - [Terminology](#terminology)\n  - [Spec](#spec)\n- [Output](#output)\n- [Examples](#examples)\n- [Contributing](#contributing)\n- [Publishing](#publishing)\n- [Supported By](#supported-by)\n- [License](#license)\n\n<!-- prettier-ignore -->\n> [!WARNING]\n> Note that `bulloak` is still `0.*.*`, so breaking changes\n> [may occur at any time](https://semver.org/#spec-item-4). If you must depend\n> on `bulloak`, we recommend pinning to a specific version, i.e., `=0.y.z`.\n\n## Installation\n\n```bash\ncargo install bulloak\n```\n\n### VSCode\n\nThe following VSCode extensions are not essential but they are recommended for a\nbetter user experience:\n\n- [Solidity Inspector](https://marketplace.visualstudio.com/items?itemName=PraneshASP.vscode-solidity-inspector) -\n  syntax highlighting for `.tree` files\n- [Ascii Tree Generator](https://marketplace.visualstudio.com/items?itemName=aprilandjan.ascii-tree-generator):\n  convenient way to generate ASCII trees\n\n## Usage\n\n`bulloak` implements two commands:\n\n- `bulloak scaffold`\n- `bulloak check`\n\n### Scaffold Solidity Files\n\nSay you have a `foo.tree` file with the following contents:\n\n```tree\nFooTest\n‚îî‚îÄ‚îÄ When stuff is called // Comments are supported.\n    ‚îî‚îÄ‚îÄ When a condition is met\n        ‚îî‚îÄ‚îÄ It should revert.\n            ‚îî‚îÄ‚îÄ Because we shouldn't allow it.\n```\n\nYou can use `bulloak scaffold` to generate a Solidity contract containing\nmodifiers and tests that match the spec described in `foo.tree`. The following\nwill be printed to `stdout`:\n\n```solidity\n// $ bulloak scaffold foo.tree\n// SPDX-License-Identifier: UNLICENSED\npragma solidity 0.8.0;\n\ncontract FooTest {\n    modifier whenStuffIsCalled() {\n        _;\n    }\n\n    function test_RevertWhen_AConditionIsMet() external whenStuffIsCalled {\n        // It should revert.\n        //     Because we shouldn't allow it.\n    }\n}\n```\n\nYou can use the `-w` option to write the generated contracts to the file system.\nSay we have a bunch of `.tree` files in the current working directory. If we run\nthe following:\n\n```text\n$ bulloak scaffold -w ./**/*.tree\n```\n\n`bulloak` will create a `.t.sol` file per `.tree` file and write the generated\ncontents to it.\n\nIf a `.t.sol` file's title matches a `.tree` in the same directory, then\n`bulloak` will skip writing to that file. However, you may override this\nbehavior with the `-f` flag. This will force `bulloak` to overwrite the contents\nof the file.\n\n```text\n$ bulloak scaffold -wf ./**/*.tree\n```\n\nNote all tests are showing as passing when their body is empty. To prevent this,\nyou can use the `-S` (or `--vm-skip`) option to add a `vm.skip(true);` at the\nbeginning of each test function. This option will also add an import for\nforge-std's `Test.sol` and all test contracts will inherit from it.\n\nYou can skip emitting the modifier definitions by passing the `-m` (or\n`--skip-modifiers`) flag. Functions will still reference these modifiers in\ntheir signatures; only the modifier definitions themselves are omitted. This is\nuseful together with bulloak check `-m` (which suppresses missing‚Äëmodifier\nviolations). If you use `-m` alone, the scaffolded file will not compile until\nyou provide the modifier definitions (or re-run without `-m`).\n\nTo normalize the generated comments, pass `-F` (or `--format-descriptions`).\nWhen enabled, bulloak capitalizes the first letter of each branch description\nand ensures it ends with a dot, so you don't need to touch the `.tree` file to\nget consistent sentence casing in the scaffolded test bodies.\n\n### Check That Your Code And Spec Match\n\nYou can use `bulloak check` to make sure that your Solidity files match your\nspec. For example, any missing tests will be reported to you.\n\nSay you have the following spec:\n\n```tree\nHashPairTest\n‚îú‚îÄ‚îÄ It should never revert.\n‚îú‚îÄ‚îÄ When first arg is smaller than second arg\n‚îÇ   ‚îî‚îÄ‚îÄ It should match the result of `keccak256(abi.encodePacked(a,b))`.\n‚îî‚îÄ‚îÄ When first arg is bigger than second arg\n    ‚îî‚îÄ‚îÄ It should match the result of `keccak256(abi.encodePacked(b,a))`.\n```\n\nAnd a matching Solidity file:\n\n```solidity\npragma solidity 0.8.0;\n\ncontract HashPairTest {\n  function test_ShouldNeverRevert() external {\n    // It should never revert.\n  }\n\n  function test_WhenFirstArgIsSmallerThanSecondArg() external {\n    // It should match the result of `keccak256(abi.encodePacked(a,b))`.\n  }\n}\n```\n\nThis Solidity file is missing the tests for the branch\n`When first arg is bigger than second arg`, which would be reported after\nrunning `bulloak check tests/scaffold/basic.tree`, like so:\n\n```text\nwarn: function \"test_WhenFirstArgIsBiggerThanSecondArg\" is missing in .sol\n     + fix: run `bulloak check --fix tests/scaffold/basic.tree`\n   --> tests/scaffold/basic.tree:5\n\nwarn: 1 check failed (run `bulloak check --fix <.tree files>` to apply 1 fix)\n```\n\nAs you can see in the above message, `bulloak` can fix the issue automatically.\nIf we run the command with the `--stdout` flag, the output is:\n\n```solidity\n--> tests/scaffold/basic.t.sol\npragma solidity 0.8.0;\n\ncontract HashPairTest {\n    function test_ShouldNeverRevert() external {\n        // It should never revert.\n    }\n\n    function test_WhenFirstArgIsSmallerThanSecondArg() external {\n        // It should match the result of `keccak256(abi.encodePacked(a,b))`.\n    }\n\n    function test_WhenFirstArgIsBiggerThanSecondArg() external {\n        // It should match the result of `keccak256(abi.encodePacked(b,a))`.\n    }\n}\n<--\n\nsuccess: 1 issue fixed.\n```\n\nRunning the command without the `--stdout` flag will overwrite the contents of\nthe solidity file with the fixes applied. Note that not all issues can be\nautomatically fixed, and bulloak's output will reflect that.\n\n```text\nwarn: 13 checks failed (run `bulloak check --fix <.tree files>` to apply 11 fixes)\n```\n\nYou can skip checking that the modifiers are present by passing the `-m` (or\n`--skip-modifiers`) option. This way, `bulloak` will not warn when a modifier is\nmissing from the generated file.\n\nUse the same `--format-descriptions` flag when running `bulloak check` if you\nrely on the normalized comments. This keeps the structural matcher aligned with\nwhat `bulloak scaffold --format-descriptions` produces.\n\n#### Rules\n\nThe following rules are currently implemented:\n\n- A Solidity file matching the spec file must exist and be readable.\n  - The spec and the Solidity file match if the difference between their names\n    is only `.tree` and `.t.sol`.\n- There is a contract in the Solidity file and its name matches the root node of\n  the spec.\n- Every construct, as it would be generated by `bulloak scaffold`, is present in\n  the Solidity file.\n- The order of every construct, as it would be generated by `bulloak scaffold`,\n  matches the spec order.\n  - Any valid Solidity construct is allowed and only constructs that would be\n    generated by `bulloak scaffold` are checked. This means that any number of\n    extra functions, modifiers, etc. can be added to the file.\n- Condition titles may repeat anywhere in a tree. `bulloak` reuses a single\n  modifier definition per unique condition title and applies it wherever\n  referenced.\n- Top‚Äëlevel actions (leaves directly under th\n\n[... truncated ...]"
  },
  "Raiden1411/zabi": {
    "fetchedAt": "2025-11-12T22:51:57.038Z",
    "content": "<br/>\n\n<p align=\"center\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/Raiden1411/zabi/main/.github/zabi.svg\">\n      <img alt=\"ZAbi logo\" src=\"https://raw.githubusercontent.com/Raiden1411/zabi/main/.github/zabi.svg\" width=\"auto\" height=\"150\">\n    </picture>\n</p>\n\n<p align=\"center\">\n  A zig library to interact with EVM blockchains \n<p>\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://codecov.io/github/Raiden1411/zabi/graph/badge.svg\">\n    <img alt=\"ZAbi logo\" src=\"https://codecov.io/github/Raiden1411/zabi/graph/badge.svg\" width=\"auto\" height=\"25\">\n  </picture>\n<p>\n\n### Overview\nZabi aims to add support for interacting with ethereum or any compatible EVM based chain. \n\n\n### Zig Versions\nZabi will follow the master branch of ziglang as best as possible.\n\n\n### Installing Zig\nYou can install the latest version of zig [here](https://ziglang.org/download/) or you can also use a version manager like [zvm](https://www.zvm.app/guides/install-zvm/) to manage your zig version.\n\n\n### Integration\nIn the `build.zig.zon` file, add the following to the dependencies object.\n\n```zig\n.zabi = .{\n    .url = \"https://github.com/Raiden1411/zabi/archive/VERSION_NUMBER.tar.gz\",\n}\n```\n\nThe compiler will produce a hash mismatch error, add the `.hash` field to `build.zig.zon`\nwith the hash the compiler tells you it found.\nYou can also use `zig fetch` to automatically do the above steps.\n\n```bash\nzig fetch --save https://github.com/Raiden1411/zabi/archive/VERSION_NUMBER.tar.gz \nzig fetch --save git+https://github.com/Raiden1411/zabi.git#LATEST_COMMIT\n```\n\nTo install zabi with the latest zig version you can install it like so\n\n```bash\nzig fetch --save git+https://github.com/Raiden1411/zabi.git#zig_version_0.14.0\n```\n\nThen in your `build.zig` file add the following to the `exe` section for the executable where you wish to have `zabi` available.\n\n```zig\nconst zabi_module = b.dependency(\"zabi\", .{}).module(\"zabi\");\n// for exe, lib, tests, etc.\nexe.root_module.addImport(\"zabi\", zabi_module);\n```\n\nNow in the code, you can import components like this:\n\n```zig\nconst zabi = @import(\"zabi\");\nconst meta = zabi.meta;\nconst encoder = zabi.encoder;\n```\n\nZabi is a modular library meaning that you can import separete modules if you just need some components of zabi.\n\n```zig\nconst zabi = b.dependency(\"zabi\", .{});\n// for exe, lib, tests, etc.\nexe.root_module.addImport(\"zabi-evm\", zabi.module(\"zabi-evm\"));\n```\n\nNow in the code, you can import components like this:\n\n```zig\nconst zabi_evm = @import(\"zabi-evm\");\n```\n\nCurrently these are all of the modules available for you to use in `zabi`:\n- zabi -> contains all modules.\n- zabi-abi -> contains all abi types and eip712.\n- zabi-ast -> contains a solidity tokenizer, parser and Ast.\n- zabi-clients -> contains all supported RPC clients and a block explorer clients.\n- zabi-crypto -> contains the signer used in zabi as well BIP32 and BIP39\n- zabi-decoding -> contains all decoding methods supported.\n- zabi-encoding -> contains all encoding methods supported.\n- zabi-evm -> contains the EVM interpreter.\n- zabi-human -> contains a custom human readable abi parser.\n- zabi-meta -> contains all of the meta programming utils used in zabi.\n- zabi-types -> contains all of the types used in zabi.\n- zabi-utils -> contains all of the utils used in zabi as well as the custom cli parser data generator.\n\n\n### Example Usage\nYou can check of the examples in the example/ folder but for a simple introduction you can checkout the bellow example.\n\n```zig\nconst args_parser = @import(\"zabi\").utils.args;\nconst std = @import(\"std\");\nconst clients = @import(\"zabi\").clients;\n\nconst HttpProvider = clients.Provider.HttpProvider;\nconst Wallet = clients.Wallet;\n\nconst CliOptions = struct {\n    priv_key: [32]u8,\n    url: []const u8,\n};\n\npub fn main() !void {\n    var gpa = std.heap.GeneralPurposeAllocator(.{}){};\n    defer _ = gpa.deinit();\n\n    var iter = try std.process.argsWithAllocator(gpa.allocator());\n    defer iter.deinit();\n\n    const parsed = args_parser.parseArgs(CliOptions, gpa.allocator(), &iter);\n\n    const uri = try std.Uri.parse(parsed.url);\n    var provider = try HttpProvider.init(.{\n        .allocator = gpa.allocator(),\n        .network_config = .{ .endpoint = .{ .uri = uri } },\n    });\n    defer provider.deinit();\n\n    var wallet = try Wallet.init(parsed.priv_key, gpa.allocator(), &provider.provider, false);\n    defer wallet.deinit();\n\n    const message = try wallet.signEthereumMessage(\"Hello World\");\n\n    const hexed = try message.toHex(wallet.allocator);\n    defer gpa.allocator().free(hexed);\n\n    std.debug.print(\"Ethereum message: {s}\\n\", .{hexed});\n}\n```\n\n\n### Features\n\n- Json RPC with support for http/s, ws/s and ipc connections.\n- EVM Interpreter that you can use to run contract bytecode.\n- Wallet instances and contract instances to use for interacting with nodes/json rpc.\n- Wallet nonce manager that uses a json rpc as a source of truth.\n- BlockExplorer support. Only the free methods from those api endpoints are supported.\n- Custom Secp256k1 ECDSA signer using only Zig and implementation of RFC6979 nonce generator.\n- Custom Schnorr signer. BIP0340 and ERC-7816 are both supported.\n- Custom JSON Parser that can be used to deserialize and serialized RPC data at runtime.\n- Custom solidity tokenizer and parser generator.\n- Ability to translate solidity source code to zig.\n- ABI to zig types.\n- Support for EIP712.\n- Support for EIP3074 authorization message. Also supports EIP7702 transactions.\n- Parsing of human readable ABIs into zig types with custom Parser and Lexer.\n- HD Wallet and Mnemonic passphrases.\n- RLP Encoding/Decoding.\n- SSZ Encoding/Decoding.\n- ABI Encoding/Decoding with support for Log topics encoding and decoding.\n- Parsing of encoded transactions and serialization of transaction objects.\n- Support for all transaction types and the new EIP4844 KZG commitments.\n- Support for OPStack and ENS.\n- Custom meta programming functions to translate ABI's into zig types.\n- Support for interacting with test chains such as Anvil or Hardhat.\n- Custom cli args parser that translates commands to zig types and can be used to pass data to methods.\n- Custom data generator usefull for fuzzing.\n\nAnd a lot more yet to come...\n\n### Goal\nThe goal of zabi is to be one of the best library to use by the ethereum ecosystem and to expose to more people to the zig programming language.\n\n\n### Contributing\nContributions to Zabi are greatly appreciated! If you're interested in contributing to ZAbi, feel free to create a pull request with a feature or a bug fix. \\\nYou can also read the [contributing guide](/.github/CONTRIBUTING.md) **before submitting a pull request**\n\n\n### Sponsors\nIf you find Zabi useful or use it for work, please consider supporting development on [GitHub Sponsors]( https://github.com/sponsors/Raiden1411) or sending crypto to [zzabi.eth](https://etherscan.io/name-lookup-search?id=zzabi.eth) or interacting with the [drip](https://www.drips.network/app/projects/github/Raiden1411/zabi?exact) platform where 40% of the revenue gets sent to zabi's dependencies. Thank you üôè\n"
  },
  "CollinsMunene/abiexplorer": {
    "fetchedAt": "2025-11-12T22:52:04.513Z",
    "content": "# **ABIExplorer**\n\n**ABIExplorer** is a web3 developer tool designed to simplify the process of testing, debugging, and documenting smart contract ABIs. With a user-friendly interface and integrated code snippets powered by GPT, ABIExplorer aims to make smart contract interactions as seamless as API testing in the web2 world.\n\n---\n\n## **Table of Contents**\n\n- [Features](#features)\n- [Usage](#usage)\n- [Contributors](#contributors)\n- [License](#license)\n- [Contact](#contact)\n\n---\n\n## **Features**\n\n- **Test Smart Contract Functions:** Easily load and test your smart contract ABIs against real blockchain data.\n- **Debug ABIs:** Interact with smart contract functions and receive detailed error messages to fix bugs.\n- **Generate Code Snippets:** Automatically generate code snippets using ChatGPT to help integrate the contract functions into your project.\n- **Documentation:** Integrated documentation features to help you understand and interact with your smart contract‚Äôs ABI without the need for manual documentation.\n- **User-Friendly Interface:** Simplified interface for both frontend developers and backend engineers to interact with smart contracts directly.\n\n---\n\n## **Usage**\n\n1. **Load an ABI:**  \n   Upload or paste your smart contract ABI JSON file into the provided input field.\n\n2. **Select Functions:**  \n   Choose the function you want to test from the loaded ABI.\n\n3. **Test:**  \n   Enter parameters and call the function. The tool will send the request to a testnet (or mainnet, depending on your setup).\n\n4. **Debug & View Results:**  \n   View the returned data and debug messages to fix issues.\n\n5. **Generate Code Snippets:**  \n   Once the function is tested successfully, use the \"Generate Code\" button to get code snippets for integration into your frontend or backend.\n\n---\n\n## **Contributors**\n\nThanks to the amazing people who have contributed to ABIExplorer! üôå\n\n- **[Collins Munene](https://github.com/yourusername)** - Creator & Lead Developer\n- **[Denis Kimanthi](https://github.com/DennohKim)** - Contributor\n\n---\n\n## **License**\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n---\n\n## **Contact**\n\nFor questions or feedback, feel free to reach out via email (hillarycollins@protonmail.com) or connect with me on Twitter(https://x.com/HillaryCollns) and LinkedIn.\n\n---\n"
  },
  "web3privacy/privacy-builder-pack": {
    "fetchedAt": "2025-11-12T22:52:11.366Z",
    "content": "# Privacy Builder Pack\n\nA curated resource hub for developers, researchers, and hackers building with privacy in mind across Web3 and beyond.\n\nThis pack brings together actionable tips, project examples, frameworks, and learning resources to help accelerate privacy-first development.\n\n![Frame 7 (1)](https://github.com/user-attachments/assets/7b6b8d4e-51b3-4b42-8788-20f5c1ee84a6)\n\n## What's Inside?\n\n### `/framework/`\nExamples of project summaries built using the **Pagency** framework. These are visual summaries of privacy-enhancing tools and architectures.\n\n- **Contribute:** Add your own `.png` summary of a privacy-focused project.  \n\n**See:** [framework contribution guide](https://github.com/web3privacy/privacy-builder-pack/blob/main/framework/contribute.md)\n\n---\n\n### `/tips/`\nShort, actionable advice from experienced builders, mentors, and hackathon veterans.\n\n- Tips on team workflow, prioritization, pitching, and privacy UX.\n- Written in a simple Markdown format.\n\n**See:** [tips contribution guide](https://github.com/web3privacy/privacy-builder-pack/blob/main/tips/contribute.md)\n\n---\n\n### `/cases/`\nPrivacy use cases across different countries and regions.\n\n- Regional examples of why privacy matters and where it‚Äôs under threat.\n- Each file describes a single use case per country.\n\n**See:** [cases contribution guide](https://github.com/web3privacy/privacy-builder-pack/blob/main/cases/contribute.md)\n\n---\n\n### `/tools/`\nA flat list of privacy-related tools, protocols, libraries, and resources.\n\n- Tagged and searchable by topic (e.g., `encryption`, `zero-knowledge`, `browser`, `vpn`, etc.)\n- Includes IDEs, EIPs, blockchain explorers, privacy libraries, and more.\n\n**See:** [tools contribution guide](https://github.com/web3privacy/privacy-builder-pack/blob/main/tools/contribute.md)\n\n---\n\n## Who Is This For?\n\n- Hackathon teams building with privacy.\n- Web3 developers learning how to integrate privacy-respecting patterns.\n- Researchers and educators exploring privacy tooling.\n- Activists, journalists, and users seeking practical privacy guidance.\n\n---\n\n## How to Contribute\n\nWe welcome your contributions! You can fork the repo, and:\n\n- Add a new tip to the `/tips/` folder.\n- Upload a use case to the `/cases/` directory.\n- Submit a project summary to the `/framework/`.\n- Suggest or categorize tools under `/tools/`.\n\nEach section has its own `contribution.md` file with simple instructions.\n\n---\n\n## License & Attribution\n\nThis project is maintained by [@web3privacy](https://web3privacy.info), a community dedicated to advancing privacy in the Web3 space.\n\n### Authors\n* **ilge.ustun** ([Github](https://github.com/ilge-ustun)) - dev\n* **jensei** ([@jensei_](https://x.com/jensei_)) - main concept, design\n* **Mykola Siusko** ([@nicksvyaznoy](https://x.com/nicksvyaznoy)) - Pagency framework, mentoring\n* **Tree** ([@tree.fail](https://bsky.app/profile/tree.fail)) - technical support\n* **web3kitty** ([Github](https://github.com/web3kitty)) - emotional support cat\n* **mf** ([Github](https://github.com/debelg)) - deployment\n---\n\n## Start Building With Privacy\n\nExplore the webpage, GitHub folders, submit your insights, and help grow a more private, transparent, and user-empowered future.\n\n> ‚ÄúIn the digital world, privacy shouldn't be a feature ‚Äî it should be a foundation.‚Äù üîê\n\n---\n\n*Privacy Builder Pack ¬© 2025 built by [Web3Privacy Now](web3privacy.info) | Resist Surveillance*\n"
  },
  "web3privacy/jobs-app": {
    "fetchedAt": "2025-11-12T22:52:18.812Z",
    "content": "# Web3Privacy Now Jobs\n\nA job board for privacy-focused roles in the Web3 industry.\n\n## Features\n\n-   Browse privacy-focused job listings in the Web3 industry\n-   Filter jobs by categories (e.g., development, research, product)\n-   Web3 authentication for adding new jobs\n-   Admin panel to manage job listings\n\n## Relevant Links\n\n-   [Job board](https://jobs.web3privacy.info)\n-   [Add a job](https://jobs.web3privacy.info/add)\n\n## For Developers\n\nIf you're interested in contributing to the project, please see our [CONTRIBUTING.md](CONTRIBUTING.md) guide.\n"
  },
  "web3privacy/cypherpunkacademy": {
    "fetchedAt": "2025-11-12T22:52:27.035Z",
    "content": "# Privacy academy\n\nFind [here](https://cryptpad.fr/pad/#/2/pad/view/5MuVtRLsPPyvOUy+eF8zg5AKgjXkNiMV+nYLwmpYNVU/) all Academy related material (code name: \"turning degens into cypherpunks\")\n\n### Why a Privacy Academy?\n\nThrough our experience organizing hackathons (ETHBrno, ETHRome, and ETHDam) as well as judging and speaking at many others, we realized that many participants were drawn to privacy without fully grasping its profound significance.\n\nThe available resources‚Äîtechnical, practical, political, philosophical, or historical‚Äîare insufficient and scattered across various platforms, websites, and playlists, making it difficult for people to access comprehensive guidance.\n\nRecognizing the necessity of education and practical development in this field, Web3Privacy Now is committed to developing and offering training, incubation, and acceleration programs. These efforts will unfold in three phases:\n\n- **LEARN** - Academy & Mentorship\n- **BUILD** - Cohort, Hackathons & Grants\n- **SCALE** - Fundraising, Advisory, & Partnerships\n\n### Goals\n1. **Create impactful privacy solutions:** ensure people avoid generating redundant or ineffective code.\n2. **Develop sustainable privacy projects:** transform hackathon demos into enduring, viable products.\n3. **Redirect misallocated funds to value-aligned stakeholders:** connect conscientious devs with experienced mentors and grant programs.\n\n## Working materials\n\n1. [Course description](https://github.com/web3privacy/cypherpunkacademy/blob/main/Course/Readme.md)\n2. [Library](https://github.com/web3privacy/cypherpunkacademy/tree/main/Books)\n3. [Videos](https://github.com/web3privacy/cypherpunkacademy/tree/main/Videos)\n4. [Research](https://github.com/web3privacy/cypherpunkacademy/tree/main/Research)\n\n### Execution Plan\n\n- **Milestone 1 [Q4 2024]** - **Curated Learning Resources**: We gather the best existing materials and curate them to be accessible to the average crypto user but also to the total beginner. This empowers users to learn exactly what they are looking for or interested in and to implement best practices effectively.\n\n- **Milestone 2 [Q2 2025]** - **Structured Learning Paths**: We create various learning paths and playlists, and run cohort-based programs similar to kernel. These programs allow participants to interact with each other, to receive guidance from mentors and experts, and to enhance their learning experience.\n\n- **Milestone 3 [Q4 2025]** - **Project Accelerator and Post-Academy Support**: We launch an accelerator for final projects from the Academy learners and provide post-academy support and work introductions. Graduates will be able to publish their projects and ideas on our grant/bounty platform where they will find the opportunity to be funded or crowdfunded.\n\n- **Milestone 4 [Q1 2026]** - **Original Content Production**: We will start producing our own content in collaboration with our network and key experts to further enhance our educational offerings.\n\n_The project was awarded a grant from [GCC](https://x.com/GCCofCommons)_\n\n\n"
  },
  "web3privacy/explorer-app": {
    "fetchedAt": "2025-11-12T22:52:33.789Z",
    "content": "# Explorer Front-End\nThis is the front-end code for explorer.web3privacy.info\n\nFeel free to propose features, additions, or new creations. \n\n## Front-end Locally\nLocal installation guidelines:\n\n\n1. git clone https://github.com/web3privacy/explorer-app\n2. cd /explorer-app\n3. pnpm install (get [pnpm](https://pnpm.io/next/installation), npm will also work etc)\n4. pnpm run dev\n\n\n\n## Run Data & Front-end\nIf you'd like to run any tests and also manipulate the data from [explorer-data](https://github.com/web3privacy/explorer-data), I'd recommend following approach:\n\n\n1. git clone https://github.com/web3privacy/explorer-app\n2. git clone https://github.com/web3privacy/explorer-data\n3. cd /explorer-data\n4. make\n\nThen we should update our data.get.ts file in the explorer-app directory, continue the commands as following:\n\n5. cd ..\n6. cd /explorer-app\n7. cd server/api\n\nThere's a file called: data.get.ts\n\nAnd you can replace the contents with:\n\n```\nimport fs from 'fs';\nimport path from 'path';\n\nexport default defineEventHandler(async () => {\n  // Define the path to the local JSON file\n  const filePath = path.join('../explorer-data/dist', 'index.json');\n\n  // Read the file asynchronously\n  const data = await fs.promises.readFile(filePath, 'utf-8');\n\n  // Parse the JSON data\n  const jsonData = JSON.parse(data);\n\n  // Return the parsed JSON data\n  return jsonData;\n});\n```\n\nAfter which you go back to your terminal:\n\n8. cd ../../\n9. pnpm install (get [pnpm](https://pnpm.io/next/installation), npm will also work etc)\n10. pnpm run dev\n\nWhich will allow you to run both the data and the front end.\n\n\n## Specifications\n\n**Features**\n\nüíö Nuxt 3 - SSR, ESR, File-based routing, components auto importing, modules, etc.\n\n‚ö°Ô∏è Vite - Instant HMR.\n\nüé® UnoCSS - The instant on-demand atomic CSS engine.\n\nüòÉ Use icons from any icon sets (Iconify) in Pure CSS, powered by UnoCSS.\n\nüî• The <script setup> syntax.\n\nüçç State Management via Pinia\n\nüì• APIs auto importing - for Composition API, VueUse and custom composables.\n\nüèé Zero-config cloud functions and deploy (Cloudflare Page preset).\n\nü¶æ TypeScript, of course.\n\n**Nuxt Modules**\nVueUse - collection of useful composition APIs.\nColorMode - dark and Light mode with auto detection made easy with Nuxt.\nUnoCSS - the instant on-demand atomic CSS engine.\nPinia - intuitive, type safe, light and flexible Store for Vue.\nDevTools - Unleash Nuxt Developer Experience. Vue.\n\n"
  },
  "web3privacy/explorer-data": {
    "fetchedAt": "2025-11-12T22:52:34.111Z",
    "content": "# Web3Privacy Now Data Repository\nYou can create/edit projects by making changes in index.yaml file, which you can find in project folder inside /src/projects/\nUpload project logo in root of project directory to be automatically included. Check below for a short guide on how to do this\n\nIf you'd rather use our UI, you can also apply your changes through our editor. \n\nHow to: <p>\n[Edit a project](https://mirror.xyz/0x0f1F3DAf416B74DB3DE55Eb4D7513a80F4841073/yDbRRq8FjSogK7iUWdiRKkm54wvx6DgRt99gFuineuY) <p>\n[Add a new project](https://mirror.xyz/0x0f1F3DAf416B74DB3DE55Eb4D7513a80F4841073/Ri2ZMIq6Os-ZKQyT_l6a5F1-gJURySvvwNRKzBvNpWM)\n\nInformation on how our scoring mechanism works [can be found here](https://mirror.xyz/0x0f1F3DAf416B74DB3DE55Eb4D7513a80F4841073/s9flkE6tMaJ4f2tzWu-FmDy7Zx_TRPe3jdXr2iYmYH0)\n# How to Add or Update Your Project's Information to the Explorer Through GitHub\n\nTo add or update your project's information to the explorer, please follow these steps. **A GitHub account is required** to complete the process.\n\n### Steps:\n\n1. **Go to the GitHub repository** at the following URL: [www.github.com/web3privacy/explorer-data](<placeholder>)\n2. Navigate to the `src` directory, then go into the `projects` folder.\n3. In the upper-right corner, click on **\"Create new file\"**.\n4. At this point, GitHub will ask you to **fork the branch**. Confirm the fork.\n5. **Enter the name of your project** in the new directory you created. Make sure there is a slash before the name. This way you create the project folder. Example: /NAME \n6. Inside your project directory, create an `index.yaml` file. Follow the template here: [sample](https://github.com/web3privacy/explorer-data/blob/main/sample-project.yaml)\n7. When you're ready to save, click **\"Commit changes...\"** in the top-right corner.\n8. Toggle the option for **\"Create a new branch for this commit and start a pull request\"**.\n9. Click **\"Propose changes\"**.\n10. GitHub will redirect you to the **\"Open a pull request\"** page.\n11. In the pull request title, add your title as such: `Create index.yaml <your_project_name>`.\n12. Finally, click **\"Create pull request\"**. Adding a description is optional.\n\n### Adding the Logo\n\n1. Now you will be able to add the logo (PNG format, 400x400 pixels). \n2. Go to `www.github.com/explorer-data/tree/main/src/projects/(name of the file added)`.\n3. In the top-right corner, click on **\"Add file\"** and then **\"Fork this Repository.\"**\n4. Navigate to your GitHub profile, find the forked repository, and open the project you're working on. The URL should look like this: `github.com/(your GitHub username)/explorer-data/tree/main/src/projects/(name of the file added)`.\n5. In the top-right corner, click on **\"Add file\"** and then **\"Upload files.\"**\n6. A window will open where you can upload your logo (name the file just **\"logo,\"** without any other text).\n7. At the bottom, select **\"Create a new branch for this commit and start a pull request.\"** Then press **\"Propose changes.\"**\n8. The pull request page will open again. Add the file name and click on **\"Create pull request.\"**\n\nüéâ **Congratulations!** Your project, including its logo, has now been submitted.\n\n# Docs\n\nThere's an ongoing effort to upkeep our docs, [have a look here.](https://docs.web3privacy.info/projects/privacy-explorer/)\n\n# Database\n\nhttps://data.web3privacy.info/\n\n# Project description\nList of variables used for Privacy Explorer (https://explorer.web3privacy.info)\nFeel free to submit any suggestions or changes to this scheme.\n\n\n\n| Field                  | Type                  | Required | Description |\n|------------------------|-----------------------|----------|-------------|\n| id                     | string                | x        | Unique project identifier            |\n| name                   | string                | x        | Name of project |\n| categories             | array                 | x        | Categories are defined in explorer-data/schema/category.yaml |\n| logos                  | array                 |          | Links to project logo (Note: Upload logos into root folder of project) |\n| ecosystem              | array               |          | What is projects native networks? (ex. Ethereum, Arbitrum, Cosmos,...) |\n|                        |                       |          |              |\n|                        |                       |          |              |\n|                        |                       |          |              |\n| project_type           | string                |          | Main usecases of project (ex. ZK Pool mixer, Privacy transactions) |\n| description            | string                |          | Short description of project features and mission |\n| product_launch_day     | string                |          | Date of the project launch (YYYY-MM-DD)|\n|                        |                       |          |              |\n|                        |                       |          |              |\n|                        |                       |          |              |\n| token_link             | string url            |          | Link to the project token contract |\n| tokens                 | array                 |          | Native tokens of project (ex. privUSDC, sETH,...) |\n| assets_used            | array                 |          | Digital assets that you can use in project/protocol (ex. BTC, ETH, USDC,...)|\n| fee                    | string                |          | Cost of usage (ex. 0.15%, $5, None) |\n|                        |                       |          |              |\n|                        |                       |          |              |\n|                        |                       |          |              |\n| team anonymous        | boolean                |          | Is project developed by anonymous team? (Yes/No) |\n| team teammembers name | string                 |          | Member's name |\n| team teammembers role | string                 |          | Member's role |\n| team teammembers link | string url             |          | Member's social link |\n|                        |                       |          |              |\n|                        |                       |          |              |\n|                        |                       |          |              |\n| funding name           | string                |          | Name of the investor |\n| funding type           | string                |          | Type of investment (Seed, Round1, Angel investment,...) |\n| funding link           | string url            |          | Link for more information about the investment |\n| funding value          | string                |          | Value of the investment ($1,500,000) |\n| funding time           | string                |          | Date of the investment (YYYY-MM-DD)|\n|                        |                       |          |              |\n|                        |                       |          |              |\n|                        |                       |          |              |\n| history title          | string                |          | Title of events/news related to the project |\n| history event_type     | string                |          | Type of event (e.g., Product release, Hack, Launch) |\n| history description    | string                |          | Description of the event |\n| history time           | string                |          | Time of the event (YYYY-MM-DD) |\n| history link           | string url            |          | Link to more information about the event |\n|                        |                       |          |              |\n|                        |                       |          |              |\n|                        |                       |          |              |\n| sunset                 | boolean               |          | Project is not active, is not recommended for use, no development  |\n\n\n\n\n# Project Links\n\n| Field           \n\n[... truncated ...]"
  },
  "qingfengzxr/gdscript-web3": {
    "fetchedAt": "2025-11-12T22:52:44.072Z",
    "content": "# GDWeb3\n\nGDWeb3 is a GDScript library for interacting with blockchain networks.\n\nSupported NetworksÔºö\n\n1. [Optimism](https://www.optimism.io/) (in progress)\n2. ...\n\n![Architecture](./imgs/image.png)\n\n## SDK Usage Introduction (Docs)\n* [en](https://gdweb3-docs.readthedocs.io/en/latest/)\n* [ÁÆÄ‰Ωì‰∏≠Êñá](https://gdweb3-docs-cn.readthedocs.io/zh-cn/latest/index.html)\n\n## Description\n\nGDWeb3 aims to help Godot game developers easily interact with blockchain networks, empowering them to develop Gamefi and FOCG (full on-chain games).\n\nHowever, supporting all blockchain networks at once is not feasible. At this stage, our primary focus is on the Optimism Network. Optimism's performance as an ETH Layer 2 solution is excellent, and it has a strong ecosystem. We believe that supporting a network with promising development will attract game developers to continue building.\n\nWe believe that the unique creativity and boundless ideas of game developers will accelerate the development of the web3 gaming industry. Being able to provide assistance to them and, perhaps one day, play enjoyable FOCG games is the joy we find in maintaining this project.\n\n## About Godot Engine\n\nGodot Engine is a feature-packed, cross-platform game engine that allows users to create 2D and 3D games from a unified interface. It provides a comprehensive set of common tools, allowing users to focus on making games without reinventing the wheel. Games can be exported with one click to various platforms, including major desktop platforms (Linux, macOS, Windows), mobile platforms (Android, iOS), web-based platforms, and consoles.\n\nGodot is completely free and open source under the permissive MIT license. Users' games belong to them, down to the last line of engine code. Godot's development is fully independent and community-driven, empowering users to shape the engine to match their expectations. It is supported by the Godot Foundation, a not-for-profit organization.\n\n## Support Godot Version\n\nAt this stage, we are developing based on `4.3-stable` version. Currently, we only guarantee upward compatibility. Therefore, when you use the program compiled from this project to extend development on older game projects, please pay attention to the version number of the Godot engine program you originally used.\n\n## Getting Started\n\nThe project is developed using the basic capabilities of Godot Engine's custom C++ modules.\n\n[Custom C++ Modules](https://docs.godotengine.org/en/stable/contributing/development/core_and_modules/custom_modules_in_cpp.html)\n\nBased on this capability, we can directly use C++ to implement code without worrying about the performance loss of using GDScript. At the same time, game developers can also use GDScript directly, and the underlying code will eventually be displayed in GDScript.\n\n> Thanks to the Godot team for their excellent work!\n\nSince GDWeb3 has not yet been merged into the main branch of Godot (this may become possible in the future), you need to recompile the engine or use our precompiled engine program.\n\n### Compiling from Source\n\n#### 1. Setup Godot Engine compilation environment\n[Building from Source](https://docs.godotengine.org/en/stable/contributing/development/compiling/index.html)\n\nYou can refer to this tutorial to set up your own Godot Engine compilation environment. Trust me, it's unbelievably simple! Definitely worth a try!\n\n#### 2. Clone our project\n```\ngit clone https://github.com/qingfengzxr/gdscript-web3.git\n```\n\n#### 3. Copy web3 module\nCopy web3 directory into Godot Engine project's modules directory.\n\n```\ncp -rf ~/gdscript-web3/modules/web3 ~/godot/modules\n```\n> Don't forget to replace your own path\n\n#### 4. Install gmp library\nubuntu:\n```\nsudo apt install libgmp-dev\n```\n\nAlso, it is can be install by source code. Reference: https://gmplib.org/\n\n#### 5. Compile Godot Engine\nLinux:\n```\nscons platform=linuxbsd\n```\n\nMacOS:\n```\nscons platform=osx arch=arm64\n```\n\n\n### Using the Released Version\nThe latest version is `v0.0.2-alpha`.\n\n>However, it is not production-ready yet. We will expedite the process as soon as possible.\n\n## Example Project\n1.[HelloOptimism](https://github.com/qingfengzxr/HelloOptimism)\n\n2.[TetrisDemo](https://github.com/hallazie/TetrisDemo)\n"
  },
  "Nethereum/Nethereum": {
    "fetchedAt": "2025-11-12T22:52:51.786Z",
    "content": "# Nethereum\n [![Documentation Status](https://readthedocs.org/projects/nethereum/badge/?version=latest)](https://nethereum.readthedocs.io/en/latest/) [![NuGet version](https://badge.fury.io/nu/nethereum.web3.svg)](https://badge.fury.io/nu/nethereum.web3)\n\nTechnical support, chat and collaboration at Discord: https://discord.gg/u3Ej2BReNn\n\n# What is Nethereum ?\n\nNethereum is the .Net integration library for Ethereum, simplifying the access and smart contract interaction with Ethereum nodes both public like Geth (or your preferred client) L2 chains like Optimism, Arbitrum (or your preferred L2), any compatible EVM chain (Gnosis, etc) and permissioned chains like [Quorum](https://www.jpmorgan.com/global/Quorum).\n\nNethereum is developed targeting netstandard 1.1, netstandard 2.0, netcore 3.1, net451, .net 6, .net 8 and also as a portable library, hence it is compatible with all the operating systems (Windows, Linux, MacOS, Android and OSX) and has been tested on cloud, mobile, desktop, consoles and IoT.\n\n# Nethereum Playground. Try Nethereum now in your browser.\nGo to http://playground.nethereum.com to browse and execute all the different samples on how to use Nethereum directly in your browser. \n\n[![Nethereum Playground](screenshots/playground.png)](http://playground.nethereum.com)\n\n# Do you need support, want to have a chat, or want to help?\nPlease join the Discord server using this link: https://discord.gg/u3Ej2BReNn\nWe should be able to answer there any simple queries, general comments or requests, everyone is welcome.\nIf you want to help or have any ideas for a pull request just come and chat.\n\n## Documentation\nThe documentation and guides can be found at [Read the docs](https://nethereum.readthedocs.io/en/latest/). \n\n## Features\n\n* JSON RPC / IPC Ethereum core methods.\n* Geth management API (admin, personal, debugging, miner).\n* [Parity](https://www.parity.io/) management API.\n* [Quorum](https://www.jpmorgan.com/global/Quorum) integration.\n* Simplified smart contract interaction for deployment, function calling, transaction and event filtering and decoding of topics.\n* [Unity 3d](https://unity3d.com/) Unity integration.\n* ABI to .Net type encoding and decoding, including attribute based for complex object deserialization.\n* Hd Wallet\n* External signers integration (Azure, AWS)\n* Wallet integration (Metamask, WalletConnect)\n* EVM Simulator\n* Transaction, RLP and message signing, verification and recovery of accounts.\n* Libraries for standard contracts Tokens, [ENS](https://ens.domains/), MUD (https://mud.dev/), Gnosis Safe\n* Integrated TestRPC testing to simplify TDD and BDD (Specflow) development.\n* Key storage using Web3 storage standard.\n* Simplified account life cycle for both managed by third party client (personal) or stand alone (signed transactions).\n* Low level Interception of RPC calls.\n* Code generation of smart contracts services.\n\n## Quick installation\n\nNethereum provides two types of packages. Standalone packages targeting Netstandard 1.1, net451 and where possible net351 to support Unity3d. There is also a Nethereum.Portable library which combines all the packages into a single portable library. As netstandard evolves and is more widely supported, the portable library might be eventually deprecated.\n\nTo install the latest version:\n\n#### Windows/Mac/Linux users\n\n```\ndotnet add package Nethereum.Web3 \n```\n\n## Simple Code generation of Contract definitions\nIf you are working with smart contracts, you can quickly code generate contract definitions using the vscode solidity extension (please check the documentation for other options)\n\n[![Code generation of Contract Definitions](https://github.com/juanfranblanco/vscode-solidity/raw/master/screenshots/compile-codegnerate-nethereum.png)](https://marketplace.visualstudio.com/items?itemName=JuanBlanco.solidity)\n\n## Main Libraries\n\n|  Project Source | Nuget_Package |  Description |\n| ------------- |--------------------------|-----------|\n| [Nethereum.Web3](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.Web3)    | [![NuGet version](https://badge.fury.io/nu/nethereum.web3.svg)](https://badge.fury.io/nu/nethereum.web3)| Ethereum Web3 Class Library simplifying the interaction via RPC. Includes contract interaction, deployment, transaction, encoding / decoding and event filters |\n| [Nethereum.Unity](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.Unity) |  | Unity3d integration, libraries can be found in the Nethereum [releases](https://github.com/Nethereum/Nethereum/releases) |\n\n\n## Core Libraries\n\n|  Project Source | Nuget_Package |  Description |\n| ------------- |--------------------------|-----------|\n| [Nethereum.ABI](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.ABI) | [![NuGet version](https://badge.fury.io/nu/nethereum.abi.svg)](https://badge.fury.io/nu/nethereum.abi)| Encoding and decoding of ABI Types, functions, events of Ethereum contracts |\n| [Nethereum.EVM](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.EVM) | |Ethereum Virtual Machine API|\n| [Nethereum.Hex](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.Hex) | [![NuGet version](https://badge.fury.io/nu/nethereum.hex.svg)](https://badge.fury.io/nu/nethereum.hex)| HexTypes for encoding and decoding String, BigInteger and different Hex helper functions|\n| [Nethereum.RPC](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.RPC)   | [![NuGet version](https://badge.fury.io/nu/nethereum.rpc.svg)](https://badge.fury.io/nu/nethereum.rpc) | Core RPC Class Library to interact via RCP with an Ethereum client |\n| [Nethereum.JsonRpc.Client](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.JsonRpc.Client)   | [![NuGet version](https://badge.fury.io/nu/nethereum.jsonrpc.client.svg)](https://badge.fury.io/nu/nethereum.jsonrpc.client) | Nethereum JsonRpc.Client core library to use in conjunction with either the JsonRpc.RpcClient, the JsonRpc.IpcClient or other custom Rpc provider |\n| [Nethereum.JsonRpc.RpcClient](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.JsonRpc.RpcClient)   | [![NuGet version](https://badge.fury.io/nu/nethereum.jsonrpc.rpcclient.svg)](https://badge.fury.io/nu/nethereum.jsonrpc.rpcclient) | JsonRpc Rpc Client using Http|\n| [Nethereum JsonRpc IpcClient](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.JsonRpc.IpcClient)| [![NuGet version](https://badge.fury.io/nu/nethereum.jsonRpc.ipcclient.svg)](https://badge.fury.io/nu/nethereum.jsonRpc.ipcclient) |JsonRpc IpcClient provider for Windows, Linux and Unix|\n| [Nethereum.RLP](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.RLP)  | [![NuGet version](https://badge.fury.io/nu/nethereum.rlp.svg)](https://badge.fury.io/nu/nethereum.rlp) | RLP encoding and decoding |\n| [Nethereum.KeyStore](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.KeyStore)  | [![NuGet version](https://badge.fury.io/nu/nethereum.keystore.svg)](https://badge.fury.io/nu/nethereum.keystore) | Keystore generation, encryption and decryption for Ethereum key files using the Web3 Secret Storage definition, https://github.com/ethereum/wiki/wiki/Web3-Secret-Storage-Definition |\n| [Nethereum.Signer](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.Signer)  | [![NuGet version](https://badge.fury.io/nu/nethereum.signer.svg)](https://badge.fury.io/nu/nethereum.signer) | Nethereum signer library to sign and verify messages, RLP and transactions using an Ethereum account private key |\n| [Nethereum.Contracts](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.Contracts)  | [![NuGet version](https://badge.fury.io/nu/nethereum.contracts.svg)](https://badge.fury.io/nu/nethereum.contracts) | Core library to interact via RPC with Smart contracts in Ethereum |\n| [Nethereum.IntegrationTesting](https://github.com/Nethereum/Nethereum/tree/master/src/Nethereum.IntegrationTesting)  |   | Integration testing module |\n| [Nethereum.H\n\n[... truncated ...]"
  },
  "ponder-sh/ponder": {
    "fetchedAt": "2025-11-12T22:53:00.748Z",
    "content": "# Ponder\n\n[![CI status][ci-badge]][ci-url]\n[![Version][version-badge]][version-url]\n[![Telegram chat][tg-badge]][tg-url]\n[![License][license-badge]][license-url]\n\nPonder is an open-source framework for blockchain application backends.\n\n## Documentation\n\nVisit [ponder.sh](https://ponder.sh) for documentation, guides, and the API reference.\n\n## Support\n\nJoin [Ponder's telegram chat](https://t.me/pondersh) for support, feedback, and general chatter.\n\n## Features\n\n‚úÖ &nbsp;Local development server with hot reloading<br/>\n‚úÖ &nbsp;`create-ponder` CLI tool to get started from an Etherscan link or Graph Protocol subgraph<br/>\n‚úÖ &nbsp;End-to-end type safety using [viem](https://viem.sh) and [ABIType](https://github.com/wagmi-dev/abitype)<br/>\n‚úÖ &nbsp;Autogenerated GraphQL API<br/>\n‚úÖ &nbsp;Easy to deploy anywhere using Node.js/Docker<br/>\n‚úÖ &nbsp;Supports all Ethereum-based blockchains, including test nodes like [Anvil](https://book.getfoundry.sh/anvil)<br/>\n‚úÖ &nbsp;Index events from multiple chains in the same app<br/>\n‚úÖ &nbsp;Reconciles chain reorganization<br/>\n‚úÖ &nbsp;Factory contracts<br/>\n‚úÖ &nbsp;Process transactions calls (in addition to logs)<br/>\nüèóÔ∏è &nbsp;Run effects (e.g. send an API request) in indexing code<br/>\n\n## Quickstart\n\n### 1. Run `create-ponder`\n\nYou will be asked for a project name, and if you are using a [template](https://ponder.sh/docs/api-reference/create-ponder#templates) (recommended). Then, the CLI will create a project directory, install dependencies, and initialize a git repository.\n\n```bash\nnpm init ponder@latest\n# or\npnpm create ponder\n# or\nyarn create ponder\n```\n\n### 2. Start the development server\n\nJust like Next.js and Vite, Ponder has a development server that automatically reloads when you save changes in any project file. It also prints `console.log` statements and errors encountered while running your code. First, `cd` into your project directory, then start the server.\n\n```bash\nnpm run dev\n# or\npnpm dev\n# or\nyarn dev\n```\n\n### 3. Add contracts & chains\n\nPonder fetches event logs for the contracts added to `ponder.config.ts`, and passes those events to the indexing functions you write.\n\n```ts\n// ponder.config.ts\n\nimport { createConfig } from \"ponder\";\nimport { BaseRegistrarAbi } from \"./abis/BaseRegistrar\";\n \nexport default createConfig({\n  chains: {\n    mainnet: { \n      id: 1,\n      rpc: \"https://eth-mainnet.g.alchemy.com/v2/...\",\n    },\n  },\n  contracts: {\n    BaseRegistrar: {\n      abi: BaseRegistrarAbi,\n      chain: \"mainnet\",\n      address: \"0x57f1887a8BF19b14fC0dF6Fd9B2acc9Af147eA85\",\n      startBlock: 9380410,\n    },\n  },\n});\n```\n\n### 4. Define your schema\n\nThe `ponder.schema.ts` file contains the database schema, and defines the shape data that the GraphQL API serves.\n\n```ts\n// ponder.schema.ts\n\nimport { onchainTable } from \"ponder\";\n\nexport const ensName = onchainTable(\"ens_name\", (t) => ({\n  name: p.text().primaryKey(),\n  owner: p.text().notNull(),\n  registeredAt: p.integer().notNull(),\n}));\n```\n\n### 5. Write indexing functions\n\nFiles in the `src/` directory contain **indexing functions**, which are TypeScript functions that process a contract event. The purpose of these functions is to insert data into the entity store.\n\n```ts\n// src/BaseRegistrar.ts\n\nimport { ponder } from \"ponder:registry\";\nimport schema from \"ponder:schema\";\n\nponder.on(\"BaseRegistrar:NameRegistered\", async ({ event, context }) => {\n  const { name, owner } = event.params;\n\n  await context.db.insert(schema.ensName).values({\n    name: name,\n    owner: owner,\n    registeredAt: event.block.timestamp,\n  });\n});\n```\n\nSee the [create & update records](https://ponder.sh/docs/indexing/write) docs for a detailed guide on writing indexing functions.\n\n### 6. Query the GraphQL API\n\nPonder automatically generates a frontend-ready GraphQL API based on your `ponder.schema.ts` file. The API serves data that you inserted in your indexing functions.\n\n```ts\n{\n  ensNames(limit: 2) {\n    items {\n      name\n      owner\n      registeredAt\n    }\n  }\n}\n```\n\n```json\n{\n  \"ensNames\": {\n    \"items\": [\n      {\n        \"name\": \"vitalik.eth\",\n        \"owner\": \"0x0904Dac3347eA47d208F3Fd67402D039a3b99859\",\n        \"registeredAt\": 1580345271\n      },\n      {\n        \"name\": \"joe.eth\",\n        \"owner\": \"0x6109DD117AA5486605FC85e040ab00163a75c662\",\n        \"registeredAt\": 1580754710\n      }\n    ]\n  }\n}\n```\n\nThat's it! Visit [ponder.sh](https://ponder.sh) for documentation, guides for deploying to production, and the API reference.\n\n## Contributing\n\nIf you're interested in contributing to Ponder, please read the [contribution guide](/.github/CONTRIBUTING.md).\n\n## Packages\n\n- `ponder`\n- `@ponder/client`\n- `@ponder/react`\n- `@ponder/utils`\n- `create-ponder`\n- `eslint-config-ponder`\n\n## About\n\nPonder is MIT-licensed open-source software.\n\n[ci-badge]: https://github.com/ponder-sh/ponder/actions/workflows/main.yml/badge.svg\n[ci-url]: https://github.com/ponder-sh/ponder/actions/workflows/main.yml\n[tg-badge]: https://img.shields.io/endpoint?color=neon&logo=telegram&label=chat&url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fpondersh\n[tg-url]: https://t.me/pondersh\n[license-badge]: https://img.shields.io/npm/l/ponder?label=License\n[license-url]: https://github.com/ponder-sh/ponder/blob/main/LICENSE\n[version-badge]: https://img.shields.io/npm/v/ponder\n[version-url]: https://github.com/ponder-sh/ponder/releases\n"
  },
  "saurabhburade/substream-eth-blobs": {
    "fetchedAt": "2025-11-12T22:53:08.573Z",
    "content": "# Substreams-powered subgraph: Blobs\n\n"
  },
  "zsystm/solizard": {
    "fetchedAt": "2025-11-12T22:53:16.962Z",
    "content": "# Solizard :lizard:\n\nSuper easy interactive shell for interacting with smart contract on any evm chain.\n\n<img src=\"docs/demo.gif\" alt=\"Demo\" width=\"600\">\n\n## Features\n\n- :scroll: Read contract state (Eth Call)\n- :rocket: Write contract state (Eth SendTransaction)\n\n## How to use\n\n1. Install solizard `go install github.com/zsystm/solizard/cmd/solizard@latest`\n2. Place your contract ABI in `$HOME/.solizard/abis/*.abi`\n3. Run `solizard`\n\n## Security\n\n- private key is in memory and NEVER leaves the terminal\n- NO backend, NO database, NO tracking"
  },
  "markeljan/web3gpt": {
    "fetchedAt": "2025-11-12T22:53:24.366Z",
    "content": "# Web3GPT üöÄ\n\nWeb3GPT is an AI-powered smart contract development platform that combines Large Language Models (LLMs) with specialized AI agents to streamline blockchain development. Try it live at [w3gpt.ai](https://w3gpt.ai) or check out our [documentation](https://docs.w3gpt.ai).\n\n![image](https://github.com/Markeljan/Web3GPT/assets/12901349/c84ec7ed-3657-4d19-a739-2285e25c29a1)\n\n## Key Features üåü\n\n- **Multi-Chain Smart Contract Development:** Deploy contracts across multiple EVM-compatible testnets including:\n  - Arbitrum Sepolia\n  - Optimism Sepolia\n  - Base Sepolia\n  - Metis Sepolia\n  - Mantle Sepolia\n  - Celo Alfajores\n  - Polygon Amoy\n  - Sepolia\n\n- **Specialized AI Agents:**\n  - Web3GPT - Core smart contract development agent\n  - GENT - first token agent launched on W3GPT\n  - Unstoppable Domains - Domain resolution specialist\n  - OpenZeppelin 5.0 - Security-focused development using latest OZ libraries\n  - CTF Agent - Interactive Capture The Flag challenges\n  - Creator - Custom AI agent creation\n\n- **GitHub Authentication:** Secure login and persistence of your development sessions\n\n- **Share & Collaborate:** Share your smart contract development conversations with unique shareable URLs\n\n## Getting Started üõ†Ô∏è\n\n1. Clone the repository\n2. Configure environment variables (see `.env.example`)\n3. Install dependencies and run the development server\n\n```bash\nbun install\n```\n\n```bash\nbun dev\n```\n\n## Deploying Contracts with Local Imports\n\nWeb3GPT now supports deploying factory contracts that rely on local Solidity imports. Provide additional source files alongside your main contract and reference them with relative paths (e.g., `import \"./AddressBook.sol\";`). The compiler will include these dependencies automatically, enabling factory patterns without flattening contracts.\n"
  },
  "gobitfly/eth2-beaconchain-explorer": {
    "fetchedAt": "2025-11-12T22:53:32.217Z",
    "content": "# Ethereum Beacon Chain Explorer\n\nThe explorer provides a comprehensive and easy to use interface for the upcoming Ethereum beacon chain. It makes it easy to view proposed blocks, follow attestations and monitor your staking activity.\n\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&logo=discord&logoColor=white)](https://dsc.gg/beaconchain)\n[![Twitter](https://img.shields.io/badge/Twitter-%231DA1F2.svg?style=for-the-badge&logo=Twitter&logoColor=white)](https://twitter.com/beaconcha_in)\n\n[![Badge](https://github.com/gobitfly/eth2-beaconchain-explorer/workflows/Build/badge.svg)](https://github.com/gobitfly/eth2-beaconchain-explorer/actions?query=workflow%3A%22Build+%26+Publish+Docker+images%22)\n[![Go Report Card](https://goreportcard.com/badge/github.com/gobitfly/eth2-beaconchain-explorer)](https://goreportcard.com/report/github.com/gobitfly/eth2-beaconchain-explorer)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/gobitfly/eth2-beaconchain-explorer/badge)](https://www.gitpoap.io/gh/gobitfly/eth2-beaconchain-explorer)\n\n## About\n\nThe explorer is built using golang and utilizes a PostgreSQL database for storing and indexing data. In order to avoid the situation we currently have with the Ethereum chain where closed source block explorers dominate the market we decided to make our explorer open source and available for everybody.\n\n### Ethereum Testnet Explorers\n\n[Goerli](https://goerli.beaconcha.in)<br>\n[Sepolia](https://sepolia.beaconcha.in)<br>\n[Holesky](https://holesky.beaconcha.in)\n\n**Warning:** The explorer is still under heavy active development. More or less everything might change without prior notice and we cannot guarantee any backwards compatibility for now. Once the Ethereum ecosystem matures we will be able to provide stronger guarantees about the updatability of the explorer.\n\n![Site](https://user-images.githubusercontent.com/26490734/120495328-e351f800-c3bc-11eb-92a8-e93fbde24539.png 'Beacon Chain Web Interface Screenshot')\n\n## Features\n\n- General\n  - Open Source (GNU General Public License v3.0)\n  - Supports Execution Layer and Consensus Layer\n  - Supports multiple networks\n  - Written in Golang\n\n- Website\n  - [Validator Dashboard](https://beaconcha.in/dashboard) with status, income, balance, attestations, proposals and charts\n  - Overviews about [blocks](https://beaconcha.in/blocks), [slots](https://beaconcha.in/slots), [epochs](https://beaconcha.in/epochs), [transactions](https://beaconcha.in/transactions), [validators](https://beaconcha.in/validators), [slashings](https://beaconcha.in/validators/slashings) and the [mempool](https://beaconcha.in/mempool)\n  - Stats and info about [Rocket Pool](https://beaconcha.in/pools/rocketpool), [staking services](https://beaconcha.in/stakingServices), [MEV relays](https://beaconcha.in/relays) and [Ethereum clients](https://beaconcha.in/user/ethClients)\n  - Leaderboards about [validators](https://beaconcha.in/validators/leaderboard) and [deposits](https://beaconcha.in/validators/deposit-leaderboard)\n  - [Charts](https://beaconcha.in/charts) about various stats\n\n- Monitoring\n  - The monitoring feature analyzes blockchain data and (optionally) data provided by a user's staking setup\n  - Highly configurable [notifications and notification channels](https://beaconcha.in/user/notifications) (mobile push, email, webhooks)\n\n- Tools\n  - [APIs](https://beaconcha.in/api/v1/docs/index.html) for Execution Layer and Consensus Layer\n  - [Ethereum Staking Pool benchmark and overview](https://beaconcha.in/pools)\n  - [Income History](https://beaconcha.in/user/rewards)\n  - [Profit Calculator](https://beaconcha.in/calculator)\n  - Block Visualizer [[1](https://beaconcha.in/vis)] [[2](https://beaconcha.in/charts/slotviz)]\n  - [Unit Converter](https://beaconcha.in/tools/unitConverter)\n  - [Graffiti Wall](https://beaconcha.in/graffitiwall)\n\n- [Beaconcha.in Mobile App](https://beaconcha.in/mobile)\n  - Open Source (GNU General Public License v3.0)\n  - Dashboard with similar info as the website\n  - Notifications about client updates\n  - Advanced Rocket Pool features\n  - Machine stats with charts\n  - Widgets\n  - Themes\n\n## ToDo\n\n- Add chain statistic charts\n- Improve design, move away from stock bootstrap 4\n- Use a proper open source charting library\n- Come up with a smarter exporter logic (the current logic is stupid as it simply dumps the contents of the RPC calls into the database without doing any pre-aggregation or cleanups)\n\n## Getting started\n\nWe currently do not provide any pre-built binaries of the explorer. Docker images are available at https://hub.docker.com/repository/docker/gobitfly/eth2-beaconchain-explorer.\n\n- Download the latest version of the Prysm beacon chain client and start it with the `--archive` flag set\n- Wait till the client finishes the initial sync\n- Setup a PostgreSQL DB and import the `tables.sql` file from the root of this repository\n- Install go version 1.13 or higher\n- Clone the repository and run `make all` to build the indexer and front-end binaries\n- Copy the config-example.yml file and adapt it to your environment\n- Start the explorer binary and pass the path to the config file as argument\n- To build bootstrap run `npm run --prefix ./bootstrap dist-css` in project folder.\n\n## Developing locally with docker\n- Clone the repository\n- Run `docker-compose up` to start instances of the following containers `eth1`, `prysm`, `postgres` and `golang`.\n- Open a new terminal in project directory and run `docker run -it --rm --net=host -v $(pwd):/src  postgres psql -f /src/tables.sql -d db -h 0.0.0.0 -U postgres` to create new tables in the database  \n- Wait for the client to finish initial sync, you can check this by looking at logs of `prysm` instance.\n- Copy the `config-example.yml` file and adapt it to your environment.\\\n In your `.yml` file specify `eth1Endpoint` as `'./private/eth1_node/.ethereum/goerli/geth.ipc'`. \n For database information check `postgres` section in `docker-compose.yml` file.\n- Connect to `golang` instance by running `docker exec -ti golang bash` and run `make all`\n- Start the explorer binary and pass the path to the config file as argument \n\n      ./bin/explorer --config your_config.yml   \n\n## Development\n\nInstall golint. (see https://github.com/golang/lint)\n\n## Commercial usage\n\nThe explorer uses Highsoft charts which are not free for commercial and governmental use. If you plan to use the explorer for commercial purposes you currently need to purchase an appropriate HighSoft license.\nWe are planning to switch out the Highsoft chart library with a less restrictive charting library (suggestions are welcome).\n"
  },
  "ethereum/eth-utils": {
    "fetchedAt": "2025-11-12T22:53:36.706Z",
    "content": "# Ethereum Utilities\n\n[![Join the conversation on Discord](https://img.shields.io/discord/809793915578089484?color=blue&label=chat&logo=discord&logoColor=white)](https://discord.gg/GHryRvPB84)\n[![Build Status](https://circleci.com/gh/ethereum/eth-utils.svg?style=shield)](https://circleci.com/gh/ethereum/eth-utils)\n[![PyPI version](https://badge.fury.io/py/eth-utils.svg)](https://badge.fury.io/py/eth-utils)\n[![Python versions](https://img.shields.io/pypi/pyversions/eth-utils.svg)](https://pypi.python.org/pypi/eth-utils)\n[![Docs build](https://readthedocs.org/projects/eth-utils/badge/?version=latest)](https://eth-utils.readthedocs.io/en/latest/?badge=latest)\n\nCommon utility functions for python code that interacts with Ethereum\n\nRead the [documentation](https://eth-utils.readthedocs.io/).\n\nView the [change log](https://eth-utils.readthedocs.io/en/latest/release_notes.html).\n\n## Installation\n\n```sh\npython -m pip install eth-utils\n```\n\n## Developer Setup\n\nIf you would like to hack on eth-utils, please check out the [Snake Charmers\nTactical Manual](https://github.com/ethereum/snake-charmers-tactical-manual)\nfor information on how we do:\n\n- Testing\n- Pull Requests\n- Documentation\n\nWe use [pre-commit](https://pre-commit.com/) to maintain consistent code style. Once\ninstalled, it will run automatically with every commit. You can also run it manually\nwith `make lint`. If you need to make a commit that skips the `pre-commit` checks, you\ncan do so with `git commit --no-verify`.\n\n### Development Environment Setup\n\nYou can set up your dev environment with:\n\n```sh\ngit clone git@github.com:ethereum/eth-utils.git\ncd eth-utils\nvirtualenv -p python3 venv\n. venv/bin/activate\npython -m pip install -e \".[dev]\"\npre-commit install\n```\n\n### Update Networks\n\nThe list of networks resides in the JSON file under eth_utils/\\_\\_json/eth_networks.json.\nThis file is used to initialize Networks, which can be used to obtain network\ninformation with a chain ID.\n\nRun the script to update the JSON file with the response from the remote list.\n\n```sh\npython update_networks.py\n```\n\nIf there are new networks they will appear in the JSON file. After checking the updates,\nopen a PR to make them available in a new release.\n\n### Release setup\n\nTo release a new version:\n\n```sh\nmake release bump=$$VERSION_PART_TO_BUMP$$\n```\n\n#### How to bumpversion\n\nThe version format for this repo is `{major}.{minor}.{patch}` for stable, and\n`{major}.{minor}.{patch}-{stage}.{devnum}` for unstable (`stage` can be alpha or beta).\n\nTo issue the next version in line, specify which part to bump,\nlike `make release bump=minor` or `make release bump=devnum`. This is typically done from the\nmain branch, except when releasing a beta (in which case the beta is released from main,\nand the previous stable branch is released from said branch).\n\nIf you are in a beta version, `make release bump=stage` will switch to a stable.\n\nTo issue an unstable version when the current version is stable, specify the\nnew version explicitly, like `make release bump=\"--new-version 4.0.0-alpha.1 devnum\"`\n"
  },
  "ethereum/web3.py": {
    "fetchedAt": "2025-11-12T22:53:37.014Z",
    "content": "# web3.py\n\n[![Join the conversation on Discord](https://img.shields.io/discord/809793915578089484?color=blue&label=chat&logo=discord&logoColor=white)](https://discord.gg/GHryRvPB84)\n[![Build Status](https://circleci.com/gh/ethereum/web3.py.svg?style=shield)](https://circleci.com/gh/ethereum/web3.py)\n[![PyPI version](https://badge.fury.io/py/web3.svg)](https://badge.fury.io/py/web3)\n[![Python versions](https://img.shields.io/pypi/pyversions/web3.svg)](https://pypi.python.org/pypi/web3)\n[![Docs build](https://readthedocs.org/projects/web3py/badge/?version=latest)](https://web3py.readthedocs.io/en/latest/?badge=latest)\n\n## A Python Library for Interacting with Ethereum\n\nweb3.py allows you to interact with the Ethereum blockchain using Python, enabling you to build decentralized applications, interact with smart contracts, and much more.\n\n- Python 3.10+ support\n\n## Installation\n\n```sh\npython -m pip install web3\n```\n\n## Documentation\n\n[Get started in 5 minutes](https://web3py.readthedocs.io/en/latest/quickstart.html) or\n[take a tour](https://web3py.readthedocs.io/en/latest/overview.html) of the library.\n\nView the [change log](https://web3py.readthedocs.io/en/latest/release_notes.html).\n\nFor additional guides, examples, and APIs, see the [documentation](https://web3py.readthedocs.io/en/latest/).\n\n## Want to Help?\n\nWant to file a bug, contribute some code, or improve documentation? Excellent! Read up on our\nguidelines for [contributing](https://web3py.readthedocs.io/en/latest/contributing.html),\nthen check out issues that are labeled\n[Good First Issue](https://github.com/ethereum/web3.py/issues?q=is%3Aissue+is%3Aopen+label%3A%22Good+First+Issue%22).\n\n______________________________________________________________________\n\n## Questions on Implementation or Usage?\n\nJoin the conversation in the Ethereum Python Community [Discord](https://discord.gg/GHryRvPB84).\n"
  },
  "ethereum/eth-account": {
    "fetchedAt": "2025-11-12T22:53:37.419Z",
    "content": "# eth-account\n\n[![Join the conversation on Discord](https://img.shields.io/discord/809793915578089484?color=blue&label=chat&logo=discord&logoColor=white)](https://discord.gg/GHryRvPB84)\n[![Build Status](https://circleci.com/gh/ethereum/eth-account.svg?style=shield)](https://circleci.com/gh/ethereum/eth-account)\n[![PyPI version](https://badge.fury.io/py/eth-account.svg)](https://badge.fury.io/py/eth-account)\n[![Python versions](https://img.shields.io/pypi/pyversions/eth-account.svg)](https://pypi.python.org/pypi/eth-account)\n[![Docs build](https://readthedocs.org/projects/eth-account/badge/?version=latest)](https://eth-account.readthedocs.io/en/latest/?badge=latest)\n\nSign Ethereum transactions and messages with local private keys\n\nRead the [documentation](https://eth-account.readthedocs.io/).\n\nView the [change log](https://eth-account.readthedocs.io/en/latest/release_notes.html).\n\n## Installation\n\n```sh\npython -m pip install eth-account\n```\n"
  },
  "ethereum/py-evm": {
    "fetchedAt": "2025-11-12T22:53:37.727Z",
    "content": "> [!caution]\n> This repository has been archived, and is now read-only. For a Python implementation of the EVM, check out the [execution-specs](https://github.com/ethereum/execution-specs) repo.\n\n# Python Implementation of the Ethereum protocol\n\n[![PyPI version](https://badge.fury.io/py/py-evm.svg)](https://badge.fury.io/py/py-evm)\n[![Python versions](https://img.shields.io/pypi/pyversions/py-evm.svg)](https://pypi.python.org/pypi/py-evm)\n[![Docs build](https://readthedocs.org/projects/py-evm/badge/?version=latest)](https://py-evm.readthedocs.io/en/latest/?badge=latest)\n\n## Py-EVM\n\nPy-EVM is an implementation of the Ethereum Virtual Machine (EVM) in Python.\n\n### Goals\n\nPy-EVM aims to be a readable yet generally performant version of the EVM in Python.\n\nIn particular Py-EVM aims to:\n\n- be easy to understand and modifiable\n- be highly flexible to support research and experimentation\n- be performant enough to be used in testing for Python projects\n- be a reference implementation of the Ethereum execution layer specifications\n\nEthereum consensus today is achieved via Proof of Stake, involving a consensus layer that\nis beyond the scope of this repository.\n\n## Installation\n\n```sh\npython -m pip install py-evm\n```\n\n## Documentation\n\n[Get started in 5 minutes](https://py-evm.readthedocs.io/en/latest/guides/building_an_app_that_uses_pyevm.html)\n\nCheck out the [documentation on our official website](https://py-evm.readthedocs.io/en/latest/)\n\nView the [change log](https://py-evm.readthedocs.io/en/latest/release_notes.html).\n"
  },
  "ethereum/eth-abi": {
    "fetchedAt": "2025-11-12T22:53:38.075Z",
    "content": "# Ethereum Contract Interface (ABI) Utility\n\n[![Join the conversation on Discord](https://img.shields.io/discord/809793915578089484?color=blue&label=chat&logo=discord&logoColor=white)](https://discord.gg/GHryRvPB84)\n[![Build Status](https://circleci.com/gh/ethereum/eth-abi.svg?style=shield)](https://circleci.com/gh/ethereum/eth-abi)\n[![PyPI version](https://badge.fury.io/py/eth-abi.svg)](https://badge.fury.io/py/eth-abi)\n[![Python versions](https://img.shields.io/pypi/pyversions/eth-abi.svg)](https://pypi.python.org/pypi/eth-abi)\n[![Docs build](https://readthedocs.org/projects/eth-abi/badge/?version=latest)](https://eth-abi.readthedocs.io/en/latest/?badge=latest)\n\nPython utilities for working with Ethereum ABI definitions, especially encoding and decoding\n\nRead the [documentation](https://eth-abi.readthedocs.io/).\n\nView the [change log](https://eth-abi.readthedocs.io/en/latest/release_notes.html).\n\n## Installation\n\n```sh\npython -m pip install eth-abi\n```\n"
  },
  "jiffy-labs/jiffyscan-frontend": {
    "fetchedAt": "2025-11-12T22:53:44.937Z",
    "content": "# Contributing to Jiffyscan\n\nWelcome to Jiffyscan! We are excited to have you contribute to our open-source project. We welcome all types of contributions, from bug fixes to new features. This document will guide you through the process of contributing to our project.\nGetting Started\n\nBefore you start contributing, make sure you have the latest version of the code from our repository. You can clone our repository using the following command:\n\nbash\n\n`git clone https://github.com/jiffy-labs/jiffyscan-frontend.git`\n\nand switch to the branch `development`\n\n`git switch development && git pull`\n\nwork on development branch and raise a PR to develpoment branch\n\nOnce you have the code, you can install the dependencies by running:\n\n`npm install`\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `pages/index.tsx`. The page auto-updates as you edit the file.\n\n[API routes](https://nextjs.org/docs/api-routes/introduction) can be accessed on [http://localhost:3000/api/hello](http://localhost:3000/api/hello). This endpoint can be edited in `pages/api/hello.ts`.\n\nThe `pages/api` directory is mapped to `/api/*`. Files in this directory are treated as [API routes](https://nextjs.org/docs/api-routes/introduction) instead of React pages.\n\nThis project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.\n\n## Bug Reports and Feature Requests\n\nIf you've found a bug in Jiffyscan, please open a new issue on GitHub. Be sure to include as much detail as possible, including:\n\n-   Steps to reproduce the bug\n-   Expected behavior\n-   Actual behavior\n-   Screenshots or error messages (if applicable)\n\n## Pull Requests\n\nIf you want to contribute to the project by fixing a bug or adding a new feature, please submit a pull request. Here's how:\n\n-   Fork the repository.\n-   Create a new branch from the `development` branch.\n-   Make your changes and commit them.\n-   Push your branch to your forked repository.\n-   Open a pull request from your branch to the development branch of the original repository.\n\nWhen submitting a pull request, please include a clear description of your changes and why you made them. Please make sure your code follows our coding standards and is well-documented.\n\n## Code of Conduct\n\nWe expect all contributors to follow our code of conduct, which can be found in the CODE_OF_CONDUCT.md file in the repository. If you encounter any behavior that violates our code of conduct, please report it to the project maintainers.\nLicense\n\nThis project is licensed under the `MIT license`. By contributing to this project, you agree to license your contributions under this license.\n\nThank you for contributing to Jiffyscan! We appreciate your help in making our project better.\n"
  },
  "Farcaster-Attestation/farcaster-resolver": {
    "fetchedAt": "2025-11-12T22:53:49.448Z",
    "content": "# Farcaster Resolver\n\nIssuing attestations through a verified Farcaster wallet on the Superchain\n\n## Deployments\n\n* FarcasterResolverModule#Blake3 - [0xe9875D3A0D0dC78222aE01b2252d03F03CC3D018](https://optimistic.etherscan.io/address/0xe9875D3A0D0dC78222aE01b2252d03F03CC3D018)\n* FarcasterResolverModule#Ed25519_pow - [0x2782355596D62F991544E58F02cDb4237018eBC7](https://optimistic.etherscan.io/address/0x2782355596D62F991544E58F02cDb4237018eBC7)\n* FarcasterResolverModule#FarcasterPublicKeyVerifier - [0x20725BEf386c289110a54C8586D146EBb5Ed8C0b](https://optimistic.etherscan.io/address/0x20725BEf386c289110a54C8586D146EBb5Ed8C0b)\n* FarcasterResolverModule#FcVerificationDecoder - [0x3e189132eE05415fB1068d3086D4c1C3Cb37de37](https://optimistic.etherscan.io/address/0x3e189132eE05415fB1068d3086D4c1C3Cb37de37)\n* FarcasterResolverModule#Sha512 - [0x57bb00a1E7f9D03bcc042fAF82CCA248ec6F0f3f](https://optimistic.etherscan.io/address/0x57bb00a1E7f9D03bcc042fAF82CCA248ec6F0f3f)\n* FarcasterResolverModule#Ed25519 - [0x53A1E44420Fd09D089dd38f0dffEeEfB62Fd6826](https://optimistic.etherscan.io/address/0x53A1E44420Fd09D089dd38f0dffEeEfB62Fd6826)\n* FarcasterResolverModule#FarcasterResolver - [0xF99C4e843033831c570946a97F6195e47051C443](https://optimistic.etherscan.io/address/0xF99C4e843033831c570946a97F6195e47051C443)\n* FarcasterResolverModule#FcMessageVerification - [0x80b87f98840fE76bEb44b97bc5FE00457eaAEdb0](https://optimistic.etherscan.io/address/0x80b87f98840fE76bEb44b97bc5FE00457eaAEdb0)\n* FarcasterResolverModule#FarcasterWalletOnchainVerifier - [0xDcC7372912D743C52fD83bc7aB7810c40f449D3f](https://optimistic.etherscan.io/address/0xDcC7372912D743C52fD83bc7aB7810c40f449D3f)\n* FarcasterResolverModule#FarcasterWalletOptimisticVerifier - [0x0F12f716DFf14195875a2Da46d843770D32256d9](https://optimistic.etherscan.io/address/0x0F12f716DFf14195875a2Da46d843770D32256d9)\n* FarcasterResolverExtendedModule#FarcasterResolverInterop - [0x98561CaF79eb6a22B23fEb6366f798d7F3898c44](https://optimistic.etherscan.io/address/0x98561CaF79eb6a22B23fEb6366f798d7F3898c44)\n* FarcasterResolverExtendedModule#FarcasterMembership - [0x4FFf1356BFBC3F736c0f84412bf79358a618de3d](https://optimistic.etherscan.io/address/0x4FFf1356BFBC3F736c0f84412bf79358a618de3d)\n* FarcasterResolverExtendedModule#FarcasterResolverSimpleConsumer - [0x1a7eaD65F850862dAf2C9E3d65a43E7A4ff20C28](https://optimistic.etherscan.io/address/0x1a7eaD65F850862dAf2C9E3d65a43E7A4ff20C28)\n\n## Architecture\n\n![image](https://github.com/user-attachments/assets/ef0e9c34-c459-41dc-bd36-87ad747e0bb6)\n\n- **FarcasterResolver** - The primary contract that verifies and stores the relationship between a Farcaster-verified wallet address and its FID.\n- **FarcasterResolverInterop** - A wrapper for FarcasterResolver, enabling interoperability across the Superchain with deterministic deployment to the same address.\n- **FarcasterPublicKeyVerifier** - A contract that validates public keys and FIDs against the Farcaster KeyRegistry.\n- **FarcasterOnchainVerifier** - A contract that fully computes and verifies Farcaster wallet verification add/remove messages directly on-chain.\n- **FarcasterOptimisticVerifier** - A contract that verifies Farcaster wallet verification add/remove messages optimistically by relying on trusted, whitelisted relays. It includes a one-day challenge period, allowing anyone to dispute and verify the messages on-chain.\n- **FcVerificationDecoder** - Library for decoding Farcaster verification GRPC-encoded messages.  \n- **FcMessageVerification** - Library for verifying Farcaster message signatures.  \n- **FarcasterResolverConsumer** - Abstract contract template for implementing resolvers requiring Farcaster verification.  \n- **FarcasterResolverSimpleConsumer** - Simple resolver for schemas allowing only attestations from Farcaster-verified wallets.  \n- **FarcasterResolverStandardConsumer** - Customizable resolver for schemas needing complex verification, such as reference and membership validation.  \n- **FarcasterMembership** - Membership system enabling attestation owners to invite other Farcaster users to reference the attestation.\n\n*Note: FcVerificationDecoder, FcMessageVerification and their dependencies are on a separated repository: https://github.com/Farcaster-Attestation/farcaster-decoder*\n\n## Building the project\n \nThe Farcaster Resolver is built using Hardhat. To run tests and deploy the contract, ensure you configure your private key and the Optimism RPC address in the `.env` file, as the tests are operated in fork mode.\n\n### Setting the environment\n\nCreate an `.env` file with the following secrets\n\n```\nRPC_URL=<Optimism mainnet RPC>\nRPC_TESTNET_URL=<Optimism sepolia testnet RPC>\nPRIVATE_KEY=<Private key for contract deployment>\nETHERSCAN_API_KEY=<Etherscsn API Key>\n```\n\n### Compiling the contracts\n\n```\nnpx hardhat compile\n```\n\n### Running tests\n\n```\nnpx hardhat test\n```\n\n### Running coverage\n\n```\nnpm run coverage\n```\n\n### Deploying contracts on supersim\n\nSupersim is a lightweight tool designed to simulate the Superchain. It is primarily used to test the `FarcasterResolverInterop`. The following command launches forked OP and Base chains simultaneously and sets up an L2 <-> L2 cross-chain interoperability simulation:\n\n```\nsupersim fork --chains op,base --interop.autorelay\n```\n\nAfter starting Supersim, run the following command to deploy the necessary contracts:\n\n```\n./deploy-supersim.sh\n```\n\nNote that the `FarcasterResolverExtended` is deployed using a deterministic deployment strategy, ensuring it is deployed to the same address across all chains.\n\nThe first wallet in the test mnemonic (test junk) is designated as both the deployer and the admin of the contracts.\n\n## Attesting Wallet Verification\n\nThe first step in verifying a wallet on Farcaster is to bring its verification on-chain. Anyone can attest a wallet‚Äôs verification because it relies on a signed verification message broadcast over the Farcaster Hub.\n\n> **Note**  \n> Attestation is usually performed automatically by a relayer, though there may be a fallback to a user-driven process if the relayer fails.\n\nYou will need to retrieve your verification message from the Farcaster Hub. Then, call the FarcasterResolver contract to either:\n- **attest** a new wallet verification, or\n- **revoke** an existing onchain verification.\n\n```solidity\nfunction attest(\n    address recipient,\n    uint256 fid,\n    bytes32 publicKey,\n    uint256 verificationMethod,\n    bytes memory signature\n) public returns (bytes32)\n\nfunction revoke(\n    address recipient,\n    uint256 fid,\n    bytes32 publicKey,\n    uint256 verificationMethod,\n    bytes memory signature\n) public returns (bool)\n```\n\nParameters for `attest` and `revoke`:\n1. **recipient** ‚Äì The wallet address that is being verified\n2. **fid** ‚Äì The Farcaster FID (Farcaster ID) of the verifying user\n3. **publicKey** ‚Äì The Farcaster public key used to sign the wallet verification message (details below)\n4. **verificationMethod** - 1 (Onchain) or 2 (Optimistic) (details below)\n5. **signature** ‚Äì The encoded verification message and signature (details below)\n\n### Verification Methods\n\nThere are two verification methods: Onchain (1) and Optimistic (2)\n\n1. **Onchain Verification**  \n   - **Permissionless:** Anyone can submit an on-chain verification. The signature and message are being verified fully on-chain in the smart contract.\n   - **Pros:** Verification is instantaneous once the transaction is confirmed.  \n   - **Cons:** Higher gas costs.\n\n2. **Optimistic Verification**  \n   - **Trust-but-Verify:** A whitelisted relayer submits the verification, which can be challenged by anyone within one day if it‚Äôs malicious.  \n   - **Pros:** Lower gas costs compared to on-chain verification.  \n   - **Cons:** Relies on a whitelisted relayer and includes a one-day challenge period; not open to public submissions.\n\n### Getting publicKey and signature (verification message)\n\nYou can get verification messages of any FID by querying from the Farcaster Hub: ht\n\n[... truncated ...]"
  },
  "Farcaster-Attestation/farcaster-solidity": {
    "fetchedAt": "2025-11-12T22:53:49.857Z",
    "content": "# Farcaster Solidity\n\nA set of Solidity libraries for verifying and parsing Farcaster messages onchain. Made by [fastfourier.eth](https://warpcast.com/fastfourier.eth).\n\n## Introduction\n\nThe difference between a Farcaster and many other social networks is the cryptographic protocol that allows any user to verify any action, that happened on the network. Using cryptographic signatures and an onchain key registry, it is possible to verify the correctness of the cast, like, the following relation, etc.\n\nThe goal of this project is to provide a set of Solidity libraries and examples, helping to verify and parse Farcaster messages on-chain.\n\n## Overview\n\nFarcaster messages (cast, like, following, etc) are represented as Protobuf messages, signed with the user's private key. Here's an illustration of what happens when a new cast is sent to the Farcaster network:\n\n1. Alice publishes a cast. Application (eg Warpcast) forms a message from text, mentions, links, etc\n2. The message is encoded using the Protobuf scheme into a series of bytes. Then it gets hashed using the Blake3 hash function, and the first 20 bytes of the hash are signed with the user's Ed25519 private key. The corresponding public key is stored in a smart contract called `KeyRegistry` on Optimism Mainnet.\n3. The message and the signature, are being sent to the network\n4. Each network participant verifies, that the signature is correct and accepts the message as valid.\n\nAll these actions can be done inside the smart contract, verifying that Alice indeed sent the message!\n\n## Usage example\n\nThe full example can be found at [contracts/Test.sol](./contracts/Test.sol).\n\n```solidity\nfunction verifyCastAddMessage(\n  bytes32 public_key,\n  bytes32 signature_r,\n  bytes32 signature_s,\n  bytes memory message\n) external {\n  MessageData memory message_data = _verifyMessage(\n    public_key,\n    signature_r,\n    signature_s,\n    message\n  );\n\n  if (message_data.type_ != MessageType.MESSAGE_TYPE_CAST_ADD) {\n    revert InvalidMessageType();\n  }\n\n  emit MessageCastAddVerified(\n    message_data.fid,\n    message_data.cast_add_body.text,\n    message_data.cast_add_body.mentions\n  );\n}\n```\n\n## Gas usage\n\nGas usage mainly consists of three components:\n\n- Blake3 hashing (500k - 1m gas)\n- Ed25519 signature verification (‚âà 1m gas)\n- Message decoding (‚âà 100k gas)\n\n```\n¬∑-----------------------------------------|----------------------------|-------------|-----------------------------¬∑\n|          Solc version: 0.8.19           ¬∑  Optimizer enabled: false  ¬∑  Runs: 200  ¬∑  Block limit: 30000000 gas  ‚îÇ\n¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n|  Methods                                                                                                         ‚îÇ\n¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n|  Contract  ¬∑  Method                    ¬∑  Min         ¬∑  Max        ¬∑  Avg        ¬∑  # calls      ¬∑  usd (avg)  ‚îÇ\n¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n|  Test      ¬∑  verifyCastAddMessage      ¬∑           -  ¬∑          -  ¬∑    1922353  ¬∑            2  ¬∑          -  ‚îÇ\n¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n|  Test      ¬∑  verifyReactionAddMessage  ¬∑           -  ¬∑          -  ¬∑    1518784  ¬∑            2  ¬∑          -  ‚îÇ\n¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑|¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n```\n\n## FAQ\n\n### Is it possible to reduce gas usage per message?\n\nYes, absolutely! The main idea is to move expensive computations (Blake3 hashing and Ed25519 signature verification) offchain, using ZK proofs.\nIn this case, the Solidity contract verifies only a short proof (‚âà300k gas vs 2m).\nThis approach can be scaled with batching, so in the case of 10 messages, it takes 300k / 10 = 30k gas to verify a single message.\n\n### Which message types are supported?\n\nMost of them. Due to the contract size limitations, decodings for `CastRemoveBody`, `VerificationRemoveBody`, and `UserNameProof` are not included. You can include them yourself, by modifying the [message.proto](./protobufs/message.proto), check out the [Running Locally](#running-locally) section.\n\n### My contract does not fit into the 24 kb limit\n\nTry to use external libraries, as they are quite heavy to be used internally. Check the [test.ts](./test/test.ts) for deployment reference.\n\n### How can I verify the correctness of the public key?\n\nFarcaster uses onchain `KeyRegistry` contract ([spec](https://github.com/farcasterxyz/protocol/blob/main/docs/SPECIFICATION.md#12-key-registry)), which stores the relation between the user's FID (Farcaster ID) and a public key. Here's a verification example:\n\n```solidity\naddress KEY_REGISTRY = 0x....;\n\nIKeyRegistry.KeyData memory keyData = IKeyRegistry(KEY_REGISTRY).keyDataOf(\n  messageData.fid,\n  bytes.concat(publicKey)\n);\n\nif (keyData.state != IKeyRegistry.KeyState.ADDED) revert InvalidKey();\n```\n\nKeep in mind, that KeyRegistry contact has been migrated multiple times, so make sure you use the actual address from the [Farcaster Specification](https://github.com/farcasterxyz/protocol/blob/main/docs/SPECIFICATION.md#12-key-registry).\n\n### Can I use this project in networks other than Optimism Mainnet?\n\nTechnically it's possible, but it's quite tricky. The best way to achieve this will be by using storage proofs for KeyRegistry storage verification.\n\n### How can I use it in frames?\n\n```javascript\nimport { NextRequest, NextResponse } from \"next/server\";\nimport {\n  Factories,\n  FarcasterNetwork,\n  FrameActionBody,\n  getSSLHubRpcClient,\n  Message,\n  MessageData,\n  MessageType,\n  toFarcasterTime,\n  UserDataType,\n} from \"@farcaster/hub-nodejs\";\n\nexport async function POST(req: NextRequest) {\n  const {\n    trustedData: { messageBytes },\n  } = await req.json();\n\n  const frameMessage = Message.decode(Buffer.from(messageBytes, \"hex\"));\n\n  const messageSignature = Buffer.from(message.signature).toString('hex');\n\n  const messageData: MessageData = {\n    type: message.data?.type as MessageType,\n    fid: message.data?.fid as number,\n    timestamp: message.data?.timestamp as number,\n    network: message.data?.network as FarcasterNetwork,\n    frameActionBody: message.data?.frameActionBody,\n  };\n\n  const messageEncoded = (MessageData.encode(messageData).finish());\n\n  const args = [\n    '0x' + Buffer.from(message.signer).toString('hex'), // public_key\n    '0x' + Buffer.from(messageSignature).slice(0, 32).toString('hex'), // signature_r\n    '0x' + Buffer.from(messageSignature).slice(32, 64).toString('hex'), // signature_s\n    '0x' + Buffer.from(messageEncoded).toString('hex') // message\n  ];\n\n  // Send your transaction here\n  // ...\n}\n```\n\n## Running locally\n\n```bash\nnode --version\nv18.17.1\nnpm --version\n9.6.7\n\nyarn\nyarn hh:compile\nyarn hh:test\n# Get contract's size in kb\nyarn hh:size\n```\n\n### Modifying proto schemes\n\nTo modify .proto schemes, install [protobuf3-solidity](https://github.com/celestiaorg/protobuf3-solidity).\n\n```\ngit clone https://github.com/celestiaorg/protobuf3-solidity\ncd protobuf3-solidity\nmake\n```\n\nExport the path to the binary and run `yarn protoc` to update Solidity libraries and TS definitions\n\n```bash\nexport PROTO_GEN_SOL=./../protobuf3-solidity/bin/protoc-gen-sol\ncd farcaster-solidity\nyarn protoc\n```\n\nKeep in mind, that not all Protobuf features are supported (`oneOf` fields, repeated strings, non-packed repeated fields). Another important thing is that message fields should be enumerated in a strict incremental order.\n\n## Links & credits\n\n- [Blake3 Solidity implementation](https://github.com/mel-project/blake3-sol)\n- [Ed25519 Solidity implementation](https://github.com/chengwenxi/Ed25519)\n- [protobuf3-solidity](https://github.com/celestiaorg/protobuf3-solidity)\n- [@farcaster/core](https://gith\n\n[... truncated ...]"
  },
  "Farcaster-Attestation/op-attest": {
    "fetchedAt": "2025-11-12T22:53:50.316Z",
    "content": "# OP-Attest\nThis repository contains the code for op-attest service. This service is responsible for attesting the identity account from the Farcaster hub to the blockchain.\n\n## How it works\nOP-Attest is mono-repo that contains the following services:\n- `indexer`: This service is responsible for indexing the event stream from the Farcaster hub and storing the messages in the database.\n- `submitter`: This service is responsible for submitting the verify message to the Farcaster verify. The submitter will read the stored proof from the off-chain database and submit the proof to the EAS schema.\n- `attested`: This service will use when use optimistic attestation. This service will read all the stored proof from off-chain database and attested on-chain by calling the EAS schema. The attested service will also connect to same database as the indexer to get the proof of verification.\n- `challenge`: This service run by everyone who wants to challenge the proof of verification. Each proof of verification will have a challenge period (1 day) to allow anyone to challenge the proof. If the proof is challenged, the attestation will be revoked.\n\nTo use optimistic or on-chain attestation, you need to configure the environment variable `METHOD_VERIFY`:\n- METHOD_VERIFY=2: Use optimistic attestation, the verify message will be stored in the off-chain database and submitted on-chain.\n- METHOD_VERIFY=1: Use on-chain attestation, the verify message will be attested instantly on-chain.\n\nIf you want to run each services, do the following:\n# 1. Start the database dependencies\n```bash\n\n# Ensure you have node 21 installed, use nvm to install it\nnvm install 21\n\npnpm install && pnpm build\n\n# Start the db dependencies\ndocker compose up postgres redis\n```\n\n# 2. Start Indexer\n## 2.1. Configure the environment variables\n```bash\n# Configure the environment variables\nREDIS_URL=<redis_url>\nHUB_HOST=<host>:<port>\nHUB_SSL=false\nPOSTGRES_URL=<postgres_url>\n```\n## 2.2. Start the indexer\n```bash\n# Start the indexer\npnpm start indexer\n```\n\n# 3. Start Submitter\n## 3.1. Configure the environment variables\n```bash\n# Configure the environment variables\nPRIVATE_KEY=<private_key>\nFARCASTER_OPTIMISTIC_VERIFY_ADDRESS=<address of farcaster optimistic verify>\nPOSTGRES_URL=<postgres_url>\nMETHOD_VERIFY=<method_verify>\nSUBMITTER_SUBMIT_INTERVAL=<submit_interval_to_submit>\nSUBMITTER_BATCH_SIZE=<submit_batch_size>\nSUBMITTER_INDEX_INTERVAL=<submit_index_interval>\nSUBMITTER_MAX_L1_FEES=<submit_max_l1_fees>\nSUBMITTER_MAX_L2_GAS_PRICE=<submit_max_l2_gas_price>\n\n```\n## 3.2. Start the submitter\n```bash\n# Start the submitter\npnpm start submitter\n```\n# 4. Start Attested\n## 4.1. Configure the environment variables\n```bash\n# Configure the environment variables\nPRIVATE_KEY=<private_key>\nFARCASTER_OPTIMISTIC_VERIFY_ADDRESS=<address of farcaster optimistic verify>\nPOSTGRES_URL=<postgres_url>\nMETHOD_VERIFY=<method_verify>\nATTEST_INTERVAL=<attest_interval>\nATTEST_CHALLENGE_BLOCK_OFFSET=<attest_challenge_block_offset>\nATTEST_BATCH_SIZE=<attest_batch_size>\nATTEST_MAX_RETRIES=<attest_max_retries> default 5times\nATTEST_INTERVAL_RETRY=<attest_interval_retry> default 20s\n```\n\n## 4.2. Start the attested\n```bash\n# Start the attested\npnpm start attested\n```"
  },
  "growthepie/gtp-frontend": {
    "fetchedAt": "2025-11-12T22:53:57.989Z",
    "content": "# Welcome to the growthepie üìèü•ß Frontend!\n\n[growthepie](https://growthepie.xyz/) aims to enhance transparency and understanding of the Ethereum Layer 2 ecosystem by providing comprehensive, curated data, blockspace analysis and educational resources to users, developers and investors.\n\nThe growthepie frontend provides an engaging user interface, displaying curated data and analysis sourced from our robust [backend](https://github.com/growthepie/gtp).\n\n<p align=\"center\">\n  <img src=\"https://github.com/growthepie/.github/assets/90760534/ca2ca39f-657b-4f79-8550-242b4ee9c4ec\" alt=\"Sublime's custom image\"/>\n</p>\n\n## gtp - Frontend Repository\n\nThe [`gtp-frontend`](https://github.com/growthepie/gtp-frontend) repository is built with Next.js, leveraging modern web technologies to ensure a responsive and interactive experience for our users.\n\n### Features\n\n- Built with [Next.js](https://nextjs.org/)\n- Styled with [Tailwind CSS](https://tailwindcss.com/)\n- Data sourced from growthepie's [API](https://github.com/growthepie/gtp)\n- Data visualizations using [Highcharts](https://highcharts.com)\n- Deployed on [Vercel](https://vercel.com/)\n\n## Get Involved\n\n- **Contribute**: Fork our repo, make your changes, and submit a pull request.\n- **Join Our Community**: For discussions and collaboration, join us on [Discord](https://discord.gg/pKzYwm7h).\n\nYour involvement is vital to growthepie and our mission to enhance transparency in the Ethereum Layer 2 ecosystem.\n\n## License\n\nThe growthepie frontend is licensed under the [MIT License](LICENSE).\n"
  },
  "growthepie/gtp-dna": {
    "fetchedAt": "2025-11-12T22:53:58.375Z",
    "content": "# growthepie DNA\n\nThis repository contains the core data definitions and mapping files that power [growthepie.xyz](https://www.growthepie.xyz) - an open-source Ethereum analytics platform.\n\n## üåü Overview\n\nThe GTP-DNA repo acts as the central source of truth for growthepie's config files and metadata. It contains:\n\n- **Chain definitions** - Metadata about L1 and L2s\n- **Data availability mapping** - Information about how Layer 2 post data\n- **Economic tracking** - Transaction mapping for cost analysis across Layer 2s\n- **Label confidence lists** - Entity verification for Open Labels Initiative\n\nAll of this data feeds directly into growthepie's analytics pipelines, dashboards, and APIs.\n\n## üìÅ Repository Structure\n\n- **`/chains/`** - JSON definitions for each blockchain we track\n  - Each chain has its own directory containing:\n    - `main.json` - Core chain metadata\n    - `logo.json` - SVG path data for chain logo\n\n- **`/da_layers/`** - Data availability layer definitions\n  - Each DA layer has:\n    - `main.json` - Core DA layer metadata\n    - `logo.json` - SVG path data for DA layer logo\n\n- **`/economics_da/`** - Economics and data availability tracking\n  - `economics_mapping.yml` - Maps transaction types to their respective chains\n  - `readme.md` - Explanation of the economics mapping\n\n- **`/logos/`** -  Logo definitions for applications or chains not yet supported by growthepie\n  - `images/` - Project logos, mapping the name to the official project slug in the OSS directory\n  - `custom_logos.json` - SVG path data for custom chain logos\n\n- **`/oli/`** - Open Labels Initiative data\n  - `trusted_entities.yml` - List of trusted entities for OLI\n  - `README.md` - Explanation of the OLI integration\n\n## üîç Key Components\n\n### Chain Definitions\n\nThe chain definition files in `/chains/` directory contain structured metadata about each blockchain, including:\n\n- Basic identifiers (name, chain ID, symbol)\n- Block explorer URLs\n- Color schemes for UI\n- Technology stack details\n- Social media links\n- API deployment flags\n- Cross-check sources\n\n### Data Availability Mapping\n\nThe `/economics_da/economics_mapping.yml` file maps L2 transactions to their respective DA (Data Availability) layers. This enables:\n\n- Tracking of Layer 1 costs for each Layer 2\n- Analysis of data posting patterns\n- Monitoring of economic efficiency\n\n### Open Labels Initiative (OLI)\n\nThe `/oli/` directory contains confidence scores for trusted attesters in the Open Labels Initiative ecosystem, which helps with entity verification.\n\n## ü§ù How to Contribute\n\nWe welcome contributions from the community! Here's how you can help:\n\n### Adding or Updating Chain Information\n\n1. **Fork the repository**\n\n2. **Create or modify chain definition files**\n   - If adding a new chain, create a new directory in `/chains/` named after the chain\n   - Copy the structure from an existing chain and adapt it\n   - Include `main.json` with all required metadata\n   - Add `logo.json` with SVG path data for the chain's logo\n\n3. **Test your changes**\n   - Ensure all JSON files are properly formatted\n   - Validate that all required fields are included\n\n4. **Submit a pull request**\n   - Provide a clear description of your changes\n   - Reference any relevant issues or external resources\n\n### Updating Economics/DA Mappings\n\n1. **Fork the repository**\n\n2. **Edit the mapping file**\n   - Update `/economics_da/economics_mapping.yml` with new or corrected mappings\n   - Follow the existing structure for consistency\n   - Add detailed comments for new entries\n\n3. **Submit a pull request**\n   - Explain the reasoning behind your changes\n   - Include links to transaction examples if applicable\n\n## üìä Data Usage\n\nThe definitions in this repository power several features on growthepie.xyz:\n\n- **Economics Overview**: https://www.growthepie.xyz/economics\n- **Data Availability Overview**: https://www.growthepie.xyz/data-availability\n- **Chain Listings**: Various chain metrics and visualizations\n\nThe economics data is also available via a Dune Analytics table:\n```sql\nSELECT * FROM dune.growthepie.l2economics_mapping\n```\n\n## üìú License\n\nThis repository is licensed under the MIT License - see the LICENSE file for details.\n\n## üôè Acknowledgements\n\nSpecial thanks to all contributors who help maintain and improve this data. Your efforts help provide accurate and comprehensive information to the blockchain community.\n\n---\n\nFor questions or feedback, please open an issue on this repository or reach out to the growthepie team."
  },
  "growthepie/gtp": {
    "fetchedAt": "2025-11-12T22:53:59.223Z",
    "content": "# Welcome to the growthepie üìèü•ß Backend!\n\n[growthepie](https://growthepie.xyz/) improves transparency across the Ethereum ecosystem by curating onchain, offchain, and community-sourced signals into actionable metrics, dashboards, and research.\n\n<p align=\"center\">\n  <img src=\"https://github.com/growthepie/.github/assets/90760534/ca2ca39f-657b-4f79-8550-242b4ee9c4ec\" alt=\"growthepie logo\"/>\n</p>\n\n## What This Repo Does\n\nThe [`gtp-backend`](https://github.com/growthepie/gtp-backend) repository powers growthepie‚Äôs public dashboard and data products. It runs on Python **3.10.12** and houses:\n\n- **Data ingestion adapters** that pull metrics from RPC nodes, Dune, CoinGecko, L2Beat, DeFiLlama, BigQuery, and bespoke indexers.\n- **Curation and enrichment jobs** that normalize raw payloads, stitch cross-source identifiers, and enforce common schemas before persisting to PostgreSQL.\n- **Analytics layers** that transform curated tables into pre-aggregated highlights, trendlines, and API payloads used by the dashboard, alerts, and JSON exports.\n- **Airflow orchestration** for scheduling hourly/daily DAGs, data quality checks, and downstream notifications.\n\n## Repository Highlights\n\n- `backend/src/adapters/`: Source-specific connectors (`adapter_stables.py`, `adapter_defillama.py`, etc.) plus shared clients like `bigquery.py`.\n- `backend/src/queries/`: Jinja-templated SQL powering metrics (e.g., `select_txcount.sql.j2`) and API endpoints.\n- `backend/airflow/dags/`: Production DAGs grouped by feature area (`metrics_*`, `api_*`, `other_*`) with alerting and JSON generation pipelines.\n- `backend/src/api/`: JSON builders (`json_gen.py`, `json_creation.py`) and the lightweight API surface in `oli/api`.\n- `backend/src/config.py` and friends manage environment-specific wiring.\n\n## Functional Flows\n\n1. **Ingest** ‚Äì Adapters fetch fresh slices of chain activity, market data, or third-party metrics.\n2. **Transform** ‚Äì Helper modules clean, reconcile, and upsert into curated PostgreSQL tables.\n3. **Analyze** ‚Äì SQL templates and Python processors compute KPIs for quantities like TPS, fees, security, and ecosystem health.\n4. **Distribute** ‚Äì Airflow DAGs trigger JSON generation, API refreshes, alerts, and highlights consumed by growthepie.com and partner feeds.\n\n## Related Repositories\n\nExplore the rest of the [`growthepie org`](https://github.com/growthepie) for front-end, infra, and research companions.\n"
  },
  "zink-lang/zink": {
    "fetchedAt": "2025-11-12T22:54:06.797Z",
    "content": "<img align=\"right\" width=\"150\" height=\"150\" top=\"100\" src = \"https://avatars.githubusercontent.com/u/138247979?s=400&u=cbf4b9e9da048899a947f08d92e030806d5bd50b&v=4\"/>\n\n# The Zink Language\n\n> [!CAUTION]\n>\n> This project is still under active development, please DO NOT use it in production.\n\n[![zink][version-badge]][version-link]\n[![ci][ci-badge]][ci-link]\n[![telegram][telegram-badge]][telegram-group]\n\nWelcome to the Zink Language! [Bounty issues](https://zink-lang.org/bounties) are now available, join the development of Zink by reading the [book](https://zink-lang.org/).\n\n```rust\n//! ERC20 Example (WIP)\n#[zink::contract]\npub struct ERC20;\n\n#[zink::calls]\nimpl ERC20 {\n  /// VMs that zink supports\n  pub fn support() -> [zink::String; 4] {\n    [\"EVM\", \"WASM\", \"RISC-V\", \"...OTHER_VMS\"]\n  }\n}\n\n#[zink::interface]\nimpl ERC20 for ERC20 {\n  fn name() -> zink::String {\n    \"Zink Language\".to_string()\n  }\n}\n```\n\n- **Safe**: `rustc` monitors your code!\n\n- **Efficient**: Efficient EVM bytecode from `rustc`, `wasm-opt`, and `zinkc`.\n\n- **Modular**: Upload and download your contract components via `crates.io`.\n\n- **Rusty**: All of the rust tools are available for your contracts!\n\nRun `cargo install zinkup` to install the toolchain!\n\n## Testing & Development\n\n| Command    | Description            |\n| ---------- | ---------------------- |\n| `cargo cc` | Clippy all packages    |\n| `cargo tt` | Run all tests          |\n| `cargo be` | Build all examples     |\n| `cargo te` | Run tests for examples |\n\nWe're using `cargo-nextest` for testing, the commands above are described in [.cargo/config.toml](.cargo/config.toml).\n\n## Special Thanks\n\n- [MegaETH](https://github.com/megaeth-labs) for the funding and trust!\n- [revm](https://github.com/bluealloy/revm) for the EVM in rust!\n\n## LICENSE\n\nGPL-3.0-only\n\n[book]: https://zink-lang.org/\n[telegram-badge]: https://img.shields.io/endpoint?label=chat&style=flat&url=https%3A%2F%2Fmogyo.ro%2Fquart-apis%2Ftgmembercount%3Fchat_id%3Dzinklang\n[telegram-group]: https://t.me/zinklang\n[version-badge]: https://img.shields.io/crates/v/zinkc\n[version-link]: https://docs.rs/zinkc\n[ci-badge]: https://img.shields.io/github/actions/workflow/status/clearloop/zink/main.yml\n[ci-link]: https://github.com/clearloop/zink/actions/workflows/main.yml\n[rustc-codegen]: https://doc.rust-lang.org/rustc/codegen-options/index.html\n[wasm-opt]: https://github.com/WebAssembly/binaryen#binaryen-optimizations\n"
  },
  "sifaw23/distributler": {
    "fetchedAt": "2025-11-12T22:54:16.215Z",
    "content": "Welcome to the NextJS 13 base template bootstrapped using the `create-next-app`. This template supports TypeScript, but you can use normal JavaScript as well.\n\n## Getting Started\n\nHit the run button to start the development server.\n\nYou can start editing the page by modifying `pages/index.tsx`. The page auto-updates as you edit the file.\n\n[Route Handlers](https://nextjs.org/docs/app/building-your-application/routing/route-handlers) allow you to create custom request handlers for a given route using the Web Request and Response APIs.\n\nThe `app/api` directory is mapped to `/api/*`. Folders in this directory with files named `route.ts` are treated as [Route handlers](https://nextjs.org/docs/app/building-your-application/routing/route-handlers) instead of pages.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\n## Productionizing your Next App\n\nTo make your next App run smoothly in production make sure to deploy your project with [Repl Deployments](https://docs.replit.com/hosting/deployments/about-deployments)!\n\nYou can also produce a production build by running `npm run build` and [changing the run command](https://docs.replit.com/programming-ide/configuring-repl#run) to `npm run start`.\n# distributler\n"
  },
  "GNSPS/solidity-bytes-utils": {
    "fetchedAt": "2025-11-12T22:54:23.091Z",
    "content": "# Solidity Bytes Arrays Utils\n\nBytes tightly packed arrays' utility library for ethereum contracts written in Solidity.\n\nThe library lets you concatenate, slice and type cast bytes arrays both in memory and storage.\n\nGiven this library has an all-internal collection of methods it doesn't make sense to have it reside in the mainnet. Instead it will only be available on EPM as an installable package.\n\n## Important Fixes Changelog\n\n_**2021-01-07**_\n\nA bug regarding zero-length slices was disclosed by @MrChico following an audit to the Optimism codebase.\n\nThe exact bug happened under the following conditions: if memory slots higher then the current free-memory pointer were tainted before calling the `slice` method with a desired length of `0`, the returned bytes array, instead of being a zero-length slice was an array of arbitrary length based on the values that previously populated that memory region.\n\nOverall, the usage of zero-length slices should be pretty unusual and, as such, hopefully, this bug does not have far-reaching implications. Nonetheless, *please update the library to the new version if you're using it in production*.\n\n**TL;DR: if you're using the `slice` method with a length parameter of '0' in your codebase, please update to version 0.1.2 of the bytes library ASAP!**\n\n_**2020-11-01**_\n\nThere was a **critical bug** in the `slice` method, reported on an audit to a DXDao codebase.\n\nPreviously, no checks were being made on overflows of the `_start` and `_length` parameters since previous reviews of the codebase deemed this overflow \"unexploitable\" because of an inordinate expansion of memory (i.e., reading an immensely large memory offset causing huge memory expansion) resulting in an out-of-gas exception.\n\nHowever, as noted in the review mentioned above, this is not the case. The `slice` method in versions `<=0.9.0` actually allows for arbitrary _kind of_ (i.e., it allows memory writes to very specific values) arbitrary memory writes _in the specific case where these parameters are user-supplied inputs and not hardcoded values (which is uncommon).\n\nThis made me realize that in permissioned blockchains where gas is also not a limiting factor this could become problematic in other methods and so I updated all typecasting-related methods to include new bound checks as well.\n\n**TL;DR: if you're using the `slice` method with user-supplied inputs in your codebase please update the bytes library immediately!**\n\n## _Version Notes_:\n\n* Version `v0.9.0` has a new feature: a new \"equal_nonAligned\" method that allows for comparing two bytes arrays that are not aligned to 32 bytes.\nThis is useful for comparing bytes arrays that were created with assembly/Yul or other, non-Solidity compilers that don't pad bytes arrays to 32 bytes.\n\n* Starting from version `v0.8.0` the versioning will change to follow compatible Solidity's compiler versions.\nThis means that now the library will only compile on Solidity versions `>=0.8.0` so, if you need `<0.8.0` support for your project just use `v0.1.2` of the library with:\n\n```\n$ truffle install bytes@0.8.0\n```\nor\n```\n$ npm install solidity-bytes-utils@0.8.0\n```\n\n* Version `v0.1.2` has a major bug fix.\n\n* Version `v0.1.1` has a critical bug fix.\n\n* Version `v0.9.0` now compiles with Solidity compilers `0.5.x` and `0.6.x`.\n\n* Since version `v0.0.7` the library will only compile on Solidity versions `>0.4.22` so, if you need `v0.4.x` support for your project just use `v0.0.6` of the library with:\n\n```\n$ truffle install bytes@0.0.6\n```\nor\n```\n$ npm install solidity-bytes-utils@0.0.6\n```\n\n## Usage\n\nYou can use the library here present by direct download and importing with:\n```\nimport \"BytesLib.sol\";\n```\n\nor, if you have installed it from EPM (see below), with Truffle's specific paths:\n```\nimport \"bytes/BytesLib.sol\";\n```\n\nUsage examples and API are more thoroughly explained below.\n\nAlso there's an extra library in there called `AssertBytes` (inside the same named file) which is compatible with Truffle's Solidity testing library `Assert.sol` event firing and so lets you now test bytes equalities/inequalities in your Solidity tests by just importing it in your `.sol` test files:\n```\nimport \"bytes/AssertBytes.sol\";\n```\n\nand use the library `AssertBytes` much like they use `Assert` in Truffle's [example](http://truffleframework.com/docs/getting_started/solidity-tests).\n\n## EthPM\n\nThis library is published in EPM under the alias `bytes`\n\n**Installing it with Truffle**\n\n```\n$ truffle install bytes\n```\n\n## NPM\n\nThis library is published in NPM under the alias `solidity-bytes-utils`\n\n**Installing it with NPM**\n\n```\n$ npm install solidity-bytes-utils\n```\n\n**Importing it in your Solidity contract**\n\n```\nimport \"solidity-bytes-utils/contracts/BytesLib.sol\";\n```\n\n## Contributing\n\nContributions are more than welcome in any way shape or form! üòÑ\n\nTODOs:\n* Two storage bytes arrays concatenation\n* Slicing directly from storage\n* Implement inline assembly functions for better readability\n\n### Testing\n\nThis project uses Truffle for tests. Truffle's version of `solc` needs to be at least 0.4.19 for the contracts to compile. If you encounter compilation errors, try:\n\n    $ cd /usr/local/lib/node_modules/truffle\n    $ npm install solc@latest\n\nTo run the tests, start a `testrpc` instance, then run `truffle test`.\n\n## API\n\n* `function concat(bytes memory _preBytes, bytes memory _postBytes) internal pure returns (bytes)`\n\nConcatenates two `bytes` arrays in memory and returns the concatenation result as another `bytes` array in memory.\n\n\n* `function concatStorage(bytes storage _preBytes, bytes memory _postBytes) internal pure`\n\nConcatenates a `bytes` array present in memory directly into the given storage location addressed by the `_preBytes` storage pointer.\n\n\n* `function slice(bytes _bytes, uint _start, uint _length) internal  pure returns (bytes)`\n\nTakes a slice from a `bytes` array in memory of given `length` starting from `_start`th byte counting from the left-most one (0-based).\n\n\n* `function toAddress(bytes _bytes, uint _start) internal  pure returns (address)`\n\nTakes a 20-byte-long sequence present in a `bytes` array in memory and returns that as an address (also checks for sufficient length).\n\n\n* `function toUint(bytes _bytes, uint _start) internal  pure returns (uint256)`\n\nTakes a 32-byte-long sequence present in a `bytes` array in memory and returns that as an unsigned integer (also checks for sufficient length).\n\n\n* `function equal(bytes memory _preBytes, bytes memory _postBytes) internal view returns (bool)`\n\nCompares two `bytes` arrays in memory and returns the comparison result as a `bool` variable.\n\n\n* `function equalStorage(bytes storage _preBytes, bytes memory _postBytes) internal view returns (bool)`\n\nCompares a `bytes` array in storage against another `bytes` array in memory and returns the comparison result as a `bool` variable.\n\n\n## Examples\n\nOrdered to mimic the above `API` section ordering:\n\n```javascript\ncontract MyContract {\n\tusing BytesLib for bytes;\n\n\tfunction myFunc() {\n\t\tbytes memory _preBytes = hex\"f00dfeed\";\n\t\tbytes memory _postBytes = hex\"f00dfeed\";\n\n\t\tbytes memory concatBytes = _preBytes.concat(_postBytes);\n\n\t\t// concatBytes == 0xf00dfeedf00dfeed\n\t}\n}\n```\n\n\n```javascript\ncontract MyContract {\n\tusing BytesLib for bytes;\n\n\tbytes storageBytes = hex\"f00dfeed\";\n\n\tfunction myFunc() {\n\t\tbytes memory _postBytes = hex\"f00dfeed\";\n\n\t\tstorageBytes.concatStorage(_postBytes);\n\n\t\t// storageBytes == 0xf00dfeedf00dfeed\n\t}\n}\n```\n\n\n```javascript\ncontract MyContract {\n\tusing BytesLib for bytes;\n\n\tfunction myFunc() {\n\t\tbytes memory memBytes = hex\"f00dfeedaabbccddeeff\";\n\n\t\tbytes memory slice1 = memBytes.slice(0, 2);\n\t\tbytes memory slice2 = memBytes.slice(2, 2);\n\n\t\t// slice1 == 0xf00d\n\t\t// slice2 == 0xfeed\n\t}\n}\n```\n\n\n```javascript\ncontract MyContract {\n\tusing BytesLib for bytes;\n\n\tfunction myFunc() {\n\t\tbytes memory memBytes = hex\"f00dfeed383Fa3B60f9B4AB7fBf6835d3c26C3765cD2B2e2f00dfeed\";\n\n\t\taddress addrFromBytes = memBytes.toAddress(\n\n[... truncated ...]"
  },
  "thirdweb-dev/insight": {
    "fetchedAt": "2025-11-12T22:54:30.711Z",
    "content": "# Insight\n\n**Insight** is a high-performance, modular blockchain indexer and data API for EVM chains. It fetches, processes, and stores on-chain data‚Äîmaking it easy to query blocks, transactions, logs, token balances, and more via a robust HTTP API.\n\n## üöÄ Getting Started\n\n**Quickstart (Local Development):**\n\n```bash\n# 1. Clone the repo\ngit clone https://github.com/thirdweb-dev/insight.git\ncd insight\n\n# 2. Copy example configs and secrets\ncp configs/config.example.yml configs/config.yml\ncp configs/secrets.example.yml configs/secrets.yml\n\n# 3. (Optional) Start dependencies with Docker Compose\ndocker-compose up -d clickhouse\n\n# 4. Apply ClickHouse migrations\ncat internal/tools/clickhouse/*.sql | docker exec -i <clickhouse-container> clickhouse-client --user admin --password password\n\n# 4b. Apply Postgres migrations (if using Postgres for orchestration and staging)\npsql -h localhost -U postgres -d postgres -f internal/tools/postgres/postgres_schema.sql\n\n# 5. Build and run Insight\ngo build -o main -tags=production\n./main orchestrator   # Starts the indexer\n./main api           # Starts the API server\n\n# 6. Access the API\n# Default: http://localhost:3000\n```\n\n### üèÉ‚Äç‚ôÇÔ∏è Quick Start with Hybrid Setup (PostgreSQL + ClickHouse)\n\nFor testing the staging flow with PostgreSQL for orchestration/staging and ClickHouse for main storage:\n\n```bash\n# 1. Build the application\ngo build -o insight .\n\n# 2. Start databases (PostgreSQL + ClickHouse)\ndocker compose up -d\n\n# 3. Run the orchestrator with test configuration\n./insight orchestrator --config configs/test_config.yml\n\n# 4. (Optional) Start the API server\n./insight api --config configs/test_config.yml\n\n# 5. Monitor the databases\n# PostgreSQL (staging): docker exec insight-postgres-1 psql -U admin -d insight\n# ClickHouse (main): clickhouse-client --host localhost --port 9440 --user admin --password password\n```\n\n**Database Connections:**\n- **PostgreSQL**: `localhost:5432` (staging & orchestrator storage)\n- **ClickHouse**: `localhost:9440` (main storage)\n- **Credentials**: `admin` / `password`\n\n---\n\n## üèó How It Works\n\nInsight's architecture consists of five main components that work together to continuously index blockchain data:\n\n### 1. **Poller** \nThe Poller continuously fetches new blocks from the configured RPC endpoint. It uses multiple worker goroutines to concurrently retrieve block data, handles successful and failed results, and stores the processed block data and any failures in staging storage.\n\n### 2. **Worker** \nThe Worker processes batches of block numbers, fetching block data, logs, and traces (if supported) from the configured RPC. It divides the work into chunks, processes them concurrently, and returns the results as a collection of WorkerResult structures containing block data, transactions, logs, and traces for each processed block.\n\n### 3. **Committer** \nThe Committer periodically moves data from staging storage to main storage. It ensures blocks are committed sequentially, handling any gaps in the data, and updates various metrics while performing concurrent inserts of blocks, logs, transactions, and traces into the main storage.\n\n### 4. **Failure Recoverer** \nThe FailureRecoverer recovers from block processing failures. It periodically checks for failed blocks, attempts to reprocess them using a worker, and either removes successfully processed blocks from the failure list or updates the failure count for blocks that continue to fail.\n\n### 5. **Orchestrator** \nThe Orchestrator coordinates and manages the poller, failure recoverer, and committer. It initializes these components based on configuration settings and starts them concurrently, ensuring they run independently while waiting for all of them to complete their tasks.\n\n### Data Flow\n1. **Polling**: The Poller continuously checks for new blocks on the blockchain\n2. **Processing**: Workers fetch and process block data, transactions, logs, and traces\n3. **Staging**: Processed data is stored in staging storage for validation\n4. **Commitment**: The Committer moves validated data to main storage\n5. **Recovery**: Failed blocks are retried by the Failure Recoverer\n6. **API**: The HTTP API serves queries from the main storage\n\n### Work Modes\nInsight operates in two distinct work modes that automatically adapt based on how far behind the chain head the indexer is:\n\n**Backfill Mode** (Catching Up):\n- Used when the indexer is significantly behind the latest block\n- Processes blocks in large batches for maximum throughput\n- Optimized for an error-free indexing process over speed\n- Automatically switches to live mode when caught up\n\n**Live Mode** (Real-time):\n- Used when the indexer is close to the chain head (within ~500 blocks by default)\n- Processes blocks as they arrive with minimal latency\n- Optimized for real-time data availability\n- Switches back to backfill mode if falling behind\n\nThe work mode threshold and check interval are configurable via `workMode.liveModeThreshold` and `workMode.checkIntervalMinutes` settings.\n\nThis modular architecture allows for adaptation to various EVM chains and use cases, with configurable batch sizes, delays, and processing strategies.\n\n---\n\n## ‚öôÔ∏è Installation / Setup\n\n### Prerequisites\n\n- **Go** 1.23+\n- **ClickHouse** database (Docker Compose included)\n- (Optional) **Redis**, **Kafka**, **Prometheus**, **Grafana** for advanced features\n\n### Environment Variables & Secrets\n\nInsight supports configuration via environment variables, which is especially useful for containerized deployments and CI/CD pipelines.\n\n**Environment Variable Naming Convention:**\n- Use uppercase letters and underscores\n- Nested YAML paths become underscore-separated variables\n- Example: `rpc.url` becomes `RPC_URL`\n- Example: `storage.main.clickhouse.host` becomes `STORAGE_MAIN_CLICKHOUSE_HOST`\n\n**Common Environment Variables:**\n\n**RPC Configuration:**\n```bash\nRPC_URL=https://1.rpc.thirdweb.com/your-client-id\nRPC_CHAIN_ID=1\nRPC_BLOCKS_BLOCKS_PER_REQUEST=500\nRPC_BLOCKS_BATCH_DELAY=100\nRPC_LOGS_BLOCKS_PER_REQUEST=250\nRPC_LOGS_BATCH_DELAY=100\nRPC_TRACES_ENABLED=false\n```\n\n**Storage Configuration:**\n```bash\nSTORAGE_MAIN_CLICKHOUSE_HOST=localhost\nSTORAGE_MAIN_CLICKHOUSE_PORT=9000\nSTORAGE_MAIN_CLICKHOUSE_USERNAME=admin\nSTORAGE_MAIN_CLICKHOUSE_PASSWORD=your-password\nSTORAGE_MAIN_CLICKHOUSE_DATABASE=main\nSTORAGE_MAIN_CLICKHOUSE_DISABLE_TLS=false\n```\n\n**API Configuration:**\n```bash\nAPI_HOST=0.0.0.0\nAPI_PORT=3000\nAPI_THIRDWEB_CLIENT_ID=your-client-id\nAPI_BASIC_AUTH_USERNAME=admin\nAPI_BASIC_AUTH_PASSWORD=your-api-password\n```\n\n**Logging Configuration:**\n```bash\nLOG_LEVEL=info\nLOG_PRETTIFY=false\n```\n\n**Poller Configuration:**\n```bash\nPOLLER_ENABLED=true\nPOLLER_INTERVAL=1000\nPOLLER_BLOCKS_PER_POLL=500\nPOLLER_FROM_BLOCK=0\n```\n\n**Complete Example:**\n```bash\n# Set all configuration via environment variables\nexport RPC_URL=\"https://1.rpc.thirdweb.com/your-client-id\"\nexport RPC_CHAIN_ID=1\nexport STORAGE_MAIN_CLICKHOUSE_HOST=\"your-clickhouse-host\"\nexport STORAGE_MAIN_CLICKHOUSE_PASSWORD=\"your-password\"\nexport API_BASIC_AUTH_USERNAME=\"admin\"\nexport API_BASIC_AUTH_PASSWORD=\"your-api-password\"\nexport LOG_LEVEL=\"info\"\n\n# Run without config files\n./main orchestrator\n./main api\n```\n\n**Secrets Management:**\n- For sensitive credentials, you can use environment variables instead of `configs/secrets.yml`\n- Environment variables take precedence over config files\n- See `configs/secrets.example.yml` for the complete structure\n\n### Docker\n\n- `docker-compose.yml` provides ClickHouse, Redis, Prometheus, and Grafana for local development.\n- Exposes:\n  - ClickHouse: `localhost:8123` (web UI), `localhost:9440` (native)\n  - Prometheus: `localhost:9090`\n  - Grafana: `localhost:4000`\n  - Redis: `localhost:6379`\n\n### Database Migrations\n\n- SQL migration scripts are in `internal/tools/`.\n- Apply them to your ClickHouse instance before running the indexer.\n\n---\n\n## üí° Usage\n\n### CLI Commands\n\n- **Indexer (Orchestrator):**  \n  `./main orchestrator`  \n  Starts the block poller, committer,\n\n[... truncated ...]"
  },
  "thirdweb-dev/contracts": {
    "fetchedAt": "2025-11-12T22:54:31.046Z",
    "content": "<p align=\"center\">\n<br />\n<a href=\"https://thirdweb.com\"><img src=\"https://github.com/thirdweb-dev/typescript-sdk/blob/main/logo.svg?raw=true\" width=\"200\" alt=\"\"/></a>\n<br />\n</p>\n<h1 align=\"center\">thirdweb Contracts</h1>\n<p align=\"center\">\n<a href=\"https://www.npmjs.com/package/@thirdweb-dev/contracts\"><img src=\"https://img.shields.io/npm/v/@thirdweb-dev/contracts?color=red&logo=npm\" alt=\"npm version\"/></a>\n<a href=\"https://github.com/thirdweb-dev/contracts/actions\"><img alt=\"Build Status\" src=\"https://github.com/thirdweb-dev/contracts/actions/workflows/tests.yml/badge.svg\"/></a>\n<a href=\"https://discord.gg/thirdweb\"><img alt=\"Join our Discord!\" src=\"https://img.shields.io/discord/834227967404146718.svg?color=7289da&label=discord&logo=discord&style=flat\"/></a>\n\n</p>\n<p align=\"center\"><strong>Collection of smart contracts deployable via the thirdweb SDK, dashboard and CLI</strong></p>\n<br />\n\n## Installation\n\n```shell\n# Forge projects\nforge install https://github.com/thirdweb-dev/contracts\n\n# Hardhat / npm based projects\nnpm i @thirdweb-dev/contracts\n```\n\n```bash\ncontracts\n|\n|-- extension: \"extensions that can be inherited by NON-upgradeable contracts\"\n|   |-- interface: \"interfaces of all extension contracts\"\n|   |-- upgradeable: \"extensions that can be inherited by upgradeable contracts\"\n|   |-- [$prebuilt-category]: \"legacy extensions written specifically for a prebuilt contract\"\n|\n|-- base: \"NON-upgradeable base contracts to build on top of\"\n|   |-- interface: \"interfaces for all base contracts\"\n|   |--  upgradeable: \"upgradeable base contracts to build on top of\"\n|\n|-- prebuilt: \"audited, ready-to-deploy thirdweb smart contracts\"\n|   |-- interface: \"interfaces for all prebuilt contracts\"\n|   |--[$prebuilt-category]: \"feature-based group of prebuilt contracts\"\n|   |-- unaudited: \"yet-to-audit thirdweb smart contracts\"\n|       |-- [$prebuilt-category]: \"feature-based group of prebuilt contracts\"\n|\n|-- infra: \"onchain infrastructure contracts\"\n|   |-- interface: \"interfaces for all infrastructure contracts\"\n|\n|-- eip: \"implementations of relevant EIP standards\"\n|   |-- interface \"all interfaces of relevant EIP standards\"\n|\n|-- lib: \"Solidity libraries\"\n|\n|-- external-deps: \"modified / copied over external dependencies\"\n|   |-- openzeppelin: \"modified / copied over openzeppelin dependencies\"\n|   |-- chainlink: \"modified / copied over chainlink dependencies\"\n|\n|-- legacy-contracts: \"maintained legacy thirdweb contracts\"\n```\n\n## Running Tests\n\n1. `yarn`: install contracts dependencies\n2. `forge install`: install tests dependencies\n3. `forge test`: run the tests\n\nThis repository is a [forge](https://github.com/foundry-rs/foundry/tree/master/forge) project.\n\nFirst install the relevant dependencies of the project:\n\n```bash\nyarn\n\nforge install\n```\n\nTo compile contracts, run:\n\n```bash\nforge build\n```\n\nTo run tests:\n\n```bash\nforge test\n```\n\n## Pre-built Contracts\n\nPre-built contracts are written by the thirdweb team, and cover the most common use cases for smart contracts.\n\n- [DropERC20](https://thirdweb.com/deployer.thirdweb.eth/DropERC20)\n- [DropERC721](https://thirdweb.com/deployer.thirdweb.eth/DropERC721)\n- [DropERC1155](https://thirdweb.com/deployer.thirdweb.eth/DropERC1155)\n- [SignatureDrop](https://thirdweb.com/deployer.thirdweb.eth/SignatureDrop)\n- [Marketplace](https://thirdweb.com/deployer.thirdweb.eth/Marketplace)\n- [Multiwrap](https://thirdweb.com/deployer.thirdweb.eth/Multiwrap)\n- [TokenERC20](https://thirdweb.com/deployer.thirdweb.eth/TokenERC20)\n- [TokenERC721](https://thirdweb.com/deployer.thirdweb.eth/TokenERC721)\n- [TokenERC1155](https://thirdweb.com/deployer.thirdweb.eth/TokenERC1155)\n- [VoteERC20](https://thirdweb.com/deployer.thirdweb.eth/VoteERC20)\n- [Split](https://thirdweb.com/deployer.thirdweb.eth/Split)\n\n[Learn more about pre-built contracts](https://portal.thirdweb.com/pre-built-contracts)\n\n## Extensions\n\nExtensions are building blocks that help enrich smart contracts with features.\n\nSome blocks come packaged together as Base Contracts, which come with a full set of features out of the box that you can modify and extend. These contracts are available at `contracts/base/`.\n\nOther (smaller) blocks are Features, which provide a way for you to pick and choose which individual pieces you want to put into your contract; with full customization of how those features work. These are available at `contracts/extension/`.\n\n[Learn more about extensions](https://portal.thirdweb.com/extensions)\n\n## Contract Audits\n\n- [Audit 1](audit-reports/audit-1.pdf)\n- [Audit 2](audit-reports/audit-2.pdf)\n- [Audit 3](audit-reports/audit-3.pdf)\n- [Audit 4](audit-reports/audit-4.pdf)\n- [Audit 5](audit-reports/audit-5.pdf)\n- [Audit 6](audit-reports/audit-6.pdf)\n- [Audit 7](audit-reports/audit-7.pdf)\n- [Audit 8](audit-reports/audit-8.pdf)\n- [Audit 9](audit-reports/audit-9.pdf)\n- [Audit 10](audit-reports/audit-10.pdf)\n- [Audit 11](audit-reports/audit-11.pdf)\n- [Audit 12](audit-reports/audit-12.pdf)\n\n## Bug reports\n\nFound a security issue with our smart contracts? Send bug reports to security@thirdweb.com and we'll continue communicating with you from there. We're actively developing a bug bounty program; bug report payouts happen on a case by case basis, for now.\n\n## Feedback\n\nIf you have any feedback, please reach out to us at support@thirdweb.com.\n\n## Authors\n\n- [thirdweb](https://thirdweb.com)\n\n## License\n\n[Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0.txt)\n"
  },
  "thirdweb-dev/js": {
    "fetchedAt": "2025-11-12T22:54:31.351Z",
    "content": "<p align=\"center\">\n    <br />\n    <a href=\"https://thirdweb.com\">\n        <img src=\"https://thirdweb.com/brand/thirdweb-icon.svg\" width=\"200\" alt=\"\"/></a>\n    <br />\n</p>\n\n<h1 align=\"center\"><a href='https://thirdweb.com/'>thirdweb</a> TypeScript SDK</h1>\n\n<p align=\"center\">\n    <a href=\"https://github.com/thirdweb-dev/js/actions/workflows/CI.yml\">\n        <img alt=\"Build Status\" src=\"https://github.com/thirdweb-dev/js/actions/workflows/CI.yml/badge.svg\"/>\n    </a>\n</p>\n\n<p align=\"center\"><strong>All-in-one web3 SDK for Browser, Node and Mobile apps</strong></p>\n\n## Core Package\n\n#### [`thirdweb`](./packages/thirdweb/README.md)\n\nThe main SDK package providing all-in-one web3 functionality for Browser, Node, and Mobile applications.\n\n```bash\nnpm install thirdweb\n```\n\n**Features:**\n\n- Type-safe contract and transaction APIs\n- In-app wallets with social/email login\n- Account abstraction (ERC4337/EIP7702) support\n- 500+ external wallets supported\n- Built in infra (RPC, bundler, paymaster, indexer)\n- React hooks and UI components\n- Automatic ABI resolution\n- IPFS upload/download\n- Cross-platform support (Web, React Native)\n\n### Documentation\n\nVisit the [developer portal](https://portal.thirdweb.com) for full documentation.\n\n### üöÄ Quick Start\n\n#### For React Applications\n\n```bash\nnpm install thirdweb\n```\n\n```typescript\nimport { createThirdwebClient } from \"thirdweb\";\nimport { ConnectButton, useActiveAccount } from \"thirdweb/react\";\n\nconst client = createThirdwebClient({\n  clientId: \"YOUR_CLIENT_ID\",\n});\n\nfunction App() {\n  const account = useActiveAccount();\n  console.log(\"Connected as\", account?.address);\n\n  return <ConnectButton client={client} />;\n}\n```\n\nFor React Native Applications, you'll also need to install the `@thirdweb-dev/react-native-adapter` package and import it at app startup for polyfills.\n\n#### For Backend Applications\n\n```bash\nnpm install thirdweb\n```\n\n```typescript\nimport { createThirdwebClient, Engine } from \"thirdweb\";\n\nconst client = createThirdwebClient({\n  secretKey: \"YOUR_SECRET_KEY\",\n});\n\nconst wallet = Engine.serverWallet({\n  client,\n  address: \"0x...\",\n});\n\nconst transaction = transfer({\n  contract: getContract({\n    client,\n    address: \"0x...\", // token contract\n    chain: defineChain(1),\n  }),\n  to: \"0x...\", // recipient\n  amount: \"0.01\", // amount in tokens\n});\n\nawait wallet.enqueueTransaction({\n  transaction,\n});\n```\n\n## Adapters\n\n#### [`@thirdweb-dev/react-native-adapter`](./packages/react-native-adapter/README.md)\n\nRequired polyfills and configuration for running the thirdweb SDK in React Native applications.\n\n```bash\nnpm install @thirdweb-dev/react-native-adapter\n```\n\n#### [`@thirdweb-dev/wagmi-adapter`](./packages/wagmi-adapter/README.md)\n\nIntegration layer for using thirdweb's in-app wallets with wagmi.\n\n```bash\nnpm install @thirdweb-dev/wagmi-adapter\n```\n\n## Type safe API wrappers\n\n#### [`@thirdweb-dev/api`](./packages/api/README.md)\n\nTypeScript SDK for thirdweb's API, combining all of thirdweb products.\n\n```bash\nnpm install @thirdweb-dev/api\n```\n\n#### [`@thirdweb-dev/engine`](./packages/engine/README.md)\n\nTypeScript SDK for Engine, thirdweb's backend onchain executor service.\n\n```bash\nnpm install @thirdweb-dev/engine\n```\n\n#### [`@thirdweb-dev/insight`](./packages/insight/README.md)\n\nTypeScript SDK for Insight, thirdweb's multichain indexer service.\n\n```bash\nnpm install @thirdweb-dev/insight\n```\n\n#### [`@thirdweb-dev/vault-sdk`](./packages/vault-sdk/README.md)\n\nSDK for interacting with Vault, thirdweb's secure key management service.\n\n```bash\nnpm install @thirdweb-dev/vault-sdk\n```\n\n#### [`@thirdweb-dev/nebula`](./packages/nebula/README.md)\n\nTypeScript SDK for Nebula, thirdweb's AI agent service.\n\n```bash\nnpm install @thirdweb-dev/nebula\n```\n\n## Contributing\n\nWe welcome contributions from all developers regardless of experience level. If you are interested in contributing, please read our [Contributing Guide](.github/contributing.md) to learn how the repo works, how to test your changes, and how to submit a pull request.\n\nSee our [open source page](https://thirdweb.com/open-source) for more information on our open-source bounties and program.\n\n## Additional Resources\n\n- [Dashboard](https://thirdweb.com/login)\n- [Documentation](https://portal.thirdweb.com/)\n- [Templates](https://thirdweb.com/templates)\n- [YouTube](https://www.youtube.com/c/thirdweb)\n- [X/Twitter](https://x.com/thirdweb)\n- [Telegram](https://t.me/officialthirdweb)\n\n## Support\n\nFor help or feedback, please [visit our support site](https://thirdweb.com/support)\n\n## Security\n\nIf you believe you have found a security vulnerability in any of our packages, we kindly ask you not to open a public issue; and to disclose this to us by emailing `security@thirdweb.com`.\n"
  },
  "Ackee-Blockchain/solidity-for-vscode": {
    "fetchedAt": "2025-11-12T22:54:39.089Z",
    "content": "# Solidity by Ackee Blockchain Security\n\n[![Discord Badge](https://img.shields.io/discord/867746290678104064?colorA=21262d&colorB=0000FF&style=flat)](https://discord.gg/x7qXXnGCsa)\n[![Visual Studio Marketplace Badge](https://img.shields.io/visual-studio-marketplace/d/AckeeBlockchain.tools-for-solidity?colorA=21262d&colorB=0000FF&style=flat)](https://marketplace.visualstudio.com/items?itemName=AckeeBlockchain.tools-for-solidity)\n[![Follow on X Badge](https://img.shields.io/badge/Follow%20on%20X-for%20release%20updates-0000FF?colorA=21262d&style=flat)](https://x.com/WakeFramework)\n\n![Solidity for VS Code](images/readme/solidity_wake.gif)\n\nEthereum Solidity local node testing with security features for Visual Studio Code.\n\nDevelop, test, and secure Solidity smart contracts directly in Visual Studio Code with real-time security analysis, local node testing, and advanced debugging tools. Solidity (Wake) brings a Remix-like experience to your existing workflow with tools for compilation, deployment, and contract interaction on a local Ethereum network. Catch security risks early with built-in vulnerability detection, call graphs, and contract inheritance visualization without leaving VS Code.\n\nThis extension was built by a leading blockchain auditing firm that has worked with Lido, AAVE, Axelar, Safe, LayerZero, and more. It was developed for our professional needs and made open-source for a safer web3.\n\nBenefits:\n- [Test and interact with your smart contracts on an Ethereum local node](#test-and-interact-with-your-smart-contracts-on-an-ethereum-local-node)\n  - [Compile and deploy contracts](#compile-and-deploy-contracts)\n  - [Interact with contracts](#interact-with-contracts)\n  - [Fork mainnet or L2s to interact with onchain contracts](#forking-chain-and-fetching-contracts)\n  - [Native support for proxy contracts](#native-support-for-proxy-contracts)\n- [See vulnerabilities from static analysis in real-time](#see-vulnerabilities-from-static-analysis-in-real-time)\n  - [Compilation Errors](#compilation-errors)\n  - [See vulnerabilities from static analysis in real-time](#see-vulnerabilities-from-static-analysis-in-real-time-1)\n  - [Security Overview in the Sidebar](#security-overview-in-the-sidebar)\n- [Best code navigation experience, call-graphs and more](#best-code-navigation-experience-call-graphs-and-more)\n  - [Go to definition](#go-to-definition)\n  - [Find references](#find-references)\n  - [Document Links](#document-links)\n  - [Hover](#hover)\n  - [Contract Outline](#contract-outline)\n  - [Code Lens](#code-lens)\n  - [Graphs](#graphs)\n\n## Test and interact with your smart contracts on an Ethereum local node\n\n### Compile and deploy contracts\n\nCompile your contracts and deploy them on a local chain for testing\n\n![Compile and deploy contracts](images/readme/sake/1-compile-deploy.gif)\n\n### Interact with contracts\n\nTest your deployed contracts by interacting with them using function calls with different inputs\n\n![Interact with contracts](images/readme/sake/2-interact.gif)\n\n### Fork mainnet or L2s to interact with onchain contracts\n\n![Forking chain and fetching contracts](images/readme/sake/forking_chain_and_fetching_contracts.gif)\n\n### Native support for proxy contracts\n\n![Proxy support](images/readme/sake/proxy_support.gif)\n\n## See vulnerabilities from static analysis in real-time\n\n### Free detections with leading security tool Wake\n\nCatch potential issues early with real-time static analysis\n\n![Real-time detectors](images/readme/diagnostics/2-realtime-detectors.gif)\n\n### Security Overview in the Sidebar\n\nGet an overall overview of issues in your project\n\n![Security overview in the sidebar](images/readme/diagnostics/3-sidebar-overview.gif)\nit\n### Compilation Errors\n\nSee compilation errors highlighted in code\n\n![Compilation errors](images/readme/diagnostics/1-compilation-errors.gif)\n\n## Best code navigation experience, call-graphs and more\n\n### Go to definition\n\nQuickly navigate to any function or variable definition with a click\n\n![Go to definition](images/readme/development/go_to_definition.gif)\n\n### Find references\n\nRight click to see a context menu, and use it to find all references\n\n![Find references](images/readme/development/references.gif)\n\n### Document Links\n\nClick and jump to linked files and resources\n\n![Document links](images/readme/development/document_links.gif)\n\n### Hover\n\nUse hover to see instant documentation in your code\n\n![Hover](images/readme/development/hover.gif)\n\n### Contract Outline\n\nNavigate big projects with ease using the Contract Outline\n\n![Contract outline](images/readme/development/outline.gif)\n\n### Code Lens\n\nCode Lens shows you relevant information like functions selectors and parameter references inside your code\n\n![Code Lens](images/readme/development/codelens.gif)\n\n### Graphs\n\nVisualise contract inheritance and function control flows with graphs\n\n![Graphs](images/readme/development/graph.gif)\n\n\n## Requirements\n\nThe Solidity extension uses the PyPi package [eth-wake](https://pypi.org/project/eth-wake/) which requires Python 3.8 or higher. This package is automatically installed via [conda](https://conda.github.io/conda-pack/) by default.\n\nRosetta is required to be enabled on Apple Silicon Macs.\n\n## Credits\n[juanfranblanco/vscode-solidity](https://github.com/juanfranblanco/vscode-solidity/blob/master/syntaxes/solidity.json): a base of our Solidity grammar\n\n[joaompinto/vscode-graphviz](https://github.com/joaompinto/vscode-graphviz): a base of our Graphviz integration\n\n\n## Feedback, help and news\nEnjoy the extension? Consider [giving it a review](https://marketplace.visualstudio.com/items?itemName=AckeeBlockchain.tools-for-solidity&ssr=false#review-details)!\n\nGet help and give feedback in our [Discord](https://discord.gg/x7qXXnGCsa)\n\nFollow Ackee on [Twitter](https://twitter.com/AckeeBlockchain)\n\n\n## Known Issues\n\n- **`Go to references`, number of references and other features do not work correctly with no workspace open**\n\nIt is always recommended to open a project as a folder (`File -> Open folder`). `Open file` should only be used when opening a single file or several files inside the same folder.\n\n- **Analysis does not work when the workspace contains compilation errors**\n\nThe extension relies on the `solc` compiler. For this reason, files containing compilation errors and files importing these files cannot be analyzed.\n"
  },
  "andrei0x309/clear-wallet": {
    "fetchedAt": "2025-11-12T22:54:46.294Z",
    "content": "# ![CLW LOGO](/public/assets/extension-icon/wallet_16.png?raw=true \"CLW LOGO\") Clear EVM wallet\n\n## Description\n\nThis is an open source, NON-KYC, privacy-focused, EVM wallet browser extension implementation using Ethers, manifest version 3, Ionic, and Vue, first released on the Chrome Webstore in August 2022.\n\nATM, it also includes some Farcaster-related features.\n\nFor more info, you can check [docs website](https://clear-wallet.flashsoft.eu)\n\n![Featured on Alchemy](/repo_res/alchemy.png?raw=true \"Featured on Alchemy\")\n\n**Listed on:** ethereum.org, alchemy, product hunt, alternativeto, walletconnect, and most connect kits, including Rainbow, thirdweb, privy, and more.\n\n## How to Build from Github\n\n```bash\ngit clone https://github.com/andrei0x309/clear-wallet.git\ncd clear-wallet\nbun install\nbun run build # will build extension with chromium manifest\nbun run build-firefox # will build extension with firefox manifest\n```\n\nThis will create a Chromium extension in the dist folder.\n\nYou can also generate both Chromium and Firefox zip archives by running:\n\n```bash\nbun install\nbun run rebuild\n```\n\nThis will create both Firefox and Chromium extensions in these locations:\n\n- releases/x.x.x.zip (chromium x is replaced with the version number)\n- releases/firefox/x.x.x.zip (firefox x is replaced with the version number)\n\n## Create Source Archive\n\n```bash\nbun run build-source\n```\n\nThis will create a zip archive containing the source code in the releases/source/source-x.x.x.zip (x is replaced with the version number)\n\nBuilding from source is similar:\n\n```bash\ncd source-x.x.x # x.x.x is replaced with the version number\nbun install\nbun run build # will build extension with chromium manifest\nbun run build-firefox # will build extension with firefox manifest\n```\n\n<!-- [![Clear EVM Wallet (CLW) - Open source EVM wallet that implements meta mask API. | Product Hunt](https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=381026&theme=dark)](https://www.producthunt.com/posts/clear-evm-wallet-clw?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-clear-evm-wallet-clw) -->\n\n### Badges\n\n[![Quality gate](https://sonarcloud.io/api/project_badges/quality_gate?project=andrei0x309_clear-wallet)](https://sonarcloud.io/summary/new_code?id=andrei0x309_clear-wallet)\n\n### Extended article about this repo\n\n[Article on Mirror](https://mirror.xyz/andrei0x309.eth/9nc8UXrGIGOvz694ZY2gouS1JM9L8-Z8ITLNtirqD6Q)\n\n### Latest Demo Clip\n<!-- markdownlint-disable MD034 -->\nhttps://github.com/user-attachments/assets/4f7d267a-7410-43cf-b3bd-0256f1ccc954\n\n### LINKS\n\n[LICENSE.md](LICENSE.md)\n\n[PRIVACY_POLICY.md](PRIVACY_POLICY.md)\n"
  },
  "snapshot-labs/sx-evm": {
    "fetchedAt": "2025-11-12T22:54:53.661Z",
    "content": "[![codecov](https://codecov.io/github/snapshot-labs/sx-evm/branch/main/graph/badge.svg?token=BZ4XKYU3FT)](https://app.codecov.io/gh/snapshot-labs/sx-evm)\n[![ci](https://github.com/snapshot-labs/sx-evm/actions/workflows/ci.yml/badge.svg)](https://github.com/snapshot-labs/sx-evm/actions/workflows/ci.yml)\n\n# Snapshot X\n\nAn EVM implementation of the Snapshot X Protocol. Refer to the [documentation](https://docs.snapshot.box) for more\ninformation.\n\n## Contracts Blueprint\n\n```ml\nsrc\n‚îú‚îÄ authenticators\n‚îÇ  ‚îú‚îÄ Authenticator.sol - \"Base Authenticator contract\"\n‚îÇ  ‚îú‚îÄ EthSigAuthenticator.sol - \"Strategy that authenticates users via an EIP712 signature\"\n‚îÇ  ‚îú‚îÄ EthTxAuthenticator.sol - \"Strategy that authenticates users via checking the tx sender address\"\n‚îÇ  ‚îî‚îÄ VanillaAuthenticator.sol ‚Äî \"Vanilla Strategy\"\n‚îú‚îÄ voting-strategies\n‚îÇ  ‚îú‚îÄ CompVotingStrategy.sol - \"Strategy that uses delegated balances of Comp tokens as voting power\"\n‚îÇ  ‚îú‚îÄ OZVotesVotingStrategy.sol - \"Strategy that uses delegated balances of OZ Votes tokens as voting power\"\n‚îÇ  ‚îú‚îÄ WhitelistVotingStrategy.sol ‚Äî \"Strategy that gives predetermined voting power for members in a whitelist. Whitelist is stored in a bytes array On-Chain.\"\n‚îÇ  ‚îú‚îÄ MerkleWhitelistVotingStrategy.sol ‚Äî \"Strategy that gives predetermined voting power for members in a whitelist. Whitelist is stored in a Merkle tree Off-Chain, with only the root being stored On-Chain.\"\n‚îÇ  ‚îî‚îÄ VanillaVotingStrategy.sol ‚Äî \"Vanilla Strategy\"\n‚îú‚îÄ execution-strategies\n‚îÇ  ‚îú‚îÄ timelocks\n‚îÇ  |  ‚îú‚îÄ CompTimelockCompatibleExecutionStrategy.sol - \"Strategy that provides compatibility with existing Comp Timelock contracts\"\n‚îÇ  |  ‚îú‚îÄ OptimisticCompTimelockCompatibleExecutionStrategy.sol - \"Optimistic strategy that provides compatibility with existing Comp Timelock contracts\"\n‚îÇ  |  ‚îú‚îÄ OptimisticTimelockExecutionStrategy.sol - \"Optimistic strategy that can be used to execute proposal transactions according to a timelock delay\"\n‚îÇ  |  ‚îî‚îÄ TimelockExecutionStrategy.sol - \"Strategy that can be used to execute proposal transactions according to a timelock delay\"\n‚îÇ  ‚îú‚îÄ AvatarExecutionStrategy.sol - \"Strategy that allows proposal transactions to be executed from an Avatar contract\"\n‚îÇ  ‚îú‚îÄ TimelockExecutionStrategy.sol - \"Strategy that can be used to execute proposal transactions according to a timelock delay\"\n‚îÇ  ‚îú‚îÄ CompTimelockCompatibleExecutionStrategy.sol - \"Strategy that provides compatibility with existing Comp Timelock contracts\"\n‚îÇ  ‚îú‚îÄ EmergencyQuorumExecutionStrategy.sol - \"Base Strategy that uses an additional Emergency Quorum to determine the status of a proposal\"\n‚îÇ  ‚îú‚îÄ OptimisticQuorumExecutionStrategy.sol - \"Base Strategy that uses an Optimistic Quorum to determine the status of a proposal\"\n‚îÇ  ‚îú‚îÄ SimpleQuorumExecutionStrategy.sol - \"Base Strategy that uses a Simple Quorum to determine the status of a proposal\"\n‚îÇ  ‚îî‚îÄ VanillaExecutionStrategy.sol - \"Vanilla Strategy\"\n‚îú‚îÄ interfaces\n‚îÇ  ‚îú‚îÄ ...\n‚îú‚îÄ proposal-validation-strategies\n‚îÇ  ‚îú‚îÄ ActiveProposalsLimiterProposalValidationStrategy.sol - \"Strategy to that validates with the ActiveProposalsLimiter module\"\n‚îÇ  ‚îú‚îÄ PropositionPowerAndActiveProposalsLimiterProposalValidationStrategy.sol - \"Strategy that validates with the ActiveProposalsLimiter and PropositionPower modules\"\n‚îÇ  ‚îî‚îÄ PropositionPowerProposalValidationStrategy.sol - \"Strategy that validates with the PropositionPower module\"\n‚îú‚îÄ utils\n‚îÇ  ‚îú‚îÄ ActiveProposalsLimiter.sol - \"Module to limit the number of active proposals per author\"\n‚îÇ  ‚îú‚îÄ BitPacker.sol - \"Uint256 Bit Setting and Checking Library\"\n‚îÇ  ‚îú‚îÄ PropositionPower.sol - \"Module that checks proposal authors exceed a threshold proposition power over a set of strategies\"\n‚îÇ  ‚îú‚îÄ SXHash.sol - \"Snapshot X Types Hashing Library\"\n‚îÇ  ‚îú‚îÄ SXUtils.sol - \"Snapshot X Types Utilities Library\"\n‚îÇ  ‚îú‚îÄ SignatureVerifier.sol - \"Verifies EIP712 Signatures for Snapshot X actions\"\n‚îÇ  ‚îî‚îÄ SpaceManager.sol - \"Manages a whitelist of Spaces that have permissions to execute transactions\"\n‚îú‚îÄ ProxyFactory.sol - \"Handles the deployment and tracking of Space contracts\"\n‚îî‚îÄ Space.sol - \"The base contract for each Snapshot X space\"\n‚îî‚îÄ types.sol - \"Definitions for Snapshot X custom types\"\n```\n\n## Usage\n\n### Build\n\nBuild the contracts:\n\n```sh\n$ forge build\n```\n\n### Test\n\nRun the tests:\n\n```sh\n$ forge test\n```\n\n### Coverage\n\nGet a test coverage report:\n\n```sh\n$ forge coverage --ir-minimum\n```\n\n### Deployment\n\nTo deploy the protocol to an EVM chain, first set the following environment variables:\n\n```sh\n# The address of the account that the protocol will be deployed from.\nDEPLOYER_ADDRESS=\n# The name of the chain you want to deploy on. The addresses of the deployed contracts will be stored at /deployments/network.json\nNETWORK=\n# An RPC URL for the chain.\nRPC_URL=\n# An API key for a block explorer on the chain (Optional).\nETHERSCAN_API_KEY=\n```\n\nFollowing this, a [Foundry Script](https://book.getfoundry.sh/tutorials/solidity-scripting) can be run to deploy the\nentire protocol. Example usage to deploy from a Ledger Hardware Wallet and verify on a block explorer:\n\n```sh\nforge script script/Deployer.s.sol:Deployer --rpc-url $RPC_URL --optimize --broadcast --verify -vvvv --ledger --sender $DEPLOYER_ADDRESS --hd-paths \"m/44'/60'/4'/0/0\"\n```\n\nThe script uses the [Singleton Factory](https://eips.ethereum.org/EIPS/eip-2470) for the deployments which ensures that\nthe addresses of the contracts are the same on all chains (so long as the chain is fully EVM equivalent).\n"
  },
  "snapshot-labs/snapshot": {
    "fetchedAt": "2025-11-12T22:54:54.374Z",
    "content": "<div align=\"center\">\n    <img src=\"public/icon.svg\" height=\"70\" alt=\"Snapshot Logo\">\n    <h1>Snapshot</h1>\n    <strong>Snapshot is an off-chain gasless multi-governance client with easy to verify and hard to contest results.</strong>\n</div>\n<br>\n<div align=\"center\">\n    <a href=\"https://github.com/snapshot-labs/snapshot/actions/workflows/nodejs.yml\">\n        <img src=\"https://github.com/snapshot-labs/snapshot/actions/workflows/nodejs.yml/badge.svg\" alt=\"Node CI\">\n    </a>\n    <img src=\"https://img.shields.io/github/commit-activity/w/snapshot-labs/snapshot\" alt=\"GitHub commit activity\">\n    <a href=\"https://github.com/snapshot-labs/snapshot/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22\">\n        <img src=\"https://img.shields.io/github/issues/snapshot-labs/snapshot/help wanted\" alt=\"GitHub issues help wanted\">\n    </a>\n    <a href=\"https://discord.snapshot.org/\">\n        <img src=\"https://img.shields.io/discord/707079246388133940.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2\" alt=\"Discord\">\n    </a>\n    <a href=\"https://x.com/SnapshotLabs\">\n        <img src=\"https://img.shields.io/twitter/follow/SnapshotLabs?label=SnapshotLabs&style=social\">\n    </a>\n</div>\n<div align=\"center\">\n    <br>\n    <a href=\"https://snapshot.org\"><b>snapshot.org ¬ª</b></a>\n    <br><br>\n    <a href=\"https://docs.snapshot.org\"><b>Documentation</b></a>\n    ‚Ä¢\n    <a href=\"https://features.snapshot.org/feature-requests\"><b>Feature requests</b></a>\n    ‚Ä¢\n    <a href=\"https://docs.snapshot.org/introduction#contributing\"><b>Contribute</b></a>\n</div>\n\n## Project setup\n\n```\nyarn\n```\n\n### Compiles and hot-reloads for development\n\n```\nyarn dev\n```\n\n### Compiles and minifies for production\n\n```\nyarn build\n```\n\n### Lints and fixes files\n\n```\nyarn run lint\n```\n\n### Development Guide\n\nUse `http://localhost:8080/#/fabien.eth` for testing your code.\n\nBy default your instance will connect to the hub at `https://testnet.hub.snapshot.org`. To change that (or other values) you can create a `.env.local` and overwrite the values from `.env`.\n\n## Running service locally with Docker\n1. Run `docker build -t snapshot .` to build the image\n2. Run `docker run --name snapshot -p 8080:8080 snapshot` to run the container\n3. Go to `http://localhost:8080/#/fabien.eth` to test your code\n\n## License\n\nSnapshot is open-sourced software licensed under the ¬© [MIT license](LICENSE).\n"
  },
  "snapshot-labs/sx-monorepo": {
    "fetchedAt": "2025-11-12T22:54:54.791Z",
    "content": "[![Test CI](https://github.com/snapshot-labs/sx-monorepo/actions/workflows/test.yml/badge.svg)](https://github.com/snapshot-labs/sx-monorepo/actions/workflows/test.yml)\n[![Discord](https://img.shields.io/discord/707079246388133940.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.snapshot.org/)\n\n# Snapshot monorepository\n\nThis is the Snapshot monorepository containing a Vue frontend, GraphQL API, transaction relayer, and TypeScript SDK.\n\n## Apps and packages\n\n- [`./apps/ui`](./apps/ui): Snapshot official frontend using Vue 3\n- [`./apps/api`](./apps/api): Multichain indexer for Snapshot X using [Checkpoint](https://checkpoint.box)\n- [`./apps/mana`](./apps/mana): Transaction relayer for gasless voting on Snapshot X\n- [`./packages/sx.js`](./packages/sx.js): TypeScript SDK for Snapshot and Snapshot X\n\n# Usage\n\n## Project setup\n\n```\nyarn\n```\n\n### Compiles and hot-reloads for development\n\n#### UI only\n\n```sh\nyarn dev\n```\n\n#### UI with backend services\n\n[See here.](./README.md#running-local-services)\n\n### Compiles and minifies for production\n\n```\nyarn build\n```\n\n### Lints and fixes files\n\n```\nyarn lint\n```\n\n### Runs tests\n\n```\nyarn test\n```\n\n### Run E2E tests using Playwright\n\n```\nyarn test:e2e\n```\n\n### Verifies TypeScript code\n\n```\nyarn typecheck\n```\n\n## Running local services\n\nYou can run all local services (api, mana, ui) with single command assuming you have all necessary environment variables set up.\nLocal APIs will only be used for Ethereum Sepolia and Starknet Sepolia.\n\nThis command will allow you to select which services you want to run.\n\n```\nyarn dev:interactive\n```\n\n### Setup\n\nYou need to have Docker running on your machine.\n\nIn `apps/api` and `apps/mana` copy `.env.example` to `.env` files.\n\nIn `apps/mana/.env` you need to fill in following empty variables:\n\n- `WALLET_SECRET` - if you want to use it as relayer (used for both Starknet and Ethereum wallets).\n- `HERODOTUS_API_KEY` and `HERODOTUS_LEGACY_API_KEY` - if you want to use L1<->L2 messaging (voting with strategies that use L1 proofs)\n\n### Getting it running faster\n\nIf you run `yarn dev:interactive` it will take long time to sync all the blocks for the first time. To mitigate it you can just change starting block\nfor indexing here:\n\n- https://github.com/snapshot-labs/sx-monorepo/blob/daad48dbd2aa775e47334d0697cb84477c1d3427/apps/api/src/starknet/config.ts#L40 (for Starknet)\n- https://github.com/snapshot-labs/sx-monorepo/blob/9f5c78468c72e0ddd51578bdd984cc9da19f119a/apps/api/src/evm/config.ts#L23 (for Ethereum)\n\nIf you do that make sure to create a new space, because spaces created before the new starting block you picked won't be available.\n\n## Versioning packages\n\nPackages are versioned using [`changesets`](https://github.com/changesets/changesets).\nIn most cases all you need to do is when adding new changes to versioned packages (right now it's just `sx.js`)\nis to execute `yarn changeset`, specify package you updated, version bump per [semver](https://semver.org/) and description of your changes.\nThen commit generated files in your PR.\n\nOnce merged changesets actions will create PR that can be used to release and publish those packages.\n\n## Development docs\n\n- [Using `vue-query` to fetch data](./docs/vue-query.md)\n"
  },
  "ethereum/fe": {
    "fetchedAt": "2025-11-12T22:55:05.230Z",
    "content": "\n# Fe\n\nThe Fe compiler is in the late stages of a major compiler rewrite, and the master branch isn't currently usable to compile contracts to evm bytecode.\nFor the older version of the compiler, see the [legacy branch](https://github.com/ethereum/fe/tree/legacy).\n\n## Overview\n\nFe is a statically typed language for the Ethereum Virtual Machine (EVM). The syntax and type system is similar to rust's, with the addition of higher-kinded types. We're exploring additional type system, syntax, and semantic changes.\n\n## Community\n\n- Twitter: [@official_fe](https://twitter.com/official_fe)\n- Chat:\n  - We've recently moved to [Zulip](https://fe-lang.zulipchat.com/join/dqvssgylulrmjmp2dx7vcbrq/)\n  - The [Discord](https://discord.gg/ywpkAXFjZH) server is still live, but our preference is zulip.\n\n## License\n\nLicensed under Apache License, Version 2.0.\n"
  },
  "wakeuplabs/rfg1-optimism": {
    "fetchedAt": "2025-11-12T22:55:11.510Z",
    "content": "# ‚è∞ RFG1 - Optimism Grants Council - WakeUp Labs\n\nWelcome to [WakeUp Labs](https://www.wakeuplabs.io/) implementation of the Optimism **Request For Grants #1** [RFG1](https://app.charmverse.io/op-grants/page-8928491436774362) from the Optimism Grants Council!\n\nYou can take a look at the final Delivery and Feedback Thread in [our post at the Optimism Governance Forum](https://gov.optimism.io/t/wakeup-labs-rfg-1-update-and-feedback-thread/7842).\n\nThe service allows anyone to query the blockchain for specific past moments. \n\n\n## Introduction\n\nThis is a service that will be able to query the blockchain for **specific moments in the past** ‚è∞. Specifically, the queries will be enabled for **any public view function** of any smart contract deployed on the Optimism blockchain from its first block until the current moment. It could be extended to any EVM blockchain.\n\nThe implementation is fully open source with MIT license.\n\n## How to run\n\n### Local Setup Guide\n\n#### Prerequisites\n- Node.js installed on your machine\n- Git installed for cloning the repository\n- PostgreSQL installed and running or any database deployed\n\n#### Steps to Run Locally\n  1. Clone the repository:\n```bash\n git clone https://github.com/WakeUpLabs/RFG1-Optimism-Project.git\n```\n\n  2. Complete the environment variables in a ```.env``` file\n\n  ```\n    URL=\n    PORT=\n    RPC_TESTNET_URL=\n    RPC_MAINNET_URL=\n    DATABASE_URL=\n  ```\n  - URL: The base URL for the application. If you want to run it locally, it will be set to http://localhost.\n  - PORT: Specifies the port number on which the server will listen for incoming requests.\n  - RPC_URL: Refers to the Remote Procedure Call (RPC) endpoint for connecting to the Optimism blockchain. This variable is crucial for interacting with the blockchain, fetching data, or executing transactions.\n  - PRIVATE_KEY: Represents the private key used for authentication or signing transactions. Ensure that this key is kept confidential and not shared publicly.\n  - DATABASE_URL: Specifies the URL for connecting to the PostgreSQL database.\n\n3. Run database migrations:\n```bash\n npm run migrate\n```\n4. Install dependencies:\n\n```bash\n npm install\n``` \n\n5. Start the local server:\n\n```bash\n npm run start\n``` \n\n\n## Our architecture\n\nOur service is designed for easy integration, streamlined maintenance, and adaptable extensibility with external services.\n\n![image.png](./src/assets/archi-rfg1-simple.png)\n\nThis RESTful API seamlessly interacts with the OP blockchain, persisting invoked functions in a dedicated database. Subsequently, users can conveniently bypass providing ABI information on following interactions.\n\nMoreover, an additional [component](https://github.com/wakeuplabs/rfg1-popular-contracts-loader) empowers project owners to populate the database with smart contracts they deem pertinent.\n\n---\n\nTo grasp the full spectrum of possibilities, delve into our sequence diagrams:\n\nThis diagram shows how to leverage pre-loaded contracts. In that way, the user could check which are those contracts considered most popular and avoid the need to manually load the ABI information.\n\n![image.png](./src/assets/rfg1-sequence-diagram.png)\n\nNevertheless, users always have the option to inspect any contract using a generic endpoint by passing the necessary parameters.\n\n![image.png](./src/assets/sequence-diagram-simple.png)\n\n\n## Try It Out - Quick Demo\nSometimes, examples speak louder than words.\n\nWe've also coded the first implementation of these APIs.\nThe main idea behind the integration is to provide a user-friendly UI where users can define a specific Address or ENS and determine the amount of OP tokens it holds on a specific date on the Optimism Blockchain.\n\nTry it out here: https://rfg1-demo.wakeuplabs.link/\n\n![Demo](/src/assets/demo.png)\n\n## Try It Out - Dedicated Instance\nFor your convenience, WakeUp Labs offers an easier solution by providing a deployed version and dedicated instance that is ready to use and seamlessly integrates with your services via REST APIs. To get started, simply log in to the [WakeUp Platform](https://platform.wakeuplabs.io/) and obtain your free apikey.\n\n### Integration via WakeUp Platform REST APIs\n\n#### 1. Sign Up & Get Free API Key\n\nTo use the service, you need to [sign up](https://platform.wakeuplabs.io/) and create a free API key with your email account. \n\nOnce you have completed the registration process, go to the API Key section to view your API key information. \n\n![image.png](./src/assets/image.png)\n\nCopy the generated API key and keep it safe, as it will be your credential for accessing our services üîê\n\n\n#### 2. Use the REST API\n\nYou can explore the service's capabilities in the [WakeUp Platform API Docs](https://wakeuplabs.stoplight.io/docs/stoplight-platform/19iod9xapzajp-rfg-1-optimism-grants-council-wake-up-labs)\n\n\n\nFollow the instructions to use the REST API as you please.\nThese are some API endpoints you will find and be able to use to try RFG1 implementation:\n\n* [Healthcheck Endpoint:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/jbhm9uyfok2dt-healthcheck-endpoint) Check the health status of the service.\n* [Retrieve Wallet Balance:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/zst7kbmqxuxgp-retrieve-wallet-balance) Retrieve the current balance of a wallet.\n* [Retrieve Wallet Balance at Block:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/kqng1cecb32qx-retrieve-wallet-balance-at-block) Get the wallet balance at a specific block in the past.\n* [Retrieve Wallet Balance at Date](https://wakeuplabs.stoplight.io/docs/stoplight-platform/vj8jtm9fbdl0n-retrieve-wallet-balance-at-date): Fetch the wallet balance at a specific date in the past.\n* [Execute Contract Function:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/ugoyma40tq7jm-execute-contract-function) Execute a contract ```public view``` function to get historical data, by input of ABI.\n* [Execute Known Contract Function:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/by55d5fnj48cl-execute-known-contract-function) Execute a ```public view``` function of a known contract to get historical data, no ABI input needed.\n* [Get View Functions of Known Contracts:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/dctukth2fct7k-get-a-functions-known-abi) List ```public view``` functions of known contracts.\n* [Get most popular smart contracts:](https://wakeuplabs.stoplight.io/docs/stoplight-platform/1kjq0rkc09qt7-get-most-popular-smart-contracts) List ```contract addresses``` of the most popular contracts loaded previously.\n"
  },
  "ethereum/sourcify": {
    "fetchedAt": "2025-11-12T22:55:19.756Z",
    "content": "&nbsp;\n\n<p align=\"center\">\n  &nbsp;\n  <a href=\"https://sourcify.dev\"><img src=\"https://raw.githubusercontent.com/sourcifyeth/assets/master/logo-assets-png/sourcify-eth-card.png\" alt=\"sourcify logo\" role=\"presentation\" width=300></a>\n</p>\n\n[![codecov](https://codecov.io/gh/argotorg/sourcify/branch/staging/graph/badge.svg?token=eN6XDAwWfV)](https://codecov.io/gh/argotorg/sourcify)\n[![Matrix Chat](https://img.shields.io/badge/Matrix%20-chat-brightgreen?style=plastic&logo=matrix)](https://matrix.to/#/#ethereum_source-verify:gitter.im)\n[![Discord](https://img.shields.io/badge/Discord%20-chat-brightgreen?style=plastic&logo=discord)](https://discord.com/invite/6aqd9cfZ9s)\n[![X Follow](https://img.shields.io/twitter/follow/SourcifyEth?style=plastic&logo=x)](https://X.com/SourcifyEth)\n\nSourcify ([sourcify.dev](https://sourcify.dev)) is a source-code verification service for Ethereum smart contracts supporting Solidity and Vyper. Sourcify is fully commited to\n\n- Open-source (MIT License)\n- Open-data (see [Downloading the repository](https://docs.sourcify.dev/docs/repository/))\n- Open-standards (see the [Verifier Alliance](https://github.com/verifier-alliance))\n\nin smart-contract verification instead of siloed, propriety services. We foster these values across the ecosystem and work actively to push the status-quo in this direction.\n\nDifferent than other verification services, Sourcify leverages the [Solidity metadata](https://docs.sourcify.dev/docs/metadata/) and file and its integrity hash to [\"fully verify\"](https://docs.sourcify.dev/docs/full-vs-partial-match/) the Solidity contracts (see [the playground](https://playground.sourcify.dev)).\n\nSourcify mainly consists of:\n\n- [sourcify-server](/services/server) - an HTTP server to run source-code verifications and store the verified contracts for the supported chains through an [API](https://docs.sourcify.dev/docs/api/)\n- [sourcify-database](/services/database) - a PostgreSQL database to store the verified contracts and their metadata, and a repository for the database schema and migrations.\n- [sourcify-monitor](/services/monitor) - a standalone service that listens to various EVM chains for new contract creations and automatically submits them to a Sourcify API for verification if published on IPFS.\n- Packages:\n  - [@ethereum-sourcify/lib-sourcify](/packages/lib-sourcify/): The core library for Sourcify. It contains the logic to verify contracts.\n  - [@ethereum-sourcify/bytecode-utils](/packages/bytecode-utils/): A library to extract and parse the CBOR encoded metadata from the bytecode.\n  - [@ethereum-sourcify/compilers](/packages/compilers/): A wrapper around Solidity and Vyper compilers to download the right version and invoke the compilation with a common interface.\n  - [@ethereum-sourcify/compilers-types](/packages/compilers-types/): TypeScript types for the compilers.\n- [Sourcify UI](https://github.com/sourcifyeth/ui) - a web UI to interact with the server, lookup, and verify contracts\n- [repo.sourcify.dev](https://github.com/sourcifyeth/repo.sourcify.dev) - a web UI to browse and display verified contract information.\n\n_‚ÑπÔ∏è [This monorepo](https://github.com/argotorg/sourcify) contains the main modules. The [sourcifyeth Github organization](https://github.com/sourcifyeth) contains all other auxiliary services and components._\n\n## Documentation\n\nFor more details refer to [docs.sourcify.dev](https://docs.sourcify.dev/docs/intro/)\n\n## How we work\n\nSourcify aims to be fully open and transparent. You can see what we are working day-to-day on on our [Public Issue Board](https://github.com/orgs/ethereum/projects/46) as well our [Quarterly Milestones](https://github.com/orgs/ethereum/projects/46/views/3) for our longer term plans.\n\n## Adding a new chain\n\nIf you'd like to add a new chain support to Sourcify please follow the [chain support instructions](https://docs.sourcify.dev/docs/chain-support/) in docs.\n\n_Sourcify is an [Argot Collective](https://argot.org) project_\n"
  },
  "upnodedev/signer-proxy": {
    "fetchedAt": "2025-11-12T22:55:26.923Z",
    "content": "# signer-proxy\n\nAn RPC signer proxy server that listens for the `eth_signTransaction` requests and performs transaction signing using the YubiHSM2 hardware or AWS KMS signer.\n\n## Install\n\n```bash\ncargo install --path . --no-default-features\n```\n\n```bash\nsigner-proxy -h\n```\n\nCurrently, the signer-proxy supports two signers: YubiHSM2 and AWS KMS.\n\n```bash\nsigner-proxy yubihsm -h\nsigner-proxy aws-kms -h\n```\n\n## YubiHSM2\n\n### Global options for `generate-key` and `serve` subcommands\n\n> [!NOTE]  \n> You can connect to YubiHSM2 using two methods: usb or http via `-m, --mode` option.\n\n````bash\n-a, --auth-key <auth-key-id>              YubiHSM auth key ID [env: YUBIHSM_AUTH_KEY_ID=]\n-d, --device-serial <device-serial-id>    YubiHSM device serial ID (for USB mode) [env: YUBIHSM_DEVICE_SERIAL_ID=]\n    --addr <http-address>                 YubiHSM HTTP address (for HTTP mode) [env: YUBIHSM_HTTP_ADDRESS=]\n    --port <http-port>                    YubiHSM HTTP port (for HTTP mode) [env: YUBIHSM_HTTP_PORT=]\n-m, --mode <mode>                         Connection mode (usb or http) [env: YUBIHSM_MODE=] [default: usb] [possible values: usb, http]\n-p, --pass <password>                     YubiHSM auth key password [env: YUBIHSM_PASSWORD]\n````\n\n### generate-key\n\nGenerates a valid secp256k1 key for signing eth transactions with capability `SIGN_ECDSA` and `EXPORTABLE_UNDER_WRAP` (if flag `-e, --exportable`). See docs about Capability [here](https://docs.yubico.com/hardware/yubihsm-2/hsm-2-user-guide/hsm2-core-concepts.html#capability).\n\n```bash\nsigner-proxy yubihsm -d <device-serial-id> -a <auth-key-id> -p <password> generate-key -l <label> -e\n```\n\n#### Options/flags for `generate-key` subcommand\n\n```bash\nsigner-proxy yubihsm generate-key -h\n```\n\n```bash\n-e, --exportable       The key will be exportable or not\n-l, --label <label>    Key label [default: ]\n```\n\n### serve\n\nStarts a YubiHSM-based proxy server that listens for `eth_signTransaction` requests.\n\n```bash\nsigner-proxy yubihsm -d <device-serial-id> -a <auth-key-id> -p <password> serve\n```\n\nNo additional options and flags for `serve` subcommand.\n\n## AWS KMS\n### Set Up\nTo use the signer-proxy with AWS KMS, you must have an asymmetric key configured for signing transactions. If you don‚Äôt have one, follow this [guide](https://aws.amazon.com/blogs/web3/import-ethereum-private-keys-to-aws-kms/).\n\nYou‚Äôll also need the AWS CLI installed on the device where you plan to run the proxy. Installation instructions can be found [here](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).\n\n### Configuration\nWherever you run the proxy, it must be configured with your KMS key. \n\n```bash\naws configure\n```\n\nEnter the Access Key ID, Secret Access Key and Default region name for an IAM account that has usage permissions for your key. Put the output format as json.\n\nAlternatively, set your environment variables:\n\n```bash\nexport AWS_ACCESS_KEY_ID=\nexport AWS_SECRET_ACCESS_KEY=\nexport AWS_REGION=\n```\n\n### serve\n\nStarts an AWS KMS-based proxy server that listens for `eth_signTransaction` requests. By default, it listens on `0.0.0.0:4000`\n\n```bash\nsigner-proxy aws-kms serve\n```\n\n### API\n\n\n| Method | Endpoint | Description | Parameters | Body |\n| ---  | --- | --- | --- | --- | \n| `GET` |    `/ping` | Tests that the server is running | - | - |\n| `POST` | `/key/{key_id}` | Signs a proposed transaction and returns it RLP encoded | `key_id` (string) - key identifier of your Amazon KMS key | `{\"id\": 1,\"jsonrpc\": \"2.0\",\"method\": \"eth_signTransaction\",\"params\": [{\"chainId\": \"{chain_id}\",\"data\": \"0x\",\"from\": \"{from_address}\",\"gas\": \"{gas}\",\"gasPrice\": \"{gas_price}\",\"nonce\": \"{nonce}\",\"to\": \"{to_address}\",\"value\": \"{value_to_send}\"}]}`\n| `GET` | `/key/{key_id}/address` | Returns the wallet address of your KMS key | `key_id` (string) - key identifier of your Amazon KMS key | - | \n\n\n### Example Requests\n\n#### /key/{key_id}\n_Request:_\n```bash\ncurl -X POST -H \"Content-Type: application/json\" -d '{\n    \"id\": 1,\n    \"jsonrpc\": \"2.0\",\n    \"method\": \"eth_signTransaction\",\n    \"params\": [\n        {\n            \"chainId\": 17000,\n            \"data\": \"0x\",\n            \"from\": \"0xD0e9d614E8d5C5C3e7F09Dcb31CB3A7552deC836\",\n            \"gas\": \"0x7b0c\",\n            \"gasPrice\": \"0x1250b1\",\n            \"nonce\": \"0x0\",\n            \"to\": \"0x75dA2Ff67BE16c30195067b3CD40702E1F6D4EAE\",\n            \"value\": \"0x2386f26fc10000\"\n        }\n    ]\n}' http://localhost:4000/key/65021b59-0433-47e7-975d-0dcbfe898f9e\n```\n\n_Response:_\n```bash\n{\"id\":1,\"jsonrpc\":\"2.0\",\"result\":\"0xf86b80831250b1827b0c9475da2ff67be16c30195067b3cd40702e1f6d4eae872386f26fc10000808284f4a009c813f8739ef99dae0c28109ffa1c167c62ec3f0b4f9027106969e4f1aaf966a02d696fee7ae9547cfa027193ba2ab514c2c71ee0bcd262034355b16b2b319c78\"}\n```\n\n#### /key/{key_id}/address\n_Request:_\n```bash\ncurl -X GET http://localhost:4000/key/65021b59-0433-47e7-975d-0dcbfe898f9e/address\n```\n\n_Response:_\n```bash\n{\"address\":\"0xD0e9d614E8d5C5C3e7F09Dcb31CB3A7552deC836\"}\n```\n\n## Authentication and Firewall  \n\n`signer-proxy` does not include built-in basic authentication. For enhanced security, we recommend securing `signer-proxy` behind a firewall or using a reverse proxy, such as [NGINX](https://nginx.org) or [Traefik](https://traefik.io). This setup allows you to implement basic authentication and optionally add a TLS certificate for an extra layer of protection.  \n\n## Using `signer-proxy` with the OP Stack  \n\nTo secure the private keys used by [OP Stack Privileged Roles](https://docs.optimism.io/chain/security/privileged-roles) with `signer-proxy`, you **must remove all private keys from environment variables and arguments** passed to any OP Stack services (e.g., `op-batcher`, `op-proposer`, `op-challenger`, `op-node` etc.). Instead, configure the signer address and endpoint as environment variables or arguments as shown below:  \n\n### Environment Variables  \n\nDefine the signer address and endpoint for each OP Stack service:  \n\n```  \n# op-batcher  \nOP_BATCHER_SIGNER_ADDRESS=0x...  \nOP_BATCHER_SIGNER_ENDPOINT=http://127.0.0.1:4000/key/...  \n\n# op-proposer  \nOP_PROPOSER_SIGNER_ADDRESS=0x...  \nOP_PROPOSER_SIGNER_ENDPOINT=http://127.0.0.1:4000/key/...  \n\n# op-challenger  \nOP_CHALLENGER_SIGNER_ADDRESS=0x...  \nOP_CHALLENGER_SIGNER_ENDPOINT=http://127.0.0.1:4000/key/...  \n\n# op-node\nOP_NODE_SIGNER_ADDRESS=0x... \nOP_NODE_SIGNER_ENDPOINT=http://127.0.0.1:4000/key/...\n\n# For other services, replace [SERVICE] with the service name:  \nOP_[SERVICE]_SIGNER_ADDRESS=0x...  \nOP_[SERVICE]_SIGNER_ENDPOINT=http://127.0.0.1:4000/key/...  \n```  \n\n### Command-Line Arguments  \n\nAlternatively, you can pass the same command-line arguments for every service:  \n\n```  \n--signer.address=0x...  \n--signer.endpoint=http://127.0.0.1:4000/key/...  \n```  \n\n### Adding an Authentication Header  \n\nIf your reverse proxy enforces authentication headers, include them in your configuration using the following options:  \n\n**Environment Variables:**  \n\n```  \nOP_[SERVICE]_SIGNER_HEADER=Authorization=Bearer 123abc  \n```  \nReplace `[SERVICE]` with each service name.  \n\n**Command-Line Arguments:**  \n\n```  \n--signer.header=\"Authorization=Bearer 123abc\"  \n```  \n\n### Using TLS  \n\nIf `signer-proxy` is hosted with TLS for added security, and you're not using the default certificate paths (`tls/ca.crt`, `tls/tls.crt`, `tls/tls.key`), you can specify custom paths using these options:  \n\n**Environment Variables:**  \n\n```  \nOP_[SERVICE]_SIGNER_TLS_CA=tls/ca.crt  \nOP_[SERVICE]_SIGNER_TLS_CERT=tls/tls.crt  \nOP_[SERVICE]_SIGNER_TLS_KEY=tls/tls.key  \n```\nReplace `[SERVICE]` with each service name.  \n\n**Command-Line Arguments:**  \n\n```  \n--signer.tls.ca=tls/ca.crt  \n--signer.tls.cert=tls/tls.crt  \n--signer.tls.key=tls/tls.key  \n```  \n\n## Tests\n\nStart [anvil](https://github.com/foundry-rs/foundry/tree/master/crates/anvil) and the proxy server, and then:\n\n```bash\ncd test\nnode .\n```\n"
  },
  "ApeWorX/ape-optimism": {
    "fetchedAt": "2025-11-12T22:55:34.331Z",
    "content": "# Quick Start\n\nEcosystem Plugin for Optimism support in Ape.\n\n## Dependencies\n\n- [python3](https://www.python.org/downloads) version 3.9 up to 3.12.\n\n## Installation\n\n### via `ape`\n\nYou can install this plugin using `ape`:\n\n```bash\nape plugins install optimism\n```\n\nor via config file:\n\n```yaml\n# ape-config.yaml\nplugins:\n  - name: optimism\n```\n\n### via `pip`\n\nYou can install the latest release via [`pip`](https://pypi.org/project/pip/):\n\n```bash\npip install ape-optimism\n```\n\n### via `setuptools`\n\nYou can clone the repository and use [`setuptools`](https://github.com/pypa/setuptools) for the most up-to-date version:\n\n```bash\ngit clone https://github.com/ApeWorX/ape-optimism.git\ncd ape-optimism\npython3 setup.py install\n```\n\n## Quick Usage\n\nInstalling this plugin adds support for the Optimism ecosystem:\n\n```bash\nape console --network optimism:sepolia\n```\n\n### OP Stack\n\nUse the `optimism` base-class in any custom networks using the OP stack.\nFor example, to configure a custom network for Fraxtal network, add the following to your `pyproject.toml`\n\n```toml\n[[tool.ape.networks.custom]]\nname = \"mainnet\"\necosystem = \"fraxtal\"\n# Tell Ape to use optimism as the base plugin, instead of ethereum.\nbase_ecosystem_plugin = \"optimism\"\nchain_id = 252\n\n# (optional): Configure an RPC. Else, Ape will select a random one automatically.\n[tool.ape.node.fraxtal.mainnet]\nuri = \"https://rpc.frax.com\"\n```\n\nOr equivalent `ape-config.yaml`:\n\n```yaml\nnetworks:\n  custom:\n    - name: mainnet\n      ecosystem: fraxtal\n      base_ecosystem_plugin: optimism\n\nnode:\n fraxtal:\n    mainnet:\n      uri: https://rpc.frax.com\n```\n\nThere are two main benefits of using Optimism as the base-class instead of Ethereum for networks using the OP stack:\n\n1. **Closer defaults**: The block time default is `2` for Optimism networks, which may be a better default value than Ethereum's higher block time parameters.\n2. **Existence of System Transactions**: The Optimism base-class is aware of system transactions, which are transactions invoked by the sequencer.\n\n## Development\n\nComments, questions, criticisms and pull requests are welcomed.\n"
  },
  "ApeWorX/ape": {
    "fetchedAt": "2025-11-12T22:55:34.655Z",
    "content": "[![Pypi.org][pypi-badge]][pypi-url]\n[![Apache licensed][licence-badge]][licence-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n[![Twitter][twitter-badge]][twitter-url]\n\n# Overview\n\n[Ape Framework](https://apeworx.io/framework/) is an easy-to-use Web3 development tool.\nUsers can compile, test, and interact with smart contracts all in one command line session.\nWith our [modular plugin system](#plugin-system), Ape supports multiple contract languages and chains.\n\nApe is built by [ApeWorX LTD](https://www.apeworx.io/).\n\nJoin our [ApeWorX Discord server][discord-url] to stay up to date on new releases, plugins, and tutorials.\n\nIf you want to get started now, see the [Quickstart](#quickstart) section.\n\n## Documentation\n\nRead our [technical documentation](https://docs.apeworx.io/ape/stable/) to get a deeper understanding of our open source Framework.\n\nRead our [academic platform](https://academy.apeworx.io/) which will help you master Ape Framework with tutorials and challenges.\n\n## Prerequisite\n\nIn the latest release, Ape requires:\n\n- Linux or macOS\n- Python 3.9 up to 3.12\n- **Windows**: Install Windows Subsystem Linux [(WSL)](https://docs.microsoft.com/en-us/windows/wsl/install)\n\nCheck your python version in a terminal with `python3 --version`.\n\n## Installation\n\nThere are three ways to install ape: `pipx`, `pip`, or `Docker`.\n\n### Considerations for Installing\n\n- If using `pip`, we advise using the most up-to-date version of `pip` to increase the chance of a successful installation.\n\n  - See issue https://github.com/ApeWorX/ape/issues/1558.\n  - To upgrade `pip` from the command line, run: `pip install --upgrade pip`.\n\n- We advise installing in a [virtualenv](https://pypi.org/project/virtualenv/) or [venv](https://docs.python.org/3/library/venv.html) to avoid interfering with *OS-level site packages*.\n\n- We advise installing **`ape`** with recommended plugins `pip install eth-ape'[recommended-plugins]'`.\n\n- We advise for **macOS** users to install virtual env via [homebrew](https://formulae.brew.sh/formula/virtualenv).\n\n### Installing with `pipx` or `pip`\n\n1. Install `pipx` via their [installation instructions](https://pypa.github.io/pipx/) or `pip` via their [installation instructions](https://pip.pypa.io/en/stable/cli/pip_install/).\n\n2. Install **`ape`** via `pipx install eth-ape` or `pip install eth-ape`.\n\n### Installing with `docker`\n\nApe can also run in a docker container.\n\nYou can pull our images from [ghcr](https://ghcr.io/apeworx/ape).\nThis image is built using our `recommended-plugins` extra, so it is a great starting point for running ape in a containerized environment.\n\nWe also have a `slim` docker image that is built without any installed plugins.\nThis image is meant for production support and must be further configured if any plugins are in use.\n\nYou can pull the image:\n\n```bash\n$ docker pull ghcr.io/apeworx/ape:latest  # installs with recommended-plugins\n```\n\nor pull the slim if you have specific needs that you'd like to build from:\n\n```bash\n$ docker pull ghcr.io/apeworx/ape:latest-slim  # installs ape with required packages\n```\n\nor build the image locally from source:\n\n```bash\n$ docker build -t ape:latest-slim -f Dockerfile.slim .\n$ docker build -t ape:latest .\n```\n\nAn example of running a command from the container would be:\n\n```bash\ndocker run \\\n  --volume $HOME/.ape:/home/harambe/.ape \\\n  --volume $HOME/.vvm:/home/harambe/.vvm \\\n  --volume $HOME/.solcx:/home/harambe/.solcx \\\n  --volume $PWD:/home/harambe/project \\\n  apeworx/ape compile\n```\n\n> **Note:**\n> The above command requires the full install which includes `recommended-plugins` installation extra.\n\n## Quickstart\n\nAfter you have installed Ape, run `ape --version` to verify the installation was successful.\n\nYou can interact with Ape using the [command line](https://docs.apeworx.io/ape/stable/userguides/clis.html) or the [Ape console](https://docs.apeworx.io/ape/stable/userguides/console.html).\n\nSee the following user-guides for more in-depth tutorials:\n\n- [Accounts][accounts-guide]\n- [Networks][networks-guide]\n- [Projects][projects-guide]\n- [Compiling][compile-guide]\n- [Testing][testing-guide]\n- [Console][console-guide]\n- [Scripting][scripting-guide]\n- [Logging][logging-guide]\n\n## Plugin System\n\nApe's modular plugin system allows users to have an interoperable experience with Web3.\n\n- Learn about **installing** plugins from following this [installing user guide](https://docs.apeworx.io/ape/stable/userguides/installing_plugins.html).\n\n- Learn more about **developing** your own plugins from this [developing user guide](https://docs.apeworx.io/ape/stable/userguides/developing_plugins.html).\n\n```{note}\nIf a plugin does not originate from the [ApeWorX GitHub Organization](https://github.com/ApeWorX?q=ape&type=all), you will get a warning about installing 3rd-party plugins.\nInstall 3rd party plugins at your own risk.\n```\n\n[accounts-guide]: https://docs.apeworx.io/ape/stable/userguides/accounts.html\n[actions-badge]: https://github.com/ApeWorX/ape/actions/workflows/test.yaml/badge.svg\n[actions-url]: https://github.com/ApeWorX/ape/actions?query=branch%3Amain+event%3Apush\n[compile-guide]: https://docs.apeworx.io/ape/stable/userguides/compile.html\n[console-guide]: https://docs.apeworx.io/ape/stable/userguides/console.html\n[discord-badge]: https://img.shields.io/discord/922917176040640612.svg?logo=discord&style=flat-square\n[discord-url]: https://discord.gg/apeworx\n[licence-badge]: https://img.shields.io/github/license/ApeWorX/ape?color=blue\n[licence-url]: https://github.com/ApeWorX/ape/blob/main/LICENSE\n[logging-guide]: https://docs.apeworx.io/ape/stable/userguides/logging.html\n[networks-guide]: https://docs.apeworx.io/ape/stable/userguides/networks.html\n[projects-guide]: https://docs.apeworx.io/ape/stable/userguides/projects.html\n[pypi-badge]: https://img.shields.io/pypi/dm/eth-ape?label=pypi.org\n[pypi-url]: https://pypi.org/project/eth-ape/\n[scripting-guide]: https://docs.apeworx.io/ape/stable/userguides/scripts.html\n[testing-guide]: https://docs.apeworx.io/ape/stable/userguides/testing.html\n[twitter-badge]: https://img.shields.io/twitter/follow/ApeFramework\n[twitter-url]: https://twitter.com/ApeFramework\n"
  },
  "ApeWorX/silverback": {
    "fetchedAt": "2025-11-12T22:55:34.962Z",
    "content": "# Quick Start\n\nSilverback lets you create and deploy your own Python bots that respond to on-chain events.\nThe Silverback library leverages the [Ape](https://docs.apeworx.io/ape/stable/userguides/quickstart) development framework as well as it's ecosystem of plugins and packages to enable you to develop simple-yet-sophisticated automated bots that can listen and respond to live chain data.\n\nSilverback bots are excellent for use cases that involve continuously monitoring and responding to on-chain events, such as newly confirmed blocks or contract event logs.\n\nSome examples of these types of bots:\n\n- Monitoring new pool creations, and depositing liquidity\n- Measuring trading activity of popular pools\n- Listening for large swaps to update a telegram group\n\n## Documentation\n\nPlease read the [development userguide](https://docs.apeworx.io/silverback/stable/userguides/development.html) for more information on how to develop a bot.\n\n## Dependencies\n\n- [python3](https://www.python.org/downloads) version 3.10 or greater, python3-dev\n\n## Installation\n\nSilverback relies heavily on the Ape development framework, so it's worth it to familarize yourself with how to install Ape and it's plugins using the [Ape installation userguide](https://docs.apeworx.io/ape/latest/userguides/quickstart#installation).\n\n```{note}\nIt is suggested that you use a virtual environment of your choosing, and then install the Silverback package via one of the following options.\n```\n\n### via `pip`\n\nYou can install the latest release via [`pip`](https://pypi.org/project/pip/):\n\n```bash\npip install silverback\n```\n\n### via `setuptools`\n\nYou can clone the repository and use [`setuptools`](https://github.com/pypa/setuptools) for the most up-to-date version:\n\n```bash\ngit clone https://github.com/ApeWorX/silverback.git silverback\ncd silverback\npython3 setup.py install\n```\n\n## Quick Usage\n\nCheckout [the example](https://github.com/ApeWorX/silverback/blob/main/bots/example.py) to see how to use the library.\n\n```{note}\nThe example makes use of the [Ape Tokens](https://github.com/ApeWorX/ape-tokens) plugin.\nBe sure to properly configure your environment for the USDC and YFI tokens on Ethereum mainnet.\n```\n\nTo run your bot against a live network, this SDK includes a simple bot command you can use via:\n\n```sh\n$ silverback run example --network :mainnet:alchemy\n```\n\n```{note}\nThis bot uses an in-memory task broker by default.\nIf you want to learn more about what that means, please visit the [development userguide](https://docs.apeworx.io/silverback/stable/userguides/development.html).\n```\n\n```{note}\nIt is suggested that you create a bots/ folder in the root of your project.\nSilverback will automatically register files in this folder as separate bots that can be run via the `silverback run` command.\n```\n\n```{note}\nIt is also suggested that you treat this as a scripts folder, and do not include an __init__.py\nIf you have a complicated project, follow the previous example to ensure you run the bot correctly.\n```\n\n```{note}\nA final suggestion would be to name your `SilverbackBot` object `bot`. Silverback automatically searches \nfor this object name when running. If you do not do so, once again, ensure you replace `example` with \n`example:<name-of-object>` the previous example.\n```\n\nTo auto-generate Dockerfiles for your bots, from the root of your project, you can run:\n\n```bash\nsilverback build --generate\n```\n\nThis will place the generated dockerfiles in a special directory in the root of your project.\n\nAs an example, if you have a bots directory that looks like:\n\n```\nbots/\n‚îú‚îÄ‚îÄ botA.py\n‚îú‚îÄ‚îÄ botB.py\n‚îú‚îÄ‚îÄ botC.py\n```\n\nThis method will generate 3 Dockerfiles:\n\n```\n.silverback-images/\n‚îú‚îÄ‚îÄ Dockerfile.botA\n‚îú‚îÄ‚îÄ Dockerfile.botB\n‚îú‚îÄ‚îÄ Dockerfile.botC\n```\n\nThese Dockerfiles can be deployed with the `docker push` command documented in the next section so you can use it in cloud-based deployments.\n\n```{note}\nAs an aside, if your bots/ directory is a python package, you will cause conflicts with the dockerfile generation feature. This method will warn you that you are generating bots for a python package, but will not stop you from doing so. If you choose to generate dockerfiles, the user should be aware that it will only copy each individual file into the Dockerfile, and will not include any supporting python functionality. Each python file is expected to run independently. If you require more complex bots, you will have to build a custom docker image.\n```\n\n## Docker Usage\n\n```sh\n$ docker run -it apeworx/silverback-example:latest run --network :mainnet\n```\n\n```{note}\nThe Docker image we publish uses Python 3.11.\n```\n\n## Development\n\nThis project is under active development in preparation of the release of the [Silverback Platform](https://silverback.apeworx.io).\nThings might not be in their final state and breaking changes may occur.\nComments, questions, criticisms and pull requests are welcomed.\n\nSee [Contributing](https://github.com/ApeWorX/silverback/blob/main/CONTRIBUTING.md) for more information.\n"
  },
  "ApeWorX/ape-base": {
    "fetchedAt": "2025-11-12T22:55:35.421Z",
    "content": "# Quick Start\n\nEcosystem Plugin for [Base](https://base.org/) support in Ape.\n\n## Dependencies\n\n- [python3](https://www.python.org/downloads) version 3.9 up to 3.12.\n\n## Installation\n\n### via `pip`\n\nYou can install the latest release via [`pip`](https://pypi.org/project/pip/):\n\n```bash\npip install ape-base\n```\n\n### via `setuptools`\n\nYou can clone the repository and use [`setuptools`](https://github.com/pypa/setuptools) for the most up-to-date version:\n\n```bash\ngit clone https://github.com/ApeWorX/ape-base.git\ncd ape-base\npython3 setup.py install\n```\n\n## Quick Usage\n\nInstalling this plugin adds support for the Base ecosystem:\n\n```\nape console --network base:sepolia\n```\n\n## Development\n\nThis project is in development and should be considered a beta.\nThings might not be in their final state and breaking changes may occur.\nComments, questions, criticisms and pull requests are welcomed.\n"
  },
  "upnodedev/evm-faucet": {
    "fetchedAt": "2025-11-12T22:55:44.694Z",
    "content": "# eth-faucet\n\n[![Build](https://img.shields.io/github/actions/workflow/status/chainflag/eth-faucet/build.yml?branch=main)](https://github.com/chainflag/eth-faucet/actions/workflows/build.yml)\n[![Release](https://img.shields.io/github/v/release/chainflag/eth-faucet)](https://github.com/chainflag/eth-faucet/releases)\n[![Report](https://goreportcard.com/badge/github.com/chainflag/eth-faucet)](https://goreportcard.com/report/github.com/chainflag/eth-faucet)\n[![Go](https://img.shields.io/github/go-mod/go-version/chainflag/eth-faucet)](https://go.dev/)\n[![License](https://img.shields.io/github/license/chainflag/eth-faucet)](https://github.com/chainflag/eth-faucet/blob/main/LICENSE)\n\nThe faucet is a web application with the goal of distributing small amounts of Ether in private and test networks.\n\n## Features\n\n* Allow to configure the funding account via private key or keystore\n* Asynchronous processing Txs to achieve parallel execution of user requests\n* Rate limiting by ETH address and IP address as a precaution against spam\n* Prevent X-Forwarded-For spoofing by specifying the count of reverse proxies\n\n## Get started\n\n### Prerequisites\n\n* Go (1.21 or later)\n* Node.js\n\n### Installation\n\n1. Clone the repository and navigate to the app‚Äôs directory\n```bash\ngit clone https://github.com/chainflag/eth-faucet.git\ncd eth-faucet\n```\n\n2. Bundle Frontend web with Vite\n```bash\ngo generate\n```\n\n3. Build Go project \n```bash\ngo build -o eth-faucet\n```\n\n## Usage\n\n**Use private key to fund users**\n\n```bash\n./eth-faucet -httpport 8080 -wallet.provider http://localhost:8545 -wallet.privkey privkey\n```\n\n**Use keystore to fund users**\n\n```bash\n./eth-faucet -httpport 8080 -wallet.provider http://localhost:8545 -wallet.keyjson keystore -wallet.keypass password.txt\n```\n\n### Configuration\n\nYou can configure the funder by using environment variables instead of command-line flags as follows:\n```bash\nexport FAUCET_NAME=Chain Name\nexport FAUCET_AMOUNT=0.001\nexport FAUCET_INTERVAL=1440\n\nexport WEB3_PROVIDER=rpc endpoint\nexport PRIVATE_KEY=hex private key\n```\n\nor\n\n```bash\nexport FAUCET_NAME=Chain Name\nexport WEB3_PROVIDER=rpc endpoint\nexport KEYSTORE=keystore path\necho \"your keystore password\" > `pwd`/password.txt\n```\n\nThen run the faucet application without the wallet command-line flags:\n```bash\n./eth-faucet -httpport 8080\n```\n\n**Optional Flags**\n\nThe following are the available command-line flags(excluding above wallet flags):\n\n| Flag              | Description                                      | Default Value |\n|-------------------|--------------------------------------------------|---------------|\n| -httpport         | Listener port to serve HTTP connection           | 8080          |\n| -proxycount       | Count of reverse proxies in front of the server  | 0             |\n| -faucet.amount    | Number of Ethers to transfer per user request    | 1             |\n| -faucet.minutes   | Number of minutes to wait between funding rounds | 1440          |\n| -faucet.name      | Network name to display on the frontend          | testnet       |\n| -faucet.symbol    | Token symbol to display on the frontend          | ETH           |\n| -hcaptcha.sitekey | hCaptcha sitekey                                 |               |\n| -hcaptcha.secret  | hCaptcha secret                                  |               |\n\n### Docker deployment\n\n```bash\ndocker run -d -p 8080:8080 -e WEB3_PROVIDER=rpc endpoint -e PRIVATE_KEY=hex private key chainflag/eth-faucet:1.1.0\n```\n\nor\n\n```bash\ndocker run -d -p 8080:8080 -e WEB3_PROVIDER=rpc endpoint -e KEYSTORE=keystore path -v `pwd`/keystore:/app/keystore -v `pwd`/password.txt:/app/password.txt chainflag/eth-faucet:1.1.0\n```\n\n## License\n\nDistributed under the MIT License. See LICENSE for more information.\n"
  },
  "upnodedev/opstack-bridge-indexer": {
    "fetchedAt": "2025-11-12T22:55:45.135Z",
    "content": "# opstack-bridge-indexer\n\n## Description\nopstack-bridge-indexer is a project designed to securely store and receive events related to the `TransactionDeposited` event on Layer 1 and the `WithdrawalInitiated` event on Layer 2. The project exposes a server to be used in a frontend application using TypeScript, Viem, SQLite, Ether.js, and Express.\n\n## Prerequisites\n- Node.js v20+\n- Recommendation use Full Node to run fetch pass events\n\n## Setup Instructions\n\n### Step 1: Clone the Repository\nClone this repository to your local machine using the following command\n```bash\ngit clone <repository-url>\ncd opstack-bridge-indexer\n```\n\n### Step 2: Install Packages\nInstall the necessary packages by running\n```bash\nnpm install --ignore-engines\n```\n\n### Step 3: Configure Environment Variables\nCreate a .env file in the root directory and configure the following environment variables (example provided for mainnet and optimism) \n```bash\n# Layer 1 (L1) Configuration (Recommendation use Full Node)\nL1_RPC_URL_1=https://eth-mainnet.g.alchemy.com/v2/demo\nL1_RPC_URL_2=https://eth-mainnet.g.alchemy.com/v2/demo\nL1_RPC_URL_3=https://eth-mainnet.g.alchemy.com/v2/demo\nL1_CHAIN_NAME=Sepolia\nL1_CHAIN_ID=11155111\nL1_PORTAL_ADDRESS=0x16Fc5058F25648194471939df75CF27A2fdC48BC\nL1_PORTAL_BLOCK_CREATED=4071248\nL1_WSS_URL_1=wss://sepolia.gateway.tenderly.co\n\n# Layer 2 (L2) Configuration (Recommendation use Full Node)\nL2_RPC_URL_1=https://mainnet.optimism.io\nL2_RPC_URL_2=https://mainnet.optimism.io\nL2_RPC_URL_3=https://mainnet.optimism.io\nL2_CHAIN_NAME=OP Sepolia Testnet\nL2_CHAIN_ID=11155420\nL2_STANDARD_BRIDGE_ADDRESS=0x4200000000000000000000000000000000000010\nL2_STANDARD_BRIDGE_BLOCK_CREATED=0\n\n# PORT to expose API\nPORT = 3000\n```\n\n### Step 4: Build the Project\nBuild the project by running\n``` bash\nnpm run build\n```\n\n### Step 5: Create local Database\nCreate local SQLite via run :\n``` bash\nnpm run db\n```\n\n### Step 6: Store and Receive Events\nTo start the process of storing and receiving events, run\n``` bash\nnpx pm2 start npm --name \"opstack-bridge-indexer\" -- run start\n```\n\n### Step 7: Start the Server\nTo start the server for frontend using, run\n``` bash\nnpx pm2 start npm --name \"opstack-bridge-server\" -- run server\n```\n\n### Step 8: Checking\n``` bash\n# opstack-bridge-indexer\nnpx pm2 logs opstack-bridge-indexer\n``` \n``` bash\n# opstack-bridge-server\nnpx pm2 logs opstack-bridge-server\n```\n\n### Usage\nThe server exposes endpoints to interact with the stored events. You can use these endpoints in your frontend application to fetch and display the events as needed.\n\n``` bash\ncurl http://{IP Address}:{PORT}/deposit?limit=100&to={address}&from={address}\ncurl http://{IP Address}:{PORT}/withdrawal?limit=100&to={address}&from={address}\n```"
  },
  "upnodedev/opstack-bridge-ui": {
    "fetchedAt": "2025-11-12T22:55:45.980Z",
    "content": "# React + TypeScript + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n\n## Expanding the ESLint configuration\n\nIf you are developing a production application, we recommend updating the configuration to enable type aware lint rules:\n\n- Configure the top-level `parserOptions` property like this:\n\n```js\nexport default {\n  // other rules...\n  parserOptions: {\n    ecmaVersion: 'latest',\n    sourceType: 'module',\n    project: ['./tsconfig.json', './tsconfig.node.json'],\n    tsconfigRootDir: __dirname,\n  },\n}\n```\n\n- Replace `plugin:@typescript-eslint/recommended` to `plugin:@typescript-eslint/recommended-type-checked` or `plugin:@typescript-eslint/strict-type-checked`\n- Optionally add `plugin:@typescript-eslint/stylistic-type-checked`\n- Install [eslint-plugin-react](https://github.com/jsx-eslint/eslint-plugin-react) and add `plugin:react/recommended` & `plugin:react/jsx-runtime` to the `extends` list\n"
  },
  "upnodedev/opstack-bridge-ui-v2": {
    "fetchedAt": "2025-11-12T22:55:46.373Z",
    "content": "# React + TypeScript + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n\n## Expanding the ESLint configuration\n\nIf you are developing a production application, we recommend updating the configuration to enable type aware lint rules:\n\n- Configure the top-level `parserOptions` property like this:\n\n```js\nexport default tseslint.config({\n  languageOptions: {\n    // other options...\n    parserOptions: {\n      project: ['./tsconfig.node.json', './tsconfig.app.json'],\n      tsconfigRootDir: import.meta.dirname,\n    },\n  },\n})\n```\n\n- Replace `tseslint.configs.recommended` to `tseslint.configs.recommendedTypeChecked` or `tseslint.configs.strictTypeChecked`\n- Optionally add `...tseslint.configs.stylisticTypeChecked`\n- Install [eslint-plugin-react](https://github.com/jsx-eslint/eslint-plugin-react) and update the config:\n\n```js\n// eslint.config.js\nimport react from 'eslint-plugin-react'\n\nexport default tseslint.config({\n  // Set the react version\n  settings: { react: { version: '18.3' } },\n  plugins: {\n    // Add the react plugin\n    react,\n  },\n  rules: {\n    // other rules...\n    // Enable its recommended rules\n    ...react.configs.recommended.rules,\n    ...react.configs['jsx-runtime'].rules,\n  },\n})\n```\n"
  },
  "upnodedev/opstack-compose": {
    "fetchedAt": "2025-11-12T22:55:46.773Z",
    "content": "# Upnode Deploy\n\nUpnode Deploy is an open-source Docker Compose and UI tool for deploying an OP Stack chain.\n\nUnlike Conduit, which is a paid, closed-source RaaS, Upnode Deploy is an open-source public good that helps developers customize and deploy their OP Stack chain.\n\n## Getting Started\n\nClone the repository: https://github.com/upnodedev/opstack-compose\n\nCopy the .env.example file to .env.\n\nEdit the following sections in the .env file:\n\n```\n##################################################\n#                 Accounts Info                  #\n##################################################\n\n# Admin account\nADMIN_PRIVATE_KEY=\n\n# Batcher account\nBATCHER_PRIVATE_KEY=\n\n# Proposer account\nPROPOSER_PRIVATE_KEY=\n\n# Sequencer account\nSEQUENCER_PRIVATE_KEY=\n\n# Contract deployer account\nDEPLOYER_PRIVATE_KEY=$ADMIN_PRIVATE_KEY\n\n##################################################\n#                 L1 RPC Info                    #\n##################################################\n\n# The kind of RPC provider, used to inform optimal transaction receipts\n# fetching. Valid options: alchemy, quicknode, infura, parity, nethermind,\n# debug_geth, erigon, basic, any.\nL1_RPC_KIND=basic\n\n# RPC URL for the L1 network to interact with\nL1_RPC_URL=<Tenderly Fraxtal RPC Endpoint>\n\n##################################################\n#               Deployment Info                  #\n##################################################\n\n# The chain identifier for the L2 network\nL2_CHAIN_ID=<Chain ID>\n```\n\nYou can use the same private key for Admin, Batcher, Proposer, and Sequencer for ease of testing. However, this practice is not recommended on the mainnet.\n\nAfter editing the .env file, deploy the chain using Docker Compose by running the following command:\n\n```\ndocker compose --profile sequencer up -d --build\n```\n\nWait for it to deploy the OP Stack chain as a Fraxtal L3.\n\nOnce the deployment is complete, your Fraxtal L3 will be accessible at:\n\n* **RPC:** http://YOURIPADDRESS:8545\n* **WS:** ws://YOURIPADDRESS:8545\n\nTo deploy the Blockscout explorer for your Fraxtal L3 chain, navigate to the blockscout folder and run:\n\n```\ndocker compose -f geth.yml up -d --build\n```\n\nIf you want to point a domain name to these endpoints or introduce a rate limit, you can use a reverse proxy such as Nginx or Traefik to handle this job.\n\nSpan batch activated by default!\n"
  },
  "upnodedev/upnode-deploy-ui": {
    "fetchedAt": "2025-11-12T22:55:47.144Z",
    "content": "This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.\n"
  },
  "upnodedev/opstack-cli": {
    "fetchedAt": "2025-11-12T22:55:47.897Z",
    "content": "<p align=\"center\">\n    <picture>\n          <img src=\"./media/images/upnode_logo.png\" height=\"188\">\n    </picture>\n    <h1 align=\"center\">UpRoll CLI Tool</h1>\n    <h4 align=\"center\">By Upnode</h4>\n</p>\n\n# UpRoll CLI Tool\n\n<div style=\"text-align: center;\">\n    <img src=\"media/gifs/run.gif\" style=\"width:60%; height:auto;\" border=\"0\">\n</div>\n\nThe **UpRoll CLI Tool** by Upnode enables chain operators and developers to efficiently configure and deploy OP Stack chains. You can create a chain configuration either through our [website](https://uproll-web.vercel.app/) or directly via the CLI.\n\n\nDeployment is handled through the CLI. After building your chain using the website, deployment is as easy as running:\n ```\n uproll deploy -i [config_id]\n ```\n\n\nFor deployment, UpRoll uses a fork of the [optimism package](https://github.com/upnodedev/optimism-package) which provides greater levels of customisation. Unlike Conduit, which is a paid, closed-source solution that relies on third-party managed servers, UpRoll CLI Tool is free, open-source, and allows developers to deploy OP Stack chains on their own infrastructure with full transparency.\n\n\n\n## Requirements\nTo run the CLI, you will first need to make sure you have the following programs:\n\n- [Node.js](https://nodejs.org/en/download) version 18 or higher and [Node package management](https://www.npmjs.com/)\n- [Docker](https://docs.docker.com/get-started/get-docker/) version 27 or higher\n- [Kurtosis](https://docs.kurtosis.com/install) latest version\n\n\n**Install UpRoll CLI Tool**\n\n```console\nnpm install -g uproll-cli\n```\n\n**Verify version**\n\n```console\nuproll version\n```\n\n**Update version**\n\n```console\nnpm update -g uproll-cli\n```\n\n\n## Creating and Deploying a Chain\n\n### Option 1: Website + CLI\n\nOur website allows you to create and store rollup configurations, which can then be used for deployment via the CLI.\n\n\n\n\n#### 1. Create a Rollup Configuration\n  1.  **Sign up** and navigate to the [Create Your Rollup](https://uproll.upnode.org/config) page\n  2. Configure your chain settings and click **Save**\n  3. Your configuration will be assigned a unique **configuration ID**\n\n  <img src=\"media/images/website.png\" alt=\"Alt Text\" style=\"width:40%; height:auto;\">\n\n#### 2. Deploy Your Chain\nTo deploy your saved configuration, run:\n```\nuproll deploy -i [config_id]\n```\nReplace `config_id` with your chain's unique configuration ID.\n\nYou will then be prompted for the project name. Once entered, the chain configuration will be deployed.\n### Option 2: CLI Only\n#### 1. Create a Rollup Configuration\nRun the following command:\n```\nuproll run\n```\nSelect **Deploy Rollup** from the menu.\n\n<img src=\"media/images/image.png\" alt=\"Alt Text\" style=\"width:60%; height:auto;\">\n\n\nYou will then be prompted for values for various parameters. After confirming your selections, a valid configuration file will be generated automatically.\n\n<img src=\"media/images/image-1.png\" alt=\"Alt Text\" style=\"width:60%; height:auto;\">\n\n\n#### 2. Deploy your Chain\nDeployment begins automatically once the configuration file is created. Alternatively, if you already have a configuration file, you can deploy it directly by running `uproll deploy -f [path/config.yaml]`\n\n\n\n## Other Menu Options\nAll other menu options can be accessed by running:\n\n```\nuproll run\n```\n\n\n  <img src=\"media/gifs/run.gif\" style=\"width:60%; height:auto;\">\n\n\n\n\n### Stop Rollup\n\nThis option stops a specific rollup from running and deletes its project folder. Since Kurtosis does not support restarting an enclave after stopping it, the rollup and its associated project folder are removed.\n\n\n<img src=\"media/gifs/stop.gif\" style=\"width:60%; height:auto;\">\n\n### Chain Info\n\nAfter deployment, chain information is saved to a chain's project folder. \n\nThe **Chain info** command retrieves files related to a rollup's deployment, such as `intent.toml` and `wallets.json` or its genesis file.\n\n\n\n<img src=\"media/gifs/info.gif\" style=\"width:60%; height:auto;\">\n\n\n\n\nA list of active rollups is displayed. After selecting one, a list of available files appears. The chosen file is then displayed.\n\n### Status of the deployment\n\nThis command displays the deployment status of a rollup, including each service.\n\n\n<img src=\"media/gifs/status.gif\" style=\"width:60%; height:auto;\">\n\n\n### View logs\n\nThis command displays the log files of a particular rollup after it has been deployed.\n\n\n<img src=\"media/gifs/logs.gif\" style=\"width:60%; height:auto;\">\n\n### Clean\n\nKurtosis runs multiple Docker containers for each deployed chain, which can significantly impact your computer‚Äôs performance.\n\nIf you no longer need to run any chains, use the following command to stop and remove them.\n\n**Note:** This will permanently delete their project folders, including all configuration files and logs.\n\n\n<img src=\"media/gifs/clean.gif\" style=\"width:60%; height:auto;\">\n\n\n\n## Layer 1 & Rollup Configuration Parameters\n\n### **Wallet Configuration**\n| Parameter | Description |\n|-----------|-------------|\n| **Enter the Deployer Private Key** | Private key of the contract deployer account. It will need funds on L1 to deploy contracts there |\n\n### **Layer 1 Configuration**\n| Parameter | Description |\n|-----------|-------------|\n| **Select Settlement Layer** | Choose between ETH Mainnet, ETH Sepolia, or a Custom Layer 1 |\n| **Enter the Custom Chain ID (if applicable)** | Chain ID for custom Layer 1 setup |\n| **Enter the EL RPC URL** | Execution Layer RPC URL |\n| **Enter the EL WS URL** | Execution Layer WebSocket URL |\n| **Enter the CL RPC URL** | Consensus Layer RPC URL |\n| **Select RPC Kind for L1** | Determined automatically based on the RPC URL (Alchemy, QuickNode, or Standard) |\n\n### **Signer Configuration**\n| Parameter | Description |\n|-----------|-------------|\n| **Enter the Batcher Private Key or Signer Endpoint** | Choose between a private key or a signer address and endpoint for the batcher |\n| **Enter the Sequencer Private Key or Signer Endpoint** | Choose between a private key or a signer address and endpoint for the sequencer |\n| **Enter the Proposer Private Key or Signer Endpoint** | Choose between a private key or a signer address and endpoint for the proposer |\n| **Enter the Challenger Private Key or Signer Endpoint** | Choose between a private key or a signer address and endpoint for the challenger |\n\nWe proivde a [signer-proxy](https://github.com/upnodedev/signer-proxy) tool which can sign be used as a signer endpoint to sign transactions for any of these roles. Instructions for setting up a signer address are also given there.\n\n\n### **Rollup Configuration**\n| Parameter | Description |\n|-----------|-------------|\n| **Enter the L2 Chain ID** | Unique identifier for the Layer 2 chain |\n| **Enter the L2 Block Time (in seconds)** | Time interval between Layer 2 blocks |\n| **Enter the Withdrawal Delay (proofMaturityDelaySeconds)** | Time before withdrawals are finalised |\n| **Enter the Dispute Game Finality Delay** | Time before dispute resolution is finalised |\n| **Select the network for vault fee withdrawal** | Choose between L1 and L2 for withdrawal fees |\n\n### **Gas Configuration**\n| Parameter | Description |\n|-----------|-------------|\n| **Enter the Block Gas Limit** | Maximum gas allowed per block |\n| **Enter the EIP 1559 Elasticity** | Elasticity multiplier for EIP-1559 fee model |\n| **Enter the EIP 1559 Denominator** | Denominator for EIP-1559 fee model |\n| **Enter the Base Fee Scalar** | Base fee multiplier |\n| **Enter the Blob Base Fee Scalar** | Blob base fee multiplier |\n\n### **Data Availability Configuration**\n| Parameter | Description |\n|-----------|-------------|\n| **Select a Data Availability Type** | Options: auto, blobs, calldata, or custom |\n| **Enter the Batcher Submission Frequency (minutes)** | Time interval between batch submissions |\n| **Enter the DA Server Endpoint (if custom)** | URL of the Data Availability server |\n| **Select a Commitment Type (if custom)** | Choose between Generic and KeccakCommitment |\n| **Enter the\n\n[... truncated ...]"
  },
  "probe-lab/hermes": {
    "fetchedAt": "2025-11-12T22:55:55.752Z",
    "content": "![Hermes ProbeLab Logo](./resources/banner-hermes.svg)\n\n# Hermes\n\n[![ProbeLab](https://img.shields.io/badge/made%20by-ProbeLab-blue.svg)](https://probelab.io)\n[![Build status](https://img.shields.io/github/actions/workflow/status/probe-lab/hermes/go-test.yml?branch=main)](https://github.com/probe-lab/hermes/actions)\n[![GoDoc](https://pkg.go.dev/badge/github.com/probe-lab/hermes)](https://pkg.go.dev/github.com/probe-lab/hermes)\n\nHermes is light libp2p networking node that serves as a GossipSub listener and tracer for multiple networks.\nIt discovers and connects with network participats subscribing to all relevant pubsub topics of the respective\nnetwork and traces all protocol interactions like grafts, prunes, and any RPCs.\nAs of `2025-08-22`, Hermes supports the Ethereum, Filecoin, and OPStack-based networks.\n\n## Table of Contents\n\n<!-- TOC -->\n* [Hermes](#hermes)\n  * [Table of Contents](#table-of-contents)\n  * [Installation](#installation)\n    * [From Source](#from-source)\n  * [Developing](#developing)\n    * [CLI Arguments](#cli-arguments)\n  * [Deployment](#deployment)\n    * [General](#general)\n    * [Ethereum](#ethereum)\n      * [Subnet Configuration](#subnet-configuration)\n      * [Topic Subscription](#topic-subscription)\n    * [Filecoin](#filecoin)\n      * [Hermes vs Filecoin Lite Nodes](#hermes-vs-filecoin-lite-nodes)\n    * [Optimism](#optimism)\n  * [Importing Hermes](#importing-hermes)\n  * [Telemetry](#telemetry)\n    * [Metrics](#metrics)\n    * [Tracing](#tracing)\n  * [Differences with other tools](#differences-with-other-tools)\n    * [Armiarma Crawler from MigaLabs vs Hermes from ProbeLab](#armiarma-crawler-from-migalabs-vs-hermes-from-probelab)\n  * [Maintainers](#maintainers)\n  * [Contributing](#contributing)\n  * [License](#license)\n<!-- TOC -->\n\n## Installation\n\n### From Source\n\n```sh\ngo install github.com/probe-lab/hermes@latest\n```\n\n## Developing\n\nCheck out the repository:\n\n```shell\ngit clone git@github.com:probe-lab/hermes.git\ncd hermes\n```\n\nStart Hermes by running:\n\n```shell\ngo run ./cmd/hermes # Show help\ngo run ./cmd/hermes eth --help # Ethereum-specific options\ngo run ./cmd/hermes fil --help # Filecoin-specific options\ngo run ./cmd/hermes op --help # OPStack-specific options\n```\n\n<details>\n<summary>This should print this help text</summary>\n\n```text\nNAME:\n   hermes - a gossipsub listener\n\nUSAGE:\n   hermes [global options] command [command options]\n\nCOMMANDS:\n   eth, ethereum  Listen to gossipsub topics of the Ethereum network\n   fil, filecoin  Listen to gossipsub topics of the Filecoin network\n   op, optimism   Listen to gossipsub topics of any OPStack-based network\n   benchmark      performs the given set of benchmarks for the hermes internals\n   help, h        Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --help, -h  show help\n\n   DataStream Configuration:\n\n   --aws.key.id value         Access key ID of the AWS account for the s3 bucket [$HERMES_AWS_ACCESS_KEY_ID]\n   --aws.secret.key value     Secret key of the AWS account for the S3 bucket [$HERMES_AWS_SECRET_KEY]\n   --data.stream.type value   Format where the traces will be submitted: logger, kinesis, noop, s3 or callback. (default: \"logger\") [$HERMES_DATA_STREAM_TYPE]\n   --kinesis.region value     The region of the AWS Kinesis Data Stream [$HERMES_KINESIS_REGION]\n   --kinesis.stream value     The name of the AWS Kinesis Data Stream [$HERMES_KINESIS_DATA_STREAM]\n   --s3.bucket value          Name of the S3 bucket that will be used as reference to submit the traces (default: \"hermes\") [$HERMES_S3_BUCKET]\n   --s3.byte.limit value      Soft upper limit of bytes for the S3 dumps (default: 10485760) [$HERMES_S3_BYTE_LIMIT]\n   --s3.endpoint value        The endpoint of our custom S3 instance to override the AWS defaults [$HERMES_S3_CUSTOM_ENDPOINT]\n   --s3.flush.interval value  Minimum time interval at which the batched traces will be dump in S3 (default: 2s) [$HERMES_S3_FLUSH_INTERVAL]\n   --s3.flushers value        Number of flushers that will be spawned to dump traces into S3 (default: 2) [$HERMES_S3_FLUSHERS]\n   --s3.region value          The name of the region where the s3 bucket will be stored [$HERMES_S3_REGION]\n   --s3.tag value             Tag within the S3 bucket that will be used as reference to submit the traces [$HERMES_S3_TAG]\n\n   Logging Configuration:\n\n   --log.format value  Sets the format to output the log statements in: text, json, hlog, tint (default: \"hlog\") [$HERMES_LOG_FORMAT]\n   --log.level value   Sets an explicitly logging level: debug, info, warn, error. Takes precedence over the verbose flag. (default: \"info\") [$HERMES_LOG_LEVEL]\n   --log.nocolor       Whether to prevent the logger from outputting colored log statements (default: false) [$HERMES_LOG_NO_COLOR]\n   --log.source        Compute the source code position of a log statement and add a SourceKey attribute to the output. Only text and json formats. (default: false) [$HERMES_LOG_SOURCE]\n   --verbose, -v       Set logging level more verbose to include debug level logs (default: false) [$HERMES_VERBOSE]\n\n   Telemetry Configuration:\n\n   --metrics             Whether to expose metrics information (default: false) [$HERMES_METRICS_ENABLED]\n   --metrics.addr value  Which network interface should the metrics endpoint bind to. (default: \"localhost\") [$HERMES_METRICS_ADDR]\n   --metrics.port value  On which port should the metrics endpoint listen (default: 6060) [$HERMES_METRICS_PORT]\n   --tracing             Whether to emit trace data (default: false) [$HERMES_TRACING_ENABLED]\n   --tracing.addr value  Where to publish the traces to. (default: \"localhost\") [$HERMES_TRACING_ADDR]\n   --tracing.port value  On which port does the traces collector listen (default: 4317) [$HERMES_TRACING_PORT]\n\n```\n\n</details>\n\n### CLI Arguments\n\nWe use dot notation to namespace command line arguments instead of hyphens because [the CLI library](https://github.com/urfave/cli) allows\nconfiguring parameters from a file which will then resolve the command line parameters. For example,\nthe CLI flag `--log.format` could be read from a yaml file that looks like this:\n\n```yaml\nlog:\n  format: json\n```\n\n_However_, Hermes currently doesn't support loading CLI arguments from a file ¬Ø\\_(„ÉÑ)_/¬Ø.\n\n## Deployment\n\nDepending on the network you want to trace Hermes requires auxiliary infrastructure.\nAs of `2025-08-22`, Hermes supports these networks:\n\n- [Ethereum](#ethereum)\n- [Filecoin](#filecoin)\n- [OPStack](#opstack)\n\n### General\n\nThere are different ways of keeping track of the events that Hermes generates:\n- [AWS Kinesis](https://aws.amazon.com/kinesis/). We're using our [own producer library](https://github.com/dennis-tra/go-kinesis) to do that.\n    - In order to hook up Hermes with AWS Kinesis you need to provide the following command line flags:\n        - `--data.stream.type=\"kinesis\"`\n        - `--kinesis.region=us-east-1` # just an example\n        - `--kinesis.stream=$YOUR_DATA_STREAM_NAME`\n    - If the name is set, Hermes will start pumping events to that stream.\n      > It's important to note that the events **will not** be strictly ordered. They will only follow a lose ordering. The reasons are 1) potential retries of event submissions and 2) [record aggregation](https://docs.aws.amazon.com/streams/latest/dev/kinesis-kpl-concepts.html#kinesis-kpl-concepts-aggretation). Depending on the configured number of submission retries the events should be ordered within each 30s time window.\n- [S3](https://aws.amazon.com/s3/). Hermes will batch the traces, format them into a parquet file, and submit them to the given S3 Bucket. These are the flags that should be provided:\n    - `--data.stream.type=\"s3\"`\n    - `--s3.region=\"us-east-1\"` # just an example\n    - `--s3.endpoint=\"\"` # only for local testing\n    - `--s3.bucket=$YOUR_S3_BUCKET_KEY`\n    - `--s3.tag=\"hermes\"` # preferred bucket key used to reference the traces\n    - `--s3.byte.limit=1269760` # 10MB is the default\n    - `--s3.flushers=2` # 2 is the default\n    - `--s3.flush\n\n[... truncated ...]"
  },
  "curvegrid/multibaas-sample-app": {
    "fetchedAt": "2025-11-12T22:56:07.040Z",
    "content": "# MultiBaas Sample App\n\nThe purpose of this project is to demonstrate how to build a frontend-only decentralized application that uses [MultiBaas](https://docs.curvegrid.com/multibaas/) to handle the complexities of interacting with an EVM smart contract.\n\n![Screenshot](screenshots/homepage.png)\n\n## Quickstart Guide\n\nYou will need a few things to get started. Do this *before* running npm install.\n\n1. Go to [console.curvegrid.com](https://console.curvegrid.com), sign up, and create a MultiBaas deployment on your network of choice (use \"Curvegrid Testnet\" if unsure).\n2. Go to Admin > API Keys > New Key and create a key with label \"sample_app_admin\" and select \"Administrators\". Copy and save the **API key** and **deployment URL**.\n![Screenshot_2025-03-26_at_16_28_54](https://github.com/user-attachments/assets/367bdcbd-a8cc-4abd-9428-70cef637a740)\n3. Go to [cloud.reown.com](http://cloud.reown.com/), sign up, create a new project with name \"Sample App\". Copy and save the **Project ID**.\n<img width=\"1624\" alt=\"Screenshot_2025-03-26_at_16_40_00\" src=\"https://github.com/user-attachments/assets/161e5136-6ec1-44f2-aacc-499ecabbb43c\" />\n\n\nThen run the installation and follow the steps as prompted:\n\n```sh\ngit clone https://github.com/curvegrid/multibaas-sample-app.git\ncd multibaas-sample-app\nnpm install\n```\n\n## Overview\n\nThe repository consists of two sub-projects:\n\n- The `blockchain` folder contains a [Hardhat](https://hardhat.org/) project that uses the [Hardhat MultiBaas Plugin](https://github.com/curvegrid/hardhat-multibaas-plugin) to compile the `SimpleVoting` smart contract, deploy it to the network, and link it to a MultiBaas deployment so that we can interact with it via the REST API.\n- The `frontend` folder contains a Next.js web application that provides a UI for interacting with the smart contract using the [MultiBaas SDK](https://github.com/curvegrid/multibaas-sdk-typescript).\n\n## MultiBaas Deployment Setup\n\nUsing the [Curvegrid Console](https://console.curvegrid.com/), create a MultiBaas deployment on the Curvegrid Testnet. We recommend using this network for smart contract development due to its near-instant block finality and easily accessible faucet for account funding. It is also possible to use this demo app on any of our other supported networks but you will need tokens to deploy and interact with the smart contract.\n\n### Connecting to the Curvegrid Testnet\n\nOnce you have created and logged into your MultiBaas Deployment, you may automatically configure your MetaMask to connect to the Curvegrid Test Network by clicking the `Select Signer` button in the top navbar and then clicking `Switch Network` button. Click the `Continue` button in `Add Network` modal. MetaMask will prompt you that MultiBaas is adding a network on your behalf. Review the details, click the `Approve` button, and then finally click the `Switch network` button.\n\n### Requesting Ether from the Faucet\n\nVia the top navbar, go to the `Blockchain > Faucet` page and request 1 ETH to your deployer account address.\n\n### Creating API Keys\n\nThere are three API keys that **MUST** be created and used within this project. If you follow the installation script, you only need to provision an `Administrators` key and the others will be provisioned for you.\n\nOtherwise, navigate to the `Admin > API Keys` page and create new keys with the following parameters:\n\n1. Label `sample_app_admin`, Group `Administrators`. This API key has admin permission over the MultiBaas deployment, so copy it somewhere safe.\n\n2. Label `nextjs_frontend`, Group `DApp User`. This API key only has permission to read existing data on the blockchain, such as the state variables of a smart contract deployment, and to request MultiBaas to format and return an unsigned transaction for a specific interaction.\n\n3. For Curvegrid Testnet Only: Label `web3_proxy`, Option: `Use this key as a public Web3 key`. This API key will be used to construct an RPC URL for interacting with the Curvegrid Testnet. The UI will automatically construct and display the URL in the form of `https://<DEPLOYMENT ID>.multibaas.com/web3/<API KEY IN WEB3 GROUP>`, but copy and save just the API key part at the end.\n\nPlease make sure not to mix up these API keys.\n\n### CORS\n\nFor security reasons, your front end application needs permissions from the server to allow requests. If you follow the installation script, this will be done for you.\n\nNavigate to `Admin > CORS Origins` and add `http://localhost:3000` to the list of allowed origins. By default, MultiBaas does not allow unknown remote clients to make API requests, so by adding the URL above, you are giving permission to your local Next.js app to query MultiBaas. By default the frontend will run on port 3000, but if you are running another server it will increment to 3001 etc. so you may need to adjust your CORS settings accordingly.\n\n## Install dependencies\n\nYou can run the installation and configure things manually by skipping the postinstall script. Otherwise, feel free to use the Quickstart Guide at the beginning of this document.\n\n```sh\nnpm install\n```\n\n## Contract Deployment via Hardhat\n\nIf you have not yet deployed the `SimpleVoting.sol` smart contract to your MultiBaas deployment, we will now do so using the Hardhat project.\n\n```sh\ncd blockchain\n```\n\nThe configuration is saved in `deployment-config.development.js`.\n\nIf you did not run the installation, you can copy the template file to the configuration and fill in the fields manually:\n\n```sh\ncp deployment-config.template.js deployment-config.development.js\n```\n\n- `deployerPrivateKey`: The private key of your account with ETH on your target network, starting with `0x`. This key may be exported from MetaMask by clicking the `Account details` button in the menu of the account selector list, but please be sure only do this on a development-only account. It is strongly advised not to check it into source control.\n- `deploymentEndpoint`: Your MultiBaas Deployment URL, beginning with `https://` and ending with `.com`.\n- `ethChainID`: `2017072401` for Curvegrid Testnet otherwise find your chain ID on [chainlist.org](https://chainlist.org/).\n- `web3Key`: The Web3 Proxy API Key you previously created. Be sure to only include the API key and not the rest of the URL.\n- `rpcUrl`: The rpc URL to be used instead of the `web3Key` for networks other than Curvegrid Testnet. You should omit this field (leave it blank) if you are using the Curvegrid Testnet. If you are instead using another network, omit the `web3Key` and use an RPC URL from [ChainList](https://chainlist.org/).\n- `adminApiKey`: The API Key you previously created with label `sample_app_admin`.\n\nFinally, deploy the smart-contract:\n\n```sh\nnpm run deploy:voting:dev\n```\n\nNavigate to your MultiBaas deployment and confirm that you can see the contract on the `Contracts > On-Chain` page.\n\n## Next.js Frontend\n\nNow, we will setup the frontend application to interact with MultiBaas. This application uses [RainbowKit](https://www.rainbowkit.com/docs/installation) to support interaction with a variety of wallets.\n\n```sh\ncd frontend\n```\n\nThe configuration is saved in `.env.development`.\n\nIf you did not run the installation, you can copy the template file to the configuration and fill in the fields manually:\n\n```sh\ncp .env.template .env.development\n```\n\nYou will need to fill in the following fields:\n- `NEXT_PUBLIC_RAINBOWKIT_PROJECT_ID`: Project ID of a WalletKit project on [reown](https://cloud.reown.com/).\n- `NEXT_PUBLIC_MULTIBAAS_DEPLOYMENT_URL`: Your MultiBaas deployment URL, beginning with `https://` and ending with `.com`.\n- `NEXT_PUBLIC_MULTIBAAS_DAPP_USER_API_KEY`: The Dapp User API Key.\n- `NEXT_PUBLIC_MULTIBAAS_WEB3_API_KEY` (For Curvegrid Testnet): The Web3 Proxy API Key.\n- `NEXT_PUBLIC_MULTIBAAS_VOTING_CONTRACT_LABEL`: 'simple_voting'\n- `NEXT_PUBLIC_MULTIBAAS_VOTING_ADDRESS_ALIAS`: 'simple_voting'\n- `NEXT_PUBLIC_MULTIBAAS_CHAIN_ID`: '2017072401' for Curvegrid Testnet otherwise the relevant [chain ID](\n\n[... truncated ...]"
  },
  "curvegrid/hardhat-multibaas-plugin": {
    "fetchedAt": "2025-11-12T22:56:07.447Z",
    "content": "# hardhat-multibaas-plugin\n\nIntegrate [MultiBaas](https://docs.curvegrid.com/multibaas/) into your [Hardhat](https://hardhat.org/getting-started/) workflow!\n\nThis plugin streamlines your development by automatically adding smart contracts deployed through Hardhat to MultiBaas, reducing manual effort. From there, you can manage your smart contracts via the MultiBaas web UI and build blockchain applications using its REST API and SDKs.\n\nFor more details about MultiBaas, check out our [introductory walkthrough](https://www.curvegrid.com/blog/2020-04-06-multibaas-intro/) and [developer documentation](https://docs.curvegrid.com/multibaas/).\n\n## Usage\n\n### Installation\n\nOn your Hardhat workspace, set up a `package.json` file (if not yet added) with\n\n```bash\nnpm init\n```\n\nor\n\n```bash\nyarn init\n```\n\nThen, add the `hardhat-multibaas-plugin` package:\n\n```bash\nnpm i hardhat-multibaas-plugin --save-dev\n```\n\nor\n\n```bash\nyarn add hardhat-multibaas-plugin -D\n```\n\n### Configuration\n\nTo configure `hardhat-multibaas-plugin`, you need to define a `MBConfig` configuration option:\n\n```typescript\n/**\n * A configuration option used to configure MultiBaas Deployer.\n *\n * @field host the MultiBaas instance's host URL\n * @field apiKey the API key used to deploy a smart contract\n * @field allowUpdateAddress a list of networks that support overriding an address\n * if there exists an address on MultiBaas with the same alias.\n * @field allowUpdateContract a list of networks that support overriding a contract\n * if there exists a contract on MultiBaas with the same (label, version) but\n * different bytecode. */\ninterface MBConfig {\n  host: string;\n  apiKey: string;\n  allowUpdateAddress: string[];\n  allowUpdateContract: string[];\n}\n```\n\nTo use `hardhat-multibaas-plugin` with `hardhat`, configure the `networks` and `mbConfig` fields in your `hardhat.config.ts` as follows:\n\n```typescript\nimport \"hardhat-multibaas-plugin\";\n\nmodule.exports = {\n  defaultNetwork: \"development\",\n  networks: {\n    development: {\n      url: `<YOUR MULTIBAAS DEPLOYMeENT URL>/web3/<YOUR API KEY>`,\n      chainId: `<NETWORK's CHAIN ID>`,\n      accounts: [\"<ACCOUNT 1's PRIVATE KEY>\", \"<ACCOUNT 2's PRIVATE KEY>\"],\n    },\n  },\n  mbConfig: {\n    apiKey: \"<YOUR API KEY>\",\n    host: \"<YOUR MULTIBAAS DEPLOYMENT URL>\",\n    allowUpdateAddress: [\"development\"],\n    allowUpdateContract: [\"development\"],\n  },\n  // other hardhat configurations...\n};\n```\n\nA sample configuration file can be found in the [sample folder](./sample/hardhat.config.ts)\n\n### Testing/Deploying smart contracts\n\nSee the [sample folder](./sample) for a complete **Geting Started** guide with `hardhat-multibaas-plugin`.\n\nThe plugin uses a single `deploy` function to upload a smart contract's artifact, deploy then link the contract on MultiBaas:\n\n```typescript\ndeploy: (\n  // A `ethers.js` Signer or a `hardhat-ethers` FactoryOptions\n  signerOrOptions: Signer | FactoryOptions,\n  contractName: string,\n  contractArguments?: unknown[],\n  options?: DeployOptions,\n) => Promise<DeployResult>;\n```\n\nin which `DeployResult` is the data returned from a successful deployment using the plugin. It has the following fields:\n\n```typescript\n/**\n * Result of MultiBaas Deployer's deploy function.\n *\n * @field contract an `ethers.js`'s `Contract`\n * @field mbContract a MultiBaas contract\n * @field mbAddress a MultiBaas address\n **/\nexport interface DeployResult {\n  contract: Contract;\n  mbContract: MultiBaasContract;\n  mbAddress: MultiBaasAddress;\n}\n```\n\n`DeployOptions` consists of different options that you can specify when deploying a contract using the plugin. It has the following fields:\n\n```typescript\nexport interface DeployOptions {\n  /**\n   * Overwrite the default contractLabel. If set and a duplicate is found,\n   * the contract is assigned a newer version.\n   */\n  contractLabel?: string;\n  /**\n   * Version override. Will fail if another binary with the same version is found.\n   */\n  contractVersion?: string;\n  /**\n   * Overwrite the default address alias. If set and a duplicate is found,\n   * the address is instead updated (or returned with an error, chosen by global setting `allowUpdateAddress`).\n   *\n   * The auto-generated address alias is never a duplicate.\n   */\n  addressAlias?: string;\n\n  /**\n   * Override the default deploy transaction arguments\n   * (gasLimit, gasPrice, etc)\n   **/\n  overrides?: unknown;\n\n  /**\n   * The kind of the proxy. Defaults to 'transparent'.\n   **/\n  proxyKind?: \"uups\" | \"transparent\" | \"beacon\";\n\n  /**\n   * The block to start syncing the contract from.\n   *\n   * empty string: disable the MultiBaas Event Monitor\n   *  0: sync from the first block\n   * <0: sync from this number of blocks prior to the current block\n   * >0: sync from a specific block number\n   *\n   * Defaults to -100, or 100 blocks prior to the current block.\n   **/\n  startingBlock?: string;\n}\n```\n\nThe `deployProxy` function will deploy a proxied smart contract that uses [OpenZeppelin's Hardhat Upgrades plugin](https://docs.openzeppelin.com/upgrades-plugins/1.x/hardhat-upgrades). It automatically deploys the implementation contract, proxy, and admin, as required, and then links the proxy smart contract. It defaults to a 'transparent' proxy type, but can be overridden.\n\n```typescript\ndeployProxy: (\n  signerOrOptions: Signer | FactoryOptions,\n  contractName: string,\n  contractArguments?: unknown[],\n  options?: DeployOptions,\n) => Promise<DeployProxyResult>;\n```\n\nin which the `DeployProxyResult` extends the data included in `DeployResult` with the following additional fields:\n\n```typescript\nexport interface DeployProxyResult extends DeployResult {\n  adminAddress: string;\n  implementationAddress: string;\n}\n```\n\nFor contracts that have been deployed outside of `hardhat-multibaas-plugin`, it is possible to simply link them in MultiBaas by calling the `link` function and providing the deployed address.\n\n```typescript\nlink: (\n  signerOrOptions: Signer | FactoryOptions,\n  contractName: string,\n  address: string,\n  options?: DeployOptions,\n) => Promise<DeployResult>;\n```\n\n## Copyright\n\nCopyright (c) 2021 Curvegrid Inc.\n"
  },
  "curvegrid/multibaas-sdk-typescript": {
    "fetchedAt": "2025-11-12T22:56:07.878Z",
    "content": "## @curvegrid/multibaas-sdk@1.1.0\n\nThis generator creates TypeScript/JavaScript client that utilizes [axios](https://github.com/axios/axios). The generated Node module can be used in the following environments:\n\nEnvironment\n* Node.js\n* Webpack\n* Browserify\n\nLanguage level\n* ES5 - you must have a Promises/A+ library installed\n* ES6\n\nModule system\n* CommonJS\n* ES6 module system\n\nIt can be used in both TypeScript and JavaScript. In TypeScript, the definition will be automatically resolved via `package.json`. ([Reference](https://www.typescriptlang.org/docs/handbook/declaration-files/consumption.html))\n\n### Building\n\nTo build and compile the typescript sources to javascript use:\n```\nnpm install\nnpm run build\n```\n\n### Publishing\n\nFirst build the package then run `npm publish`\n\n### Consuming\n\nnavigate to the folder of your consuming project and run one of the following commands.\n\n_published:_\n\n```\nnpm install @curvegrid/multibaas-sdk@1.1.0 --save\n```\n\n_unPublished (not recommended):_\n\n```\nnpm install PATH_TO_GENERATED_PACKAGE --save\n```\n\n### Documentation for API Endpoints\n\nAll URIs are relative to *https://your_deployment.multibaas.com/api/v0*\n\nClass | Method | HTTP request | Description\n------------ | ------------- | ------------- | -------------\n*AddressesApi* | [**deleteAddress**](docs/AddressesApi.md#deleteaddress) | **DELETE** /chains/ethereum/addresses/{address-or-alias} | Delete address\n*AddressesApi* | [**getAddress**](docs/AddressesApi.md#getaddress) | **GET** /chains/ethereum/addresses/{address-or-alias} | Get address\n*AddressesApi* | [**listAddresses**](docs/AddressesApi.md#listaddresses) | **GET** /chains/ethereum/addresses | List addresses\n*AddressesApi* | [**setAddress**](docs/AddressesApi.md#setaddress) | **POST** /chains/ethereum/addresses | Create or update address\n*AdminApi* | [**acceptInvite**](docs/AdminApi.md#acceptinvite) | **POST** /invites/{inviteID} | Accept invite\n*AdminApi* | [**addCorsOrigin**](docs/AdminApi.md#addcorsorigin) | **POST** /cors | Add CORS origin\n*AdminApi* | [**addGroupApiKey**](docs/AdminApi.md#addgroupapikey) | **PUT** /groups/{groupID}/api_keys/{apiKeyID} | Add API key to group\n*AdminApi* | [**addGroupRole**](docs/AdminApi.md#addgrouprole) | **PUT** /groups/{groupID}/roles/{roleShortName} | Add role to group\n*AdminApi* | [**addGroupUser**](docs/AdminApi.md#addgroupuser) | **PUT** /groups/{groupID}/users/{userID} | Add user to group\n*AdminApi* | [**checkInvite**](docs/AdminApi.md#checkinvite) | **GET** /invites/{inviteID} | Check invite\n*AdminApi* | [**createApiKey**](docs/AdminApi.md#createapikey) | **POST** /api_keys | Create API key\n*AdminApi* | [**deleteApiKey**](docs/AdminApi.md#deleteapikey) | **DELETE** /api_keys/{apiKeyID} | Delete API key\n*AdminApi* | [**deleteInvite**](docs/AdminApi.md#deleteinvite) | **DELETE** /invites/{email}/delete | Delete invite\n*AdminApi* | [**deleteUser**](docs/AdminApi.md#deleteuser) | **DELETE** /users/{userID} | Delete user\n*AdminApi* | [**getApiKey**](docs/AdminApi.md#getapikey) | **GET** /api_keys/{apiKeyID} | Get API Key\n*AdminApi* | [**getPlan**](docs/AdminApi.md#getplan) | **GET** /plan | Get plan\n*AdminApi* | [**inviteUser**](docs/AdminApi.md#inviteuser) | **POST** /invites | Invite user\n*AdminApi* | [**listApiKeys**](docs/AdminApi.md#listapikeys) | **GET** /api_keys | List API keys\n*AdminApi* | [**listAuditLogs**](docs/AdminApi.md#listauditlogs) | **GET** /systemactivities | List audit logs\n*AdminApi* | [**listCorsOrigins**](docs/AdminApi.md#listcorsorigins) | **GET** /cors | List CORS origins\n*AdminApi* | [**listGroups**](docs/AdminApi.md#listgroups) | **GET** /groups | List groups\n*AdminApi* | [**listInvites**](docs/AdminApi.md#listinvites) | **GET** /invites | List invites\n*AdminApi* | [**listUserSigners**](docs/AdminApi.md#listusersigners) | **GET** /users/{userID}/signers | List user signers\n*AdminApi* | [**listUsers**](docs/AdminApi.md#listusers) | **GET** /users | List users\n*AdminApi* | [**removeCorsOrigin**](docs/AdminApi.md#removecorsorigin) | **DELETE** /cors/{originID} | Remove CORS Origin\n*AdminApi* | [**removeGroupApiKey**](docs/AdminApi.md#removegroupapikey) | **DELETE** /groups/{groupID}/api_keys/{apiKeyID} | Remove API key from group\n*AdminApi* | [**removeGroupRole**](docs/AdminApi.md#removegrouprole) | **DELETE** /groups/{groupID}/roles/{roleShortName} | Remove role from group\n*AdminApi* | [**removeGroupUser**](docs/AdminApi.md#removegroupuser) | **DELETE** /groups/{groupID}/users/{userID} | Remove user from group\n*AdminApi* | [**removeUserSignerCloudWallet**](docs/AdminApi.md#removeusersignercloudwallet) | **DELETE** /users/{userID}/cloudwallets/{wallet_address} | Remove user cloud wallet signer\n*AdminApi* | [**removeUserSignerSafeAccount**](docs/AdminApi.md#removeusersignersafeaccount) | **DELETE** /users/{userID}/safeaccounts/{wallet_address} | Remove user safe account signer\n*AdminApi* | [**removeUserSignerWeb3Wallet**](docs/AdminApi.md#removeusersignerweb3wallet) | **DELETE** /users/{userID}/web3wallets/{wallet_address} | Remove user web3 wallet signer\n*AdminApi* | [**setUserSignerCloudWallet**](docs/AdminApi.md#setusersignercloudwallet) | **PUT** /users/{userID}/cloudwallets/{wallet_address} | Add or update user cloud wallet signer\n*AdminApi* | [**setUserSignerSafeAccount**](docs/AdminApi.md#setusersignersafeaccount) | **PUT** /users/{userID}/safeaccounts/{wallet_address} | Add or update user safe account signer\n*AdminApi* | [**setUserSignerWeb3Wallet**](docs/AdminApi.md#setusersignerweb3wallet) | **PUT** /users/{userID}/web3wallets/{wallet_address} | Add or update user web3 wallet signer\n*AdminApi* | [**updateApiKey**](docs/AdminApi.md#updateapikey) | **PUT** /api_keys/{apiKeyID} | Update API key\n*ChainsApi* | [**getBlock**](docs/ChainsApi.md#getblock) | **GET** /chains/ethereum/blocks/{block} | Get a block\n*ChainsApi* | [**getChainStatus**](docs/ChainsApi.md#getchainstatus) | **GET** /chains/ethereum/status | Get chain status\n*ChainsApi* | [**getTransaction**](docs/ChainsApi.md#gettransaction) | **GET** /chains/ethereum/transactions/{hash} | Get transaction\n*ChainsApi* | [**getTransactionReceipt**](docs/ChainsApi.md#gettransactionreceipt) | **GET** /chains/ethereum/transactions/receipt/{hash} | Get transaction receipt\n*ChainsApi* | [**submitSignedTransaction**](docs/ChainsApi.md#submitsignedtransaction) | **POST** /chains/ethereum/transactions/submit | Submit signed transaction\n*ChainsApi* | [**transferEth**](docs/ChainsApi.md#transfereth) | **POST** /chains/ethereum/transfers | Transfer ETH\n*ContractsApi* | [**callContractFunction**](docs/ContractsApi.md#callcontractfunction) | **POST** /chains/ethereum/addresses/{address-or-alias}/contracts/{contract}/methods/{method} | Call a contract function\n*ContractsApi* | [**createContract**](docs/ContractsApi.md#createcontract) | **POST** /contracts/{contract} | Create a contract\n*ContractsApi* | [**createContracts**](docs/ContractsApi.md#createcontracts) | **POST** /contracts | Create multiple contracts\n*ContractsApi* | [**deleteContract**](docs/ContractsApi.md#deletecontract) | **DELETE** /contracts/{contract} | Delete a contract\n*ContractsApi* | [**deleteContractVersion**](docs/ContractsApi.md#deletecontractversion) | **DELETE** /contracts/{contract}/{version} | Delete a contract version\n*ContractsApi* | [**deployContract**](docs/ContractsApi.md#deploycontract) | **POST** /contracts/{contract}/deploy | Deploy a contract\n*ContractsApi* | [**deployContractVersion**](docs/ContractsApi.md#deploycontractversion) | **POST** /contracts/{contract}/{version}/deploy | Deploy a contract version\n*ContractsApi* | [**getContract**](docs/ContractsApi.md#getcontract) | **GET** /contracts/{contract} | Get a contract\n*ContractsApi* | [**getContractVersion**](docs/ContractsApi.md#getcontractversion) | **GET** /contracts/{contract}/{version} | Get a contract version\n*ContractsApi* | [**getContractVersions**](docs/ContractsApi.md#getcontractversions) | **GET** /contracts/{contract}/all | Get all contract versions\n*\n\n[... truncated ...]"
  },
  "curvegrid/multibaas-for-google-sheets": {
    "fetchedAt": "2025-11-12T22:56:08.307Z",
    "content": "![logo](./logo.png)\n\n# MultiBaas for Google Sheets\n\nThis spreadsheet plugin was originally developed as part of the [ETHGlobal HackMoney hackathon](https://hack.ethglobal.co/showcase/sunset-supreme-rec3QkXTn6lVq3TH0), where it was called _Sunset Supreme Spreadsheet Blockchain Plugin_. We made the following submissions as part of our entry:\n\n- [Live Demo Spreadsheet](https://docs.google.com/spreadsheets/d/1AHCYefYNCjU80X1aSs8Ebre85nVtBeu1cVWmXDIz0_0/edit?usp=sharing) (request for access)\n- [Demo Video](https://youtu.be/YsbzTZ6Cfvc)\n- [Presentation Slides](Sunset%20Supreme%20Spreadsheet%20Blockchain%20Machine.pdf)\n\n## Prerequisite\n\nYou should deploy a MultiBaas instance before following steps below.\n\n- [Deploy MultiBaas](https://www.curvegrid.com/docs/3-0-getting-started-creating-a-multibaas-deployment/)\n\n## Developing\n\n- node.js v12.16.0 or higher\n- [clasp](https://developers.google.com/apps-script/guides/clasp)\n\nInstall clasp globally\n\n```sh\nyarn global add @google/clasp\n```\n\nor if you use `npm`\n\n```sh\nnpm install @google/clasp -g\n```\n\nLogin using `clasp login`\n\n```sh\nclasp login\nWarning: You seem to already be logged in *globally*. You have a ~/.clasprc.json\nLogging in globally...\nüîë Authorize clasp by visiting this url:\nhttps://accounts.google.com/o/oauth2/v2/auth?access_type=offline&scope=https%3A%2F%2Fwww.googleapis.com%2...redirect_uri=http%3A%2F%2Flocalhost%3A54929\n```\n\nInstall local node.js packages\n\n```sh\nyarn install\n```\n\nor\n\n```sh\nnpm install\n```\n\n## Testing in a command\n\n**Spreadsheet**\n\nYou need to prepare for a spreadsheet with small configuration.\n\n![Sheet Step 0](./.readme/config-sheet-0.png)\n![Sheet Step 1](./.readme/config-sheet-1.png)\n\n**Link Apps Script to GCP**\n\nBefore you go, you need to enable Google Apps Script API first from [Apps Script settings](https://script.google.com/home/usersettings).\n\n![](./.readme/config-gas-3.png)\n\nIn order to run tests you need to link Apps Script project to GCP project.\n\nCopy a `Project number` from GCP project settings.\n\n![GAS Step 0](./.readme/config-gas-0.png)\n\nLink **Apps Script** project to **GCP** project.\n\n![GAS Step 1](./.readme/config-gas-1.png)\n![GAS Step 2](./.readme/config-gas-2.png)\n\n**Credentials and Environments Variables**\n\nYou need to create `.client-secret.json`, `.credentials.json`, `.clasp.json`, and `.testSheet.json` files\n\n- `.client-secret.json` and `.credentials.json` are used in `auth.js`\n- `.clasp.json` and `.testSheet.json` files are used in `mbSheetsAddOn.js`\n\n`.client-secret.json` is to set your GCP project. You should download form credential settings as follows:\n\n![GCP Step 0](./.readme/config-gcp-0.png)\n![GCP Step 1](./.readme/config-gcp-1.png)\n![GCP Step 2](./.readme/config-gcp-2.png)\n![GCP Step 3](./.readme/config-gcp-3.png)\n\nYou need to replace a file name with `.client-secret.json` after downloading it.\n\n```json\n{\n  \"installed\": {\n    \"client_id\": \"[YOUR GCP PROJECT CLIENT ID]\",\n    \"project_id\": \"[YOUR GCP PROJECT PROJECT ID]\",\n    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n    \"client_secret\": \"[YOUR GCP PROJECT CLIENT SECRET]\",\n    \"redirect_uris\": [\n      \"urn:ietf:wg:oauth:2.0:oob\",\n      \"http://localhost\"\n    ]\n  }\n}\n```\n\n`.clasp.json` is to set your Apps Script project after you create a new one.\n\n```json\n{\"scriptId\": \"[YOUR APPS SCRIPT ID]\"}\n```\n\n`.testSheet.json` file in the project root is to set a test sheet URL.\n\n```json\n{\"url\": \"[YOUR SPREADSHEET URL]\"}\n```\n\nRun `yarn test`.\n\n```sh\nyarn test\n```\n\nIf you don't have `.credentials.json` then you will see this prompt:\n\n```sh\nyarn test\nyarn run v1.22.10\n$ clasp push && cd test && node mbSheetsAddOn.js\n‚îî‚îÄ appsscript.json\n‚îî‚îÄ src/Code.js\n‚îî‚îÄ src/Code.spec.js\n‚îî‚îÄ src/library/Build.js\n‚îî‚îÄ src/library/Property.js\n‚îî‚îÄ src/library/Query.js\n‚îî‚îÄ src/library/Util.js\n‚îî‚îÄ src/library/Validate.js\nPushed 8 files.\nauthorize this app by visiting this url: https://accounts.google.com/o/oauth2/v2/auth?access_type=offline&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fscript.external_request%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fspreadsheets&response_type=code&client_id=966627203108-e6125d7hosngl429qh6b52old6b7r98t.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob\nEnter the code from that page here:\n```\n\nJust follow the URL and authenticate your account then you can retrieve a code to create `.credentials.json` file.\n\n## Linter\n\n```sh\nyarn lint\n```\n"
  },
  "curvegrid/multibaas-sdk-go": {
    "fetchedAt": "2025-11-12T22:56:08.783Z",
    "content": "# Go API client for multibaas\n\nMultiBaas API provides a unified interface for interacting with blockchain networks. It enables applications to deploy and manage smart contracts, call contract methods, and query blockchain data through standard REST endpoints. The API also includes features for authentication, role-based access control, and integration with existing systems, allowing developers to build blockchain-powered applications without needing deep protocol-level expertise.\n\n## Overview\nThis API client was generated by the [OpenAPI Generator](https://openapi-generator.tech) project.  By using the [OpenAPI-spec](https://www.openapis.org/) from a remote server, you can easily generate an API client.\n\n- API version: 0.0\n- Package version: 1.1.0\n- Generator version: 7.16.0\n- Build package: org.openapitools.codegen.languages.GoClientCodegen\nFor more information, please visit [https://www.curvegrid.com/contact](https://www.curvegrid.com/contact)\n\n## Installation\n\nInstall the following dependencies:\n\n```sh\ngo get github.com/stretchr/testify/assert\ngo get golang.org/x/net/context\n```\n\nPut the package under your project folder and add the following in import:\n\n```go\nimport multibaas \"github.com/curvegrid/multibaas-sdk-go\"\n```\n\nTo use a proxy, set the environment variable `HTTP_PROXY`:\n\n```go\nos.Setenv(\"HTTP_PROXY\", \"http://proxy_name:proxy_port\")\n```\n\n## Configuration of Server URL\n\nDefault configuration comes with `Servers` field that contains server objects as defined in the OpenAPI specification.\n\n### Select Server Configuration\n\nFor using other server than the one defined on index 0 set context value `multibaas.ContextServerIndex` of type `int`.\n\n```go\nctx := context.WithValue(context.Background(), multibaas.ContextServerIndex, 1)\n```\n\n### Templated Server URL\n\nTemplated server URL is formatted using default variables from configuration or from context value `multibaas.ContextServerVariables` of type `map[string]string`.\n\n```go\nctx := context.WithValue(context.Background(), multibaas.ContextServerVariables, map[string]string{\n\t\"basePath\": \"v2\",\n})\n```\n\nNote, enum values are always validated and all unused variables are silently ignored.\n\n### URLs Configuration per Operation\n\nEach operation can use different server URL defined using `OperationServers` map in the `Configuration`.\nAn operation is uniquely identified by `\"{classname}Service.{nickname}\"` string.\nSimilar rules for overriding default operation server index and variables applies by using `multibaas.ContextOperationServerIndices` and `multibaas.ContextOperationServerVariables` context maps.\n\n```go\nctx := context.WithValue(context.Background(), multibaas.ContextOperationServerIndices, map[string]int{\n\t\"{classname}Service.{nickname}\": 2,\n})\nctx = context.WithValue(context.Background(), multibaas.ContextOperationServerVariables, map[string]map[string]string{\n\t\"{classname}Service.{nickname}\": {\n\t\t\"port\": \"8443\",\n\t},\n})\n```\n\n## Documentation for API Endpoints\n\nAll URIs are relative to *https://your_deployment.multibaas.com/api/v0*\n\nClass | Method | HTTP request | Description\n------------ | ------------- | ------------- | -------------\n*AddressesAPI* | [**DeleteAddress**](docs/AddressesAPI.md#deleteaddress) | **Delete** /chains/ethereum/addresses/{address-or-alias} | Delete address\n*AddressesAPI* | [**GetAddress**](docs/AddressesAPI.md#getaddress) | **Get** /chains/ethereum/addresses/{address-or-alias} | Get address\n*AddressesAPI* | [**ListAddresses**](docs/AddressesAPI.md#listaddresses) | **Get** /chains/ethereum/addresses | List addresses\n*AddressesAPI* | [**SetAddress**](docs/AddressesAPI.md#setaddress) | **Post** /chains/ethereum/addresses | Create or update address\n*AdminAPI* | [**AcceptInvite**](docs/AdminAPI.md#acceptinvite) | **Post** /invites/{inviteID} | Accept invite\n*AdminAPI* | [**AddCorsOrigin**](docs/AdminAPI.md#addcorsorigin) | **Post** /cors | Add CORS origin\n*AdminAPI* | [**AddGroupApiKey**](docs/AdminAPI.md#addgroupapikey) | **Put** /groups/{groupID}/api_keys/{apiKeyID} | Add API key to group\n*AdminAPI* | [**AddGroupRole**](docs/AdminAPI.md#addgrouprole) | **Put** /groups/{groupID}/roles/{roleShortName} | Add role to group\n*AdminAPI* | [**AddGroupUser**](docs/AdminAPI.md#addgroupuser) | **Put** /groups/{groupID}/users/{userID} | Add user to group\n*AdminAPI* | [**CheckInvite**](docs/AdminAPI.md#checkinvite) | **Get** /invites/{inviteID} | Check invite\n*AdminAPI* | [**CreateApiKey**](docs/AdminAPI.md#createapikey) | **Post** /api_keys | Create API key\n*AdminAPI* | [**DeleteApiKey**](docs/AdminAPI.md#deleteapikey) | **Delete** /api_keys/{apiKeyID} | Delete API key\n*AdminAPI* | [**DeleteInvite**](docs/AdminAPI.md#deleteinvite) | **Delete** /invites/{email}/delete | Delete invite\n*AdminAPI* | [**DeleteUser**](docs/AdminAPI.md#deleteuser) | **Delete** /users/{userID} | Delete user\n*AdminAPI* | [**GetApiKey**](docs/AdminAPI.md#getapikey) | **Get** /api_keys/{apiKeyID} | Get API Key\n*AdminAPI* | [**GetPlan**](docs/AdminAPI.md#getplan) | **Get** /plan | Get plan\n*AdminAPI* | [**InviteUser**](docs/AdminAPI.md#inviteuser) | **Post** /invites | Invite user\n*AdminAPI* | [**ListApiKeys**](docs/AdminAPI.md#listapikeys) | **Get** /api_keys | List API keys\n*AdminAPI* | [**ListAuditLogs**](docs/AdminAPI.md#listauditlogs) | **Get** /systemactivities | List audit logs\n*AdminAPI* | [**ListCorsOrigins**](docs/AdminAPI.md#listcorsorigins) | **Get** /cors | List CORS origins\n*AdminAPI* | [**ListGroups**](docs/AdminAPI.md#listgroups) | **Get** /groups | List groups\n*AdminAPI* | [**ListInvites**](docs/AdminAPI.md#listinvites) | **Get** /invites | List invites\n*AdminAPI* | [**ListUserSigners**](docs/AdminAPI.md#listusersigners) | **Get** /users/{userID}/signers | List user signers\n*AdminAPI* | [**ListUsers**](docs/AdminAPI.md#listusers) | **Get** /users | List users\n*AdminAPI* | [**RemoveCorsOrigin**](docs/AdminAPI.md#removecorsorigin) | **Delete** /cors/{originID} | Remove CORS Origin\n*AdminAPI* | [**RemoveGroupApiKey**](docs/AdminAPI.md#removegroupapikey) | **Delete** /groups/{groupID}/api_keys/{apiKeyID} | Remove API key from group\n*AdminAPI* | [**RemoveGroupRole**](docs/AdminAPI.md#removegrouprole) | **Delete** /groups/{groupID}/roles/{roleShortName} | Remove role from group\n*AdminAPI* | [**RemoveGroupUser**](docs/AdminAPI.md#removegroupuser) | **Delete** /groups/{groupID}/users/{userID} | Remove user from group\n*AdminAPI* | [**RemoveUserSignerCloudWallet**](docs/AdminAPI.md#removeusersignercloudwallet) | **Delete** /users/{userID}/cloudwallets/{wallet_address} | Remove user cloud wallet signer\n*AdminAPI* | [**RemoveUserSignerSafeAccount**](docs/AdminAPI.md#removeusersignersafeaccount) | **Delete** /users/{userID}/safeaccounts/{wallet_address} | Remove user safe account signer\n*AdminAPI* | [**RemoveUserSignerWeb3Wallet**](docs/AdminAPI.md#removeusersignerweb3wallet) | **Delete** /users/{userID}/web3wallets/{wallet_address} | Remove user web3 wallet signer\n*AdminAPI* | [**SetUserSignerCloudWallet**](docs/AdminAPI.md#setusersignercloudwallet) | **Put** /users/{userID}/cloudwallets/{wallet_address} | Add or update user cloud wallet signer\n*AdminAPI* | [**SetUserSignerSafeAccount**](docs/AdminAPI.md#setusersignersafeaccount) | **Put** /users/{userID}/safeaccounts/{wallet_address} | Add or update user safe account signer\n*AdminAPI* | [**SetUserSignerWeb3Wallet**](docs/AdminAPI.md#setusersignerweb3wallet) | **Put** /users/{userID}/web3wallets/{wallet_address} | Add or update user web3 wallet signer\n*AdminAPI* | [**UpdateApiKey**](docs/AdminAPI.md#updateapikey) | **Put** /api_keys/{apiKeyID} | Update API key\n*ChainsAPI* | [**GetBlock**](docs/ChainsAPI.md#getblock) | **Get** /chains/ethereum/blocks/{block} | Get a block\n*ChainsAPI* | [**GetChainStatus**](docs/ChainsAPI.md#getchainstatus) | **Get** /chains/ethereum/status | Get chain status\n*ChainsAPI* | [**GetTransaction**](docs/ChainsAPI.md#gettransaction) | **Get** /chains/ethereum/transactions/{hash} | Get transaction\n*ChainsAPI* | [**GetTransactionRecei\n\n[... truncated ...]"
  },
  "Ratimon/redprint-forge": {
    "fetchedAt": "2025-11-12T22:56:16.553Z",
    "content": "<h1>Keep Optimistic and be OPStack deployer!! </h1>\n\n- [What is it for](#what-is-it-for)\n- [Quickstart](#quickstart)\n- [Contributing](#contributing)\n- [Acknowledgement](#acknowledgement)\n\n>[!NOTE]\n> You can find our alpha mvp and relevant examples [`here`](https://github.com/Ratimon/redprint-optimism-contracts-examples)\n\n>[!WARNING]\n> The code is not audited yet. Please use it carefully in production.\n\n\n## What Is It For\n\nOne of our Swiss army knife toolset: **redprint-forge** is a developer-friendly framework/library in solidity to modify & deploy OPStack ‚Äôs contracts in a modular style.\n\nThe features include:\n\n- Type-safe smart contract deployment\n\n- Re-usable  smart contract deployment and testing pipeline\n\n- Standardized framework, minimizing developer mistake and enhancing better security\n\n- All-Solidity-based so no context switching, no new scripting syntax in other languages\n\n- Tx Management via Safe Smart Contract Deploy Script\n\nTogether with [`Redprint Wizard UI`](https://github.com/Ratimon/redprint-wizard), which is a code generator/ interactive playground oriented for OPStack development, it does not only help novice developers to deploy OPStack's smart contracts to deploy on OP mainnet, but also help them to use generated deployment script in their own projects.\n\n\n## Quickstart\n### Quick Guide\n\n1.  Fork `optimism` 's monorepo:\n\n```bash\ngit clone --depth 1 --branch v1.9.4 https://github.com/ethereum-optimism/optimism.git\n``` \n\n>[!NOTE]\n> All OPStack's contracts are based on [`v1.9.4`](https://github.com/ethereum-optimism/optimism/tree/v1.9.4/packages/contracts-bedrock). So, you may just run:\n\n```bash\ngit clone https://github.com/ethereum-optimism/optimism.git\n``` \n\n2. Enter the working ditectory:\n\n```bash\ncd optimism/packages/contracts-bedrock\n``` \n\n3. Add the `redprint-forge` using your favorite package manager, e.g., with pnpm:\n\n```bash\npnpm init\n``` \n```bash\npnpm add redprint-forge\n``` \n```bash\npnpm install\n``` \n\n4. Modify OPStack 's [remapping](https://github.com/ethereum-optimism/optimism/blob/v1.9.4/packages/contracts-bedrock/foundry.toml) as following:\n\n```diff\n\n[profile.default]\n\n# Compilation settings\nsrc = 'src'\nout = 'forge-artifacts'\nscript = 'scripts'\noptimizer = true\noptimizer_runs = 999999\nremappings = [\n  '@openzeppelin/contracts-upgradeable/=lib/openzeppelin-contracts-upgradeable/contracts',\n  '@openzeppelin/contracts/=lib/openzeppelin-contracts/contracts',\n  '@openzeppelin/contracts-v5/=lib/openzeppelin-contracts-v5/contracts',\n  '@rari-capital/solmate/=lib/solmate',\n  '@lib-keccak/=lib/lib-keccak/contracts/lib',\n  '@solady/=lib/solady/src',\n  'forge-std/=lib/forge-std/src',\n  'ds-test/=lib/forge-std/lib/ds-test/src',\n  'safe-contracts/=lib/safe-contracts/contracts',\n  'kontrol-cheatcodes/=lib/kontrol-cheatcodes/src',\n  'gelato/=lib/automate/contracts'\n+ '@redprint-core/=src/',\n+ '@redprint-deploy/=node_modules/redprint-forge/script',\n+ '@scripts/=scripts/',\n+ '@redprint-test/=node_modules/redprint-forge/test/',\n+ '@redprint-forge-std/=lib/forge-std/src',\n+ '@redprint-openzeppelin/=lib/openzeppelin-contracts/contracts',\n+ '@redprint-openzeppelin-upgradeable/=lib/openzeppelin-contracts-upgradeable/contracts',\n+ '@redprint-safe-contracts/=lib/safe-contracts/contracts',\n+ '@redprint-lib-keccak/=lib/lib-keccak/contracts/lib',\n+ '@redprint-solady/=lib/solady/src',\n]\n...\n```\n\n>[!TIP]\n> We use @redprint-<yourLib>/ as a convention to avoid any naming conflicts with your previously installed libararies ( i.e. `@redprint-forge-std/` vs `@forge-std/`)\n\n\n5. Copy `.env` and modify as following.\n\n```sh\n\nRPC_URL_localhost=http://localhost:8545\n\n#secret management\nMNEMONIC=\"test test test test test test test test test test test junk\"\n# local network 's default private key so it is still not exposed\nDEPLOYER_PRIVATE_KEY=0x59c6995e998f97a5a0044966f0945389dc9e86dae88c7a8412f4603b6b78690d\nDEPLOYER_ADDRESS=0x70997970C51812dc3A010C7d01b50e0d17dc79C8\n\n# script/Config.sol\nDEPLOYMENT_OUTFILE=deployments/31337/.save.json\nDEPLOY_CONFIG_PATH=deploy-config/hardhat.json\nCHAIN_ID=\nIMPL_SALT=$(openssl rand -hex 32)\nSTATE_DUMP_PATH=\nSIG=\nDEPLOY_FILE=\nDRIPPIE_OWNER_PRIVATE_KEY=9000\n\n# deploy-Config\nGS_ADMIN_ADDRESS=0x70997970C51812dc3A010C7d01b50e0d17dc79C8\nGS_BATCHER_ADDRESS=0x70997970C51812dc3A010C7d01b50e0d17dc79C8\nGS_PROPOSER_ADDRESS=0x70997970C51812dc3A010C7d01b50e0d17dc79C8\nGS_SEQUENCER_ADDRESS=0x70997970C51812dc3A010C7d01b50e0d17dc79C8\nL1_RPC_URL=http://localhost:8545\n```\n\n6. Copy a set of deploy scripts example except [`/deployer`](./script/deployer/):\n\n```sh\nrsync -av --exclude='deployer/' node_modules/redprint-forge/script/ script/\n```\n\nAlternatively:\n```sh\ncp node_modules/redprint-forge/script/example/* script/\n```\n\nNow, copy a test suite:\n```sh\ncp node_modules/redprint-forge/test/DeployAll.t.sol test/\n```\n\n7. Compile and run test:\n\nThis will take a while to compile:\n```sh\nforge b\n```\n\nThen run a test command against a copied set of deploy scripts:\n```sh\nforge test -vvvv --match-path test/DeployAll.t.sol\n```\n\n>[!NOTE]\n>Behind the scene, the test suite works by replicating the same environment as production script, because it utilizes the same deployment logic script inside `setUp()` as following:\n\n```ts\n\n/** ... */\n\n// deployment logic\nimport {DeployAllScript} from \"@scripts/000_DeployAll.s.sol\";\n\ncontract DeployAll_Test is Test {\n\n    /** ... */\n\n    function setUp() external {\n\n         /** ... */\n\n        deployerProcedue = getDeployer();\n        deployerProcedue.setAutoBroadcast(false);\n\n        DeployAllScript allDeployments = new DeployAllScript();\n        allDeployments.run();\n\n        deployerProcedue.deactivatePrank();\n\n    }\n    /** ... */\n\n}\n```\n\n>[!NOTE]\n> You can chekout [this](https://github.com/Ratimon/redprint-forge/blob/main/script/example/000_DeployAll.s.sol)\n\n\n### Tx Management Via Safe-Multisig\n\nYou can write solidity script, then execute it from command-line in order to make any smart contract calls, or send transactions from your own safe multi-sig wallet.\n\nYou can access both [`_upgradeAndCallViaSafe`](https://github.com/Ratimon/redprint-forge/blob/main/script/safe-management/SafeScript.sol#L27) and [`_callViaSafe`](https://github.com/Ratimon/redprint-forge/blob/main/script/safe-management/SafeScript.sol#L23) easily by inheriting and using from  in `redprint-forge` module ‚Äôs parent contract [`SafeScript`](https://github.com/Ratimon/redprint-forge/blob/main/script/safe-management/SafeScript.sol).\n \n#### Call and Upgrade Proxy Contract\n\nLet‚Äôs see a practical example when initializing one of OPStack's proxy contract ( eg. [`ProtocolVersions`](https://github.com/Ratimon/redprint-forge/blob/main/src/L1/ProtocolVersions.sol) ) by calling [`_upgradeAndCallViaSafe`](https://github.com/Ratimon/redprint-forge/blob/main/script/safe-management/SafeScript.sol#L27C1-L28C1):\n\n```ts\n\n/** ... */\n\n// `redprint-forge` 's core engine\nimport { SafeScript} from \"@redprint-deploy/safe-management/SafeScript.sol\";\n\n/** ... */\n\ncontract DeployAndInitializeProtocolVersionsScript is DeployScript, SafeScript {\n\n    /** ... */\n\n    function initializeProtocolVersions() public {\n      console.log(\"Upgrading and initializing ProtocolVersions proxy\");\n\n      /** ... */\n\n      address proxyAdmin = deployer.mustGetAddress(\"ProxyAdmin\");\n      address safe = deployer.mustGetAddress(\"SystemOwnerSafe\");\n\n      /** ... */\n\n      _upgradeAndCallViaSafe({\n          _proxyAdmin: proxyAdmin,\n          _safe: safe,\n          _owner: owner,\n          _proxy: payable(protocolVersionsProxy),\n          _implementation: protocolVersions,\n          _innerCallData: abi.encodeCall(\n              ProtocolVersions.initialize,\n              (\n                  finalSystemOwner,\n                  ProtocolVersion.wrap(requiredProtocolVersion),\n                  ProtocolVersion.wrap(recommendedProtocolVersion)\n              )\n          )\n      });\n      /** ... */\n    }\n\n}\n\n```\n\n>[!NOTE]\n> You can the see full example here: [`03B_DeployAndInitializeProtocolVersions.s.sol`](htt\n\n[... truncated ...]"
  },
  "Ratimon/redprint-wizard": {
    "fetchedAt": "2025-11-12T22:56:17.097Z",
    "content": "<h1>Keep Optimistic and be OPStack deployer!! </h1>\n\n- [Installation](#installation)\n- [What is it for](#what-is-it-for)\n- [Architecture](#architecture)\n- [Metric Definitions](#metrics)\n- [Contributing](#contributing)\n- [Acknowledgement](#acknowledgement)\n\n>[!NOTE]\n> You can find our relevant examples [`here`](https://github.com/Ratimon/redprint-optimism-contracts-examples). Geneated contract code from the Redprint Wizard is stored here due to documentation and testing purpose.\n\n## Installation\n\n### with npm\n\nWe assume that you already setup your own working front-end environment and `cd` into it\n\n```bash\ncd my-project;\nnvm use v22.14.0\n``` \n\nAdd the `redprint-wizard` using your favorite package manager, e.g., with pnpm:\n\n```sh\nnpm add -D redprint-wizard\n```\n\nAlternatively, you can fork a project and installed dependencies with `pnpm install` (or `yarn`), then start a development server:\n\n```bash\ngit clone git@github.com:Ratimon/redprint-wizard.git\ncd redprint-wizard;\npnpm dev\n```\n\n## What Is It For\n\nOne of our Swiss army knife toolset: **Redprint Wizard UI**. It is a code generator/ interactive developer playground. It supports a space to experience, innovate and build features that either lie far along ether Optimism or Ethereum 's roadmaps which aren't yet available on the production at all, empowering developers to dream, tinker, and push the boundaries of what's possible by composing their own different OPStack components together.\n\nTogether with [`redprint-forge`](https://github.com/Ratimon/redprint-forge), it does not only help novice developers to deploy OPStack's smart contracts to deploy on OP mainnet, but also help them to use generated deployment script in their own projects.\n\n## Architecture\n\n```sh\n‚îú‚îÄ‚îÄ src\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lib\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ analytics            # Google Analytics \n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model                # Front-end Data Model\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ui                   # UI Compoment\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ utils\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ wizard               # code generation logic.\n‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ deploy-scripts\n‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ shared\n‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ smart-contracts\n‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ utils\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ routes                    # the UIinterface (Svelte routes)\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 1-governance\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 2-superchain\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 3-alt-da\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 4-opchain-proxies\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ 4-opchain-implementations\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ about\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ blog\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ privacy-policy\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ tos\n‚îî‚îÄ‚îÄ static                        # Static files\n    ‚îú‚îÄ‚îÄ blog\n    ‚îî‚îÄ‚îÄ pwa\n```\n\n#metrics\n\n1. **Active Users** or **Number of (Monthly/Yearly) Visitor**: a unique person who engaged with your website or app within a given time frame\n\nThis figure can be represented by GA's `page_view` events, and these events can be grouped into different OPStack components. They are :\n\n- `Set up Governance Layer | Redprint Wizard` page\n- `Set up Super Chain | Redprint Wizard` page\n- `Set up OpAltDA Chain | Redprint Wizard` page\n- `Set up OP Chain | Redprint Wizard` page\n\n>[!NOTE]\n> These figures can be checked in [reports/](https://github.com/Ratimon/redprint-wizard/tree/main/reports/) directory.\n\n2. **Number of Link Clicks Toward the Code copy button** : the number of developers who come to experiment our interactive turorial. It shows **usability** of our tool to **modify** OPStack components.\n\n3. **Number of Downloaded code as zip file** : the number of developers who use our generated contract. It suggests **usability** of our tool to **deploy** OPStack components.\n\nThese figures can be represented by GA's  custoizrd events. They are :\n- `copy-contract-Safe`\n- `copy-contract-Governor`\n- `copy-script-Safe`\n- `copy-script-Governor`\n\n>[!NOTE]\n> All events'names can be found in in [lib/analytics/analytics.Store.ts](https://github.com/Ratimon/redprint-wizard/blob/main/src/lib/analytics/analytics.Store.ts#L5).\n\n>[!NOTE]\n> The convention is : `<event_name>`-`<contract_kind>`-`<contract_name>`\n\n> `<event_name>` could be either `copy` or `downloadd`\n> `<contract_kind>` could be either `contract` or `script`\n\n4. **Number of visitors to our articles in our blog** : The number of views on our blog/turorial. It indicates **accessibility** of The OPStack tool.\n\n\nThis metric can be represented by GA's  events which are named by blog title For instance, they are :\n\n- `Introducing Redprint Wizard` [page](https://redprint.ninja/blog/1-introduce-forge)\n- `Introducing redprint-forge\t` [page](https://redprint.ninja/blog/2-introduce-wizard)\n\n>[!NOTE]\n> These figures can be checked in [reports/](https://github.com/Ratimon/redprint-wizard/tree/main/reports/) directory.\n\n\n5. **Version Releases**: The software features releases of `Ratimon/redprint-wizard` and `Ratimon/redprint-forge`.\n\nGiven a version number `MAJOR.MINOR.PATCH`, the definition is:\n\n- MAJOR version for making incompatible changes\n- MINOR version for adding functionality in a backwards-compatible manner\n- PATCH version for making backwards-compatible bug fixes\n\n>[!NOTE]\n> The released versions can be checked as following:\n\n> [github link](https://github.com/Ratimon/redprint-wizard/releases). (for redprint-wizard)\n> [github link](https://github.com/Ratimon/redprint-forge/releases). (for redprint-forge)\n\n6. **Number of repo stars**: The number of stars on the github repositories for `Ratimon/redprint-wizard` and `Ratimon/redprint-forge`.\n\n- [redprint-wizard's Repo Link](https://github.com/Ratimon/redprint-wizard)\n- [redprint-forge's Repo Link](https://github.com/Ratimon/redprint-forge)\n\n7. **Number of repo forks**: The number of forks on the github repositories for `Ratimon/redprint-wizard` and `Ratimon/redprint-forge`.\n\n- [redprint-wizard's Repo Link](https://github.com/Ratimon/redprint-wizard)\n- [redprint-forge's Repo Link](https://github.com/Ratimon/redprint-forge)\n\n8. **Number of npm packages downloaded**: The number of downloads of `redprint-wizard` and `redprint-forge` on npm.\n\n- [redprint-wizard's Package Link](https://www.npmjs.com/package/redprint-wizard)\n- [redprint-forge's Package Link](https://www.npmjs.com/package/redprint-forge)\n\n\n## Contributing\n\nSee our [`contributing guidelines`](./CONTRIBUTING.md).\n\nIf you want to say **thank you** or/and support active development of Redprint Wizard:\n\n- Add a [GitHub Star](https://github.com/Ratimon/redprint-wizard) to the\n  project.\n- Tweet about [Redprint](https://redprint.ninja/blog/2-introduce-wizard)\n- Write interesting articles about the project on\n  [Medium](https://medium.com/), or your personal blog.\n- Keep Optimimstic !!\n\n## Acknowledgement\n\nThis project would not have been possible to build without the advanced iniatiative from opensource software including  [contracts-wizard](https://github.com/OpenZeppelin/contracts-wizard), so we are deeply thankful for their contributions in our web3 ecosystem.\n\nIf we‚Äôve overlooked anyone, please open an issue so we can correct it. While we always aim to acknowledge the inspirations and code we utilize, mistakes can happen in a team setting, and a reference might unintentionally be missed."
  },
  "Nodeguardians/optimism": {
    "fetchedAt": "2025-11-12T22:56:29.141Z",
    "content": "# Optimism\n\nThis repository holds the content of the Node Guardians [Playing With OP Stack](https://nodeguardians.io/campaigns/playing-op-stack) campaign.\n\n| Quest                    | Skill      | Type             | Rarity    |\n| ------------------------ | ---------- | ---------------- | --------- |\n| Introduction to OP stack | Ecosystems | Theory           | Legendary |\n| Cross Layer Secrets      | Ecosystems | Capture the Flag | Legendary |\n| Custom OP Rollup         | Ecosystems | Capture the Flag | Legendary |\n\n## Learning Outcome\n\nUsers will learn about the OP stack, with both theory content and hands on hacking.\n\n## Directory\n\n[Campaign Description](./description.md) (Start here)\n\n** Introduction to OP Stack **\n\nIn this quest, we explore the different components of the OP stack.\n\n1. [Part 1](./introduction-to-op-stack/introduction-to-op-stack.md)\n\n** Cross Layer Messaging **\n\nIn this quest, we dive into cross layer communication to open a series of locks.\n\n1. [Prelude](./cross-layer-messaging/description/prelude.md)\n2. [Part 1](./cross-layer-messaging/description/part1.md)\n3. [Postlude](./cross-layer-messaging/description/postlude.md)\n4. [Summary](./cross-layer-messaging/description/summary.md)\n\n** Custom OP Rollup **\n\nIn this quest, we explore the OP Stack and deploy a custom OP rollup based on Sepolia.\n\n1. [Prelude](./custom-op-rollup/description/prelude.md)\n2. [Part 1](./custom-op-rollup/description/part1.md)\n3. [Part 2](./custom-op-rollup/description/part2.md)\n4. [Postlude](./custom-op-rollup/description/postlude.md)\n5. [Summary](./custom-op-rollup/description/summary.md)\n"
  },
  "ethereum/solc-js": {
    "fetchedAt": "2025-11-12T22:56:36.821Z",
    "content": "[![CircleCI](https://img.shields.io/circleci/project/github/ethereum/solc-js/master.svg?style=flat-square)](https://circleci.com/gh/ethereum/solc-js/tree/master)\n[![Coverage Status](https://img.shields.io/coveralls/ethereum/solc-js.svg?style=flat-square)](https://coveralls.io/r/ethereum/solc-js)\n\n# solc-js\n\nJavaScript bindings for the [Solidity compiler](https://github.com/ethereum/solidity).\n\nUses the Emscripten compiled Solidity found in the [solc-bin repository](https://github.com/ethereum/solc-bin).\n\n## Node.js Usage\n\nTo use the latest stable version of the Solidity compiler via Node.js you can install it via npm:\n\n```bash\nnpm install solc\n```\n\n### Usage on the Command-Line\n\nIf this package is installed globally (`npm install -g solc`), a command-line tool called `solcjs` will be available.\n\nTo see all the supported features, execute:\n\n```bash\nsolcjs --help\n```\n\nTo compile a contract that imports other contracts via relative paths:\n```bash\nsolcjs --bin --include-path node_modules/ --base-path . MainContract.sol\n```\nUse the ``--base-path`` and ``--include-path`` options to describe the layout of your project.\n``--base-path`` represents the root of your own source tree while ``--include-path`` allows you to\nspecify extra locations containing external code (e.g. libraries installed with a package manager).\n\nNote: ensure that all the files you specify on the command line are located inside the base path or\none of the include paths.\nThe compiler refers to files from outside of these directories using absolute paths.\nHaving absolute paths in contract metadata will result in your bytecode being reproducible only\nwhen it's placed in these exact absolute locations.\n\nNote: this commandline interface is not compatible with `solc` provided by the Solidity compiler package and thus cannot be\nused in combination with an Ethereum client via the `eth.compile.solidity()` RPC method. Please refer to the\n[Solidity compiler documentation](https://solidity.readthedocs.io/) for instructions to install `solc`.\nFurthermore, the commandline interface to solc-js provides fewer features than the binary release.\n\n### Usage in Projects\n\nThere are two ways to use `solc`:\n\n1. Through a high-level API giving a uniform interface to all compiler versions\n2. Through a low-level API giving access to all the compiler interfaces, which depend on the version of the compiler\n\n#### High-level API\n\nThe high-level API consists of a single method, `compile`, which expects the [Compiler Standard Input and Output JSON](https://solidity.readthedocs.io/en/v0.5.0/using-the-compiler.html#compiler-input-and-output-json-description).\n\nIt also accepts an optional set of callback functions, which include the ``import`` and the ``smtSolver`` callbacks.\nStarting 0.6.0 it only accepts an object in place of the callback to supply the callbacks.\n\nThe ``import`` callback function is used to resolve unmet dependencies.\nThis callback receives a path and must synchronously return either an error or the content of the dependency\nas a string.  It cannot be used together with callback-based, asynchronous,\nfilesystem access. A workaround is to collect the names of dependencies, return\nan error, and keep re-running the compiler until all of them are resolved.\n\n#### Example usage without the import callback\n\nExample:\n\n```javascript\nvar solc = require('solc');\n\nvar input = {\n  language: 'Solidity',\n  sources: {\n    'test.sol': {\n      content: 'contract C { function f() public { } }'\n    }\n  },\n  settings: {\n    outputSelection: {\n      '*': {\n        '*': ['*']\n      }\n    }\n  }\n};\n\nvar output = JSON.parse(solc.compile(JSON.stringify(input)));\n\n// `output` here contains the JSON output as specified in the documentation\nfor (var contractName in output.contracts['test.sol']) {\n  console.log(\n    contractName +\n      ': ' +\n      output.contracts['test.sol'][contractName].evm.bytecode.object\n  );\n}\n```\n\n#### Example usage with import callback\n\n```javascript\nvar solc = require('solc');\n\nvar input = {\n  language: 'Solidity',\n  sources: {\n    'test.sol': {\n      content: 'import \"lib.sol\"; contract C { function f() public { L.f(); } }'\n    }\n  },\n  settings: {\n    outputSelection: {\n      '*': {\n        '*': ['*']\n      }\n    }\n  }\n};\n\nfunction findImports(path) {\n  if (path === 'lib.sol')\n    return {\n      contents:\n        'library L { function f() internal returns (uint) { return 7; } }'\n    };\n  else return { error: 'File not found' };\n}\n\n// New syntax (supported from 0.5.12, mandatory from 0.6.0)\nvar output = JSON.parse(\n  solc.compile(JSON.stringify(input), { import: findImports })\n);\n\n// `output` here contains the JSON output as specified in the documentation\nfor (var contractName in output.contracts['test.sol']) {\n  console.log(\n    contractName +\n      ': ' +\n      output.contracts['test.sol'][contractName].evm.bytecode.object\n  );\n}\n```\n\nSince version 0.5.1, the ``smtSolver`` callback function is used to solve SMT queries generated by\nSolidity's SMTChecker.  If you have an SMT solver installed locally, it can\nbe used to solve the given queries, where the callback must synchronously\nreturn either an error or the result from the solver.  A default\n``smtSolver`` callback is included in this package via the module\n``smtchecker.js`` which exports the ``smtCallback`` function that takes 1) a\nfunction that takes queries and returns the solving result, and 2) a solver\nconfiguration object. The module ``smtsolver.js`` has a few predefined solver\nconfigurations, and relies on Z3, Eldarica or cvc5 being installed locally.  It\nexports the list of locally found solvers and a function that invokes a given\nsolver.\n\nThe API of the SMT callback is **experimental** and can change at any time.\nThe last change was in version 0.8.11.\n\n#### Example usage with smtSolver callback\n\n```javascript\nvar solc = require('solc');\nconst smtchecker = require('solc/smtchecker');\nconst smtsolver = require('solc/smtsolver');\n// Note that this example only works via node and not in the browser.\n\nvar input = {\n  language: 'Solidity',\n  sources: {\n    'test.sol': {\n      content: 'contract C { function f(uint x) public { assert(x > 0); } }'\n    }\n  },\n  settings: {\n    modelChecker: {\n      engine: \"chc\",\n      solvers: [ \"smtlib2\" ]\n    }\n  }\n};\n\nvar output = JSON.parse(\n  solc.compile(\n    JSON.stringify(input),\n    { smtSolver: smtchecker.smtCallback(smtsolver.smtSolver, smtsolver.availableSolvers[0]) }\n  )\n);\n\n```\nThe assertion is clearly false, and an ``assertion failure`` warning\nshould be returned, together with a counterexample.\n\n#### Low-level API\n\nThe low-level API is as follows:\n\n- `solc.lowlevel.compileSingle`: the original entry point, supports only a single file\n- `solc.lowlevel.compileMulti`: this supports multiple files, introduced in 0.1.6\n- `solc.lowlevel.compileCallback`: this supports callbacks, introduced in 0.2.1\n- `solc.lowlevel.compileStandard`: this works just like `compile` above, but is only present in compilers after (and including) 0.4.11\n\nFor examples how to use them, please refer to the README of the above mentioned solc-js releases.\n\n**Note**: These low-level functions remain available for compatibility reasons.\nHowever, they were superseded by the `compile()` function and are no longer required.\nStarting from version `0.5.0+commit.1d4f565a`, the functions `compileSingle`, `compileMulti`, and `compileCallback` are always `null` when using newer solc binary versions.\nIt is recommended to use the latest release of solc-js, but it should also handle all the older solc binaries down to `0.1.x`.\n\n### Using with Electron\n\n**Note:**\nIf you are using Electron, `nodeIntegration` is on for `BrowserWindow` by default. If it is on, Electron will provide a `require` method which will not behave as expected and this may cause calls, such as `require('solc')`, to fail.\n\nTo turn off `nodeIntegration`, use the following:\n\n```javascript\nnew BrowserWindow({\n  webPreferences: {\n    nodeIntegration: false\n  }\n});\n```\n\n### Using a Legac\n\n[... truncated ...]"
  },
  "ethereum/solidity": {
    "fetchedAt": "2025-11-12T22:56:37.427Z",
    "content": "# The Solidity Contract-Oriented Programming Language\n\n[![Matrix Chat](https://img.shields.io/badge/Matrix%20-chat-brightgreen?style=plastic&logo=matrix)](https://matrix.to/#/#ethereum_solidity:gitter.im)\n[![Gitter Chat](https://img.shields.io/badge/Gitter%20-chat-brightgreen?style=plastic&logo=gitter)](https://gitter.im/ethereum/solidity)\n[![Solidity¬†Forum](https://img.shields.io/badge/Solidity_Forum%20-discuss-brightgreen?style=plastic&logo=discourse)](https://forum.soliditylang.org/)\n[![X Follow](https://img.shields.io/twitter/follow/solidity_lang?style=plastic&logo=x)](https://X.com/solidity_lang)\n[![Mastodon Follow](https://img.shields.io/mastodon/follow/000335908?domain=https%3A%2F%2Ffosstodon.org%2F&logo=mastodon&style=plastic)](https://fosstodon.org/@solidity)\n\nYou can talk to us on Gitter and Matrix, tweet at us on X (previously Twitter) or create a new topic in the Solidity forum. Questions, feedback, and suggestions are welcome!\n\nSolidity is a statically-typed, contract-oriented, high-level language for implementing smart contracts on the Ethereum platform.\n\nFor a good overview and starting point, please check out the official [Solidity Language Portal](https://soliditylang.org).\n\n## Table of Contents\n\n- [Background](#background)\n- [Build and Install](#build-and-install)\n- [Example](#example)\n- [Documentation](#documentation)\n- [Development](#development)\n- [Maintainers](#maintainers)\n- [License](#license)\n- [Security](#security)\n\n## Background\n\nSolidity is a statically-typed curly-braces programming language designed for developing smart contracts\nthat run on the Ethereum Virtual Machine. Smart contracts are programs that are executed inside a peer-to-peer\nnetwork where nobody has special authority over the execution, and thus they allow anyone to implement tokens of value,\nownership, voting, and other kinds of logic.\n\nWhen deploying contracts, you should use the latest released version of\nSolidity. This is because breaking changes, as well as new features and bug fixes, are\nintroduced regularly. We currently use a 0.x version\nnumber [to indicate this fast pace of change](https://semver.org/#spec-item-4).\n\n## Build and Install\n\nInstructions about how to build and install the Solidity compiler can be\nfound in the [Solidity documentation](https://docs.soliditylang.org/en/latest/installing-solidity.html#building-from-source).\n\n\n## Example\n\nA \"Hello World\" program in Solidity is of even less use than in other languages, but still:\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity >=0.6.0 <0.9.0;\n\ncontract HelloWorld {\n    function helloWorld() external pure returns (string memory) {\n        return \"Hello, World!\";\n    }\n}\n```\n\nTo get started with Solidity, you can use [Remix](https://remix.ethereum.org/), which is a\nbrowser-based IDE. Here are some example contracts:\n\n1. [Voting](https://docs.soliditylang.org/en/latest/solidity-by-example.html#voting)\n2. [Blind Auction](https://docs.soliditylang.org/en/latest/solidity-by-example.html#blind-auction)\n3. [Safe remote purchase](https://docs.soliditylang.org/en/latest/solidity-by-example.html#safe-remote-purchase)\n4. [Micropayment Channel](https://docs.soliditylang.org/en/latest/solidity-by-example.html#micropayment-channel)\n\n## Documentation\n\nThe Solidity documentation is hosted using [Read the Docs](https://docs.soliditylang.org).\n\n## Development\n\nSolidity is still under development. Contributions are always welcome!\nPlease follow the\n[Developer's Guide](https://docs.soliditylang.org/en/latest/contributing.html)\nif you want to help.\n\nYou can find our current feature and bug priorities for forthcoming\nreleases in the [projects section](https://github.com/argotorg/solidity/projects).\n\n## Maintainers\nThe Solidity programming language and compiler are open-source community projects governed by a core team.\nThe core team is sponsored by the [Ethereum Foundation](https://ethereum.foundation/).\n\n## License\nSolidity is licensed under [GNU General Public License v3.0](LICENSE.txt).\n\nSome third-party code has its [own licensing terms](cmake/templates/license.h.in).\n\n## Security\n\nThe security policy may be [found here](SECURITY.md).\n"
  },
  "darrylyeo/blockhead": {
    "fetchedAt": "2025-11-12T22:56:45.425Z",
    "content": "<div align=\"center\">\n\n# B‚Éû Blockhead\n\n**Track/visualize/explore ALL of crypto/DeFi/web3  \nin ONE informative, customizable, user-friendly interface!**\n\n**[Website](https://blockhead.info)**„Éª**[GitHub](https://github.com/darrylyeo/blockhead)**„Éª**[Twitter](https://twitter.com/0xBlockhead)**\n\n<sup>by **[Darryl Yeo](https://darryl-yeo.com/blockhead)**„Éª2020 ‚Äì 2024</sup>\n\n</div>\n\n---\n\n[**Blockhead**](https://blockhead.info) is an all-in-one browser for **Ethereum**, **EVM-based blockchains**, **web3 protocols**, and their collective ecosystem of **DeFi apps**, **digital organizations** and **internet experiences**.\n\nIt features a [**crypto/DeFi/NFT portfolio tracker**](https://blockhead.info/portfolio); a [**cross-EVM block explorer**](https://blockhead.info/explorer); [**dynamic interfaces** and **explorers**](https://blockhead.info/apps) for **smart contracts**, **DeFi protocols** and **web3 apps**; and **comprehensive data controls** that let YOU decide the infrastructure powering the interface.\n\nBlockhead **pushes the limits of web3-native UX** by embracing the multi-faceted **architectural trade-offs** at each layer of the web3 stack, synthesizing them into a **unified interface** that is **informative**, **concise**, **transparent** and **adaptive** toward many use cases.\n\nWith a **local-first**, **dynamic**, **data-agnostic** design, Blockhead is the ideal place to **track**, **visualize** and **explore** the **decentralized world wide web**!\n\n---\n\n‚ÄÇ\n\n<div align=\"center\">\n\n### üîé‚ÄÇ**TRACK YOUR ASSETS**\nKeep tabs on your **blockchain accounts**, **web3 identities** and **crypto net worth**  \nwith **token balances**, **DeFi balances**, **NFT collections** and **activity feeds** displayed on a **single page**.  \n‚ÄÇ\n\n### üìä‚ÄÇ**VISUALIZE YOUR ACTIVITY**\nSee transactions, smart contract interactions and web3 data **in context** with a **multi-chain block explorer**,  \n**intuitive visualizations**, **human-friendly metadata**, and **seamless navigation**.  \n‚ÄÇ\n\n### üî≠‚ÄÇ**EXPLORE THE METAVERSE**\nDiscover **apps**, **services** and **communities** using **decentralized internet infrastructure**  \nto **deploy** capital, **coordinate** action, **inform** with data, and create **web3-native digital experiences**.  \n‚ÄÇ\n\n### üß©‚ÄÇ**UNSTOPPABLE WEB3 TECH**\nBuilt on a **transparent**, **composable**, **verifiable** foundation of **math**, **cryptography**, **open protocols**,  \n**incentive-aligned computer networks**, **account abstractions** and **user-owned data**.  \n‚ÄÇ\n\n### üéõÔ∏è‚ÄÇ**YOU CONTROL THE DATA**\nThere's no central backend ‚Äî **you choose which data sources power the user interface!**  \nOptimize for **speed**, **reliability**, **privacy** and/or **decentralization** without compromises.  \n> <sup>Choose from **30+ data providers** including Airstack, Alchemy, Chainbase, Chainlink, Cloudflare, Covalent, Decommas, ENS, Etherscan, Figment, Gateway.fm, GetBlock, \nThe Graph, IPFS, Infura, Lens, Liquality, LlamaNodes, Mod Protocol, Moralis, Nexandria, Neynar, NFTPort, Pinata, Pocket Network, Push, QuickNode, Sourcify, Tenderly, Zapper, Zerion and more!</sup>\n\n\n### üåê‚ÄÇ**TO ETHEREUM & BEYOND!**\nSupporting [**Ethereum**](https://blockhead.info/explorer/ethereum) + **layer-2s** ([Polygon PoS](https://blockhead.info/explorer/polygon), [Gnosis Chain](https://blockhead.info/explorer/chain), [Arbitrum](https://blockhead.info/explorer/arbitrum-one), [Optimism](https://blockhead.info/explorer/optimism),  \n**EVM-based chains** ([Aurora](https://blockhead.info/explorer/aurora), [Avalanche](https://blockhead.info/explorer/avalanche), [BNB Smart Chain](https://blockhead.info/explorer/bsc), [Celo](https://blockhead.info/explorer/celo), [Cronos](https://blockhead.info/explorer/cronos), [Evmos](https://blockhead.info/explorer/evmos), [Fantom](https://blockhead.info/explorer/fantom)),  \nand many more **blockchain networks** and **web3-native ecosystems** to come!\n\n</div>\n\n‚ÄÇ\n\n---\n\n‚ÄÇ\n\n# üÖ± Features/Integrations\n\n### üßÆ [**Portfolio**](https://blockhead.info/portfolio):\n* **Portfolio**: create groups of Ethereum/EVM-based blockchain accounts to see associated token balances, DeFi balances and NFTs across the selected Ethereum and EVM-compatible chains and estimate their crypto net worth.\n  * **Add Account**: enter a raw wallet address (`0xabcd...6789`), ENS name (e.g. `vitalik.eth`) or Lens handle (e.g. `stani.lens`), along with one or more supported EVM-based networks.\n* **Account**:\n  * **Balances**: sort assets alphabetically or numerically, and optionally hide small/irrelevant balances.\n  * **DeFi**: view DeFi balances grouped by DeFi protocol (red-colored numbers denote debt/borrowed assets). Optionally show underlying assets backing vaults, liquidity pools, or index tokens.\n  * **NFTs**: browse non-fungible tokens and their associated images, grouped by collection (contract). Optionally show their on-chain or off-chain metadata/attributes.\n  * **Feed**: optionally show a live activity feed for supported web3 apps.\n* **Explore**: Click any address, DeFi app, NFT contract name, ENS name or Lens handle to show more details in [Explorer](https://blockhead.info/explorer) or [Apps](https://blockhead.info/apps).\n* **Data transparency**:\n  * All data is sourced though data providers defined in Preferences and tagged with corresponding labels and icons throughout the interface.\n  * Preferences and portfolio data are saved/cached within your browser's local storage.\n\n### üß≠ [**Explorer**](https://blockhead.info/explorer):\n* Explore **blocks** and **transactions** across several **EVM-based blockchain networks**: [Ethereum](https://blockhead.info/explorer/ethereum), [Polygon](https://blockhead.info/explorer/polygon), [Gnosis Chain](https://blockhead.info/explorer/chain), [Arbitrum](https://blockhead.info/explorer/arbitrum-one), [Optimism](https://blockhead.info/explorer/optimism), [Aurora](https://blockhead.info/explorer/aurora), [Avalanche](https://blockhead.info/explorer/avalanche), [BNB Smart Chain](https://blockhead.info/explorer/bsc), [Celo](https://blockhead.info/explorer/celo), [Cronos](https://blockhead.info/explorer/cronos), [Evmos](https://blockhead.info/explorer/evmos), [Fantom](https://blockhead.info/explorer/fantom) and [more](https://blockhead.info/explorer)!\n* **Network overview**: monitor statistics for a given network including the current block height and the native currency's current/historical price.\n* Look up a **transaction ID**, **block number**, or **address** (`0xabcd...6789`, **ENS name** or **Lens handle**) by typing in the search field or via URL (`blockhead.info/explorer/{networkName}/{query}`).\n  * The search field query is preserved when switching chains so you can easily look up details for the same address across multiple chains.\n* **Address** (externally-owned accounts or smart contracts):\n  * **Balances**: native/ERC-20 token balances associated with the address. Click a token to filter for transactions involving that token.\n  * **Smart contracts**: browse verified smart contract code from Sourcify (IPFS).\n* **Block** (by block number):\n  * Look up consensus metadata and associated transactions.\n  * Cross-reference blocks produced around the same time on other chains.\n* **Transactions** (by transaction hash):\n  * Browse transactions in three levels of detail:\n    * **Summary**: just the primary action and/or native currency transfers, based on context.\n    * **Detailed**: includes just the smart contract event logs directly involving the address, based on context.\n    * **Exhaustive**: includes all transaction fees and smart contract event logs.\n* **Data transparency**:\n  * All data is sourced though data providers defined in Preferences and tagged with corresponding labels and icons throughout the interface.\n\n### üì± [**Apps**](https://blockhead.info/apps):\n* **Dynamic interfaces** and **data explorers** for popular **dapps** and **web3 infrastructure** projects:\n  * [**ENS**](https://blockhead.info/apps/ens): browse registration details and records associated w\n\n[... truncated ...]"
  },
  "libp2p/rust-libp2p": {
    "fetchedAt": "2025-11-12T22:56:53.569Z",
    "content": "# Central repository for work on libp2p\n\n<a href=\"http://libp2p.io/\"><img src=\"https://img.shields.io/badge/project-libp2p-yellow.svg?style=flat-square\" /></a>\n[![dependency status](https://deps.rs/repo/github/libp2p/rust-libp2p/status.svg?style=flat-square)](https://deps.rs/repo/github/libp2p/rust-libp2p)\n[![Crates.io](https://img.shields.io/crates/v/libp2p.svg)](https://crates.io/crates/libp2p)\n[![docs.rs](https://img.shields.io/badge/api-rustdoc-blue.svg)](https://docs.rs/libp2p)\n[![docs.rs master](https://img.shields.io/badge/docs-master-blueviolet)](https://libp2p.github.io/rust-libp2p/libp2p/)\n\nThis repository is the central place for Rust development of the [libp2p](https://libp2p.io) spec.\n\n## Getting started\n\n- **Main documentation** can be found on https://docs.rs/libp2p.\n\n- The **[examples](examples)** folder contains small binaries showcasing the\n  many protocols in this repository.\n\n- For **security related issues** please [file a private security vulnerability\n  report](https://github.com/libp2p/rust-libp2p/security/advisories/new) . Please do not file a\n  public issue on GitHub.\n\n- To **report bugs, suggest improvements or request new features** please open a\n  GitHub issue on this repository.\n\n- For **rust-libp2p specific questions** please use the GitHub _Discussions_\n  forum https://github.com/libp2p/rust-libp2p/discussions.\n\n- For **discussions and questions related to multiple libp2p implementations**\n  please use the libp2p _Discourse_ forum https://discuss.libp2p.io.\n\n- For synchronous discussions join the [open rust-libp2p maintainer\n  calls](https://github.com/libp2p/rust-libp2p/discussions?discussions_q=open+maintainers+call+)\n  or the [biweekly libp2p community calls](https://discuss.libp2p.io/t/libp2p-community-calls/1157).\n\n## Repository Structure\n\nThe main components of this repository are structured as follows:\n\n  * `core/`: The implementation of `libp2p-core` with its `Transport` and\n    `StreamMuxer` API on which almost all other crates depend.\n\n  * `transports/`: Implementations of transport protocols (e.g. TCP) and protocol upgrades\n    (e.g. for authenticated encryption, compression, ...) based on the `libp2p-core` `Transport`\n    API.\n\n  * `muxers/`: Implementations of the `StreamMuxer` interface of `libp2p-core`,\n    e.g. (sub)stream multiplexing protocols on top of (typically TCP) connections.\n    Multiplexing protocols are (mandatory) `Transport` upgrades.\n\n  * `swarm/`: The implementation of `libp2p-swarm` building on `libp2p-core`\n    with the central interfaces `NetworkBehaviour` and `ConnectionHandler` used\n    to implement application protocols (see `protocols/`).\n\n  * `protocols/`: Implementations of application protocols based on the\n    `libp2p-swarm` APIs.\n\n  * `misc/`: Utility libraries.\n\n  * `libp2p/examples/`: Worked examples of built-in application protocols (see `protocols/`)\n    with common `Transport` configurations.\n\n## Community Guidelines\n\nThe libp2p project operates under the [IPFS Code of\nConduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).\n\n> tl;dr\n>\n> - Be respectful.\n> - We're here to help: abuse@ipfs.io\n> - Abusive behavior is never tolerated.\n> - Violations of this code may result in swift and permanent expulsion from the\n>   IPFS [and libp2p] community.\n> - \"Too long, didn't read\" is not a valid excuse for not knowing what is in\n>   this document.\n\n## Maintainers\n\n(In alphabetical order.)\n\n- Jo√£o Oliveira ([@jxs](https://github.com/jxs))\n\n## Notable users\n\n(open a pull request if you want your project to be added here)\n\n- [COMIT](https://github.com/comit-network/xmr-btc-swap) - Bitcoin‚ÄìMonero Cross-chain Atomic Swap.\n- [Forest](https://github.com/ChainSafe/forest) - An implementation of Filecoin written in Rust.\n- [fuel-core](https://github.com/FuelLabs/fuel-core) - A Rust implementation of the Fuel protocol.\n- [HotShot](https://github.com/EspressoSystems/HotShot) - Decentralized sequencer in Rust developed by [Espresso Systems](https://www.espressosys.com/).\n- [ipfs-embed](https://github.com/ipfs-rust/ipfs-embed) - A small embeddable ipfs implementation used and maintained by [Actyx](https://www.actyx.com).\n- [Homestar](https://github.com/ipvm-wg/homestar) - An InterPlanetary Virtual Machine (IPVM) implementation used and maintained by Fission.\n- [beetle](https://github.com/n0-computer/beetle) - Next-generation implementation of IPFS for Cloud & Mobile platforms.\n- [Lighthouse](https://github.com/sigp/lighthouse) - Ethereum consensus client in Rust.\n- [Locutus](https://github.com/freenet/locutus) - Global, observable, decentralized key-value store.\n- [OpenMina](https://github.com/openmina/openmina) - In-browser Mina Rust implementation.\n- [qaul ŸÇŸàŸÑ](https://github.com/qaul/qaul.net) - Internet Independent Wireless Mesh Communication App\n- [rust-ipfs](https://github.com/rs-ipfs/rust-ipfs) - IPFS implementation in Rust.\n- [Safe Network](https://github.com/maidsafe/safe_network) - Safe Network implementation in Rust.\n- [SQD Network](https://github.com/subsquid/sqd-network) - A decentralized storage for Web3 data.\n- [Starcoin](https://github.com/starcoinorg/starcoin) - A smart contract blockchain network that scales by layering.\n- [Subspace](https://github.com/subspace/subspace) - Subspace Network reference implementation\n- [Substrate](https://github.com/paritytech/substrate) - Framework for blockchain innovation,\nused by [Polkadot](https://www.parity.io/technologies/polkadot/).\n- [Swarm NL](https://github.com/algorealmInc/SwarmNL) - A library that makes it easy to configure the networking requirements for any distributed application.\n- [Taple](https://github.com/opencanarias/taple-core) - Sustainable DLT for asset and process traceability by [OpenCanarias](https://www.opencanarias.com/en/).\n- [Ceylon](https://github.com/ceylonai/ceylon) - A Multi-Agent System (MAS) Development Framework.\n- [Fungi](https://github.com/enbop/fungi) - A platform built for seamless multi-device integration.\n"
  },
  "Blobscan/blobscan": {
    "fetchedAt": "2025-11-12T22:57:04.547Z",
    "content": "# Blobscan <a href=\"#\"><img align=\"right\" src=\".github/assets/logo.svg\" height=\"80px\" /></a>\n\n[![codecov](https://codecov.io/gh/Blobscan/blobscan/graph/badge.svg?token=KIPV5TH011)](https://codecov.io/gh/Blobscan/blobscan)\n\nBlobscan is the first blockchain explorer that helps to navigate and visualize shard blob transactions ([EIP-4844](https://www.eip4844.com)), providing the necessary infrastructure to scale Ethereum.\n\nTo learn more about Blobscan, please check out our [documentation website](https://docs.blobscan.com).\n\n# Features\n\n- **Blob explorer** - Delve into blobs and examine their content.\n- **Search capabilities** - Look up blobs by their versioned hash, kzg commitment, transaction hash, slot or block number, along with associated transactions and blocks.\n- **Blob persistence** - For consistent availability even after pruning from the chain, blobscan support storing blobs in multiple storage systems, both centralized and decentralized.\n- **Blob decoding** - Seamlessly access detailed insights into blobs encoded in specialized formats, including rollup blobs or blobscriptions.\n- **Rich analytics dashboard** - Gain insights into blobs, blocks and transactions. View diverse charts and metrics.\n- **Blob API** - Blobscan's API facilitates queries on blobs, their associated blocks and transactions, along with relevant statistics and metrics.\n- **Open source** - Blobscan is open-source and available to everyone. We welcome contributions too. Check out our issues to see how you can help.\n- **Docker images** - available at [blobscan-web](https://hub.docker.com/r/blossomlabs/blobscan-web) and [blobscan-api](https://hub.docker.com/r/blossomlabs/blobscan-api).\n\n# Installation\n\nCheck out [Installation guide](https://docs.blobscan.com/docs/installation).\n\n# Sponsors\n\nWe extend our gratitude to each one of them. Thank you üôè\n\n<p>\n  <a href=\"https://ethereum.foundation\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://esp.ethereum.foundation/_next/static/media/esp-logo.96fc01cc.svg\"/>\n      <img alt=\"paradigm logo\" src=\"https://esp.ethereum.foundation/_next/static/media/esp-logo.96fc01cc.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.optimism.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/Profile-Logo.svg\"/>\n      <img alt=\"optimism\" src=\"https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/Profile-Logo.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://scroll.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://scroll.io/_next/static/media/Scroll_Logomark.ad5d0348.svg\"/>\n      <img alt=\"context logo\" src=\"https://scroll.io/_next/static/media/Scroll_Logomark.ad5d0348.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.ethswarm.org\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://docs.ethswarm.org/img/logo.svg\"/>\n      <img alt=\"context logo\" src=\"https://docs.ethswarm.org/img/logo.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n</p>\n\n#\n\n[Join us on Discord!](https://discordapp.com/invite/fmqrqhkjHY/)\n"
  },
  "Blobscan/blobscan-infra": {
    "fetchedAt": "2025-11-12T22:57:04.953Z",
    "content": "# Blobscan infra\n\nThis repository contains Infrastructure as Code (IaC) resources to deploy\nand provision Blobscan to a Kubernetes cluster.\n\nIf you want to check out our previous infrastructure using GCP VMs, provisioned using Terraform and Ansible,\ncheck out the [legacy branch](https://github.com/Blobscan/blobscan-infra/tree/legacy) in this repository.\n\n## Install dependencies\n\n* Helm\n* Helmfile\n* SOPS\n\n## Deploy databases\n\n```\ncd databases\nhelmfile apply\n```\n\n## Deploy blobscan\n\n```\ncd environments\n./apply_all.sh\n```\n"
  },
  "Blobscan/blobscan-indexer.rs": {
    "fetchedAt": "2025-11-12T22:57:05.364Z",
    "content": "# Blobscan indexer <a href=\"#\"><img align=\"right\" src=\".github/assets/logo.svg\" height=\"80px\" /></a>\n\nThe indexer for the [Blobscan](https://github.com/Blobscan/blobscan) explorer implemented in Rust.\n\n# Installation and usage\n\nCheck out our [documentation website](https://docs.blobscan.com/docs/indexer).\n\n```\n./blob-indexer --help\nBlobscan's indexer for blob transactions (EIP-4844).\n\nUsage: blob-indexer [OPTIONS]\n\nOptions:\n  -f, --from-slot <FROM_SLOT>\n          Slot to start indexing from\n  -t, --to-slot <TO_SLOT>\n          Slot to stop indexing at\n  -n, --num-threads <NUM_THREADS>\n          Number of threads used for parallel indexing\n  -s, --slots-per-save <SLOTS_PER_SAVE>\n          Amount of slots to be processed before saving latest slot in the database\n  -c, --disable-sync-checkpoint-save\n          Disable slot checkpoint saving when syncing\n  -d, --disable-sync-historical\n          Disable backfill indexing thread\n  -h, --help\n          Print help\n  -V, --version\n          Print version\n```\n\n# Sponsors\n\nWe extend our gratitude to each one of them. Thank you üôè\n\n<p>\n  <a href=\"https://ethereum.foundation\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://esp.ethereum.foundation/_next/static/media/esp-logo.96fc01cc.svg\"/>\n      <img alt=\"paradigm logo\" src=\"https://esp.ethereum.foundation/_next/static/media/esp-logo.96fc01cc.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.optimism.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/Profile-Logo.svg\"/>\n      <img alt=\"optimism\" src=\"https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/Profile-Logo.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://scroll.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://scroll.io/static/media/Scroll_InvertedLogo.ea3b717f2a3ae7275378c2d43550dd38.svg\"/>\n      <img alt=\"context logo\" src=\"https://scroll.io/static/media/Scroll_FullLogo.07032ebd8a84b79128eb669f2822bc5e.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <a href=\"https://www.ethswarm.org\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://docs.ethswarm.org/img/logo.svg\"/>\n      <img alt=\"context logo\" src=\"https://docs.ethswarm.org/img/logo.svg\" width=\"auto\" height=\"50\"/>\n    </picture>\n  </a>\n</p>\n\n\n#\n\n[Join us on Discord!](https://discordapp.com/invite/fmqrqhkjHY/)\n"
  },
  "Blobscan/blobscan-helm-charts": {
    "fetchedAt": "2025-11-12T22:57:05.790Z",
    "content": "# Blobscan Helm Charts <a href=\"#\"><img align=\"right\" src=\".github/assets/logo.svg\" height=\"80px\" /></a>\n\n[![Release Helm Charts](https://github.com/blobscan/blobscan-helm-charts/actions/workflows/release.yaml/badge.svg)](https://github.com/blobscan/blobscan-helm-charts/actions/workflows/release.yaml)\n\nA set of [Helm](https://helm.sh/) charts to run blobscan on [Kubernetes](https://kubernetes.io/).\n\n## Usage\n\n[Helm](https://helm.sh) must be installed to use the charts.  Please refer to\nHelm's [documentation](https://helm.sh/docs) to get started.\n\nOnce Helm has been set up correctly, add the repo as follows:\n\n```sh\nhelm repo add blobscan-helm-charts https://blobscan.github.io/blobscan-helm-charts\n```\n\nIf you had already added this repo earlier, run `helm repo update` to retrieve\nthe latest versions of the packages.  You can then run the following command to see the charts.\n\n```sh\nhelm search repo blobscan-helm-charts\n```\n\nTo install the blobscan chart:\n\n```sh\nhelm install blobscan blobscan-helm-charts/blobscan\n```\n\nTo uninstall the chart:\n\n```sh\nhelm delete blobscan\n```\n\n## List of charts\n\n- [`blobscan`](charts/blobscan) - Blobscan meta-chart (depends on blobscan-api, blobscan-web and blobscan-indexer).\n- [`blobscan-api`](charts/blobscan-api) - Blobscan API.\n- [`blobscan-web`](charts/blobscan-web) - Blobscan Web UI.\n- [`blobscan-indexer`](charts/blobscan-indexer) - Blobscan blob indexer.\n\n## Development\n\n### Prerequisites\n\n- [`pre-commit`](https://pre-commit.com/) - Used to setup pre-commit git hooks\n- [`docker`](https://www.docker.com/) - Used by many Makefile targets\n\n### Pre-commit hooks\n\nThis repository used [`pre-commit`](https://pre-commit.com/) to manage and run certain git hooks. Hook definitions can be found within the [`.pre-commit-config.yaml`](.pre-commit-config.yaml) file.\n\nRun the following to add the hooks to your local repository:\n\n```sh\nmake init\n```\n\n### Useful commands\n\nThe `README` for every chart is auto generated using [helm-docs](https://github.com/norwoodj/helm-docs). This is defined as a pre-commit hook. If you want to run it manually, you can run:\n\n```sh\nmake docs\n```\n\nThe [CT (Chart Testing)](https://github.com/helm/chart-testing) tool is used to lint and validate charts. You can run this via:\n\n```sh\nmake lint\n```\n\n## License\n\n[MIT License](LICENSE)\n"
  },
  "opstack-kit/opstack-kit": {
    "fetchedAt": "2025-11-12T22:57:14.089Z",
    "content": "# opstack-kit\n<div align=\"center\">\n  <a href=\"https://github.com/opstack-kit\">\n    <img src=\"https://avatars.githubusercontent.com/u/176029081?s=200&v=4\" title=\"Logo\" alt=\"Logo\" width=\"200\" height=\"200\"/>\n  </a>\n  <br><br>\n  <a href=\"https://opstack-kit.pages.dev\"><img src=\"https://readme-typing-svg.demolab.com?font=JetBrains+Mono&weight=800&size=30&pause=1000&center=true&repeat=false&random=false&width=435&lines&color=F70000&width=435&lines=Opstack+Kit\" alt=\"Typing SVG\" />\n  </a>\n\n</div>\n<p align=\"center\">\n  Bridging hooks for OP Stack Chains\n    <br><br>\n  <a href=\"https://www.npmjs.com/package/opstack-kit\">\n    <picture>\n      <img src=\"https://img.shields.io/npm/v/opstack-kit\" alt=\"Npm Badge\">\n    </picture>\n  </a>\n</p>\n\n<div align=\"center\" style=\"display: flex; justify-content: center; flex-wrap: wrap; gap: 10px;\">\n  <a href=\"https://github.com/opstack-kit/opstack-kit/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/opstack-kit\" alt=\"Stars Badge\" />\n  </a>\n  <a href=\"https://github.com/opstack-kit/opstack-kit/forks\"><img src=\"https://img.shields.io/github/forks/opstack-kit/opstack-kit\" alt=\"Forks Badge\"/>\n  </a>\n  <a href=\"https://github.com/opstack-kit/opstack-kit/pulls\">\n    <img src=\"https://img.shields.io/github/issues-pr/opstack-kit/opstack-kit\" alt=\"Pull Requests Badge\" />\n  </a>\n  <a href=\"https://github.com/opstack-kit/opstack-kit/issues\">\n    <img src=\"https://img.shields.io/github/issues/opstack-kit/opstack-kit\" alt=\"Issues Badge\" />\n  </a>\n  <a href=\"https://github.com/opstack-kit/opstack-kit/graphs/contributors\">\n    <img alt=\"GitHub contributors\" src=\"https://img.shields.io/github/contributors/opstack-kit/opstack-kit?color=2b9348\">\n  </a>\n</div>\n\n## Features\n\n- Simplifies cross L1 & L2 interactions\n- Supports \"CustomGasToken\" deposit & withdrawal functions\n- Supports multi-functionality & new fault-proof feature\n- CLI command development tools\n\n## Installation\n\nRecommend: use [Nodejs v20+](https://nodejs.org/en/download/prebuilt-installer/current) and add `-g` is a **global** package installation. ([guide](https://docs.npmjs.com/cli/v9/commands/npm-install#global-installation))\n\n```bash [npm]\nnpm i -g opstack-kit\n```\nor\n```bash [pnpm]\npnpm i -g opstack-kit\n```\nor\n```bash [bun]\nbun i -g opstack-kit\n```\nor\n```yarn\nyarn add -g opstack-kit\n```\n\n- #### Types\n  - ##### opstack-kit[/chains](https://opstack-kit.pages.dev/docs/types/chains.html)\n\n## Example\n\nAfter use `opstack-kit/chains` for [configuring](https://opstack-kit.pages.dev/docs/configuration.html) the network in your app,  just import the `opstack-kit` hooks to start interacting with OP Stack chains.\n\n```tsx\nimport { useWriteDepositETH } from 'opstack-kit'\n\nconst { writeDepositETH } = useWriteDepositETH()\n\nreturn (\n  <button\n    onClick={() =>\n      writeDepositETH({\n        args: {\n          to: '0x215db47f1B2ae03ec45024Cf62ce82879b137469',\n          amount: 1n,\n        },\n        l2ChainId: 11155420,\n      })}\n  >\n    Deposit ETH\n  </button>\n)\n```\n\n## Donate\n```EVM [EVM]\n0xB6Be617b1D6fE5DbdD21A6AcFD9e97A35ddCEfF5\n```\n"
  },
  "libp2p/js-libp2p": {
    "fetchedAt": "2025-11-12T22:57:21.573Z",
    "content": "<h1 align=\"center\">\n  <a href=\"https://libp2p.io\"><img width=\"250\" src=\"https://github.com/libp2p/js-libp2p/blob/main/img/libp2p.png?raw=true\" alt=\"libp2p hex logo\" /></a>\n</h1>\n\n<h3 align=\"center\">The JavaScript implementation of the libp2p Networking Stack</h3>\n\n[![libp2p.io](https://img.shields.io/badge/project-libp2p-yellow.svg?style=flat-square)](http://libp2p.io/)\n[![npm](https://img.shields.io/npm/dm/libp2p.svg?style=flat-square)](https://www.npmjs.com/package/libp2p)\n[![Discuss](https://img.shields.io/discourse/https/discuss.libp2p.io/posts.svg?style=flat-square)](https://discuss.libp2p.io)\n[![Matrix](https://img.shields.io/badge/matrix-%23libp2p--implementers%3Aipfs.io-blue.svg?style=flat-square)](http://webchat.freenode.net/?channels=%23libp2p)\n[![Discord](https://img.shields.io/discord/806902334369824788?color=blueviolet&label=discord&style=flat-square)](https://discord.com/invite/Ae4TbahHaT)\n[![codecov](https://img.shields.io/codecov/c/github/libp2p/js-libp2p.svg?style=flat-square)](https://codecov.io/gh/libp2p/js-libp2p)\n[![CI](https://img.shields.io/github/actions/workflow/status/libp2p/js-libp2p/main.yml?branch=main\\&style=flat-square)](https://github.com/libp2p/js-libp2p/actions/workflows/main.yml?query=branch%3Amain)\n\n> [!NOTE]\n> Are you trying to upgrade libp2p to the latest version?  Check out the [migration guides](https://github.com/libp2p/js-libp2p/tree/main/doc/migrations) for any changes you need to make.\n\n### Project status\n\nThis project has been used in production for years in Ethereum, IPFS, and more.  It is actively maintained by multiple organizations and continues to be improved!  The API might change, but we strictly follow semver.\n\nThe documentation in the main branch may contain changes from a pre-release.\n\nIf you are looking for the documentation of the latest release, you can view the latest release on [npm](https://www.npmjs.com/package/libp2p), or select the tag in github that matches the version you are looking for.\n\n> [!TIP]\n> Just trying to figure out what this is all about? Check our [GETTING\\_STARTED.md](https://github.com/libp2p/js-libp2p/blob/main/doc/GETTING_STARTED.md) guide and [examples](https://github.com/libp2p/js-libp2p-examples).\n\n## Background\n\nlibp2p is the product of a long and arduous quest to understand the evolution of the Internet networking stack. In order to build P2P applications, devs have long had to make custom ad-hoc solutions to fit their needs, sometimes making some hard assumptions about their runtimes and the state of the network at the time of their development. Today, looking back more than 20 years, we see a clear pattern in the types of mechanisms built around the Internet Protocol, IP, which can be found throughout many layers of the OSI layer system, libp2p distils these mechanisms into flat categories and defines clear interfaces that once exposed, enable other protocols and applications to use and swap them, enabling upgradability and adaptability for the runtime, without breaking the API.\n\nWe are in the process of writing better documentation, blog posts, tutorials and a formal specification. Today you can find:\n\n- [libp2p.io](https://libp2p.io)\n- [docs.libp2p.io](https://docs.libp2p.io)\n- [Specification (WIP)](https://github.com/libp2p/specs)\n- [Discussion Forums](https://discuss.libp2p.io)\n- Talks\n  - [`libp2p <3 ethereum` at DEVCON2](https://archive.devcon.org/archive/watch/2/libp2p-devp2p-ipfs-and-ethereum-networking/)\n- Articles\n  - [The overview of libp2p](https://github.com/libp2p/libp2p#description)\n\nTo sum up, libp2p is a \"network stack\" -- a protocol suite -- that cleanly separates concerns, and enables sophisticated applications to only use the protocols they absolutely need, without giving up interoperability and upgradability. libp2p grew out of IPFS, but it is built so that lots of people can use it, for lots of different projects.\n\n## Roadmap\n\nThe js-libp2p roadmap can be found here: <https://github.com/libp2p/js-libp2p/blob/main/ROADMAP.md>\n\nIt represents current projects the js-libp2p maintainers are focused on and provides an estimation of completion targets.\n\n## Install\n\n```sh\nnpm install libp2p\n```\n\n## Usage\n\n### Configuration\n\nFor all the information on how you can configure libp2p see [CONFIGURATION.md](https://github.com/libp2p/js-libp2p/blob/main/doc/CONFIGURATION.md).\n\n### Limits\n\nFor help configuring your node to resist malicious network peers, see [LIMITS.md](https://github.com/libp2p/js-libp2p/blob/main/doc/LIMITS.md)\n\n### Getting started\n\nIf you are starting your journey with `js-libp2p`, read the [GETTING\\_STARTED.md](https://github.com/libp2p/js-libp2p/blob/main/doc/GETTING_STARTED.md) guide.\n\n### Tutorials and Examples\n\nYou can find multiple examples on the [examples repo](https://github.com/libp2p/js-libp2p-examples) that will guide you through using libp2p for several scenarios.\n\n## Structure\n\n- [`/doc`](https://github.com/libp2p/js-libp2p/blob/main/doc) Docs for libp2p\n- [`/interop`](https://github.com/libp2p/js-libp2p/tree/main/interop) Multidimensional Interop Test\n- [`/packages/crypto`](https://github.com/libp2p/js-libp2p/tree/main/packages/crypto) Crypto primitives for libp2p\n- [`/packages/interface`](https://github.com/libp2p/js-libp2p/tree/main/packages/interface) The interface implemented by a libp2p node\n- [`/packages/interface-compliance-tests`](https://github.com/libp2p/js-libp2p/tree/main/packages/interface-compliance-tests) Compliance tests for JS libp2p interfaces\n- [`/packages/interface-internal`](https://github.com/libp2p/js-libp2p/tree/main/packages/interface-internal) Interfaces implemented by internal libp2p components\n- [`/packages/kad-dht`](https://github.com/libp2p/js-libp2p/tree/main/packages/kad-dht) JavaScript implementation of the Kad-DHT for libp2p\n- [`/packages/keychain`](https://github.com/libp2p/js-libp2p/tree/main/packages/keychain) Key management and cryptographically protected messages\n- [`/packages/libp2p`](https://github.com/libp2p/js-libp2p/tree/main/packages/libp2p) JavaScript implementation of libp2p, a modular peer to peer network stack\n- [`/packages/logger`](https://github.com/libp2p/js-libp2p/tree/main/packages/logger) A logging component for use in js-libp2p modules\n- [`/packages/metrics-prometheus`](https://github.com/libp2p/js-libp2p/tree/main/packages/metrics-prometheus) Collect libp2p metrics for scraping by Prometheus or Graphana\n- [`/packages/multistream-select`](https://github.com/libp2p/js-libp2p/tree/main/packages/multistream-select) JavaScript implementation of multistream-select\n- [`/packages/peer-collections`](https://github.com/libp2p/js-libp2p/tree/main/packages/peer-collections) Stores values against a peer id\n- [`/packages/peer-discovery-bootstrap`](https://github.com/libp2p/js-libp2p/tree/main/packages/peer-discovery-bootstrap) Peer discovery via a list of bootstrap peers\n- [`/packages/peer-discovery-mdns`](https://github.com/libp2p/js-libp2p/tree/main/packages/peer-discovery-mdns) Node.js libp2p mDNS discovery implementation for peer discovery\n- [`/packages/peer-id`](https://github.com/libp2p/js-libp2p/tree/main/packages/peer-id) Implementation of @libp2p/interface-peer-id\n- [`/packages/peer-record`](https://github.com/libp2p/js-libp2p/tree/main/packages/peer-record) Used to transfer signed peer data across the network\n- [`/packages/peer-store`](https://github.com/libp2p/js-libp2p/tree/main/packages/peer-store) Stores information about peers libp2p knows on the network\n- [`/packages/protocol-echo`](https://github.com/libp2p/js-libp2p/tree/main/packages/protocol-echo) Implementation of an Echo protocol\n- [`/packages/protocol-perf`](https://github.com/libp2p/js-libp2p/tree/main/packages/protocol-perf) Implementation of the Perf protocol\n- [`/packages/pubsub`](https://github.com/libp2p/js-libp2p/tree/main/packages/pubsub) libp2p pubsub base class\n- [`/packages/floodsub`](https://github.com/libp2p/js-libp2p/tree/main/packages/floodsub) libp2p-floodsub, also known as pubsub-flood or \n\n[... truncated ...]"
  },
  "libp2p/go-libp2p": {
    "fetchedAt": "2025-11-12T22:57:29.139Z",
    "content": "\n<h1 align=\"center\">\n  <a href=\"https://libp2p.io/\"><img width=\"250\" src=\"https://github.com/libp2p/libp2p/blob/master/logo/black-bg-2.png?raw=true\" alt=\"libp2p hex logo\" /></a>\n</h1>\n\n<h3 align=\"center\">The Go implementation of the libp2p Networking Stack.</h3>\n\n<p align=\"center\">\n  <a href=\"http://protocol.ai\"><img src=\"https://img.shields.io/badge/made%20by-Protocol%20Labs-blue.svg?style=flat-square\" /></a>\n  <a href=\"http://libp2p.io/\"><img src=\"https://img.shields.io/badge/project-libp2p-yellow.svg?style=flat-square\" /></a>\n  <a href=\"https://pkg.go.dev/github.com/libp2p/go-libp2p\"><img src=\"https://pkg.go.dev/badge/github.com/libp2p/go-libp2p.svg\" alt=\"Go Reference\"></a>\n  <a href=\"https://discuss.libp2p.io\"><img src=\"https://img.shields.io/discourse/https/discuss.libp2p.io/posts.svg\"/></a>\n  <a href=\"https://marcopolo.github.io/FlakyTests/\"><img src=\"https://marcopolo.github.io/FlakyTests/current-score.svg\"/></a>\n</p>\n\n# Table of Contents <!-- omit in toc -->\n- [Background](#background)\n- [Usage](#usage)\n  - [Examples](#examples)\n  - [Dashboards](#dashboards)\n- [Contribute](#contribute)\n  - [Supported Go Versions](#supported-go-versions)\n- [Notable Users](#notable-users)\n\n# Background\n\n[libp2p](https://github.com/libp2p/specs) is a networking stack and library modularized out of [The IPFS Project](https://github.com/ipfs/ipfs), and bundled separately for other tools to use.\n>\nlibp2p is the product of a long, and arduous quest of understanding -- a deep dive into the internet's network stack, and plentiful peer-to-peer protocols from the past. Building large-scale peer-to-peer systems has been complex and difficult in the last 15 years, and libp2p is a way to fix that. It is a \"network stack\" -- a protocol suite -- that cleanly separates concerns, and enables sophisticated applications to only use the protocols they absolutely need, without giving up interoperability and upgradeability. libp2p grew out of IPFS, but it is built so that lots of people can use it, for lots of different projects.\n\nTo learn more, check out the following resources:\n- [**Our documentation**](https://docs.libp2p.io)\n- [**Our community discussion forum**](https://discuss.libp2p.io)\n- [**The libp2p Specification**](https://github.com/libp2p/specs)\n- [**js-libp2p implementation**](https://github.com/libp2p/js-libp2p)\n- [**rust-libp2p implementation**](https://github.com/libp2p/rust-libp2p)\n\n# Usage\n\nThis repository (`go-libp2p`) serves as the entrypoint to the universe of packages that compose the Go implementation of the libp2p stack.\n\nYou can start using go-libp2p in your Go application simply by adding imports from our repos, e.g.:\n\n```go\nimport \"github.com/libp2p/go-libp2p\"\n```\n\n## Examples\n\nExamples can be found in the [examples folder](examples).\n\n## Dashboards\n\nWe provide prebuilt Grafana dashboards so that applications can better monitor libp2p in production.\nYou can find the [dashboard JSON files here](https://github.com/libp2p/go-libp2p/tree/master/dashboards).\n\nWe also have live [Public Dashboards](https://github.com/libp2p/go-libp2p/tree/master/dashboards/README.md#public-dashboards) that you can check out to see real time monitoring in action.\n\n\n# Contribute\n\ngo-libp2p is MIT-licensed open source software. We welcome contributions big and small! Take a look at the [community contributing notes](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md). Please make sure to check the [issues](https://github.com/libp2p/go-libp2p/issues). Search the closed ones before reporting things, and help us with the open ones.\n\nGuidelines:\n\n- read the [libp2p spec](https://github.com/libp2p/specs)\n- for general questions, use our [discussion forum](https://github.com/libp2p/go-libp2p/discussions)\n- for bug reports, open an [issue](https://github.com/libp2p/go-libp2p/issues)\n- for development questions of go-libp2p itself, please join the [mailing list](mailto:go+subscribe@libp2p.io)\n- chat at [#libp2p on Libera Chat](https://web.libera.chat/gamja/?channel=#libp2p)\n- ensure you are able to contribute (no legal issues please -- we use the DCO)\n- get in touch with @libp2p/go-libp2p-maintainers about how best to contribute\n- No drive-by contributions seeking to collect airdrops.\n  - Many projects aim to reward contributors to common goods. Great. However,\n    this creates an unfortunate incentive for low-effort PRs, submitted solely to\n    claim rewards. These PRs consume maintainers‚Äô time and energy to triage, with\n    little to no impact on end users. If we suspect this is the intent of a PR,\n    we may close it without comment. If you believe this was done in error,\n    contact us via email. Reference this README section and explain why your PR\n    is not a ‚Äúdrive-by contribution.‚Äù\n- have fun!\n\nThere's a few things you can do right now to help out:\n - **Perform code reviews**.\n - **Add tests**. There can never be enough tests.\n - Go through the modules below and **check out existing issues**. This would\n   be especially useful for modules in active development. Some knowledge of\n   IPFS/libp2p may be required, as well as the infrastructure behind it - for\n   instance, you may need to read up on p2p and more complex operations like\n   muxing to be able to help technically.\n\n## AI Assistance Notice\n\n> [!IMPORTANT]\n>\n> If you are using **any kind of AI assistance** to contribute to libp2p,\n> it must be disclosed in the pull request.\n\nIf you are using any kind of AI assistance while contributing to libp2p,\n**this must be disclosed in the pull request**, along with the extent to\nwhich AI assistance was used (e.g. docs only vs. code generation).\nIf PR responses are being generated by an AI, disclose that as well.\nAs a small exception, trivial tab-completion doesn't need to be disclosed,\nso long as it is limited to single keywords or short phrases.\n\nAn example disclosure:\n\n> This PR was written primarily by Claude Code.\n\nOr a more detailed disclosure:\n\n> I consulted ChatGPT to understand the codebase but the solution\n> was fully authored manually by myself.\n\nFailure to disclose this is first and foremost rude to the human operators\non the other end of the pull request, but it also makes it difficult to\ndetermine how much scrutiny to apply to the contribution.\n\nIn a perfect world, AI assistance would produce equal or higher quality\nwork than any human. That isn't the world we live in today, and in most cases\nit's generating slop. I say this despite being a fan of and using them\nsuccessfully myself (with heavy supervision)!\n\nPlease be respectful to maintainers and disclose AI assistance.\n\n# Supported Go Versions\n\nWe test against and support the two most recent major releases of Go. This is\ninformed by Go's own [security policy](https://go.dev/doc/security/policy).\n\n# Notable Users\nSome notable users of go-libp2p are:\n- [Kubo](https://github.com/ipfs/kubo) - The original Go implementation of IPFS\n- [Lotus](https://github.com/filecoin-project/lotus) - An implementation of the Filecoin protocol\n- [Prysm](https://github.com/prysmaticlabs/prysm) - An Ethereum Beacon Chain consensus client built by [Prysmatic Labs](https://prysmaticlabs.com/)\n- [Berty](https://github.com/berty/berty) - An open, secure, offline-first, peer-to-peer and zero trust messaging app.\n- [Wasp](https://github.com/iotaledger/wasp) - A node that runs IOTA Smart Contracts built by the [IOTA Foundation](https://www.iota.org/)\n- [Mina](https://github.com/minaprotocol/mina) - A lightweight, constant-sized blockchain that runs zero-knowledge smart contracts\n- [Polygon Edge](https://github.com/0xPolygon/polygon-edge) - A modular, extensible framework for building Ethereum compatible networks\n- [Celestia Node](https://github.com/celestiaorg/celestia-node) - The Go implementation of Celestia's data availability nodes\n- [Status go](https://github.com/status-im/status-go) - Status bindings for go-ethereum, built by [Status.im](https://status.im/)\n- [Flow](https://github.com/onflow/flow-go) - A blockchain built to suppor\n\n[... truncated ...]"
  },
  "Cyfrin/aderyn": {
    "fetchedAt": "2025-11-12T22:57:37.094Z",
    "content": "<p align=\"center\">\n    <br />\n    <a href=\"https://cyfrin.io/\">\n        <img src=\"https://github.com/Cyfrin/aderyn/blob/dev/.github/images/aderyn_logo.png\" width=\"400\" alt=\"\"/></a>\n    <br />\n</p>\n<p align=\"center\"><strong>A powerful Solidity static analyzer that takes a bird's eye view over your smart contracts.\n</strong></p>\n<p align=\"center\">\n    <br />\n    <a href=\"https://cyfrin.io/\">\n        <img src=\"https://github.com/Cyfrin/aderyn/blob/dev/.github/images/poweredbycyfrinblue.png\" width=\"145\" alt=\"\"/></a>\n    <br />\n</p>\n\n<p align=\"center\">\n<a href=\"https://cyfrin.gitbook.io/cyfrin-docs/aderyn-cli/readme\">Docs</a>\n<a href=\"https://discord.gg/cyfrin\">Discord</a>\n<a href=\"https://twitter.com/cyfrinaudits\">Twitter</a>\n<p>\n\n---\n\n<div align=\"center\">\n\n[![Stargazers][stars-shield]][stars-url] [![Forks][forks-shield]][forks-url]\n[![Contributors][contributors-shield]][contributors-url]\n[![Release][release-shield]][release-url]\n[![Issues][issues-shield]][issues-url]\n[![GPL-3.0 License][license-shield]][license-url]\n\n</div>\n\n## What is Aderyn?\n\n**Aderyn is an open-source public good developer tool.** It is a Rust-based solidity smart contract static analyzer designed to help protocol engineers and security researchers find vulnerabilities in Solidity code bases.\n\nYou can read the [Cyfrin official documentation](https://cyfrin.gitbook.io/cyfrin-docs/aderyn-cli/readme) for an in-depth look at Aderyn's functionalities.\n\nThere is also an officially supported [VSCode extension](https://github.com/Cyfrin/vscode-aderyn/) for Aderyn. Download from the [Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=Cyfrin.aderyn&ssr=false#overview) and start identifying vulnerabilities in your Solidity \ncode with ease.  \n\n## Features\n\n- Off the shelf support for Foundry projects.\n- Off the shelf support for Hardhat projects. (Sometimes `remappings.txt` maybe required)\n- Configuration file (`aderyn.toml`) needed to support custom frameworks.\n- Markdown, JSON and Sarif reports\n\n## Installation\n\n> **NOTE** Windows users must have WSL installed\n\n### Using Cyfrinup\n\n**Cyfrinup** is the cross platform installation manager for Cyfrin tools.\n\n[One time setup](https://github.com/Cyfrin/up).\n\nRun `aderyn --version` to check the installation.\n\nRun `cyfrinup` to upgrade everything to the latest version.\n\n---\n\n### Using curl\n\n```sh\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/cyfrin/aderyn/releases/latest/download/aderyn-installer.sh | bash\n```\n\n##### Upgrade older versions by running: `aderyn-update`\n\n---\n\n### Using Homebrew\n\n```sh\nbrew install cyfrin/tap/aderyn\n```\n\n##### Upgrade older versions by running: `brew upgrade cyfrin/tap/aderyn`\n\n---\n\n### Using npm\n\n```sh\nnpm install @cyfrin/aderyn -g\n```\n\n##### Upgrade older versions by (re)running: `npm install @cyfrin/aderyn -g`\n\n---\n\nIf you are installing with Curl or Homebrew or npm, ensure that the correct version of Aderyn in your path comes from either the Homebrew or npm global packages directory. If an older version exists at `~/.cyfrin/bin/aderyn`, remove it using `rm -f ~/.cyfrin/bin/aderyn`, as this is no longer the default installation location.\n\n## Quick Start\n\n[Quick Start](https://cyfrin.gitbook.io/cyfrin-docs/aderyn-cli/quickstart) example with video guide.\n\n```\ncd path/to/solidity/project/root\naderyn\n```\n\nThis generates a [report.md](https://github.com/Cyfrin/aderyn/blob/dev/reports/report.md)\n\nSee examples using more CLI options [here](https://cyfrin.gitbook.io/cyfrin-docs/cli-options)\n\n## VS Code extension\n\nOfficially supported [VSCode extension](https://github.com/Cyfrin/vscode-aderyn/) for Aderyn. \nDownload from [Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=Cyfrin.aderyn&ssr=false#overview)\n\n## Contributing & License\n\nHelp us build Aderyn ü¶ú Please see our [contribution guidelines](./CONTRIBUTING.md) for in-depth developer environment setup and PR approval process.\nAderyn is an open-source software licensed under the [GPL-3.0 License](./LICENSE).\n\n## Building a custom Aderyn detector\n\nAderyn makes it easy to build Static Analysis detectors that can adapt to any Solidity codebase and protocol. This guide will teach you how to build, test, and run your custom Aderyn detectors.\nTo learn how to create your custom Aderyn detectors, [checkout the official docs](https://cyfrin.gitbook.io/cyfrin-docs/aderyn-cli/detectors-quickstart)\n\n\n## Credits\n\nThis project exists thanks to all the people who [contribute](/CONTRIBUTING.md).<br>\n\n<a href=\"https://github.com/cyfrin/Aderyn/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=cyfrin/Aderyn\" />\n</a>\n\n## Attribution\n\n- AST Visitor code from [solc-ast-rs](https://github.com/hrkrshnn/solc-ast-rs).\n- Foundry Compilers for backend AST generation [foundry-compilers](https://github.com/foundry-rs/compilers)\n- Original detectors based on [4naly3er](https://github.com/Picodes/4naly3er) detectors.\n- Shoutout to the original king of static analysis [slither](https://github.com/crytic/slither).\n- Solidity AST Generator [solidity-ast-rs](https://github.com/Cyfrin/solidity-ast-rs). \n\n[contributors-shield]: https://img.shields.io/github/contributors/cyfrin/aderyn\n[contributors-url]: https://github.com/cyfrin/aderyn/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/cyfrin/aderyn\n[forks-url]: https://github.com/cyfrin/aderyn/network/members\n[stars-shield]: https://img.shields.io/github/stars/cyfrin/aderyn\n[stars-url]: https://github.com/cyfrin/aderyn/stargazers\n[release-shield]: https://img.shields.io/github/v/release/Cyfrin/aderyn\n[release-url]: https://github.com/Cyfrin/aderyn/releases\n[issues-shield]: https://img.shields.io/github/issues/cyfrin/aderyn\n[issues-url]: https://github.com/cyfrin/aderyn/issues\n[license-shield]: https://img.shields.io/github/license/cyfrin/aderyn?logoColor=%23fff&color=blue\n[license-url]: https://github.com/cyfrin/aderyn/blob/master/LICENSE\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n"
  },
  "runtimeverification/yearn-v3-term-vault": {
    "fetchedAt": "2025-11-12T22:57:44.674Z",
    "content": "# Tokenized Strategy Mix for Yearn V3 strategies\n\nThis repo will allow you to write, test and deploy V3 \"Tokenized Strategies\" using [Foundry](https://book.getfoundry.sh/).\n\nYou will only need to override the three functions in Strategy.sol of `_deployFunds`, `_freeFunds` and `_harvestAndReport`. With the option to also override `_tend`, `_tendTrigger`, `availableDepositLimit`, `availableWithdrawLimit` and `_emergencyWithdraw` if desired.\n\nFor a more complete overview of how the Tokenized Strategies work please visit the [TokenizedStrategy Repo](https://github.com/yearn/tokenized-strategy).\n\n## How to start\n\n### Requirements\n\n- First you will need to install [Foundry](https://book.getfoundry.sh/getting-started/installation).\nNOTE: If you are on a windows machine it is recommended to use [WSL](https://learn.microsoft.com/en-us/windows/wsl/install)\n- Install [Node.js](https://nodejs.org/en/download/package-manager/)\n\n### Clone this repository\n\n```sh\ngit clone --recursive https://github.com/yearn/tokenized-strategy-foundry-mix\n\ncd tokenized-strategy-foundry-mix\n\nyarn\n```\n\n### Set your environment Variables\n\nUse the `.env.example` template to create a `.env` file and store the environement variables. You will need to populate the `RPC_URL` for the desired network(s). RPC url can be obtained from various providers, including [Ankr](https://www.ankr.com/rpc/) (no sign-up required) and [Infura](https://infura.io/).\n\nUse .env file\n\n1. Make a copy of `.env.example`\n2. Add the value for `ETH_RPC_URL` and other example vars\n     NOTE: If you set up a global environment variable, that will take precedence.\n\n### Build the project\n\n```sh\nmake build\n```\n\nRun tests\n\n```sh\nmake test\n```\n\n## Strategy Writing\n\nFor a complete guide to creating a Tokenized Strategy please visit: https://docs.yearn.fi/developers/v3/strategy_writing_guide\n\nNOTE: Compiler defaults to 8.23 but it can be adjusted in the foundry toml.\n\n## Testing\n\nDue to the nature of the BaseStrategy utilizing an external contract for the majority of its logic, the default interface for any tokenized strategy will not allow proper testing of all functions. Testing of your Strategy should utilize the pre-built [IStrategyInterface](https://github.com/yearn/tokenized-strategy-foundry-mix/blob/master/src/interfaces/IStrategyInterface.sol) to cast any deployed strategy through for testing, as seen in the Setup example. You can add any external functions that you add for your specific strategy to this interface to be able to test all functions with one variable. \n\nExample:\n\n```solidity\nStrategy _strategy = new Strategy(asset, name);\nIStrategyInterface strategy =  IStrategyInterface(address(_strategy));\n```\n\nDue to the permissionless nature of the tokenized Strategies, all tests are written without integration with any meta vault funding it. While those tests can be added, all V3 vaults utilize the ERC-4626 standard for deposit/withdraw and accounting, so they can be plugged in easily to any number of different vaults with the same `asset.`\n\nTests run in fork environment, you need to complete the full installation and setup to be able to run these commands.\n\n```sh\nmake test\n```\n\nRun tests with traces (very useful)\n\n```sh\nmake trace\n```\n\nRun specific test contract (e.g. `test/StrategyOperation.t.sol`)\n\n```sh\nmake test-contract contract=StrategyOperationsTest\n```\n\nRun specific test contract with traces (e.g. `test/StrategyOperation.t.sol`)\n\n```sh\nmake trace-contract contract=StrategyOperationsTest\n```\n\nSee here for some tips on testing [`Testing Tips`](https://book.getfoundry.sh/forge/tests.html)\n\nWhen testing on chains other than mainnet you will need to make sure a valid `CHAIN_RPC_URL` for that chain is set in your .env. You will then need to simply adjust the variable that RPC_URL is set to in the Makefile to match your chain.\n\nTo update to a new API version of the TokenizeStrategy you will need to simply remove and reinstall the dependency.\n\n### Deployment\n\n#### Contract Verification\n\nOnce the Strategy is fully deployed and verified, you will need to verify the TokenizedStrategy functions. To do this, navigate to the /#code page on Etherscan.\n\n1. Click on the `More Options` drop-down menu\n2. Click \"is this a proxy?\"\n3. Click the \"Verify\" button\n4. Click \"Save\"\n\nThis should add all of the external `TokenizedStrategy` functions to the contract interface on Etherscan.\n\n## CI\n\nThis repo uses [GitHub Actions](.github/workflows) for CI. There are three workflows: lint, test and slither for static analysis.\n\nTo enable test workflow you need to add the `ETH_RPC_URL` secret to your repo. For more info see [GitHub Actions docs](https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/managing-encrypted-secrets-for-your-repository-and-organization-for-github-codespaces#adding-secrets-for-a-repository).\n\nIf the slither finds some issues that you want to suppress, before the issue add comment: `//slither-disable-next-line DETECTOR_NAME`. For more info about detectors see [Slither docs](https://github.com/crytic/slither/wiki/Detector-Documentation).\n"
  },
  "runtimeverification/Depeg-swap": {
    "fetchedAt": "2025-11-12T22:57:45.181Z",
    "content": "# Depeg Swap V1\n\nThis repository contains core smart contracts of Depeg Swaps, for higher level specification and flows please see the design [documents](https://corkfi.notion.site/Smart-Contract-Flow-fc170aec36bc43579a7d0429c49e08ab) for now.\n\n# Build\n\nInstall required dependencies :(related to hardhat)\n\n```bash\nyarn\n```\n\nInstall required dependencies :(related to foundry)\n\n```bash\nforge install Openzeppelin/openzeppelin-contracts@v5.0.2\nforge install Openzeppelin/openzeppelin-contracts-upgradeable@v5.0.2\nforge install Cork-Technology/v2-core@v1.0.2\nforge install Cork-Technology/v2-periphery@v1.0.1                   \n```\n\nTo build & compile all contracts simply run :\n\n```bash\nyarn build\n```\n\n# Tests\n\nTo run test, use this command :\n\n```bash\nyarn test\n```\n\n# Deployments\n\n- read `.env.example` variables descriptions\n- copy the contents to your `.env` and fill it with your value\n- run this command :\n\n```bash\nnpx hardhat run scripts/deploy.ts --network <network>\n```\n\nin the first run you may see errors like :\n\n```bash\nIgnitionError: IGN403: You have sent transactions from 0x3e995c17172ea3e23505adfe5630df395a738e51 and they interfere with Hardhat Ignition. Please wait until they get 5 confirmations before running Hardhat Ignition again.\n```\n\nThis is because we actualy don't use ignition when deploying uniswap v2 related contracts(e.g factory, router). Instead, we use ethers due to the fact that for some reason, deploying using ignition modules won't work with uniswap v2 contracts. To resolve this, simply run the command again. This usually takes 1-2 times, but don't worry, all of the previous deployments will be cached\n\n```bash\nnpx hardhat run script/hardhat-scripts/deploy.ts --network <network>\n\nforge script script/foundry-scripts/Deploy.s.sol:DeployScript --rpc-url https://1rpc.io/sepolia --broadcast -vvv --with-gas-price 25000000000\n```\n\nAFter that, you should see something like this on your terminal :\n\n```bash\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  PRODUCTION                   : undefined\n  Network                      : sepolia\n  Chain Id                     : 11155111\n  Deployer                     : 0xFFB6b6896D469798cE64136fd3129979411B5514\n -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  CETH                            :  0x93D16d90490d812ca6fBFD29E8eF3B31495d257D\n  bsETH                           :  0xb194fc7C6ab86dCF5D96CF8525576245d0459ea9\n  lbETH                           :  0xF24177162B1604e56EB338dd9775d75CC79DaC2B\n  wamuETH                         :  0x38B61B429a3526cC6C446400DbfcA4c1ae61F11B\n  mlETH                           :  0xCDc1133148121F43bE5F1CfB3a6426BbC01a9AF6\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  Asset Factory Implementation    :  0x92D8b534237C5Be34753b975D53a14b494b96Ef4\n  Asset Factory                   :  0xbdfc069558B9d87Df40f9A4876Fa7c52f6492788\n  Cork Config                     :  0x8c996E7f76fB033cDb83CE1de7c3A134e17Cc227\n  Flashswap Router Implementation :  0xE6F58Dd84869542d7Ec1c0153417E20Fa220B63d\n  Flashswap Router Proxy          :  0x6629e017455CB886669e725AF1BC826b65cB6f24\n  Univ2 Factory                   :  0x8fD48F4ec9cB04540134c02f4dAa5f68585c3936\n  Univ2 Router                    :  0x363E8886E8FF30b6f6770712Cf4e758e2Bf3E353\n  ModuleCore Router Implementation :  0x26De252a30812645960846cEA402E4B34A8eaD89\n  Module Core                     :  0xe56565c208d0a8Ca28FB632aD7F6518f273B8B9f\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  Transferred ownerships to Modulecore\n  Modulecore configured in Config contract\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  New DS issued\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  LV Deposited\n  Liquidity Added to AMM\n  New DS issued\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  LV Deposited\n  Liquidity Added to AMM\n  New DS issued\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n  Funder Contract                 :  0xdAD2E0651F88D5EA6725274153209Fe94DF8c829\n  Reader Contract                 :  0xC4736Ba3D54df3725771d889b964114535d4bF2D\n  -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n```\n"
  },
  "runtimeverification/_audits_lidofinance_dual-governance_fork": {
    "fetchedAt": "2025-11-12T22:57:45.898Z",
    "content": "# Lido Dual Governance contracts\n\n**WARNING**: this code is an early draft and is not functional yet.\n\nSee [this research forum discussion](https://research.lido.fi/t/ldo-steth-dual-governance-continuation/5727) for the relevant context.\n\n## Setup\n\nThis project uses NPM for dependency management and Forge for tests so you'll need to have Node.js, NPM, and Foundry installed.\n\n* Install NVM https://github.com/nvm-sh/nvm/blob/master/README.md#install--update-script\n\n* Install specific Node.js version\n    ```sh\n    nvm install\n    ```\n\n* Install the dependencies:\n    ```sh\n    npm ci\n    ```\n\n* Install Foundry and `forge` https://book.getfoundry.sh/getting-started/installation\n\n* Create `.env` file\n    ```sh\n    cp .env.example .env\n    ```\n\n    and specify there your `MAINNET_RPC_URL`.\n\n    > **_NOTE:_**  You may need to specify manually maximum allowed requests per second (rps) value for an API key/RPC url for some providers. In our experience max 100 rps will be enough to run tests.\n\n## Running tests\n\n```sh\nforge test\n```\n\n## Test coverage HTML report generation\n\n1. Install `lcov` package in your OS\n    ```sh\n    brew install lcov\n    \n    -OR-\n\n    apt-get install lcov\n    ```\n2. Run\n    ```sh\n    npm run cov-report\n    ```\n3. Open `./coverage-report/index.html` in your browser.\n"
  },
  "runtimeverification/_audits_Ethereum-optimism_pausability": {
    "fetchedAt": "2025-11-12T22:57:46.245Z",
    "content": "<div align=\"center\">\n  <br />\n  <br />\n  <a href=\"https://optimism.io\"><img alt=\"Optimism\" src=\"https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/OPTIMISM-R.svg\" width=600></a>\n  <br />\n  <h3><a href=\"https://optimism.io\">Optimism</a> is Ethereum, scaled.</h3>\n  <br />\n</div>\n\n**Table of Contents**\n\n<!--TOC-->\n\n- [What is Optimism?](#what-is-optimism)\n- [Documentation](#documentation)\n- [Specification](#specification)\n- [Community](#community)\n- [Contributing](#contributing)\n- [Security Policy and Vulnerability Reporting](#security-policy-and-vulnerability-reporting)\n- [Directory Structure](#directory-structure)\n- [Development and Release Process](#development-and-release-process)\n  - [Overview](#overview)\n  - [Production Releases](#production-releases)\n  - [Development branch](#development-branch)\n- [License](#license)\n\n<!--TOC-->\n\n## What is Optimism?\n\n[Optimism](https://www.optimism.io/) is a project dedicated to scaling Ethereum's technology and expanding its ability to coordinate people from across the world to build effective decentralized economies and governance systems. The [Optimism Collective](https://www.optimism.io/vision) builds open-source software that powers scalable blockchains and aims to address key governance and economic challenges in the wider Ethereum ecosystem. Optimism operates on the principle of **impact=profit**, the idea that individuals who positively impact the Collective should be proportionally rewarded with profit. **Change the incentives and you change the world.**\n\nIn this repository you'll find numerous core components of the OP Stack, the decentralized software stack maintained by the Optimism Collective that powers Optimism and forms the backbone of blockchains like [OP Mainnet](https://explorer.optimism.io/) and [Base](https://base.org). The OP Stack is designed to be aggressively open-source ‚Äî you are welcome to explore, modify, and extend this code.\n\n## Documentation\n\n- If you want to build on top of OP Mainnet, refer to the [Optimism Documentation](https://docs.optimism.io)\n- If you want to build your own OP Stack based blockchain, refer to the [OP Stack Guide](https://docs.optimism.io/stack/getting-started) and make sure to understand this repository's [Development and Release Process](#development-and-release-process)\n\n## Specification\n\nDetailed specifications for the OP Stack can be found within the [OP Stack Specs](https://github.com/ethereum-optimism/specs) repository.\n\n## Community\n\nGeneral discussion happens most frequently on the [Optimism discord](https://discord.gg/optimism).\nGovernance discussion can also be found on the [Optimism Governance Forum](https://gov.optimism.io/).\n\n## Contributing\n\nThe OP Stack is a collaborative project. By collaborating on free, open software and shared standards, the Optimism Collective aims to prevent siloed software development and rapidly accelerate the development of the Ethereum ecosystem. Come contribute, build the future, and redefine power, together.\n\n[CONTRIBUTING.md](./CONTRIBUTING.md) contains a detailed explanation of the contributing process for this repository. Make sure to use the [Developer Quick Start](./CONTRIBUTING.md#development-quick-start) to properly set up your development environment.\n\n[Good First Issues](https://github.com/ethereum-optimism/optimism/issues?q=is:open+is:issue+label:D-good-first-issue) are a great place to look for tasks to tackle if you're not sure where to start, and see [CONTRIBUTING.md](./CONTRIBUTING.md) for info on larger projects.\n\n## Security Policy and Vulnerability Reporting\n\nPlease refer to the canonical [Security Policy](https://github.com/ethereum-optimism/.github/blob/master/SECURITY.md) document for detailed information about how to report vulnerabilities in this codebase.\nBounty hunters are encouraged to check out the [Optimism Immunefi bug bounty program](https://immunefi.com/bounty/optimism/).\nThe Optimism Immunefi program offers up to $2,000,042 for in-scope critical vulnerabilities.\n\n## Directory Structure\n\n<pre>\n‚îú‚îÄ‚îÄ <a href=\"./docs\">docs</a>: A collection of documents including audits and post-mortems\n‚îú‚îÄ‚îÄ <a href=\"./kurtosis-devnet\">kurtosis-devnet</a>: OP-Stack Kurtosis devnet\n‚îú‚îÄ‚îÄ <a href=\"./op-batcher\">op-batcher</a>: L2-Batch Submitter, submits bundles of batches to L1\n‚îú‚îÄ‚îÄ <a href=\"./op-chain-ops\">op-chain-ops</a>: State surgery utilities\n‚îú‚îÄ‚îÄ <a href=\"./op-challenger\">op-challenger</a>: Dispute game challenge agent\n‚îú‚îÄ‚îÄ <a href=\"./op-e2e\">op-e2e</a>: End-to-End testing of all bedrock components in Go\n‚îú‚îÄ‚îÄ <a href=\"./op-node\">op-node</a>: rollup consensus-layer client\n‚îú‚îÄ‚îÄ <a href=\"./op-preimage\">op-preimage</a>: Go bindings for Preimage Oracle\n‚îú‚îÄ‚îÄ <a href=\"./op-program\">op-program</a>: Fault proof program\n‚îú‚îÄ‚îÄ <a href=\"./op-proposer\">op-proposer</a>: L2-Output Submitter, submits proposals to L1\n‚îú‚îÄ‚îÄ <a href=\"./op-service\">op-service</a>: Common codebase utilities\n‚îú‚îÄ‚îÄ <a href=\"./op-wheel\">op-wheel</a>: Database utilities\n‚îú‚îÄ‚îÄ <a href=\"./ops\">ops</a>: Various operational packages\n‚îú‚îÄ‚îÄ <a href=\"./packages\">packages</a>\n‚îÇ   ‚îú‚îÄ‚îÄ <a href=\"./packages/contracts-bedrock\">contracts-bedrock</a>: OP Stack smart contracts\n‚îú‚îÄ‚îÄ <a href=\"./.semgrep\">semgrep</a>: Semgrep rules and tests\n</pre>\n\n## Development and Release Process\n\n### Overview\n\nPlease read this section carefully if you're planning to fork or make frequent PRs into this repository.\n\n### Production Releases\n\nProduction releases are always tags, versioned as `<component-name>/v<semver>`.\nFor example, an `op-node` release might be versioned as `op-node/v1.1.2`, and  smart contract releases might be versioned as `op-contracts/v1.0.0`.\nRelease candidates are versioned in the format `op-node/v1.1.2-rc.1`.\nWe always start with `rc.1` rather than `rc`.\n\nFor contract releases, refer to the GitHub release notes for a given release which will list the specific contracts being released. Not all contracts are considered production ready within a release and many are under active development.\n\nTags of the form `v<semver>`, such as `v1.1.4`, indicate releases of all Go code only, and **DO NOT** include smart contracts.\nThis naming scheme is required by Golang.\nIn the above list, this means these `v<semver>` releases contain all `op-*` components and exclude all `contracts-*` components.\n\n`op-geth` embeds upstream geth‚Äôs version inside its own version as follows: `vMAJOR.GETH_MAJOR GETH_MINOR GETH_PATCH.PATCH`.\nBasically, geth‚Äôs version is our minor version.\nFor example if geth is at `v1.12.0`, the corresponding op-geth version would be `v1.101200.0`.\nNote that we pad out to three characters for the geth minor version and two characters for the geth patch version.\nSince we cannot left-pad with zeroes, the geth major version is not padded.\n\nSee the [Node Software Releases](https://docs.optimism.io/builders/node-operators/releases) page of the documentation for more information about releases for the latest node components.\n\nThe full set of components that have releases are:\n\n- `op-batcher`\n- `op-contracts`\n- `op-challenger`\n- `op-node`\n- `op-proposer`\n\nAll other components and packages should be considered development components only and do not have releases.\n\n### Development branch\n\nThe primary development branch is [`develop`](https://github.com/ethereum-optimism/optimism/tree/develop/).\n`develop` contains the most up-to-date software that remains backwards compatible with the latest experimental [network deployments](https://docs.optimism.io/chain/networks).\nIf you're making a backwards compatible change, please direct your pull request towards `develop`.\n\n**Changes to contracts within `packages/contracts-bedrock/src` are usually NOT considered backwards compatible.**\nSome exceptions to this rule exist for cases in which we absolutely must deploy some new contract after a tag has already been fully deployed.\nIf you're changing or adding a contract and you're unsure about which branch to make a PR into, default to using a feature branch.\nFeature \n\n[... truncated ...]"
  },
  "runtimeverification/optimism-ci": {
    "fetchedAt": "2025-11-12T22:57:46.600Z",
    "content": "# Audit Repository\n\n# Use Kup to install Specific Versions of RV Tools On a Local Box for Development and personal Testing\n[kup](https://github.com/runtimeverification/k/blob/master/k-distribution/INSTALL.md)\n```\nbash <(curl https://kframework.org/install)\nkup install k\nor \nkup install kevm \nor \nkup install kontrol\n```\n\n# Tool Suggestions\nWhen working with RV tools for audits at times requires making custom changes. Check these tools out separately apart from this project. \nUtilize a tool called `git worktree` to work on multiple branches of the same repo at the same time. \n\nSource Doc Reading for [git worktree](https://git-scm.com/docs/git-worktree)\nThese repositories will track and test the associated deps main releases and run tests against new releases as they update. \n\n# Reproduce builds locally \nInstructions to install Docker are here: [Docker Install](https://docs.docker.com/engine/install/ubuntu/) \nDo not install Docker Desktop. For businesses it is not free and a violation of their user policy. Be sure to install Docker Engine. \n\n## Local CI Setup to reproduce issues in CI\nThis is intended to setup a local environment that mimic what is done in a CI environment. \n```bash\n      docker run                          \\\n        --name kontrol-test               \\\n        --rm                              \\\n        --interactive                     \\\n        --tty                             \\\n        --detach                          \\\n        --user root                       \\\n        --workdir /home/user/workspace            \\\n        runtimeverificationinc/kontrol:ubuntu-jammy-0.1.12\n\n      # Copy the current Checkout direcotry into the container\n      # Run the following again if you need to update scripts or proofs to run tests again\n      docker cp . kontrol-test:/home/user/workspace\n      docker exec kontrol-test chown -R user:user /home/user\n      # Get a shell in the environment \n      docker exec -it --user user kontrol-test bash\n      # Now with a shell go to the scripts you wish to run. \n```\n"
  },
  "runtimeverification/kontrol": {
    "fetchedAt": "2025-11-12T22:57:46.885Z",
    "content": "# Kontrol\nKontrol combines [KEVM](https://github.com/runtimeverification/evm-semantics) and [Foundry](https://book.getfoundry.sh/) to grant developers the ability to perform formal verification without learning a new language or tool. This is especially useful for those who are not verification engineers. Additionally, developers can leverage Foundry test suites they have already developed and use symbolic execution to increase the level of confidence.\n\n## Documentation & Support\nDocumentation for Kontrol can be found in [Kontrol book](https://docs.runtimeverification.com/kontrol).\n\nJoin our [Kontrol Telegram Group](https://t.me/rv_kontrol) or [Discord server](https://discord.com/invite/CurfmXNtbN) if you have any questions or require support.\n\n## Fast Installation\n\n-   `bash <(curl https://kframework.org/install)`: install [kup package manager].\n-   `kup install kontrol`: install Kontrol.\n-   `kup list kontrol`: list available Kontrol versions.\n\n**NOTE**: The first run will take longer to fetch all the libraries and compile sources. (30m to 1h)\n\n## Build from source\n\n#### K Framework\n\nYou need to install the [K Framework] on your system, see the instructions there.\nThe fastest way is via the [kup package manager], with which you can do to get the correct version of K:\n\n```sh\nkup install k.openssl.secp256k1 --version v$(cat deps/k_release)\n```\n\n#### uv\nSetting up Python dependencies and the virtual environment is done using `uv`. You can either [install `uv` directly](https://docs.astral.sh/uv/getting-started/installation/) or use the `nix develop` shell:\n```sh\nnix develop\nuv sync\nexit # exit nix develop shell\n```\n\n\n#### Build using the virtual environment\n\nIn order to build `kontrol`, you need to build these specific targets.\nNote that you can use `kontrol.base` (without [keccak](https://github.com/runtimeverification/kontrol/blob/master/src/kontrol/kdist/keccak.md) or [aux](https://github.com/runtimeverification/kontrol/blob/master/src/kontrol/kdist/kontrol_lemmas.md) lemmas), `kontrol.aux` (with aux lemmas), `kontrol.keccak` (with keccak lemmas) and `kontrol.full` (with all lemmas) instead of `kontrol.*` (which builds them all).\n\n```sh\nuv run kdist --verbose build -j2 \"kontrol.*\"\n```\n\nTo change the default compiler:\n```sh\nCXX=clang++-14 uv run kdist --verbose build -j2 \"kontrol.*\"\n```\n\nOn Apple Silicon:\n```sh\nAPPLE_SILICON=true uv run kdist --verbose build -j2 \"kontrol.*\"\n```\n\nTargets can be cleaned with:\n```sh\nuv run kdist clean\n```\n\nFor more information, refer to `kdist --help`.\n\n\n## For developers\n\nUse `make` to run common tasks (see the [Makefile](Makefile) for a complete list of available targets).\n\n* `make build`: Build wheel\n* `make check`: Check code style\n* `make format`: Format code\n* `make test-unit`: Run unit tests\n\nTo update the expected output of the tests, use the `--update-expected-output` flag:\n```sh\nmake cov-integration TEST_ARGS=\"--numprocesses=8 --update-expected-output\"\n```\n\n### Build Development Kontrol Image with Fixed Upstream Dependencies\n--------------------------------\nRelevant to this workflow [kontrol-push-fixed-deps.yml](.github/workflows/kontrol-push-fixed-deps.yml)\n>This is relevant for internal development to publish development images of Kontrol with modified Kontrol changes and retain fixed upstream dependencies.\nThe use case for this workflow is intended to facilitate testing changes to Kontrol needed for use in testing CI or in other downstream workflows without needing to publish changes or PRs first.\n\nThe intent is to reduce the friction of needing custom builds and avoiding lengthy upstream changes and PRs.\n\n### Build Kontrol with Kup and Specific Dependency Overrides\n--------------------------------\nRelevant to this workflow [kup-build-kontrol.yml](.github/workflows/kontrol-push-unfixed-deps.yml)\n> This is relevant for internal development to publish development images of Kontrol for use in KaaS or a dockerized test environment.\nUse the workflow [Kup Build Kontrol](.github/workflows/kup-build-kontrol.yml) to publish a custom version of Kontrol for use in CI and [KaaS](https://kaas.runtimeverification.com/).\n[See KUP docs for more information](https://github.com/runtimeverification/kup/blob/master/src/kup/install-help.md#kup-install----override)\n\n#### Using Kup \n-------------\nRelevant dependency options are shown below and can be listed using `kup list kontrol --inputs`  \nFor example: \n```\nInputs:\n‚îú‚îÄ‚îÄ k-framework - follows kevm/k-framework\n‚îú‚îÄ‚îÄ kevm - github:runtimeverification/evm-semantics (6c2526b)\n‚îÇ   ‚îú‚îÄ‚îÄ blockchain-k-plugin - github:runtimeverification/blockchain-k-plugin (c9264b2)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ k-framework - github:runtimeverification/k (5d1ccd5)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ haskell-backend - github:runtimeverification/haskell-backend (d933d5c)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - follows kevm/blockchain-k-plugin/k-framework/llvm-backend/rv-utils\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llvm-backend - github:runtimeverification/llvm-backend (37b1dd9)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ immer-src - github:runtimeverification/immer (4b0914f)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - github:runtimeverification/rv-nix-tools (a650588)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - follows kevm/blockchain-k-plugin/k-framework/llvm-backend/rv-utils\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - follows kevm/blockchain-k-plugin/k-framework/rv-utils\n‚îÇ   ‚îú‚îÄ‚îÄ haskell-backend - follows kevm/k-framework/haskell-backend\n‚îÇ   ‚îú‚îÄ‚îÄ k-framework - github:runtimeverification/k (81bcc24)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ haskell-backend - github:runtimeverification/haskell-backend (786c780)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - follows kevm/k-framework/llvm-backend/rv-utils\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llvm-backend - github:runtimeverification/llvm-backend (d5eab4b)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ immer-src - github:runtimeverification/immer (4b0914f)\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - github:runtimeverification/rv-nix-tools (a650588)\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - follows kevm/k-framework/llvm-backend/rv-utils\n‚îÇ   ‚îî‚îÄ‚îÄ rv-utils - follows kevm/k-framework/rv-utils\n‚îî‚îÄ‚îÄ rv-utils - follows kevm/rv-utils\n```\n> **Notice**: the 'follows' in the 'kup list' output. This shows the links to the important dependencies and which are affected when you set the overrides. \n\nNow run a build using kup and specific dependency overrides:    \n\n`kup install kontrol --override kevm/k-framework/haskell-backend \"hash/branch_name\" --override kevm/k-framework/haskell-backend \"hash\"`  \n\n> **Note**: It's important that you use the short-rev hash or the long for specific revisions of the dependencies to modify. \n\n#### Using the workflow to publish to ghcr.io/runtimeverification\n--------------------------------\n\n#### Running the workflow\n- Go to repo [Kontrol Actions Page](https://github.com/runtimeverification/kontrol/actions) \n- Click on \"Push Kontrol w/ Dependencies\" from the left hand list \n- Click on \"Run Workflow\" on the top right corner of the list of workflow runs is an option \"Run Workflow\".\n- Use the 'master' branch unless you're doing something special.\n- Input the override hash strings for specific dependencies to override in kontrol. See below on how to find the hash for the dependency.\n- Then click \"Run Workflow\" and a job will start.\n- The workflow summary shows the name of the image that was built and pushed e.g. ghcr.io/runtimeverification/kontrol-custom:tag \n\n> **Note**: The tag will be a randomly generated string.\n\n[The workflow](.github/workflows/kontrol-push-unfixed-deps.yml) takes multiple inputs to override the various components of kontrol. Those overrides are listed above in the example output of 'kup list kontrol --inputs' \n\nTo set the desired revisions of the dependencies. Find the associated hash on the branch and commit made to be used for the dependnecy override. \nIf an input is left blank, the workflow will workout the default hash to use based on kontrols latest release. \n\nExample to fetch the desired hash to insert a different dependency version into the kontrol build.\nSubstitude the k-framework revision used to build kontrol.\n```\nK_TAG=$(curl -s https://raw.githubusercontent.com/runtimeverification/kontrol/master/d\n\n[... truncated ...]"
  },
  "Charged-Particles/ionx-ccip": {
    "fetchedAt": "2025-11-12T22:57:54.246Z",
    "content": "# ionx-ccip v1.0\nIONX on ChainLink CCIP\n\nPart of the Charged Particles Protocol\n<https://charged.fi>\n\n## Deploy Steps:\n\n- nvm use\n- yarn\n- yarn deploy sepolia\n- yarn deploy modeSepolia\n- yarn setup sepolia\n- yarn setup modeSepolia\n\n## Test Bridge:\n### Sepolia -> Mode-Sepolia\n- yarn test-bridge sepolia\n- ref: https://ccip.chain.link/tx/0xb960b33043e70609cfd9db560e2f782889aee8c34121040201bff396c09947b5\n\n### Mode-Sepolia -> Sepolia\n- yarn test-bridge modeSepolia\n- ref: https://ccip.chain.link/tx/0x2d4aaeb32bb0437f4488bc5937b70494c5281c9c77f2f25ec9a762a6b0645e28\n"
  },
  "Charged-Particles/web3-packs-v2": {
    "fetchedAt": "2025-11-12T22:57:54.586Z",
    "content": "# web3-packs-v2\nWeb3 Packs V2\n\n### Usage:\n\n- nvm use\n- yarn\n- yarn test\n- yarn deploy &lt;network&gt;\n"
  },
  "dappnode/DAppNodeSDK": {
    "fetchedAt": "2025-11-12T22:58:02.754Z",
    "content": "# DAppNodeSDK\n\nThe DappnodeSDK `dappnodesdk` is a tool that makes creating and publishing new Dappnode packages as simple as possible. It helps to initialize, build, test, and publish the new package/repo to an APM tracked on the Ethereum Mainnet.\n\nWe have deployed a public APM (Aragon Package Manager) registry in which anyone can create their own APM repository: [public.dappnode.eth](https://etherscan.io/address/public.dappnode.eth)\n\n## Install\n\n```\n$ npm install -g @dappnode/dappnodesdk\n```\n\n## DEMO\n\n<p align=\"center\"><img src=\"/img/demo.gif?raw=true\"/></p>\n\n## Initialization\n\nThis command runs you through a setup wizard to begin creating the basic files for a new Dappnode Package Repo.\n\n```\n$ dappnodesdk init\n```\n\n## Build\n\nOnly generates the IPFS Hash to be able to install it without needing to create the APM Repo\n\n```\n$ dappnodesdk build\n```\n\n## Publish\n\nIt does the build of the image and shows the necessary transaction to be able to publish the package. The first time will create the repository but the rest will be updates of it.\n\n**To be able to update a repository you must be the authorized dev.**\n\nThe script increases the current version of the repository based on the specified type (patch, minor, major), unless a version hasn't yet been published\n\nFor more information about versioning check [semver](https://semver.org/)\n\n```\n$ dappnodesdk publish < patch | minor | major >\n```\n\nPlease take in account that the _package version_ is not the _internal version_ of the package you want to upload.\nWe use Aragon package manager, and it only allows starting with version 1 and incrementing it one by one. Valid initial versions are `1.0.0`, `0.1.0` or `0.0.1`.\n\n## Troubleshooting\n\nIf your system does not find the binary `dappnodesdk` when running the command, please try the following alternative methods\n\n- Run with `npx` which may handle better global NPM packages\n\n```\nnpx @dappnode/dappnodesdk <command>\n```\n\n- Prefix the binary with the location of your global NPM package installation, for example:\n\n```\n~/.npm-packages/bin/dappnodesdk <command>\n```\n\n## Github Actions\n\n### `bump-upstream` action\n\nThis Github Action automatically creates pull requests bumping the version to the latest released upstream version on DAppNode Packages. It then tests building the new bumped upstream version and automatically posts an IPFS hash if the build was successful so that the new version can be tested further with other Github Actions and by human testers.\n\n_Note: This action also requires a Pinata account with an API Access Token and a Github Personal Access Token stored in the repo's, individual's, or organization's secrets in order to work properly._\n\n#### Sample Usage\n\n`.github/workflows/auto_check.yml`\n\n```yaml\nname: Bump upstream version\n\non:\n  schedule:\n    - cron: \"00 */4 * * *\"\n  push:\n    branches:\n      - \"master\"\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npx @dappnode/dappnodesdk github-action bump-upstream\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PINATA_API_KEY: ${{ secrets.PINATA_API_KEY }}\n          PINATA_SECRET_API_KEY: ${{ secrets.PINATA_SECRET_API_KEY }}\n```\n\nYou must specify in the package manifest what upstream Github repo the package is tracking. Also indicate what build variable in the docker-compose file should be updated.\n\n`dappnode_package.json`\n\n```json\n{\n  \"name\": \"prysm.dnp.dappnode.eth\",\n  \"upstreamVersion\": \"v1.0.0\",\n  \"upstreamRepo\": \"prysmaticlabs/prysm\",\n  \"upstreamArg\": \"UPSTREAM_VERSION\"\n}\n```\n\n`docker-compose.yml`\n\n```yaml\nversion: \"3.4\"\nservices:\n  beacon-chain:\n    build:\n      args:\n        UPSTREAM_VERSION: v1.0.0\n```\n\n## Internal dependencies\n\nThe dappnode SDK ueses the following internal dependencies to avoid code duplication across the `dappnodeSDK`, `DNP_DAPPMANAGER` and `sdk-publish` modules:\n\n- `@dappnode/types`\n- `@dappnode/toolkit`\n- `@dappnode/schemas`\n\nIn order to have a better developing experience these modules lives inside the DNP_DAPPMANAGER repository\n\n## License\n\nThis project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details\n"
  },
  "dappnode/DAppNode": {
    "fetchedAt": "2025-11-12T22:58:03.040Z",
    "content": "# DAppNode\n\n[![Website dappnode.io](https://img.shields.io/badge/Website-dappnode.io-brightgreen.svg)](https://dappnode.io/)\n[![Documentation Wiki](https://img.shields.io/badge/Documentation-Wiki-brightgreen.svg)](https://docs.dappnode.io)\n[![GIVETH Campaign](https://img.shields.io/badge/GIVETH-Campaign-1e083c.svg)](https://beta.giveth.io/campaigns/5b44b198647f33526e67c262)\n![GitHub All Releases](https://img.shields.io/github/downloads/dappnode/DAppNode/total.svg)\n[![GitPOAP Badge](https://public-api.gitpoap.io/v1/repo/dappnode/DAppNode/badge)](https://www.gitpoap.io/gh/dappnode/DAppNode)\n[![Twitter Follow](https://img.shields.io/twitter/follow/espadrine.svg?style=social&label=Follow)](https://twitter.com/DAppNODE?lang=es)\n[![Discord](https://img.shields.io/discord/747647430450741309?logo=discord&style=plastic)](https://discord.gg/dappnode)\n\n\n\n<br/>\n<p align=\"center\">\n  <a href=\"https://dappnode.com/\">\n    <img width=\"800\" src=\"doc/DAppNodeLogoWide-outlined.png\">\n  </a>\n</p>\n<br/>\n<p align=\"center\">\n  <a href=\"https://docs.dappnode.io/docs/user/install/overview\">\n    <img width=\"200\" src=\"doc/DappnodeInstall.png\">\n  </a>\n</p>\n<br/>\n\n## Infrastructure for the decentralized world\n\nDAppNode is empowering people by creating a simple, transparent system for hosting P2P clients for DApps, Cryptocurrencies, VPNs, IPFS and more\n\n- Read about our purpose and mission on [Our Website](https://dappnode.com/)\n- Join our community and find support on [Our Discord](https://discord.gg/dappnode)\n- Check out what we are up to on [Our Medium](https://medium.com/dappnode)\n- Share your ideas and find how to guides on [Our Forum](https://discourse.dappnode.io/)\n\n## Discover DAppNode\n\nDAppNode lowers the barrier of entry for non tech-savvy participants. It allows you to deploy, update, and manage P2P clients and nodes without leaving your browser. No terminal or command line interface.\n\n<p align=\"center\">\n  <a href=\"https://docs.dappnode.io/docs/user/install/overview\">\n    <img width=\"800\" src=\"doc/DAppNodeAdminUI-demo.png\">\n  </a>\n</p>\n\n## Develop with DAppNode\n\nDAppNode modular architecture allows any team to or project to publish a dockerized application to the DAppNode packages eco-system. Benefit from an enthusiastic crypto savvy user based and offer a user interface-only experience to lower onboarding friction.\n\nCheck out the [DAppNodeSDK](https://github.com/dappnode/DAppNodeSDK) to learn how to get started.\n\n_Note: packages are published to Ethereum mainnet and incur costs. Given the current high gas prices the DAppNode team is willing to subsidize gas costs for packages of great interest to users._\n\n## Packages eco-system\n\nThe community and core team members have created many useful packages for users. Checkout the [**package explorer**](https://explorer.dappnode.io) to browse an up-to-date list of all packages and their versions.\n\n<p align=\"center\">\n  <a href=\"https://explorer.dappnode.io\">\n    <img width=\"600\" src=\"doc/DAppNodeExplorer.png\">\n  </a>\n</p>\n\n### Champions\n\nChampions are community members that are in charge of maintaining packages: keeping them updated and working. All packages in this list without a champion are actively looking for a champion. Join our [DAppNode Discord **#champion-process**](https://discord.gg/dappnode) to suggest a package to be championed and/or offer to be a champion for a project you care about!\n\n| Package                                                                                  | Champion         |\n| ---------------------------------------------------------------------------------------- | ---------------- |\n| [Avalanche](https://github.com/Colm3na/DAppNodePackage-avalanche)                        | Wimel            |\n| [ARTIS-sigma1](https://github.com/lab10-coop/DAppNodePackage-ARTIS-sigma1)               | -                |\n| [Bee](https://github.com/dappnode/DAppNodePackage-bee)                                   | @tropicar        |\n| [Bitcoin](https://github.com/dappnode/DAppNodePackage-bitcoin)                           | @Pol-Lanski      |\n| [Block-explorer](https://github.com/dappnode/DappnodePackage-block-explorer)             | -                |\n| [Cosmos](https://github.com/Colm3na/DAppNodePackage-cosmos)                              | Wimel            |\n| [DMS](https://github.com/dappnode/DAppNodePackage-DMS)                                   | @eduadiez        |\n| [Eth2stats-client](https://github.com/dappnode/DAppNodePackage-eth2stats-client)         | -                |\n| [Ethereum Classic](https://github.com/dappnode/DAppNodePackage-ethereum-classic)         | -                |\n| [Ethereum Optimism](https://github.com/dappnode/DAppNodePackage-ethereum-optimism)       | -                |\n| [Exporter](https://github.com/dappnode/DAppNodePackage-exporter)                         | @eduadiez        |\n| [Geth](https://github.com/dappnode/DAppNodePackage-geth)                                 | @pablomendezroyo |\n| [Goerli Geth](https://github.com/dappnode/DAppNodePackage-goerli-geth)                   | @pablomendezroyo |\n| [HTTPs Portal](https://github.com/dappnode/DAppNodePackage-https-portal)                 | @3alpha          |\n| [Ipfs Cluster](https://github.com/dappnode/DAppNodePackage-ipfs-cluster)                 | @dapplion        |\n| [Ipfs Pinner](https://github.com/dappnode/DAppNodePackage-ipfs-pinner)                   | @dapplion        |\n| [Kovan](https://github.com/dappnode/DAppNodePackage-kovan)                               | @pablomendezroyo |\n| [LightningNetwork](https://github.com/dappnode/DAppNodePackage-LightningNetwork)         | @pablomendezroyo |\n| [Matrix](https://github.com/dappnode/DAppNodePackage-matrix)                             | -                |\n| [Metrics Tools](https://github.com/dappnode/DAppNodePackage-metrics-tools)               | @eduadiez        |\n| [Monero](https://github.com/dappnode/DAppNodePackage-monero)                             | @pablomendezroyo |\n| [Nethermind](https://github.com/dappnode/DAppNodePackage-nethermind)                     | @pablomendezroyo |\n| [Openethereum](https://github.com/dappnode/DAppNodePackage-openethereum)                 | @pablomendezroyo |\n| [Owncloud](https://github.com/dappnode/DAppNodePackage-owncloud)                         | @tropicar        |\n| Polkadot Kusama                                                                          | -                |\n| [Prysm](https://github.com/dappnode/DAppNodePackage-prysm)                               | @pablomendezroyo |\n| [Prysm Pyrmont](https://github.com/dappnode/DAppNodePackage-prysm-pyrmont)               | @pablomendezroyo |\n| [Raiden](https://github.com/dappnode/DAppNodePackage-raiden)                             | @eduadiez        |\n| [Raiden Testnet](https://github.com/dappnode/DAppnodePackage-raiden-testnet)             | @eduadiez        |\n| [Rinkeby](https://github.com/dappnode/DAppNodePackage-rinkeby)                           | @pablomendezroyo |\n| [Ropsten](https://github.com/dappnode/DAppNodePackage-ropsten)                           | @pablomendezroyo |\n| [Storj](https://github.com/dappnode/DAppNodePackage-storj)                               | @pablomendezroyo |\n| [Tornado Cash Relayer](https://github.com/dappnode/DAppNodePackage-Tornado-Cash-Relayer) | -                |\n| [Trustlines](https://github.com/dappnode/DAppNodePackage-trustlines)                     | -                |\n| [Turbo-geth](https://github.com/dappnode/DAppNodePackage-turbo-geth)                     | @gnidan          |\n| [Vipnode](https://github.com/dappnode/DAppNodePackage-vipnode)                           | -                |\n| [Wireguard](https://github.com/dappnode/DAppNodePackage-wireguard)                       | @3alpha          |\n| [ZCash](https://github.com/dappnode/DAppNodePackage-zcash)                               | -                |\n\n## Core packages\n\n- [DNP_DAPPMANAGER](https://github.com/dappnode/DNP_DAPPMANAGER)\n- [DNP_VPN](https://github.com/dappnode/DNP_VPN)\n- [DNP\n\n[... truncated ...]"
  },
  "Pfed-prog/EVMExplorer-Blockscout": {
    "fetchedAt": "2025-11-12T22:58:10.566Z",
    "content": "# EVMExplorer-Blockscout\n\n[EVM Explorer](https://evmexplorer.com) TypeScript Blockscout v2 sdk.\n\n## üìö Install\n\n```bash\nnpm install @evmexplorer/blockscout\n```\n\nor\n\n```bash\nyarn add @evmexplorer/blockscout\n```\n\n## Using EVMExplorer-Blockscout SDK\n\n### Fetching a Transaction\n\nTo fetch a transaction on Ethereum mainnet as demonstrated on [Ethereum Stack Oveflow answer](https://ethereum.stackexchange.com/a/167002/79075):\n\n```ts\nimport type { TransactionBlockscout } from '@evmexplorer/blockscout';\nimport { fetchTransactionBlockscout } from '@evmexplorer/blockscout';\n\nconst data: TransactionBlockscout = await fetchTransactionBlockscout(\n  '0xdc7ddf3d0e53532eeeda7a7a99c88255ccee5a3b4404441278cbbd79b4c85086',\n);\n\nconsole.log(data);\n```\n\n### Output\n\nThe `fetchTransactionBlockscout` function returns an object with the following properties:\n\n```yaml\n{\n  priority_fee: '70439166556560',\n  tx_burnt_fee: '676806248593230',\n  raw_input: '0xa22cb4650000000000000000000000001e0049783f008a0085193e00003d00cd54003c710000000000000000000000000000000000000000000000000000000000000001',\n  result: 'success',\n  hash: '0xdc7ddf3d0e53532eeeda7a7a99c88255ccee5a3b4404441278cbbd79b4c85086',\n  max_fee_per_gas: '15917702655',\n  revert_reason: null,\n  confirmation_duration: [0, 12000],\n  type: 2,\n  token_transfers_overflow: false,\n  confirmations: 47513,\n  position: 72,\n  max_priority_fee_per_gas: '1267119384',\n  transaction_tag: null,\n  created_contract: null,\n  value: '0',\n  tx_types: ['contract_call'],\n  from:\n    {\n      ens_domain_name: null,\n      hash: '0xA3b711752f08980F4a71777217FA81304aEB8ee7',\n      implementations: [],\n      is_contract: false,\n      is_scam: false,\n      is_verified: false,\n      metadata: null,\n      name: null,\n      private_tags: [],\n      proxy_type: null,\n      public_tags: [],\n      watchlist_names: [],\n    },\n  gas_used: '55590',\n  status: 'ok',\n  to:\n    {\n      ens_domain_name: null,\n      hash: '0x22C1f6050E56d2876009903609a2cC3fEf83B415',\n      implementations: [[Object]],\n      is_contract: true,\n      is_scam: false,\n      is_verified: true,\n      metadata: { tags: [Array] },\n      name: 'AdminUpgradeabilityProxy',\n      private_tags: [],\n      proxy_type: 'eip1967',\n      public_tags: [],\n      watchlist_names: [],\n    },\n  authorization_list: [],\n  method: 'setApprovalForAll',\n  fee: { type: 'actual', value: '747245415149790' },\n  tx_tag: null,\n  actions: [],\n  gas_limit: '73310',\n  gas_price: '13442083381',\n  decoded_input:\n    {\n      method_call: 'setApprovalForAll(address to, bool approved)',\n      method_id: 'a22cb465',\n      parameters: [[Object], [Object]],\n    },\n  has_error_in_internal_txs: false,\n  token_transfers: [],\n  base_fee_per_gas: '12174963997',\n  timestamp: '2024-12-08T17:44:23.000000Z',\n  nonce: 464,\n  block: 21359346,\n  transaction_types: ['contract_call'],\n  exchange_rate: '3859.75',\n  block_number: 21359346,\n  has_error_in_internal_transactions: false,\n}\n```\n\nYou can also go over the transaction visually at [EVM Explorer transaction page](https://evmexplorer.com/transactions/mainnet/0xdc7ddf3d0e53532eeeda7a7a99c88255ccee5a3b4404441278cbbd79b4c85086).\n\n### Fetching Vitalik's Address Tokens\n\nYou can also query the blockchain address token balances as demonstrated on [Stack Overflow](https://stackoverflow.com/a/79314959/13943679). For example, let's query [Vitalik's balances](https://evmexplorer.com/contracts/mainnet/0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045):\n\n```js\nexport type { AddressTokens } from \"@evmexplorer/blockscout\";\nexport { fetchTokensAddress } from \"@evmexplorer/blockscout\";\n\nconst data: AddressTokens = await fetchTokensAddress(\n  '0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045',\n);\nconsole.log(data.length)\nconsole.log(data[0])\n```\n\n### Address Tokens Output\n\n```yaml\n6081\n{\n  token: {\n    address: '0x28561B8A2360F463011c16b6Cc0B0cbEF8dbBcad',\n    circulating_market_cap: '75858317.61202328',\n    decimals: '9',\n    exchange_rate: '0.00017784',\n    holders: '14334',\n    icon_url: 'https://assets.coingecko.com/coins/images/50348/small/1000000612.jpg?1727248974',\n    name: 'MOO DENG',\n    symbol: 'MOODENG',\n    total_supply: '420690000000000000000',\n    type: 'ERC-20',\n    volume_24h: '10219755.637613483'\n  },\n  token_id: null,\n  token_instance: null,\n  value: '30000105889157756560'\n}\n```\n\nVitalik has 6081 tokens. The first token in the array of all 6081 tokens is [Moo Deng token](https://evmexplorer.com/contracts/mainnet/0x28561B8A2360F463011c16b6Cc0B0cbEF8dbBcad).\n\n## Fetching Latest Block Transactions\n\nYou can also query the latest block transactions with `Ethers` provider as demonstrated on [Stack Overflow](https://stackoverflow.com/a/79361865/13943679).\n\n```js\nimport { fetchBlockTransactionsBlockscout } from '@evmexplorer/blockscout';\nconst block = await provider.getBlock();\nconst data = await fetchBlockTransactionsBlockscout(block);\n```\n\n## More information\n\n[EVM Explorer - Tracking Smart Contract Transaction Data](https://dspyt.com/evmexplorer)\n\n[Blockscout - Ethereum API documentation](https://eth.blockscout.com/api-docs)\n\n[Blockscout - REST API Endpoints](https://docs.blockscout.com/devs/apis/rest)\n"
  },
  "Pfed-prog/EVMExplorer-Uniswap": {
    "fetchedAt": "2025-11-12T22:58:10.963Z",
    "content": "# EVMExplorer-Uniswap\n\n[EVM Explorer](https://evmexplorer.com) TypeScript Uniswap v3 SDK.\n\n## üì¶ Install\n\n```bash\nnpm install @evmexplorer/uniswap\n```\n\nor\n\n```bash\nyarn add @evmexplorer/uniswap\n```\n\n## üöÄ Features\n\n- Fetch USD price quotes for various tokens on Uniswap V3.\n- Easily integrated with Ethers.js for Ethereum network interactions.\n- Simple TypeScript API with clear typings for improved developer experience.\n\n## Example usage\n\nTo get a quote of [AAVE token](https://evmexplorer.com/contracts/mainnet/0x7Fc66500c84A76Ad7e9c93437bFc5Ac33E2DDaE9) price in USD from Uniswap V3:\n\n```ts\nimport { getQuoteUniswapUSD } from '@evmexplorer/uniswap';\nimport { AlchemyProvider } from 'ethers';\nimport dotenv from 'dotenv';\n\ndotenv.config();\n\nconst api = process.env.API;\nconst provider = new AlchemyProvider('mainnet', api);\n\nconst tokenData = {\n  address: '0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9',\n  decimals: 18,\n  chainId: 1,\n};\n\nconst exchangeRateWETH = '3920.84';\n\nconst result = await getQuoteUniswapUSD(tokenData, provider, exchangeRateWETH);\n```\n\n### üåø Notes\n\n- Ensure you have an Alchemy API key, which can be obtained by signing up on the Alchemy website.\n- Update the `exchangeRateWETH` variable with the current price for accurate results. This can be sourced dynamically from price feeds or exchanges.\n\n## More information\n\n[EVM Explorer - Tracking Smart Contract Transaction Data](https://dspyt.com/evmexplorer)\n\n[Understanding Slot0 Data](https://stackoverflow.com/a/79280489/13943679)\n"
  },
  "Pfed-prog/EVMExplorer-Utility": {
    "fetchedAt": "2025-11-12T22:58:11.569Z",
    "content": "# EVMExplorer-Utilities\n\n[EVM Explorer](https://evmexplorer.com) TypeScript utility sdk.\n\n## üìö Install\n\n```bash\nnpm install @evmexplorer/utility\n```\n\nor\n\n```bash\nyarn add @evmexplorer/utility\n```\n\n## More information\n\n[EVM Explorer - Tracking Smart Contract Transaction Data](https://dspyt.com/evmexplorer)\n"
  },
  "Pfed-prog/NextJsExplorer": {
    "fetchedAt": "2025-11-12T22:58:11.903Z",
    "content": "# NextJs EVM Explorer\n\n![Welcome Page](https://github.com/Pfed-prog/NextJsExplorer/blob/main/assets/evmexplorer.png)\n\n## Features\n\n- Address Search: the application allows users to search for Ethereum contracts by their address on 9 evm chains: ethereum mainnet, optimism, base, mode network, zora, redstone, polygon, arbitrum and filecoin.\n\n- Address Page Balance Data: token logo, native token balance in USD, token name, contract implementation name, ENS associated name or address hash.\n\n  - Token Data: value of 1 token in USD, holders number, 24h volume in USD, 24h volume % of market cap, market cap in USD.\n\n- Address Page Smart Contract Statistics: aggregate data for total `Gas usage`, `Token transfers` count, `Transactions` count, `Average Gas per Transaction` and `Validations` count.\n\n- Address Page Transactions: users can view 50 latest transactions associated with an address, including their receiver, sender, contract method called, eth or matic value, fees and gas used.\n\n  - Fees: display gas fee cost in USD.\n  - Transaction Method and Type: colored to reflect the mix of coin transfer, token transfer and contract call.\n\n- Blocks page: block miner and date. Aggregate data for total `Gas usage`, `Transactions` count and `Average Gas per Transaction`. Display all the transactions in the block with their receiver, sender, gas used and value in USD.\n\n  - Token Transfers\n\n- Transaction page: block number, transaction type, receiver, contract method call details, sender, gas used in USD and token transfers details.\n\nOverall, EVM Explorer simplifies the process of exploring Ethereum contracts and their associated data. It provides a user-friendly interface that allows users to quickly and easily access important information about contracts.\n\n## Development\n\n`yarn`\n\n`yarn dev`\n\n## Features in Progress\n\n- Current state: The application displays all the current states for a contract.\n\nThis can only work for verified contracts. `Smart-contracts` endpoint in blockscout.\n\n[Smart contract state](https://ethereum.stackexchange.com/questions/159456/extract-read-write-set-of-state-variables-from-a-smart-contract)\n\n[Machine translation-based fine-grained comments generation for solidity smart contracts](https://www.sciencedirect.com/science/article/abs/pii/S0950584922001744)\n\n- Display tokens on contracts page\n\n## Further Information\n\n[Blockscout being open-source and having a token balances sdk](https://stackoverflow.com/a/79314977/13943679)\n\n[BlockScout Chains](https://www.blockscout.com/chains-and-projects)\n\n### BlockScout Bugs and Feature Requests\n\n- [BlockScout Tx API Feedback request](https://blockscout.canny.io/feedback/p/what-is-the-meaning-behind-tx-api-outputs)\n\n- [BlockScout Contract Counters Bugs](https://blockscout.canny.io/feedback/p/contract-counters-bugs)\n\n- [Add Explicit Pagination in get requests](https://blockscout.canny.io/feature-requests/p/add-explicit-pagination-in-get-requests)\n\n#### Rest API Bugs\n\n[Duplciate transactions](https://blockscout.canny.io/feedback/p/duplicate-variables-when-fetching-transactions) and linked [rest api issue in docs](https://github.com/blockscout/docs/issues/366)\n\n### Etherscan\n\n- [Etherscan is considered the notary for validating contract source-code matches bytecode](https://x.com/dmihal/status/1791622407653904880)\n\n- [Etherscan goes down & Blockscout steps up](https://www.blog.blockscout.com/blockscout-news-april-2024/)\n\n### TrueBlocks\n\n- [Getting started with TrueBlocks](https://github.com/TrueBlocks/trueblocks-core/issues/3700)\n\n- [Exporting detailed data from indexer: 429 too many requests](https://github.com/TrueBlocks/trueblocks-core/issues/3703)\n\n### Viem\n\n- [Added new Chain Configuration: Redstone](https://github.com/wevm/viem/pull/2315)\n\n- [Found bug: useEthersProvider Example TS error](https://github.com/wevm/wagmi/issues/3923)\n\n### Other Useful Resources\n\n- [ENS Deployments](https://docs.ens.domains/learn/deployments)\n\n- [ChainList is a list of EVM networks](https://chainlist.org/)\n\n- [Bitcoin and Ethereum Lack Data Range Search Functionality?](https://ingeun92.medium.com/bitcoin-and-ethereum-lack-data-range-search-functionality-41acfa1f5279)\n\n- [DeFi Llama API](https://defillama.com/docs/api)\n"
  },
  "PinSaveDAO/PinSave": {
    "fetchedAt": "2025-11-12T22:58:19.897Z",
    "content": "# Pin Save - decentralized Pinterest\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Pfed-prog/Dspyt-NFTs-EVM/master/assets/PinSaveL.png\" alt=\"Size Limit CLI\" width=\"738\" >\n</p>\n\n<p align=\"center\">\n    <a href=\"https://twitter.com/intent/follow?screen_name=pinsav3\">\n        <img src=\"https://img.shields.io/twitter/follow/pinsav3?style=social\"\n            alt=\"follow on Twitter\"></a>\n</p>\n\n<div align=\"center\">\n\n[Features](#features) ‚Ä¢\n[Setup](#setup) ‚Ä¢\n[Resources](#further-resources)\n\n</div>\n\nPin Save is a decentralized image and content aggregation platform where users can not only control the content but also the platform itself.\n\n1. The decentralized feed reinforces the discovery of content and feedback.\n2. Decentralized Identity, which provides anonymity and data protection.\n3. Upgradeable, resilient, and open decentralized storage.\n4. Smart contracts to securely serve web experiences directly to users.\n\n## Features\n\n- Mina, first zk-blockhain, smart contracts.\n\n  1. NFTContract to mint and transfer nfts.\n  2. SwapContract to buy, sell and swap nfts.\n\n- Mina Merkle Trees.\n\n- NextJS API to obtain adminSignatures.\n\n- NextJS API routes save requested data to Vercel Redis Database.\n\n  1. Main schema that stores data for a MerkleMap with the same root as on-chain contract.\n  2. Pending schema that tracks submitted transactions and promotes the data to main schema.\n  3. Admin Signed schema that tracks admin signed data.\n\n- Decentralized feed of NFTs:\n\n![Pin Save decentralized feed](https://github.com/Pfed-prog/Dspyt-NFTs-EVM/blob/master/assets/feed.png)\n\n- Image posting:\n\n![Pin Save Upload](https://github.com/Pfed-prog/Dspyt-NFTs-EVM/blob/master/assets/upload.png)\n\n- Decentralized post comments verified with Auro Wallet:\n\n![Pin Save Post](https://github.com/Pfed-prog/Dspyt-NFTs-EVM/blob/master/assets/post.png)\n\n## Setup\n\nTo run this project and start the project in development mode, install it locally using `yarn` and run `yarn dev`:\n\n```bash\nyarn\nyarn dev\n```\n\n## Further Resources\n\n- [PinSave Figma Resources](https://www.figma.com/community/file/1102944149244783025)\n- [Pin Save on zkok](https://zkok.io/mina/pin-save/)\n- [Npm Pin Save mina package](https://www.npmjs.com/package/pin-mina)\n- [EthBucharest 2024: Zero Knowledge proofs on Mina, zkPassport and SoulBound NFTs](https://docs.google.com/presentation/d/1OmJJgzk4iFbKexqBw87oU7oh4H9lXlFFh3eas0EF9y8/edit?usp=sharing)\n- [PinSave.app DR](https://ahrefs.com/website-authority-checker/?input=pinsave.app)\n"
  },
  "PinSaveDAO/PinSave-EVM": {
    "fetchedAt": "2025-11-12T22:58:20.295Z",
    "content": "# Pin Save - decentralized Pinterest\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Pfed-prog/Dspyt-NFTs-EVM/master/packages/frontend/public/PinSaveL.png\" alt=\"Size Limit CLI\" width=\"738\" >\n</p>\n\n<p align=\"center\">\n    <a href=\"https://twitter.com/intent/follow?screen_name=pinsav3\">\n        <img src=\"https://img.shields.io/twitter/follow/pinsav3?style=social\"\n            alt=\"follow on Twitter\"></a>\n</p>\n\n<div align=\"center\">\n\n[Features](#features) ‚Ä¢\n[Setup](#setup) ‚Ä¢\n[Resources](#further-resources)\n\n</div>\n\nPin Save is a decentralized image, video sharing and content aggregation platform where community controls the platform.\n\n1. The decentralized feed reinforces the discovery of content and feedback.\n2. Decentralized Identity provides anonymity and data protection.\n3. Upgradeable, resilient decentralized storage.\n4. Smart contracts to securely serve web experiences directly to users.\n\n## Features\n\n- Decentralized feed of NFTs on Optimism chain with decentralized storage on IPFS with NFTPort, Estuary and Nft.storage:\n\n![decentralized feed](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/feed.png)\n\n- Decentralized comments section on orbis, ceramic and ipfs connected to a decentralized Pin Save identity, decentralized Pin Save post and ENS:\n\n![decentralized comments](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/comments.png)\n\n- Decentralized Profile:\n\n![decentralized Profile](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/profile.png)\n\n- Decentralized Profile ENS resolution:\n\n![Pin Save ENS resolution Profile](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/ensProfile.png)\n\n- Pin Save update your profile page:\n\n![Pin Save update your profile page](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/updateProfile.png)\n\n- Video and Image posting:\n\n![Pin Save Upload](https://bafybeiaj46fxgxax6z3nd45n7p42rh7dbyweyssi3dunr3wfewh7ys2d7y.ipfs.nftstorage.link/)\n\n- Livepeer Video Player:\n\n![Video Player](https://bafybeiacg6yoxvxvk2ayugwlcfnnjpm5kcchvy3t2fl7mu64ft4zt4fs6m.ipfs.nftstorage.link/)\n\n### Optimism Smart contracts\n\n[Optimism Smart contract Etherscan](https://optimistic.etherscan.io/address/0x40F320CD3Cd616E59599568c4eA011E2eE49a175#code)\n\n[PinSave on EVM Explorer](https://evmexplorer.com/contracts/optimism/0x40F320CD3Cd616E59599568c4eA011E2eE49a175)\n\n### Ceramic Orbis Context\n\n[More information about Orbis Contexts](https://docs.useorbis.com/docs/primitives/contexts)\n\n[Ceramic Scan Indexer Stream Data](https://cerscan.com/mainnet/stream/kjzl6cwe1jw147hcck185xfdlrxq9zv0y0hoa6shzskqfnio56lhf8190yaei7w)\n\n## Setup\n\nTo run this project and start the project in development mode, install it locally using `yarn` and run `yarn dev`:\n\n```bash\nyarn\nyarn dev\n```\n\n## Latest Updates\n\n- Integrated ENS Name and Avatar resolver on Profile Display. [luc.eth profile](https://evm.pinsave.app/profile/0x225f137127d9067788314bc7fcc1f36746a3c3B5).\n- Integrated ENS useEnsAddress hook from wagmi on upload page.\n- Built API route and React-Query for Pin Save Comments.\n- Built React Context for Orbis Client.\n- Enhanced page to update your Profile.\n- Refactoring Orbis types.\n- Removed faulty Lit Orbis encryption.\n- Connected Vercel Analytics.\n- Built SEO Component and connected on every page.\n- Fixed NFTPort as ipfs provider.\n\n## Further Resources\n\n- [PinSave Figma Resources](https://www.figma.com/community/file/1102944149244783025)\n- [Zk Ok Pin Save](https://zkok.io/mina/pin-save/)\n- [EthBucharest 2024: Zero Knowledge proofs on Mina, zkPassport and SoulBound NFTs](https://docs.google.com/presentation/d/1OmJJgzk4iFbKexqBw87oU7oh4H9lXlFFh3eas0EF9y8/edit?usp=sharing)\n- [PinSave.app DR](https://ahrefs.com/website-authority-checker/?input=pinsave.app)\n- [Npm Pin Save mina package](https://www.npmjs.com/package/pin-mina)\n- [Pin Save on Dspyt](https://dspyt.com/PinSave)\n- [Pin Save retroPGF3](https://round3.optimism.io/projects/0xc613e2a991ce0dbcf8fae1d6128e67543da9710e14831112fba654cc8fe8c389)\n\n## RoadMap\n\nWe are at the stage where we need to improve read and write speeds for the content on PinSave.\n\nOur Roadmap includes:\n\n- Further enhancing SEO\n- Fixing faulty Dweb ipfs provider\n- Adding more Ipfs providers\n- Researching further erc 725 contract and available registry contracts\n- Deploying erc 725 contract once again and syncing orbis profiles\n- Improving Upload page with batch mint\n- Improving Upload page UX and UI\n- Improving posts contract to contain function to display metadata\n- Deploying PinSavePosts Contract V2 that contains function:\n  - metadata function supported by marketplaces such as OpenSea\n  - add new function similar to `tokenIdsOf` return uint instead of bytes\n  - add a function to query posts by `bytes` `tokenId`\n\nSome interesting links for developers:\n\n- [Practical React Query](https://tkdodo.eu/blog/practical-react-query)\n- [next/image](https://nextjs.org/docs/api-reference/next/image)\n- [Next Js ISG](https://nextjs.org/docs/basic-features/data-fetching/incremental-static-regeneration)\n- [Universal Profiles](https://docs.lukso.tech/standards/universal-profile/introduction)\n- [Working with Lit Access Control](https://litproject.substack.com/p/working-with-access-control)\n- [Lit Supported Blockchains](https://developer.litprotocol.com/support/supportedchains/)\n"
  },
  "Pfed-prog/Dspyt-NFTs-EVM": {
    "fetchedAt": "2025-11-12T22:58:20.680Z",
    "content": "# Pin Save - decentralized Pinterest\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Pfed-prog/Dspyt-NFTs-EVM/master/assets/PinSaveL.png\" alt=\"Size Limit CLI\" width=\"738\" >\n</p>\n\n<p align=\"center\">\n    <a href=\"https://twitter.com/intent/follow?screen_name=pinsav3\">\n        <img src=\"https://img.shields.io/twitter/follow/pinsav3?style=social\"\n            alt=\"follow on Twitter\"></a>\n</p>\n\n<div align=\"center\">\n\n[Features](#features) ‚Ä¢\n[Setup](#setup) ‚Ä¢\n[Resources](#further-resources)\n\n</div>\n\nPin Save is a decentralized image and content aggregation platform where users can not only control the content but also the platform itself.\n\n1. The decentralized feed reinforces the discovery of content and feedback.\n2. Decentralized Identity, which provides anonymity and data protection.\n3. Upgradeable, resilient, and open decentralized storage.\n4. Smart contracts to securely serve web experiences directly to users.\n\n## Features\n\n- Mina, first zk-blockhain, smart contracts.\n\n  1. NFTContract to mint and transfer nfts.\n  2. SwapContract to buy, sell and swap nfts.\n\n- Mina Merkle Trees.\n\n- NextJS API to obtain adminSignatures.\n\n- NextJS API routes save requested data to Vercel Redis Database.\n\n  1. Main schema that stores data for a MerkleMap with the same root as on-chain contract.\n  2. Pending schema that tracks submitted transactions and promotes the data to main schema.\n  3. Admin Signed schema that tracks admin signed data.\n\n- Decentralized feed of NFTs:\n\n![Pin Save decentralized feed](https://github.com/Pfed-prog/Dspyt-NFTs-EVM/blob/master/assets/feed.png)\n\n- Image posting:\n\n![Pin Save Upload](https://github.com/Pfed-prog/Dspyt-NFTs-EVM/blob/master/assets/upload.png)\n\n- Decentralized post comments verified with Auro Wallet:\n\n![Pin Save Post](https://github.com/Pfed-prog/Dspyt-NFTs-EVM/blob/master/assets/post.png)\n\n## Setup\n\nTo run this project and start the project in development mode, install it locally using `yarn` and run `yarn dev`:\n\n```bash\nyarn\nyarn dev\n```\n\n## Further Resources\n\n- [PinSave Figma Resources](https://www.figma.com/community/file/1102944149244783025)\n- [Pin Save on zkok](https://zkok.io/mina/pin-save/)\n- [Npm Pin Save mina package](https://www.npmjs.com/package/pin-mina)\n- [EthBucharest 2024: Zero Knowledge proofs on Mina, zkPassport and SoulBound NFTs](https://docs.google.com/presentation/d/1OmJJgzk4iFbKexqBw87oU7oh4H9lXlFFh3eas0EF9y8/edit?usp=sharing)\n- [PinSave.app DR](https://ahrefs.com/website-authority-checker/?input=pinsave.app)\n"
  },
  "PinSaveDAO/PinSave-Optimism": {
    "fetchedAt": "2025-11-12T22:58:21.106Z",
    "content": "# PinSave - decentralized Pinterest\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Pfed-prog/Dspyt-NFTs-EVM/master/packages/frontend/public/PinSaveL.png\" alt=\"Size Limit CLI\" width=\"738\" >\n</p>\n\n<p align=\"center\">\n    <a href=\"https://twitter.com/intent/follow?screen_name=pinsav3\">\n        <img src=\"https://img.shields.io/twitter/follow/pinsav3?style=social\"\n            alt=\"follow on Twitter\"></a>\n</p>\n\n<div align=\"center\">\n\n[Features](#features) ‚Ä¢\n[Setup](#setup) ‚Ä¢\n[Resources](#further-resources)\n\n</div>\n\nPinSave is a decentralized image, video sharing and content aggregation platform where community controls the platform.\n\n1. The decentralized feed reinforces the discovery of content and feedback.\n2. Decentralized Identity provides anonymity and data protection.\n3. Upgradeable, resilient decentralized storage.\n4. Smart contracts to securely serve web experiences directly to users.\n\n## Features\n\n- Decentralized feed of NFTs on Optimism chain with decentralized storage on IPFS with NFTPort, Estuary and Nft.storage:\n\n![decentralized feed](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/feed.png)\n\n- Decentralized comments section on orbis, ceramic and ipfs connected to a decentralized Pin Save identity, decentralized Pin Save post and ENS:\n\n![decentralized comments](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/comments.png)\n\n- Decentralized Profile:\n\n![decentralized Profile](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/profile.png)\n\n- Decentralized Profile ENS resolution:\n\n![Pin Save ENS resolution Profile](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/ensProfile.png)\n\n- Pin Save update your profile page:\n\n![Pin Save update your profile page](https://raw.githubusercontent.com/PinSaveDAO/PinSave-EVM/evm/assets/updateProfile.png)\n\n- Video and Image posting:\n\n![Pin Save Upload](https://bafybeiaj46fxgxax6z3nd45n7p42rh7dbyweyssi3dunr3wfewh7ys2d7y.ipfs.nftstorage.link/)\n\n- Livepeer Video Player:\n\n![Video Player](https://bafybeiacg6yoxvxvk2ayugwlcfnnjpm5kcchvy3t2fl7mu64ft4zt4fs6m.ipfs.nftstorage.link/)\n\n### Optimism Smart contracts\n\n[Optimism Smart contract Etherscan](https://optimistic.etherscan.io/address/0x40F320CD3Cd616E59599568c4eA011E2eE49a175#code)\n\n[PinSave on EVM Explorer](https://evmexplorer.com/contracts/optimism/0x40F320CD3Cd616E59599568c4eA011E2eE49a175)\n\n### Ceramic Orbis Context\n\n[More information about Orbis Contexts](https://docs.useorbis.com/docs/primitives/contexts)\n\n[Ceramic Scan Indexer Stream Data](https://cerscan.com/mainnet/stream/kjzl6cwe1jw147hcck185xfdlrxq9zv0y0hoa6shzskqfnio56lhf8190yaei7w)\n\n## Setup\n\nTo run this project and start the project in development mode, install it locally using `yarn` and run `yarn dev`:\n\n```bash\nyarn\nyarn dev\n```\n\n## Latest Updates\n\n- Integrated ENS Name and Avatar resolver on Profile Display. [luc.eth profile](https://evm.pinsave.app/profile/0x225f137127d9067788314bc7fcc1f36746a3c3B5).\n- Integrated ENS useEnsAddress hook from wagmi on upload page.\n- Built API route and React-Query for Pin Save Comments.\n- Built React Context for Orbis Client.\n- Enhanced page to update your Profile.\n- Refactoring Orbis types.\n- Removed faulty Lit Orbis encryption.\n- Connected Vercel Analytics.\n- Built SEO Component and connected on every page.\n- Fixed NFTPort as ipfs provider.\n\n## Further Resources\n\n- [PinSave Figma Resources](https://www.figma.com/community/file/1102944149244783025)\n- [Zk Ok Pin Save](https://zkok.io/mina/pin-save/)\n- [EthBucharest 2024: Zero Knowledge proofs on Mina, zkPassport and SoulBound NFTs](https://docs.google.com/presentation/d/1OmJJgzk4iFbKexqBw87oU7oh4H9lXlFFh3eas0EF9y8/edit?usp=sharing)\n- [PinSave.app DR](https://ahrefs.com/website-authority-checker/?input=pinsave.app)\n- [Npm Pin Save mina package](https://www.npmjs.com/package/pin-mina)\n- [Pin Save on Dspyt](https://dspyt.com/PinSave)\n- [Pin Save retroPGF3](https://round3.optimism.io/projects/0xc613e2a991ce0dbcf8fae1d6128e67543da9710e14831112fba654cc8fe8c389)\n\n## RoadMap\n\nWe are at the stage where we need to improve read and write speeds for the content on PinSave.\n\nOur Roadmap includes:\n\n- Further enhancing SEO\n- Fixing faulty Dweb ipfs provider\n- Adding more Ipfs providers\n- Researching further erc 725 contract and available registry contracts\n- Deploying erc 725 contract once again and syncing orbis profiles\n- Improving Upload page with batch mint\n- Improving Upload page UX and UI\n- Improving posts contract to contain function to display metadata\n- Deploying PinSavePosts Contract V2 that contains function:\n  - metadata function supported by marketplaces such as OpenSea\n  - add new function similar to `tokenIdsOf` return uint instead of bytes\n  - add a function to query posts by `bytes` `tokenId`\n\nSome interesting links for developers:\n\n- [Practical React Query](https://tkdodo.eu/blog/practical-react-query)\n- [next/image](https://nextjs.org/docs/api-reference/next/image)\n- [Next Js ISG](https://nextjs.org/docs/basic-features/data-fetching/incremental-static-regeneration)\n- [Universal Profiles](https://docs.lukso.tech/standards/universal-profile/introduction)\n- [Working with Lit Access Control](https://litproject.substack.com/p/working-with-access-control)\n- [Lit Supported Blockchains](https://developer.litprotocol.com/support/supportedchains/)\n"
  },
  "ethereum/hevm": {
    "fetchedAt": "2025-11-12T22:58:28.045Z",
    "content": "# hevm\nhevm is an implementation of the Ethereum virtual machine (EVM) made for\nsymbolic execution, equivalence checking, and (symbolic) unit testing of smart\ncontracts. `hevm` can symbolically execute smart contracts, perform symbolic\nequivalence testing, and run arbitrary EVM code. In particular, it can run\n[Forge](https://book.getfoundry.sh/forge/writing-tests) test suites in a\nsymbolic way, thereby being much more thorough than fuzz testing.\n\n## Documentation & Support\nUser facing documentation can be found in the [hevm book](https://hevm.dev/).\nWe have a public matrix chat room\n[here](https://matrix.to/#/%23hevm%3Amatrix.org).\n\n## Installing via Static Binaries\nStatic binaries for x86 linux and macos are available for each\n[release](https://github.com/argotorg/hevm/releases). These binaries expect to have `z3` installed.\nYou can install `z3` via your package manager, such as `apt install z3` on Ubuntu,\nor `brew install z3` on macOS.\n\n## Quick User Guide for a Forge Project\nFor a Forge project, you can run:\n```bash\ncd my-forge-project\nforge clean\nforge build --ast\nhevm test --prefix test # will symbolically execute all tests prefixed with \"test\"\n```\n\nFor a more comprehensive guide on how to use hevm for a Forge project, see our [Forge\nstd-test tutorial](https://hevm.dev/std-test-tutorial.html)\n\n## Installing via nix\nhevm nix package is available in\n[nixpkgs](https://search.nixos.org/packages?channel=unstable&show=haskellPackages.hevm),\nand can be installed via:\n- flakes: `nix profile install nixpkgs#haskellPackages.hevm`\n- legacy: `nix-env -iA haskellPackages.hevm`\n\nhevm flake can be installed directly from the `main` branch of this repo via the following command:\n```plain\nnix profile install github:argotorg/hevm\n```\n\n## Development\nWe use `nix` to manage project dependencies. To start hacking on hevm you should first [install\nnix](https://nixos.org/download.html).\n\nOnce nix is installed you can run `nix develop` from the repo root to enter a development shell\ncontaining all required dev dependencies.\n\nOnce in the shell you can use the usual `cabal` commands to build and test hevm:\n```plain\n$ cabal run hevm -- test --root myproject # run the cli\n$ cabal run test                          # run the tests\n$ cabal repl test                         # enter the repl for the test.sh\n$ cabal run ethereum-tests                # run the ethereum standard tests\n\n# run the cli binary with profiling enabled\n$ cabal run --enable-profiling hevm -- <CLI SUBCOMMAND> +RTS -s -p -RTS\n```\n\n## History\n`hevm` was originally developed as part of the\n[dapptools](https://github.com/dapphub/dapptools/) project, and was forked to\nthis repo by the formal methods team at the Ethereum Foundation in August 2022.\n\n"
  },
  "unruggable-labs/unruggable-gateways": {
    "fetchedAt": "2025-11-12T22:58:36.338Z",
    "content": "<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/unruggable-labs/unruggable-gateways/main/unruggable-logo-black.png\" width=\"300\" alt=\"Unruggable Gateways\">\n</p>\n\n# Unruggable Gateways \n\nThis repository provides an end-to-end solution for proving data from rollup chains and verifying it against state posted on the parent chain.\n\n![Unruggable Gateways CI](https://github.com/unruggable-labs/unruggable-gateways/actions/workflows/unruggable-gateways.yml/badge.svg)\n\n## Audits\n\nThe codebase has been audited. Details of our audits can be found [here](./audits/audits.md).\n\n## Quickstart\n\n`npm i @unruggable/gateways` [&check;](https://www.npmjs.com/package/@unruggable/gateways)\n\n* We have extensive [documentation](https://gateway-docs.unruggable.com), with a slightly less quick [Quickstart](https://gateway-docs.unruggable.com/quickstart). \n* The [examples](https://gateway-docs.unruggable.com/examples) page may be of particular interest. \n* We also have an [examples repo](https://github.com/unruggable-labs/gateway-examples) that utilises our npm package to demonstrate both simple and complex use cases in a few clicks.\n\n## Architecture\n\n- **Request** &mdash; a program that fetches data from one or more contracts\n\t* constructable in [Solidity](./contracts/GatewayFetcher.sol) and [TypeScript](./src/vm.ts) using (almost) the same syntax\n- **Commit** &mdash; a commitment (eg. `StateRoot`) of one chain on another\n- **VM** &mdash; a machine that executes a **Request** for a **Commit**\n\t* TypeScript &mdash; records sequence of necessary proofs\n\t* Solidity &mdash; verifies sequence of supplied proofs (in the same order)\n- **Rollup** (TypeScript) &mdash; traverses **Commit** history, generates a **Commit** proof and supplies a **Prover**\n- **Prover** (TypeScript) &mdash; generates rollup-specific Account and Storage proofs\n- **Gateway** (TypeScript) &mdash; receives a **Request**, finds the appropriate **Commit**, executes the **VM**, and responds with a sequence of proofs via [CCIP-Read](https://eips.ethereum.org/EIPS/eip-3668)\n- **Verifier** (Solidity) &mdash; verifies a **Commit** proof and executes the **VM** with **Hooks**\n- **Verifier Hooks** (Solidity) &mdash; verifies rollup-specific Account and Storage proofs\n\n## Chain Support\n* Rollups &amp; Verifers\n\t* [Superchain](./src/op/OPRollup.ts)\n\t* [Superchain w/Fault Proofs](./src/op/OPFaultRollup.ts)\n\t* Arbitrum: [Nitro](./src/arbitrum/NitroRollup.ts) and [BoLD](./src/arbitrum/BoLDRollup.ts)\n\t* [Linea](./src/linea/LineaRollup.ts) (and [Unfinalized](./src/linea/UnfinalizedLineaRollup.ts))\n\t* [Polygon PoS](./src/polygon/PolygonPoSRollup.ts)\n\t* [Scroll](./src/scroll/ScrollRollup.ts) and [Euclid](./src/scroll/EuclidRollup.ts)\n\t* [Taiko](./src/taiko/TaikoRollup.ts)\n\t* [ZKSync](./src/zksync/ZKSyncRollup.ts)\n\t* [Reverse OP](./src/op/ReverseOPRollup.ts) &mdash; L2 &rarr; L1\n\t* [Self](./src/eth/EthSelfRollup.ts) &mdash; any &rarr; itself\n\t* [Trusted](./src/TrustedRollup.ts) &mdash; any &rarr; any\n\t* [Unchecked](./src/UncheckedRollup.ts) &mdash; any &rarr; any\n\t* [DoubleArbitrum](./src/arbitrum/DoubleArbitrumRollup.ts) &mdash; L1 &rarr; L2 &rarr; L3\n\t* [Polygon ZK](./src/polygon/ZKEVMRollup.ts) &mdash; *WIP*\n\t* [Morph](./src/morph/MorphRollup.ts) &mdash; *WIP*\n\t* [Starknet](./src/starknet/StarknetRollup.ts) &mdash; *WIP*\n* Provers\n\t* [Eth](./src/eth//EthProver.ts) &mdash; `eth_getProof`\n\t* [Linea](./src/linea/LineaProver.ts) &mdash; `linea_getProof`\n\t* [ZKSync](./src/zksync/ZKSyncProver.ts) &mdash; `zks_getProof`\n\t* [ZKEVM](./src/polygon/ZKEVMProver.ts) &mdash; `zkevm_getProof` &mdash; *WIP*\n\t* [Starknet](./src/starknet/StarknetProver.ts) &mdash; `pathfinder_getProof` &mdash; *WIP*\n* Verifier Hooks\n\t* [Eth](./contracts/eth/EthVerifierHooks.sol) &mdash; [Patricia Merkle Tree](./contracts/eth/MerkleTrie.sol)\n\t* [Linea](./contracts/linea/LineaVerifierHooks.sol) &mdash; [Sparse Merkle Tree](./contracts/linea/SparseMerkleProof.sol) + [Mimc](./contracts/linea/Mimc.sol)\n\t* [Scroll](./contracts/scroll/ScrollVerifierHooks.sol) &mdash; Binary Merkle Tree + Poseidon\n\t* [ZKSync](./contracts/zksync/ZKSyncVerifierHooks.sol) &mdash; [Sparse Merkle Tree](./contracts/zksync/ZKSyncSMT.sol) + [Blake2S](./contracts/zksync/Blake2S.sol)\n\nIf you are interested in building a solution for another chain, please take a look at our our [Contribution Guidelines](#contribution-guidelines) and/or [get in touch](https://unruggable.com/contact).\n\n## Setup\n\n1. [`foundryup`](https://book.getfoundry.sh/getting-started/installation)\n1. `forge i`\n1. `bun i --frozen-lockfile`\n1. create [`.env`](./.env.example)\n\n## Running a Gateway\n\n* `bun run serve <chain> [port]`\n\t* eg. `bun run serve op 9000`\n\t* [Chains](./src/chains.ts): `1` or `0x1` or `mainnet`\n\t* Default port: `8000`\n\t* Use `trusted:<chain>` for [`TrustedRollup`](./src/TrustedRollup.ts)\n\t\t* eg. `bun run serve trusted:op`\n\t\t* Include `0x{64}` to set signing key\n\t* Use `unchecked:<chain>` for [`UncheckedRollup`](./src/UncheckedRollup.ts)\n\t* Use `reverse:<chain>` for [`ReverseOPRollup`](./src/op/ReverseOPRollup.ts)\n\t* Use `self:<chain>` for [`EthSelfRollup`](./src/eth/EthSelfRollup.ts)\n\t* Include `--unfinalized(=minAge)` to use unfinalized commits (will throw if not available)\n\t* Include `--latest` for `\"latest\"` instead of `\"finalized\"` block tag\n\t* Include `--debug` to print `OP_DEBUG` statements\n\t* Include `--calls` to print RPC calls.\n\t* Include `--dump` to print config, latest commit, prover information, and then exit.\n\t* Include `--no-fast` to disable `eth_getStorageAt`\n\t* Include `--no-cache` to disable caching\n\t* Include `--no-double` to disable double rollups\n\t\t* eg. if `APE`, serves L2 &rarr; L3 instead of L1 &rarr; L2 &rarr; L3\n\t* Include `--depth=#` to adjust commit depth\n\t* Include `--step=#` to adjust commit step\n\t* Use [`PROVIDER_ORDER`](./test/providers.ts#L479) to customize global RPC provider priority.\n\t* Use `PROVIDER_ORDER_{CHAIN_NAME}` to customize per-chain RPC provider priority.\n\t* Use `PROVIDER_{CHAIN_NAME}` to customize per-chain RPC provider override.\n\t* Use `BEACON_{CHAIN_NAME}` to customize per-chain Beacon RPC provider override.\n\n## Testing\n\nThere is an extensive test suite available for testing individual components of the solution in an isolated manner. \n\nUsing [Foundry](https://getfoundry.sh/) and [blocksmith.js](https://github.com/adraffy/blocksmith.js/), we fork the chain in question (such that can interact with contracts deployed on a real network) and then deploy and test against an isolated unit (for example the chain specific verifier).\n\nCommands available include:\n\n* `bun run test`\n\t* `bun run test-components`\n\t\t* [Supported Operations](./test/components/ops.test.ts)\n\t\t* [Protocol Limits](./test/components/limits.test.ts)\n\t\t* [Batched `eth_getProof`](./test/components/proofs.test.ts)\n\t* `bun run test-gateways`\n\t\t* [Contract](./test/gateway/SlotDataContract.sol) &rarr; [Reader](./test/gateway/SlotDataReader.sol) &rarr; [Tests](./test/gateway/tests.ts)\n\t\t* ‚ö†Ô∏è Polygon has poor `eth_getProof` support\n\n## Examples\n\nA number of examples are provided as part of this repository. For more extensive step-wise example code, please see our [documentation](https://gateway-docs.unruggable.com/examples).\n\n* [linea-ens](./test/v1/linea-ens.ts)\n\t* Replacement backend demo for https://names.linea.build/\n\t* `bun serve v1:linea`\n\n## Notes\n\n#### Suggested VSCode Extensions\n\n* [JuanBlanco.solidity](https://marketplace.visualstudio.com/items?itemName=JuanBlanco.solidity)\n* [esbenp.prettier-vscode](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode)\n* [dbaeumer.vscode-eslint](https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint)\n\n#### Forge Setup\n```sh\n# installed by forge in step (2)\n# provided for reference\nforge install foundry-rs/forge-std\nforge install OpenZeppelin/openzeppelin-contracts@v5.0.2\n\n# installed by script instead of the following command\n# placed at standard remapping location\n# see: https://github.com/ethereum-optimi\n\n[... truncated ...]"
  },
  "unruggable-labs/unruggable-gateways-examples": {
    "fetchedAt": "2025-11-12T22:58:36.746Z",
    "content": "<p align=\"center\">\n    <img src=\"./unruggable-logo-black.png\" style = \"width:300px;\" alt = \"Unruggable Gateways\" />\n</p>\n\n# Gateway examples\n\n![Gateway Examples](https://github.com/unruggable-labs/unruggable-gateways-examples/actions/workflows/examples.yml/badge.svg)\n\nThis repository contains a number of examples that utilise our [@unruggable/gateways](https://www.npmjs.com/package/@unruggable/gateways) package to demonstrate the functionality of our gateway codebase.\n\nWe recommend interested users take a look through our extensive [Gateway documentation](https://gateway-docs.unruggable.com) to supplement the code within this repo.\n\n## Prerequisites\n\nBefore running the examples you must clone the repo:\n\n```bash\ngit clone https://github.com/unruggable-labs/unruggable-gateways-examples.git\n``` \n\ninstall the dependencies using:\n\n ```bash\n bun install\n ```\n\nand set `SEPOLIA_PROVIDER_URL` in `.env`:\n\n```bash\nSEPOLIA_PROVIDER_URL=https://eth.public-rpc.com\n```\n\n## Running the examples\n\nYou can run an example using the following syntax:\n\n```bash\nbun run examples/EXAMPLE_FILENAME.ts\n```\n\nFor example:\n\n```bash\nbun run examples/6-keccak-of-concat-as-key-with-debug.ts\n```\n\n## Troubleshooting\n\nThese examples use a verifier deployed on Ethereum Sepolia. We utilse a public RPC defined in `.env`.\n\nIf there are RPC issues you can set up a free account at a service like [Alchemy](https://www.alchemy.com/), [Ankr](https://www.ankr.com/), or [Infura](https://www.infura.io/) and set the `SEPOLIA_PROVIDER_URL` variable in `.env`."
  },
  "ethereum/act": {
    "fetchedAt": "2025-11-12T22:58:46.980Z",
    "content": "# Act\n\nAct is a formal specification language, designed to allow for the construction of an exhaustive,\nmathematically rigorous description of evm programs. Act allows diverse toolchains to interoperate\non a single specification, with each generating and exchanging different kinds of knowledge. It has\na built-in analysis engine that can automatically prove properties about the specification itself,\nas well as an integrated symbolic execution engine (based on hevm) that can prove equivalence\nbetween a specification and a given bytecode object. Finally, specifications can be exported into\nhigher level reasoning tools (e.g. theorem provers, economic analysis tooling), allowing for the\nverification of properties of almost arbitrary complexity, all with a proof chain right down to the\nbytecode level.\n\nIt extends on the previous [Act](https://github.com/dapphub/klab/blob/master/acts.md) project.\n\nMore in depth documentation can be found in [The Act Book](https://ethereum.github.io/act/).\n\n# Building\n\nYou can build the project with nix. If you do not have nix installed yet, you can try using the [Determinate Nix installer](https://github.com/DeterminateSystems/nix-installer).\n\nBuilding with nix:\n\n```sh\nnix build\n```\n\n# Developing\n\nEnter a nix-shell to get the dependencies of the project:\n\n```sh\nnix develop\n```\n\nyou can then use `cabal` as normal from the root directory of the project:\n\n```sh\ncabal build # build\ncabal repl  # enter a repl instance\n```\n\nto execute the unit tests:\n\n```sh\nmake test # run all tests\ncabal v2-test # run haskell tests\n```\n\nTo update the project dependencies run:\n\n```sh\nnix flake update\n```\n\n# Usage\n\nOnce you are in the nix shell, you can use act backends for `smt`, `hevm` and `rocq` as follows.\n\n```sh\ncabal run act -- <OPTIONS>\n```\n\nRun the following command to get the info on how to use options and configuration flags.\n\n```sh\ncabal run act -- --help\n```\n\nAlternatively, you can `make` first and then run the executable `act` as in  `act <OPTIONS>`.\nFor more details on how to run each individual backend consult [The Act Book](https://ethereum.github.io/act/)."
  },
  "Aymen-Tirchi/op-stack-deployer": {
    "fetchedAt": "2025-11-12T22:58:55.625Z",
    "content": "# op-stack-deployer\n\nOP Stack Deployer is a tool that simplifies setting up and deploying an OP Stack chain on the Ethereum Sepolia testnet. This guide will walk you through the steps required to spin up your OP Stack chain and perform tests or customize it for your specific needs.\n\nThis project is based on the [Creating your own L2 rollup testnet](https://docs.optimism.io/operators/chain-operators/tutorials/create-l2-rollup).\n\n## Prerequisites\n\nBefore getting started, ensure that you have the following software installed: `Git`, `Go`, `Node`, `Pnpm`, `Foundry`, `Make`, `jq`, and `direnv`.\n\n## Getting Started\n\nFirst of all clone the op-stack-deployer repository\n```bash\ngit clone https://github.com/Aymen-Tirchi/op-stack-deployer.git && cd op-stack-deployer\n```\nAnd then follow these steps: \n\n1. Build the Optimism Monorepo\n\n```bash\ngo run cmd/1_build_optimism/main.go\n```\nThis script will automatically clone the Optimism Monorepo, install the required modules, build the necessary packages, and generate the Optimism Monorepo and packages successfully.\n\n2. Build op-geth\n\n```bash\ngo run cmd/2_build_op-geth/main.go\n```\nThis script will automatically clone the op-geth repo, build the necessary packages, and generate the op-geth repo and packages successfully.\n\n3. Generate some keys\n\n```bash\ngo run cmd/3_generate_keys/main.go\n```\nThis script will generate the keys of each role and store them in a text file named `keys.txt` in the root directory of the project. The `keys.txt` file will contain the addresses and private keys for the `Admin`, `Proposer`, `Batcher`, and `Sequencer` accounts.\n\n4. Configure your network\n\n- Before you run the script go to this path `optimism/packages/contracts-bedrock` you will find `.envrc.`, set the `ETH_RPC_URL` that you are using, and replace the `PRIVATE_KEY` with the actual private key of the `Admin` which is in the `keys.txt`, and the `DEPLOYMENT_CONTEXT` stays the same which is `getting-started`.\n\n```bash\ngo run cmd/4_configure_network/main.go\n```\n- This script will automatically configure your network based on the generated keys and the provided L1 node RPC URL. It will configure `getting-started.json` in the `optimism/packages/contracts-bedrock/deploy-config` directory, which contains all the required parameters for your network setup.\n\n5. Deploy the L1 contracts\n- Before running the `deploy_L1_contracts.go` script, ensure that you have funded your `Admin` address with some Sepolia test ETH (at least 0.5 ETH). Having sufficient test ETH will cover the gas costs and ensure the successful deployment of the L1 contracts.\n\n- Now you can run the script :\n```bash\ngo run cmd/5_deploy_L1_contracts/main.go\n```\nThe script will start deploying all the L1 smart contracts. During the deployment process, you may see various transaction logs and updates. Once the deployment is successful, you will receive a confirmation message.\n\n6. Generate the L2 config files\n```bash\nsudo go run cmd/6_L2_config/main.go\n```\nThis script will automatically create the necessary L2 configuration files `genesis.json`, `rollup.json`, and `jwt.txt`. These files are crucial for the configuration and secure communication between the op-node and op-geth.\n\n7. Initialize op-geth\n```bash\ngo run cmd/7_Initialize_op-geth/main.go\n```\nThis script will create a data directory and initialize the `op-geth` with the `genesis.json` we generated in the previous script.\n\n8. Run the node software\n\nbefore running anything make sure you fund your `batcher` and `proposer` addresses with at least 0.5 Sepolia test ETH, to ensure that it can continue operating without running out of ETH for gas.\n- Run op-geth \n```bash\ngo run cmd/8_run_op-geth/main.go\n```\nThis script will run the op-geth node.\n- Run op-node\n\n```bash\ngo run cmd/9_run_op-node/main.go \n```\nThis script will set up system variables and run `op-node`.\n\n- Run op-batcher\n \n```bash\ngo run cmd/10_run_op-batcher/main.go \n```\nThis script will set up system variables and run `op-batcher`.\n\nmight have warning messages similar to: \n```bash\nWARN [03-21|14:13:55.248] Error calculating L2 block range         err=\"failed to get sync status: Post \\\"http://localhost:8547\\\": context deadline exceeded\"\n```\nThis means that `op-node` is not yet synchronized up to the present time. Just wait until it is.\n\n- Run op-proposer\n\n```bash\ngo run cmd/11_run_op-proposer/main.go \n```\nThis script will set up system variables and run the `op-proposer`.\n\ncheck out this [Rollup Operations](https://stack.optimism.io/docs/build/operations/#) \n\n9. Get some ETH on your Rollup\n\nTo get the address of your Rollup run the following command\n```bash\ngo run cmd/12_get_rollup_address/main.go \n```\nand now you can fund your rollup address with some ETH. It may take up to 5 minutes for that ETH to appear in your wallet on L2.\n\nCongratulations, You have a complete OP Stack-based EVM Rollup.\n\n10. Use your Rollup\n\nTo see your rollup in action, you can use the [optimism-tutorial](https://github.com/ethereum-optimism/optimism-tutorial/tree/main).\n\n## Contributing\n\nContributions to Op-Stack Deployer are welcome! If you have any issues or ideas for improvements, please open an issue or submit a pull request.\n\n## License\n\nThis project is licensed under the [MIT License](https://opensource.org/license/mit/).\n"
  },
  "bluealloy/revm": {
    "fetchedAt": "2025-11-12T22:59:05.806Z",
    "content": "### Revm\n\n[![CI](https://github.com/bluealloy/revm/actions/workflows/ci.yml/badge.svg)][gh-ci]\n[![License](https://img.shields.io/badge/License-MIT-orange.svg)][mit-license]\n[![crates.io](https://img.shields.io/crates/v/revm.svg)](https://crates.io/crates/revm)\n[![Chat][tg-badge]][tg-url]\n\nRevm is a highly efficient and stable implementation of the Ethereum Virtual Machine (EVM) written in Rust.\n\n![banner](https://raw.githubusercontent.com/bluealloy/revm/refs/heads/main/assets/logo/revm-banner.png)\n\n[mit-license]: https://opensource.org/license/mit/\n[gh-ci]: https://github.com/bluealloy/revm/actions/workflows/ci.yml\n[tg-url]: https://t.me/+Ig4WDWOzikA3MzA0\n[tg-badge]: https://img.shields.io/badge/chat-telegram-blue\n\nKnown for its robustness, it stands as one of the most popular libraries and a critical component of the Ethereum ecosystem. Revm plays a crucial role across various projects, being widely utilized by almost all tooling and block builders. It is integrated into Reth, multiple Layer 2 variants and other clients and serving as a standard for zkVMs.\n\nRevm offers two primary applications: firstly, it functions as an executor where users can set up block info and process mainnet transactions; secondly, it acts as a framework that facilitates the extension and support of different EVM variants such as op-revm.\n\n### How to use:\n\nHere is a straightforward example of using the Execution API: It allows us to create an Ethereum Virtual Machine (EVM) and execute transactions. Additionally, it can be utilized to generate traces with the inspector or more complex example of foundry cheatcodes.\n\n```rust,ignore\nlet mut evm = Context::mainnet().with_block(block).build_mainnet();\nlet out = evm.transact(tx);\n\n// or you can use powerful inspection tool to trace it\nlet mut evm = evm.with_inspector(tracer);\nlet out = evm.inspect_tx(tx);\n```\n\nThe EVM Framework API is somewhat complex to use, but this document provides a detailed explanation. It enables users to extend logic, incorporate various context types, and offers built-in support for inspection. For a practical example, you can refer to the [op-revm crate](https://github.com/op-rs/op-revm).\n\n### Users:\n\nAs previously noted, there are several groups of projects that utilize this technology:\n\n* **Major block builders**.\n* **Clients**: [Reth](https://github.com/paradigmxyz/reth), [Helios](https://github.com/a16z/helios), [Trin](https://github.com/ethereum/trin),..\n* **Tooling**: [Foundry](https://github.com/foundry-rs/foundry/), [Hardhat](https://github.com/NomicFoundation/hardhat),..\n* **L2s**: [Optimism](https://github.com/bluealloy/revm/tree/main/crates/op-revm), [Coinbase](https://www.base.org/), [Scroll](https://github.com/scroll-tech/revm),..\n* **zkVM**: [Risc0](https://github.com/risc0/risc0-ethereum), [Succinct](https://github.com/succinctlabs/rsp), [Boundless](https://github.com/boundless-xyz/reth)..\n\nThe full list of projects that use Revm is available in the [awesome-revm](https://bluealloy.github.io/revm/awesome.html) section of the book.\n\n### How to, dev section\n\nThe [book](https://bluealloy.github.io/revm/) and [`Architecture and API`](https://bluealloy.github.io/revm/architecture.html) page is the best starting resource.\n\nSome quick links can be found here. Some point to code documentation or the book. code docs are there to explain usage of a particular part of the code where the book is to get more of an overview of the architecture or how components/projects fit together.\n\n* [How to build and use revm](https://bluealloy.github.io/revm/dev.html)\n* [Architecture overview](https://bluealloy.github.io/revm/architecture.html)\n* [Structure of the project](https://github.com/bluealloy/revm/tree/main/crates) (list of crates and their versions)\n* [How to use Revm Framework](https://github.com/bluealloy/revm/tree/main/examples/my_evm) (MyEvm example)\n* [Release procedure and changelogs explanation](https://bluealloy.github.io/revm/release_procedure.html)\n* [How to use revme](https://github.com/bluealloy/revm/tree/main/bins/revme) (Revm binary with few commands)\n* [How to run Ethereum tests](https://bluealloy.github.io/revm/revme.html#running-eth-tests)\n* If there is more need for explanations please open a PR request.\n\n## Supported Rust Versions (MSRV)\n\nRevm always aims to stay up-to-date with the latest stable Rust release.\n\nThe Minimum Supported Rust Version (MSRV) may be updated at any time, so we can take advantage of new features and improvements in Rust.\n\n### Community:\nFor questions please open a github issue or join the public [telegram group](https://t.me/+Ig4WDWOzikA3MzA0)\n\n### Licence\nRevm is licensed under MIT Licence.\n\nUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in these crates by you, shall be licensed as above, without any additional terms or conditions.\n\nIf `gmp` feature flag is used, GPL code gets compiled, if enabled please make sure to follow this license.\n\n### Security\n\nFor any security questions or findings, please reach out to me directly via email at [dragan0rakita@gmail.com](mailto:dragan0rakita@gmail.com) or contact me on Keybase under the username @draganrakita.\n"
  },
  "wevm/viem": {
    "fetchedAt": "2025-11-12T22:59:13.276Z",
    "content": "<!-- > [!IMPORTANT] -->\n<!-- > Viem is participating in Gitcoin Grants round 21. Consider <a href=\"https://explorer.gitcoin.co/#/round/42161/389/73\">supporting the project</a>. Thank you. üôè -->\n\n<br/>\n\n<p align=\"center\">\n  <a href=\"https://viem.sh\">\n      <picture>\n        <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/viem/main/.github/gh-logo-dark.svg\">\n        <img alt=\"viem logo\" src=\"https://raw.githubusercontent.com/wevm/viem/main/.github/gh-logo-light.svg\" width=\"auto\" height=\"60\">\n      </picture>\n</a>\n</p>\n\n<p align=\"center\">\n  TypeScript Interface for Ethereum\n<p>\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/viem\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/npm/v/viem?colorA=21262d&colorB=21262d&style=flat\">\n      <img src=\"https://img.shields.io/npm/v/viem?colorA=f6f8fa&colorB=f6f8fa&style=flat\" alt=\"Version\">\n    </picture>\n  </a>\n  <a href=\"https://app.codecov.io/gh/wevm/viem\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/codecov/c/github/wevm/viem?colorA=21262d&colorB=21262d&style=flat\">\n      <img src=\"https://img.shields.io/codecov/c/github/wevm/viem?colorA=f6f8fa&colorB=f6f8fa&style=flat\" alt=\"Code coverage\">\n    </picture>\n  </a>\n  <a href=\"https://github.com/wevm/viem/blob/main/LICENSE\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/npm/l/viem?colorA=21262d&colorB=21262d&style=flat\">\n      <img src=\"https://img.shields.io/npm/l/viem?colorA=f6f8fa&colorB=f6f8fa&style=flat\" alt=\"MIT License\">\n    </picture>\n  </a>\n  <a href=\"https://www.npmjs.com/package/viem\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/npm/dm/viem?colorA=21262d&colorB=21262d&style=flat\">\n      <img src=\"https://img.shields.io/npm/dm/viem?colorA=f6f8fa&colorB=f6f8fa&style=flat\" alt=\"Downloads per month\">\n    </picture>\n  </a>\n  <a href=\"https://bestofjs.org/projects/viem\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://img.shields.io/endpoint?colorA=21262d&colorB=21262d&style=flat&url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=wevm%2Fviem%26since=daily\">\n      <img src=\"https://img.shields.io/endpoint?colorA=f6f8fa&colorB=f6f8fa&style=flat&url=https://bestofjs-serverless.now.sh/api/project-badge?fullName=wevm%2Fviem%26since=daily\" alt=\"Best of JS\">\n    </picture>\n  </a>\n</p>\n\n<br>\n\n## Features\n\n- Abstractions over the [JSON-RPC API](https://ethereum.org/en/developers/docs/apis/json-rpc/) to make your life easier\n- First-class APIs for interacting with [Smart Contracts](https://ethereum.org/en/glossary/#smart-contract)\n- Language closely aligned to official [Ethereum terminology](https://ethereum.org/en/glossary/)\n- Import your Browser Extension, WalletConnect or Private Key Wallet\n- Browser native [BigInt](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt), instead of large BigNumber libraries\n- Utilities for working with [ABIs](https://ethereum.org/en/glossary/#abi) (encoding/decoding/inspection)\n- TypeScript ready ([infer types](https://viem.sh/docs/typescript) from ABIs and EIP-712 Typed Data)\n- First-class support for [Anvil](https://book.getfoundry.sh/), [Hardhat](https://hardhat.org/) & [Ganache](https://trufflesuite.com/ganache/)\n- Test suite running against [forked](https://ethereum.org/en/glossary/#fork) Ethereum network\n\n... and a lot more.\n\n## Overview\n\n```ts\n// 1. Import modules.\nimport { createPublicClient, http } from 'viem';\nimport { mainnet } from 'viem/chains';\n\n// 2. Set up your client with desired chain & transport.\nconst client = createPublicClient({\n  chain: mainnet,\n  transport: http(),\n});\n\n// 3. Consume an action!\nconst blockNumber = await client.getBlockNumber();\n```\n\n## Documentation\n\n[Head to the documentation](https://viem.sh/docs/getting-started) to read and learn more about viem.\n\n## Community\n\nCheck out the following places for more viem-related content:\n\n- Follow [@wevm_dev](https://twitter.com/wevm_dev), [@_jxom](https://twitter.com/_jxom), and [@awkweb](https://twitter.com/awkweb) on Twitter for project updates\n- Join the [discussions on GitHub](https://github.com/wevm/viem/discussions)\n- [Share your project/organization](https://github.com/wevm/viem/discussions/104) that uses viem\n\n## Support\n\n- [GitHub Sponsors](https://github.com/sponsors/wevm?metadata_campaign=docs_support)\n- [Gitcoin Grant](https://wagmi.sh/gitcoin)\n- [wevm.eth](https://etherscan.io/name-lookup-search?id=wevm.eth)\n\n## Sponsors\n\n<a href=\"https://paradigm.xyz\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/paradigm-dark.svg\">\n    <img alt=\"paradigm logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/paradigm-light.svg\" width=\"auto\" height=\"70\">\n  </picture>\n</a>\n<a href=\"https://ithaca.xyz\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/ithaca-dark.svg\">\n    <img alt=\"ithaca logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/ithaca-light.svg\" width=\"auto\" height=\"70\">\n  </picture>\n</a>\n\n<br>\n\n<a href=\"https://twitter.com/family\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/family-dark.svg\">\n    <img alt=\"family logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/family-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://twitter.com/context\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/context-dark.svg\">\n    <img alt=\"context logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/context-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://walletconnect.com\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/walletconnect-dark.svg\">\n    <img alt=\"WalletConnect logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/walletconnect-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://twitter.com/prtyDAO\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/partydao-dark.svg\">\n    <img alt=\"PartyDAO logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/partydao-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://dynamic.xyz\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/dynamic-dark.svg\">\n    <img alt=\"Dynamic logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/dynamic-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://sushi.com\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/sushi-dark.svg\">\n    <img alt=\"Sushi logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/sushi-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://stripe.com\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/stripe-dark.svg\">\n    <img alt=\"Stripe logo\" src=\"https://raw.githubusercontent.com/wevm/.github/main/content/sponsors/stripe-light.svg\" width=\"auto\" height=\"50\">\n  </picture>\n</a>\n<a href=\"https://privy.io\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubuserconten\n\n[... truncated ...]"
  },
  "smartcontracts/simple-optimism-node": {
    "fetchedAt": "2025-11-12T22:59:21.887Z",
    "content": "# Simple Optimism Node\n\nA simple docker compose script for launching full / archive node for OP Stack chains.\n\n<!-- ## Use cases\n* Docker compose to launch Optimism mainnet full / archive node -->\n\n## Recommended Hardware\n\n### OP and Base Mainnet\n\n- 16GB+ RAM\n- 2 TB SSD (NVME Recommended)\n- 100mb/s+ Download\n\n### Testnets\n\n- 16GB+ RAM\n- 500 GB SSD (NVME Recommended)\n- 100mb/s+ Download\n\n## Installation and Configuration\n\n### Install docker and docker compose\n\n> Note: If you're not logged in as root, you'll need to log out and log in again after installation to complete the docker installation.\n\nNote: This command install docker and docker compose for Ubuntu. For windows and mac desktop or laptop, please use Docker Desktop. For other OS, please find instruction in Google.\n\n```sh\n# Update and upgrade packages\nsudo apt-get update\nsudo apt-get upgrade -y\n\n### Docker and docker compose prerequisites\nsudo apt-get install -y curl\nsudo apt-get install -y gnupg\nsudo apt-get install -y ca-certificates\nsudo apt-get install -y lsb-release\n\n### Download the docker gpg file to Ubuntu\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\n### Add Docker and docker compose support to the Ubuntu's packages list\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\nsudo apt-get update\n \n### Install docker and docker compose on Ubuntu\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\nsudo usermod -aG docker $(whoami)\n \n### Verify the Docker and docker compose install on Ubuntu\nsudo docker run hello-world\n```\n\n(For non-root user) After logged out and logged back in, test if docker is working by running.\n\n```sh\ndocker ps\n```\n\nIt should returns an empty container list without having any error. Otherwise, restart your machine if there are errors.\n\n### Clone the Repository\n\n```sh\ngit clone https://github.com/smartcontracts/simple-optimism-node.git\ncd simple-optimism-node\n```\n\n### Copy .env.example to .env\n\nMake a copy of `.env.example` named `.env`.\n\n```sh\ncp .env.example .env\n```\n\nOpen `.env` with your editor of choice\n\n### Mandatory configurations\n\n* **NETWORK_NAME** - Choose which Optimism network layer you want to operate on:\n    * `op-mainnet` - Optimism Mainnet\n    * `op-sepolia` - Optimism Sepolia (Testnet)\n    * `base-mainnet` - Base Mainnet\n    * `base-sepolia` - Base Sepolia (Testnet)\n* **NODE_TYPE** - Choose the type of node you want to run:\n    * `full` (Full node) - A Full node contains a few recent blocks without historical states.\n    * `archive` (Archive node) - An Archive node stores the complete history of the blockchain, including historical states.\n* **OP_NODE__RPC_ENDPOINT** - Specify the endpoint for the RPC of Layer 1 (e.g., Ethereum mainnet). For instance, you can use the free plan of Alchemy for the Ethereum mainnet.\n* **OP_NODE__L1_BEACON** - Specify the beacon endpoint of Layer 1. You can use [QuickNode for the beacon endpoint](https://www.quicknode.com). For example: https://xxx-xxx-xxx.quiknode.pro/db55a3908ba7e4e5756319ffd71ec270b09a7dce\n* **OP_NODE__RPC_TYPE** - Specify the service provider for the RPC endpoint you've chosen in the previous step. The available options are:\n    * `alchemy` - Alchemy\n    * `quicknode` - Quicknode (ETH only)\n    * `erigon` - Erigon\n    * `basic` - Other providers\n* **HEALTHCHECK__REFERENCE_RPC_PROVIDER** - Specify the public RPC endpoint for Layer 2 network you want to operate on for healthchecking. For instance:\n    * **Optimism Mainnet** - https://mainnet.optimism.io\n    * **Optimism Sepolia** - https://sepolia.optimism.io\n    * **Base Mainnet** - https://mainnet.base.org\n    * **Base Sepolia** - https://sepolia.base.org\n\n### OP Mainnet only configurations\n\n* **OP_GETH__HISTORICAL_RPC** - OP Mainnet RPC Endpoint for fetching pre-bedrock historical data\n    * **Recommended:** https://mainnet.optimism.io\n    * Leave blank if you want to self-host pre-bedrock historical node for high-throughput use cases such as subgraph indexing.\n\n### Optional configurations\n\n* **OP_GETH__SYNCMODE** - Specify sync mode for the execution client\n    * Unspecified - Use default snap sync for full node and full sync for archive node\n    * `snap` - Snap Sync (Default)\n    * `full` - Full Sync (For archive node, not recommended for full node)\n* **IMAGE_TAG__[...]** - Use custom docker image for specified components.\n* **PORT__[...]** - Use custom port for specified components.\n\n## Operating the Node\n\n### Start\n\n```sh\ndocker compose up -d --build\n```\n\nWill start the node in a detached shell (`-d`), meaning the node will continue to run in the background. We recommended to add `--build` to make sure that latest changes are being applied.\n\n### View logs\n\n```sh\ndocker compose logs -f --tail 10\n```\n\nTo view logs of all containers.\n\n```sh\ndocker compose logs <CONTAINER_NAME> -f --tail 10\n```\n\nTo view logs for a specific container. Most commonly used `<CONTAINER_NAME>` are:\n* op-geth\n* op-node\n* bedrock-init\n* l2geth\n\n### Stop\n\n```sh\ndocker compose down\n```\n\nWill shut down the node without wiping any volumes.\nYou can safely run this command and then restart the node again.\n\n### Restart\n\n```sh\ndocker compose restart\n```\n\nWill restart the node safely with minimal downtime but without upgrading the node.\n\n### Upgrade\n\nPull the latest updates from GitHub, and Docker Hub and rebuild the container.\n\n```sh\ngit pull\ndocker compose pull\ndocker compose up -d --build\n```\n\nWill upgrade your node with minimal downtime.\n\n### Wipe [DANGER]\n\n```sh\ndocker compose down -v\n```\n\nWill shut down the node and WIPE ALL DATA. Proceed with caution!\n\n## Monitoring\n\n### Estimate remaining sync time\n\nRun progress.sh to estimate remaining sync time and speed.\n\n```sh\n./progress.sh\n```\n\nThis will show the sync speed in blocks per minute and the time until sync is completed.\n\n```\nChain ID: 10\nPlease wait\nBlocks per minute: ...\nHours until sync completed: ...\n```\n\n### Grafana dashboard\n\nGrafana is exposed at [http://localhost:3000](http://localhost:3000) and comes with one pre-loaded dashboard (\"Simple Node Dashboard\").\nSimple Node Dashboard includes basic node information and will tell you if your node ever falls out of sync with the reference L2 node or if a state root fault is detected.\n\nUse the following login details to access the dashboard:\n\n- Username: `admin`\n- Password: `optimism`\n\nNavigate over to `Dashboards > Manage > Simple Node Dashboard` to see the dashboard, see the following gif if you need help:\n\n![metrics dashboard gif](https://user-images.githubusercontent.com/14298799/171476634-0cb84efd-adbf-4732-9c1d-d737915e1fa7.gif)\n\n## Troubleshooting\n\n### Walking back L1Block with curr=0x0000...:0 next=0x0000...:0\n\nIf you experience \"walking back L1Block with curr=0x0000...:0 next=0x0000...:0\" for a long time after the Ecotone upgrade, consider these fixes:\n1. Wait for a few minutes. This issue usually resolves itself after some time.\n2. Restart docker compose: `docker compose down` and `docker compose up -d --build`\n3. If it's still not working, try setting `OP_GETH__SYNCMODE=full` in .env and restart docker compose\n"
  },
  "Vectorized/solady": {
    "fetchedAt": "2025-11-12T22:59:29.240Z",
    "content": "# <img src=\"logo.svg\" alt=\"solady\" height=\"118\" width=\"305\"/>\n\n[![NPM][npm-shield]][npm-url]\n[![CI][ci-shield]][ci-url]\n[![Solidity][solidity-shield]][solidity-ci-url]\n[![Docs][docs-shield]][docs-url]\n\nGas optimized Solidity snippets.\n\nI'm sooooooOooooooooOoooOoooooooooooooooo...\n\n## Installation\n\nTo install with [**Foundry**](https://github.com/foundry-rs/foundry):\n\n```sh\nforge install vectorized/solady\n```\n\nTo install with [**Hardhat**](https://github.com/nomiclabs/hardhat):\n\n```sh\nnpm install solady\n```\n\n## Documentation\n\nhttps://vectorized.github.io/solady\n\n## Contracts\n\nThe Solidity smart contracts are located in the `src` directory.\n\n```ml\naccounts\n‚îú‚îÄ EIP7702Proxy ‚Äî \"Relay proxy for EIP7702 delegations\"\n‚îú‚îÄ ERC1271 ‚Äî \"ERC1271 mixin with nested EIP-712 approach\"\n‚îú‚îÄ ERC4337 ‚Äî \"Simple ERC4337 account implementation\"\n‚îú‚îÄ ERC4337Factory ‚Äî \"Simple ERC4337 account factory implementation\"\n‚îú‚îÄ ERC6551 ‚Äî \"Simple ERC6551 account implementation\"\n‚îú‚îÄ ERC6551Proxy ‚Äî \"Relay proxy for upgradeable ERC6551 accounts\"\n‚îú‚îÄ ERC7821 ‚Äî \"Minimal batch executor mixin\"\n‚îú‚îÄ LibEIP7702 ‚Äî \"Library for EIP7702 operations\"\n‚îú‚îÄ LibERC6551 ‚Äî \"Library for interacting with ERC6551 accounts\"\n‚îú‚îÄ LibERC7579 ‚Äî \"Library for handling ERC7579 mode and execution data\"\n‚îú‚îÄ Receiver ‚Äî \"Receiver mixin for ETH and safe-transferred ERC721 and ERC1155 tokens\"\n‚îú‚îÄ Timelock ‚Äî \"Simple timelock\"\nauth\n‚îú‚îÄ EnumerableRoles ‚Äî \"Enumerable multiroles authorization mixin\"\n‚îú‚îÄ Ownable ‚Äî \"Simple single owner authorization mixin\"\n‚îú‚îÄ OwnableRoles ‚Äî \"Simple single owner and multiroles authorization mixin\"\n‚îú‚îÄ TimedRoles ‚Äî \"Timed multiroles authorization mixin\"\ntokens\n‚îú‚îÄ ERC1155 ‚Äî \"Simple ERC1155 implementation\"\n‚îú‚îÄ ERC20 ‚Äî \"Simple ERC20 + EIP-2612 implementation\"\n‚îú‚îÄ ERC20Votes ‚Äî \"ERC20 with votes based on ERC5805 and ERC6372\"\n‚îú‚îÄ ERC2981 ‚Äî \"Simple ERC2981 NFT Royalty Standard implementation\"\n‚îú‚îÄ ERC4626 ‚Äî \"Simple ERC4626 tokenized Vault implementation\"\n‚îú‚îÄ ERC6909 ‚Äî \"Simple EIP-6909 minimal multi-token implementation\"\n‚îú‚îÄ ERC721 ‚Äî \"Simple ERC721 implementation with storage hitchhiking\"\n‚îú‚îÄ WETH ‚Äî \"Simple Wrapped Ether implementation\"\nutils\n‚îú‚îÄ Base58 ‚Äî \"Library for Base58 encoding and decoding\"\n‚îú‚îÄ Base64 ‚Äî \"Library for Base64 encoding and decoding\"\n‚îú‚îÄ BlockHashLib ‚Äî \"Library for accessing block hashes way beyond the 256-block limit\"\n‚îú‚îÄ CallContextChecker ‚Äî \"Call context checker mixin\"\n‚îú‚îÄ CREATE3 ‚Äî \"Deterministic deployments agnostic to the initialization code\"\n‚îú‚îÄ DateTimeLib ‚Äî \"Library for date time operations\"\n‚îú‚îÄ DeploylessPredeployQueryer ‚Äî \"Deployless queryer for predeploys\"\n‚îú‚îÄ DynamicArrayLib ‚Äî \"Library for memory arrays with automatic capacity resizing\"\n‚îú‚îÄ DynamicBufferLib ‚Äî \"Library for buffers with automatic capacity resizing\"\n‚îú‚îÄ ECDSA ‚Äî \"Library for verification of ECDSA signatures\"\n‚îú‚îÄ EIP712 ‚Äî \"Contract for EIP-712 typed structured data hashing and signing\"\n‚îú‚îÄ ERC1967Factory ‚Äî \"Factory for deploying and managing ERC1967 proxy contracts\"\n‚îú‚îÄ ERC1967FactoryConstants ‚Äî \"The address and bytecode of the canonical ERC1967Factory\"\n‚îú‚îÄ EfficientHashLib ‚Äî \"Library for efficiently performing keccak256 hashes\"\n‚îú‚îÄ EnumerableMapLib ‚Äî \"Library for managing enumerable maps in storage\"\n‚îú‚îÄ EnumerableSetLib ‚Äî \"Library for managing enumerable sets in storage\"\n‚îú‚îÄ FixedPointMathLib ‚Äî \"Arithmetic library with operations for fixed-point numbers\"\n‚îú‚îÄ GasBurnerLib ‚Äî \"Library for burning gas without reverting\"\n‚îú‚îÄ Initializable ‚Äî \"Initializable mixin for the upgradeable contracts\"\n‚îú‚îÄ JSONParserLib ‚Äî \"Library for parsing JSONs\"\n‚îú‚îÄ LibBit ‚Äî \"Library for bit twiddling and boolean operations\"\n‚îú‚îÄ LibBitmap ‚Äî \"Library for storage of packed booleans\"\n‚îú‚îÄ LibClone ‚Äî \"Minimal proxy library\"\n‚îú‚îÄ LibMap ‚Äî \"Library for storage of packed unsigned integers\"\n‚îú‚îÄ LibPRNG ‚Äî \"Library for generating pseudorandom numbers\"\n‚îú‚îÄ LibRLP ‚Äî \"Library for RLP encoding and CREATE address computation\"\n‚îú‚îÄ LibSort ‚Äî \"Library for efficient sorting of memory arrays\"\n‚îú‚îÄ LibStorage ‚Äî \"Library for basic storage operations\"\n‚îú‚îÄ LibString ‚Äî \"Library for converting numbers into strings and other string operations\"\n‚îú‚îÄ LibTransient ‚Äî \"Library for transient storage operations\"\n‚îú‚îÄ LibZip ‚Äî \"Library for compressing and decompressing bytes\"\n‚îú‚îÄ Lifebuoy ‚Äî \"Class that allows for rescue of ETH, ERC20, ERC721 tokens\"\n‚îú‚îÄ MerkleProofLib ‚Äî \"Library for verification of Merkle proofs\"\n‚îú‚îÄ MerkleTreeLib ‚Äî \"Library for generating Merkle trees\"\n‚îú‚îÄ MetadataReaderLib ‚Äî \"Library for reading contract metadata robustly\"\n‚îú‚îÄ MinHeapLib ‚Äî \"Library for managing a min-heap in storage or memory\"\n‚îú‚îÄ Multicallable ‚Äî \"Contract that enables a single call to call multiple methods on itself\"\n‚îú‚îÄ P256 ‚Äî \"Gas optimized P256 wrapper\"\n‚îú‚îÄ RedBlackTreeLib ‚Äî \"Library for managing a red-black-tree in storage\"\n‚îú‚îÄ ReentrancyGuard ‚Äî \"Reentrancy guard mixin\"\n‚îú‚îÄ SSTORE2 ‚Äî \"Library for cheaper reads and writes to persistent storage\"\n‚îú‚îÄ SafeCastLib ‚Äî \"Library for integer casting that reverts on overflow\"\n‚îú‚îÄ SafeTransferLib ‚Äî \"Safe ERC20/ETH transfer lib that handles missing return values\"\n‚îú‚îÄ SemVerLib ‚Äî \"Library for comparing SemVers\"\n‚îú‚îÄ SignatureCheckerLib ‚Äî \"Library for verification of ECDSA and ERC1271 signatures\"\n‚îú‚îÄ UUPSUpgradeable ‚Äî \"UUPS proxy mixin\"\n‚îú‚îÄ UpgradeableBeacon ‚Äî \"Upgradeable beacon for ERC1967 beacon proxies\"\n‚îú‚îÄ WebAuthn ‚Äî \"WebAuthn helper\"\n‚îú‚îÄ legacy ‚Äî \"Legacy support\"\n‚îî‚îÄ ext ‚Äî \"Utilities for external protocols\"\n```\n\n## Directories\n\n```ml\nsrc ‚Äî \"Solidity smart contracts\"\ntest ‚Äî \"Foundry Forge tests\"\njs ‚Äî \"Accompanying JavaScript helper library\"\next ‚Äî \"Extra tests\"\nprep ‚Äî \"Preprocessing scripts\"\naudits ‚Äî \"Audit reports\"\n```\n\n## Contributing\n\nThis repository serves as a laboratory for cutting edge snippets that may be merged into [Solmate](https://github.com/transmissions11/solmate).\n\nFeel free to make a pull request.\n\nDo refer to the [contribution guidelines](https://github.com/Vectorized/solady/issues/19) for more details.\n\n## Safety\n\nThis is **experimental software** and is provided on an \"as is\" and \"as available\" basis.\n\nWe **do not give any warranties** and **will not be liable for any loss** incurred through any use of this codebase.\n\nWhile Solady has been heavily tested, there may be parts that may exhibit unexpected emergent behavior when used with other code, or may break in future Solidity versions.  \n\nPlease always include your own thorough tests when using Solady to make sure it works correctly with your code.  \n\n## Upgradability\n\nMost contracts in Solady are compatible with both upgradeable and non-upgradeable (i.e. regular) contracts. \n\nPlease call any required internal initialization methods accordingly.\n\n## EVM Compatibility\n\nSome parts of Solady may not be compatible with chains with partial EVM equivalence.\n\nPlease always check and test for compatibility accordingly.\n\nIf you are deploying on ZKsync stack (e.g. Abstract) with partial EVM equivalence:\n\n- Run `node prep/zksync-compat-analysis.js` to scan the files.\n- For files that have incompatibilities (i.e. non-zero scores), look into the `ext/zksync` directories for substitutes. The substitutes may only have a subset of the original features. If there is no substitute, it means that the file is incompatible and infeasible to be implemented for ZKsync.\n\n## Acknowledgements\n\nThis repository is inspired by or directly modified from many sources, primarily:\n\n- [Solmate](https://github.com/transmissions11/solmate)\n- [OpenZeppelin](https://github.com/OpenZeppelin/openzeppelin-contracts)\n- [ERC721A](https://github.com/chiru-labs/ERC721A)\n- [Zolidity](https://github.com/z0r0z/zolidity)\n- [üêç Snekmate](https://github.com/pcaversaccio/snekmate)\n- [Femplate](https://github.com/abigger87/femplate)\n\n[npm-shield]: https://img.shields.io/npm/v/solady.svg\n[npm-url]: https://www.npmjs.com/package/solady\n\n[ci-shield]: https://img.shields.io/github/actions/workflow/status/vectorized/solady/ci.yml?branch=main&label=build\n[ci-url]: https://github.com/vectorized/solady/actions/workflows/ci.yml\n\n[solidity-shield]: https://img.shields.io/badge/solidity-%3E=0.8.4%20%3C=0.8.30-aa674\n\n[... truncated ...]"
  },
  "turtleshell-xyz/circuitbreaker": {
    "fetchedAt": "2025-11-12T22:59:36.319Z",
    "content": "# Circuit Breaker SDK\n\nCircuitbreaker SDK for implementing ERC-7265 compliant Circuit Breakers in Solidity.\n\n### Installation\n\n#### Hardhat, Truffle (npm)\n\n```\n$ npm install @turtleshell-xyz/circuitbreaker\n```\n\n#### Foundry (git)\n\n```\n$ forge install turtleshell-xyz/circuitbreaker --no-git\n```\n\nAdd `circuitbreaker/=lib/circuitbreaker/src/` in `remappings.txt`\n\nfeel free to use the inline documentation inside the contracts files for further assistance or contact dev@turtleshell.xyz"
  },
  "turtleshell-xyz/frontend-boilerplates": {
    "fetchedAt": "2025-11-12T22:59:36.643Z",
    "content": "# frontend-boilerplates\nBoilerplates for building custom security dashboards\n##### Build with React + TypeScript + Vite + Tailwind\n\nBuild your own custom security dashboard to view your protocols most vital metrics such as Circuit Breakers.\n\n#### Example UI\n![](/screenshots/screenshot1.png)\n![](/screenshots/screenshot2.png)\n![](/screenshots/screenshot3.png)\n*this is a demonstrative example of how your fronted could look like using this boilerplate repo.\n\n#### Installation & Setup\nrun the following commands in your terminal.\n1. navigate to the boilerplate folder\n```\ncd dashboard\ncd boilerplate\n```\n\n2. install all dependencies\n```\nyarn\n```\n3. Initialize the frontend\n```\nyarn run dev\n```\n*you can also use ```npm``` or ```pnpm``` instead.  \n\n##### other dependencies include:\n- Animate.css\n- react-dom\n- react-router-dom\n- recharts\n\n##### expanding the ESLint configuration\n\n- Replace `plugin:@typescript-eslint/recommended` to `plugin:@typescript-eslint/recommended-type-checked` or `plugin:@typescript-eslint/strict-type-checked`\n- Optionally add `plugin:@typescript-eslint/stylistic-type-checked`\n- Install [eslint-plugin-react](https://github.com/jsx-eslint/eslint-plugin-react) and add `plugin:react/recommended` & `plugin:react/jsx-runtime` to the `extends` list"
  },
  "turtleshell-xyz/nomad-bridge-poc": {
    "fetchedAt": "2025-11-12T22:59:37.036Z",
    "content": "## Nomad hack Circuit Breaker prevention\n\nThis repository contains a reconstruction of the Nomad bridge hack with an EIP-7265 Circuit Breaker integration.\n\nThe Circuit Breaker integration completely renders the exploit unusable and prevents the funds from being drained.\n\n## Usage\n\n### Install dependencies\n\n```shell\n$ forge install\n```\n\n### Running the hack replication\n\n```shell\n$ forge test\n```\n\nYou can notice that the balance of the attacker stays 0, meaning that they are not able to drain any funds from the bridge.\n\nFor a more detailed view run:\n\n```shell\n$ forge test -vvvv\n```\n\nYou will notice the `RateLimited` event being emitted and the `prevent` function being called on the Reject Settlement Module contract when the exploit is being run.\n\nThis means, that the Circuit Breaker has triggered and is actively preventing the liquidity drain by reverting the attack transactions.\n\n###### development & research supported by the Arbitrum Foundation"
  },
  "cgewecke/hardhat-gas-reporter": {
    "fetchedAt": "2025-11-12T22:59:43.978Z",
    "content": "[![npm version](https://badge.fury.io/js/hardhat-gas-reporter.svg)](https://badge.fury.io/js/hardhat-gas-reporter)\n![Build Status](https://github.com/cgewecke/hardhat-gas-reporter/actions/workflows/ci.yml/badge.svg?branch=master)\n[![buidler](https://hardhat.org/buidler-plugin-badge.svg?1)](https://github.com/cgewecke/hardhat-gas-reporter)\n\n\n# hardhat-gas-reporter\n\n**Gas Usage Analytics for Hardhat**\n\n- Get gas metrics for method calls and deployments on L1 and L2 by running your test suite.\n- Get national currency costs of deploying and using your contract system.\n- Output data in multiple formats including text, markdown, reStructuredText and JSON.\n\n### Example report\n\n![Screen Shot 2024-04-02 at 6 04 53 PM](https://github.com/cgewecke/hardhat-gas-reporter/assets/7332026/9f1eadb0-f47b-45fe-bfdb-57d4d2f07042)\n\n+ See [markdown format example][10]\n\n## Installation\n\n```\nnpm install --save-dev hardhat-gas-reporter\n```\n\nAdd the following to your hardhat.config.ts:\n```ts\nimport \"hardhat-gas-reporter\"\n```\n\n## Configuration\nConfiguration is optional.\n```js\n// Example\nconst config: HardhatUserConfig = {\n  gasReporter: {\n    currency: 'EUR',\n    L1: \"polygon\",\n    coinmarketcap: \"abc123...\",\n  }\n}\n```\n\n## Usage\n\nThis plugin overrides the built-in `test` task. Gas reports are generated by default with:\n```\nnpx hardhat test\n```\n\n**:bulb:  Turning the plugin on/off**\n\nThe `enabled` option lets you toggle gas reporting on and off using shell environment variables.\nTests run faster when the gas reporter is off because fewer calls are made to the client to read data.\n\n```ts\nconst config: HardhatUserConfig = {\n  gasReporter: {\n    enabled: (process.env.REPORT_GAS) ? true : false\n  }\n}\n```\n\n**:mag: Caveats about Accuracy**:\n+ Gas readings for `pure` and `view` methods are **only a lower bound** of their real world cost. Actual gas usage will depend on the way the methods are called and the storage/memory state of the EVM at the moment of invocation. For more information on this see the excellent summary at [wolfio/evm/gas][1]\n+ L1 gas readings for Arbitrum & OPStack chains are approximations - some variance is expected.\n  + Optimism estimates should be within 1% of observed usage on [optimistic-etherscan][100].\n  + Arbitrum estimates should be within 10% of observed usage on [arbiscan][111]\n+ The Hardhat client implements the Ethereum Foundation EVM. To get accurate measurements for other EVM-based chains you may need to run your tests against development clients developed specifically for those networks.\n\n\n## Options\n\n+ Option setups for common and advanced use cases can be seen in the [Config Examples][2] docs.\n+ Get a [free tier Coinmarketcap API key][3] if you want price data\n+ (Also) get a [free tier Etherscan API key](#supported-networks) if you want price data for Ethereum mainnet or an L2 network.\n\n| Options                                    |    Type    |   Default  | Description                                                                                                                                                                                                                                                         |\n| :----------------------------------------- | :--------: | :--------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| currency                                   |  _string_  |    `USD`   | National currency to represent gas costs in. Exchange rates are loaded at runtime from the `coinmarketcap` api. Available currency codes can be found [here][5]                                                                                                     |\n| coinmarketcap                              |  _string_  |      -     | [API key][3] to use when fetching live token price data                                                                                                                                                                                                             |\n| enabled                                    |   _bool_   |   `true`   | Produce gas reports with `hardhat test`                                                                                                                                                                                                                             |\n| etherscan                                  |  _string_  |      -     | [API key][4] to use when fetching live gas price and fee data from both L1 & L2 networks. (Optional, see [Supported Networks][6])                                                                                                                                      |\n| excludeAutoGeneratedGetters                |   _bool_   |   `false`  | Exclude solc generated public state vars when reporting gas for pure and view methods. (Incurs a performance penalty on test startup when `true`) ‚ö†Ô∏è SLOW ‚ö†Ô∏è                                                                                                        |\n| excludeContracts                           | _string[]_ |    `[]`    | Names of contracts to exclude from report. Ex: `[\"MyContract\"]`                                                                                                                                                                                                     |\n| includeIntrinsicGas                        |   _bool_   |   `true`   | Include standard 21_000 + calldata bytes overhead in method gas usage data. (Setting to `false` can be useful for modelling contract infra that will never be called by an EOA)                                                                                     |\n| L1                                         |  _string_  | `ethereum` | Auto-configure reporter to emulate an L1 network.  (See [supported networks][6])                                                                                                                                                                                    |\n| L2                                         |  _string_  |      -     | Auto-configure reporter to emulate an L2 network (See [supported networks][6])                                                                                                                                                                                      |\n| offline                                    |   _bool_   |   `false`  | Turn off remote calls to fetch data                                                                                                                                                                                                                                 |\n| optimismHardfork                           |  _string_  |  `ecotone` | Optimism hardfork to emulate L1 & L2 gas costs for.                                                                                                                                                                                                                 |\n| proxyResolver                              |   _Class_  |      -     | User-defined class which helps reporter identify contract targets of proxied calls. (See [Advanced Usage][7])                                                                                                                                                       |\n| remoteContracts                            |   _Array_  |      -     | List of forked-network deployed contracts to track execution costs for.(See [Advanced Usage][8])                                                                                                                                                                    |\n| reportPureAndViewMethods                   |   _bool_   |   `false`  | Track gas usage for methods invoked via `eth_call`. (Incurs\n\n[... truncated ...]"
  },
  "vyperlang/vyper": {
    "fetchedAt": "2025-11-12T22:59:50.889Z",
    "content": "<img src=\"https://raw.githubusercontent.com/vyperlang/vyper/master/docs/logo.svg?sanitize=true\" alt=\"\" width=\"110\">\n\n[![Build Status](https://github.com/vyperlang/vyper/actions/workflows/test.yml/badge.svg)](https://github.com/vyperlang/vyper/actions/workflows/test.yml)\n[![Documentation Status](https://readthedocs.org/projects/vyper/badge/?version=latest)](http://docs.vyperlang.org/en/latest/?badge=latest \"ReadTheDocs\")\n[![Discord](https://img.shields.io/discord/969926564286459934.svg?label=%23vyper)](https://discord.gg/6tw7PTM7C2)\n[![Telegram](https://img.shields.io/badge/Vyperholicsüêç-Telegram-blue)](https://t.me/vyperlang)\n[![Twitter](https://img.shields.io/twitter/follow/vyperlang)](https://x.com/vyperlang)\n\n[![PyPI](https://badge.fury.io/py/vyper.svg)](https://pypi.org/project/vyper \"PyPI\")\n[![Docker](https://img.shields.io/docker/cloud/build/vyperlang/vyper)](https://hub.docker.com/r/vyperlang/vyper \"DockerHub\")\n\n[![Coverage Status](https://codecov.io/gh/vyperlang/vyper/branch/master/graph/badge.svg)](https://codecov.io/gh/vyperlang/vyper \"Codecov\")\n[![Language grade: Python](https://github.com/vyperlang/vyper/workflows/CodeQL/badge.svg)](https://github.com/vyperlang/vyper/actions/workflows/codeql.yml)\n\n# Getting Started\nSee [Installing Vyper](http://docs.vyperlang.org/en/latest/installing-vyper.html) to install vyper.\nSee [Tools and Resources](https://docs.vyperlang.org/en/latest/resources.html) for an additional list of framework and tools with vyper support.\nSee [Documentation](http://docs.vyperlang.org/en/latest/index.html) for the documentation and overall design goals of the Vyper language.\n\nSee [learn.vyperlang.org](https://learn.vyperlang.org/) for **learning Vyper by building a Pok√©mon game**.\nSee [try.vyperlang.org](https://try.vyperlang.org/) to use Vyper in a hosted jupyter environment!\n\n**Note: Vyper is constantly evolving, use with care and understand the risks associated with smart contract development.**\n\n# Installation\nSee the [Vyper documentation](https://docs.vyperlang.org/en/latest/installing-vyper.html)\nfor build instructions.\n\n# Compiling a contract\nTo compile a contract, use:\n```bash\nvyper your_file_name.vy\n```\n***generate bytecode***\n\n    vyper -f bytecode file-name.vy > file-name.bin\n\n***generate abi***\n\n    vyper -f abi file-name.vy > file-name.abi\n\nThere is also an [online compiler](https://vyper.online/) available you can use to experiment with\nthe language and compile to ``bytecode`` and/or ``IR``.\n\n**Note: While the vyper version of the online compiler is updated on a regular basis it might\nbe a bit behind the latest version found in the master branch of this repository.**\n\n## Testing (using pytest)\n\n(Complete [installation steps](https://docs.vyperlang.org/en/latest/installing-vyper.html) first.)\n\n```bash\nmake dev-init\n./quicktest.sh -m \"not fuzzing\"\n```\n\n## Testing (with hevm)\n\nInstall hevm by downloading it from the releases page (https://github.com/ethereum/hevm/releases/latest) and making sure it is in your PATH. hevm tests can be enabled with `--hevm` flag, and hevm tests can be selected with the `-m hevm` marker. For instance, `./quicktest.sh -m \"hevm\" --hevm`.\n\n## Developing (working on the compiler)\n\nA useful script to have in your PATH is something like the following:\n```bash\n$ cat ~/.local/bin/vyc\n#!/usr/bin/env bash\nPYTHONPATH=. python vyper/cli/vyper_compile.py \"$@\"\n```\n\nTo run a python performance profile (to find compiler perf hotspots):\n```bash\nPYTHONPATH=. python -m cProfile -s tottime vyper/cli/vyper_compile.py \"$@\"\n```\n\nTo get a call graph from a python profile, pip install `gprof2dot` and `xdot`, and run it like `gprof2dot -f pstats stats | xdot -`. (See https://stackoverflow.com/a/23164271/).\n\nThe utility timer functions `timeit`, `profileit` and `cumtimeit` are available in `vyper/utils.py`.\n\n\n# Contributing\n* See Issues tab, and feel free to submit your own issues\n* Add PRs if you discover a solution to an existing issue\n* For further discussions and questions, post in [Discussions](https://github.com/vyperlang/vyper/discussions) or talk to us on [Discord](https://discord.gg/6tw7PTM7C2)\n* For more information, see [Contributing](http://docs.vyperlang.org/en/latest/contributing.html)\n"
  },
  "The-Old-Castle-Defense/FGE": {
    "fetchedAt": "2025-11-12T22:59:58.005Z",
    "content": "# FGE - Frame Generator Engine - Farcaster Frames Client\nFGE(Frame Generator Engine) - Farcaster Frames Client. Create Frames with No Code Knowledge, all you need is Google Spreadsheet. Fill it, upload your image and share with your friends around Warpcast. *Do not forget to tag @tocd when you'll become success.*\n\nTOCD will support your Frames no matter what. Only for people good.\n\n## Live Video\n\n<div>\n    <a href=\"https://www.loom.com/share/578b304830214e9ba07d1836a46bf326\">\n      <p>How to create Frames with NO Code Skills - It's Easy with FGE. Top Frames on Farcaster with FGE - Watch Video</p>\n    </a>\n    <a href=\"https://www.loom.com/share/578b304830214e9ba07d1836a46bf326\">\n      <img style=\"max-width:300px;\" src=\"https://cdn.loom.com/sessions/thumbnails/578b304830214e9ba07d1836a46bf326-with-play.gif\">\n    </a>\n  </div>\n\n## Farcaster Frames made by FGE or forked by FGE\nhttps://github.com/The-Old-Castle-Defense/FGE/tree/main/fge_app\n\n#### Cross-Chain Bridge BASE <> OPTIMISM made with DeBridge integration\nhttps://github.com/The-Old-Castle-Defense/FGE/tree/main/frames/frame_cross_chain_trades\n\n#### OnChain Events of TOCD Protocol with TheGraph\nhttps://github.com/The-Old-Castle-Defense/FGE/tree/main/frames/frame_onchain_events\nVideo: https://www.loom.com/share/ea620424706d400690b6ad85a254d408\n\n#### Frames Analytics & Farcaster's Data with Pinata\nhttps://github.com/The-Old-Castle-Defense/FGE/blob/main/frames/frame_onchain_events/pinata.py\nVideo: https://www.loom.com/share/1434ee81850546068bd73cfec0901b35\n\n# Setting Up Google Sheets API Credentials\nTo integrate Google Sheets with the Farcaster's Frame Generator Engine, you'll need to create a credentials.json file. This file enables your application to authenticate with Google's API and interact with Google Sheets. Follow these steps to generate your credentials file:\n\n### 1. Google Cloud Project: \nIf you don't already have a Google Cloud Project, create one at the Google Cloud Console. Name it accordingly to easily recognize it in the future.\n\n\n### 2. Enable Google Sheets API: \nNavigate to the \"APIs & Services > Dashboard\" section. Click on \"+ ENABLE APIS AND SERVICES\" to search for and enable the Google Sheets API for your project.\n\n### 3. Create Credentials:\n* After enabling the API, go to \"APIs & Services > Credentials\".\n* Click on \"+ CREATE CREDENTIALS\" and select \"Service account\" from the dropdown menu.\n* Follow the on-screen instructions to create a service account. Note the service account ID; it usually looks like an email address.\n* Once created, click on the service account in the list, navigate to the \"Keys\" tab, and click on \"Add Key > Create new key\".\n* Choose \"JSON\" as the key type and click \"Create\". This action downloads the credentials.json file to your computer.\n### 4. Share Google Sheet: \nFinally, share the Google Sheet with your service account using the service account ID (email) you noted earlier. This step grants the necessary permissions for the service account to access and modify the Google Sheet.\n\nUse credentials.json with Farcaster's Frame Generator Engine: Place the credentials.json file in the specified directory of your project or configure its path according to the engine's documentation.\n\nBy following these steps, you should have the credentials.json file needed to authenticate and interact with Google Sheets through the Farcaster's Frame Generator Engine.\n\n**Online Guide with images**: https://medium.com/@a.marenkov/how-to-get-credentials-for-google-sheets-456b7e88c430\n\n# Guide to Creating a Frame with FGE\n\n## Step 0: Open Google Form by following the link\nClick here: https://docs.google.com/forms/d/e/1FAIpQLSfhvuW9ITz3fuAo4R78T3ksulLfrvHTWX6_3wynR_lUZUqgFw/viewform\n\n## Step 1: Enter the FrameID\n**Description:** FrameID is a unique identifier for your Frame. Think of it as a unique name that distinguishes your Frame from others.\n\n**Rules:** It must be unique, that is, different from other FrameIDs in the Frame Group (about the Frame Group in the next step).\n\n**Example:** `saturday` or `test_1`\n\n## Step 2: Enter the GroupID:\n**Description:** GroupID is an identifier used to access a Frame Group (a set of Frames with a FrameID).\n\n**Rules:** Try to come up with an ID that will combine all your FrameIDs. For example, if the set of your FrameIDs is <Saturday> and <Sunday>, then it is logical to call the GroupID \"Weekend\". Don't forget this ID, it will still be useful to you.\n\n**Example:** `weekend`\n\n_Your Frame Group will be accessible via `https://fc.theoldcastle.xyz/frame/{GroupID}`_\n\n## Step 3: Title\n**Description:** Give your Frame a title. This should be succinct and reflective of the content or the action encouraged by the Frame.\n\n**Rules:** It may not be unique.\n\n**Example:** `View the days of the weekend!`\n\n## Step 4: Buttons\n**Description:** Define the buttons you want to include. You need at least one button.\n\n**Rules:** Each button array consists of the button name, the action type (\"post\" or \"link\"), and optionally, the URL if the action type is \"link\":\n```\n[[\"Btn1_name\", \"post\"], [\"Btn2_name\", \"post\"], [\"Btn3_name\", \"link\", \"link\"]]\n```\n\n**Example:** `[[\"üëâThe next day\", \"post\"]]`\n\n## Step 5: Image and Text Positioning\n**Description:** Specify where you want your image and text to appear within the Frame.\n\n**Rules:** The format is:\n```\n[[\"image_url\"], [x, y, \"Text\", \"#Color\", FONT_SIZE]]`\n```\n\n**Example:** `[[\"https://i.ibb.co/Km2czWx/saturday.png\"], [33, 33, \"It‚Äôs Saturday!\", \"#de7676\", 16]]`\n\n## Step 6: Input [Text Placeholder] (Optional)\n**Description:** An input field for user interaction, specify a placeholder text.\n\n**Rules:** This field is optional if you do not need to receive a response from the user in the frame.\n\n**Example:** `Write a \"+\" if you like this day`\n\n## Step 7: Next Frame URL (URL will navigate to your next Frame)\n**Description:** The next frame, which is part of a sequence in a Group of Frames, i.e. you want to redirect users to another Frame after the interaction.\n\n**Rules:** \n- Specify the Next URL in the format: `https://fc.theoldcastle.xyz/api/next/{FrameID}`\n- For buttons that navigate to other Frames, append: `?btn_1={frame_link}&btn_2={frame_link}`\n\n**Example:** `https://fc.theoldcastle.xyz/api/next/saturday?btn_1=sunday`\n\n## Step 8: Open Warpcast Dev Tools by following the link\nClick here: https://warpcast.com/~/developers/frames\n\n## Step 9: Put the link to the Warpcast Dev Tools\nDo you remember GroupID? Add it to the link template and paste it into the \"URL\" field\n\n**Template:** `https://fc.theoldcastle.xyz/frame/{GroupID}`\n\n**Example:** `https://fc.theoldcastle.xyz/frame/weekend`\n\nReady! Now you can test the operation of your Frame\n\n"
  },
  "The-Old-Castle-Defense/burnfomo": {
    "fetchedAt": "2025-11-12T22:59:58.360Z",
    "content": "# $FOMO is the first fully transparent & on-chain MEME and Community token on Base powered by TOCD Studio ([https://theoldcastle.xyz](https://theoldcastle.xyz))\n\n<code>[burnfomo.theoldcastle.xyz](https://burnfomo.theoldcastle.xyz/) - Find out how many FOMO tokens have already been burned! See how many FOMO boughtback and are waiting to get burned. We're inspired by the Best - copied and redesigned from burnbeam.com by the Merit Circle & Beam blockchain.</code>\n\n# BURN $FOMO Tracker Deployment\n\nThis repository contains the code for tracking BURN $FOMO transactions and serving statistics via a FastAPI application.\n\n## Crontab Script Deployment\n\nTo deploy the `burnfomo_tracker.py` script with `crontab`, follow these steps:\n\n1. **Clone the Repository:**\n   ```bash\n   git clone https://github.com/The-Old-Castle-Defense/burnfomo.git\n   cd burnfomo-tracker\n   ```\n\n2. **Install Dependencies:**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Set Up Crontab:**\n   Open the crontab editor:\n   ```bash\n   crontab -e\n   ```\n\n   Add the following line to run the script every 30 minutes:\n   ```bash\n   */30 * * * * /usr/bin/python3 /path/to/burnfomo_tracker.py\n   ```\n\n4. **Save and Exit:**\n   Save the changes and exit the editor. The script will now run every 30 minutes.\n\n## FastAPI with NGINX Deployment\n\nTo deploy the FastAPI application using NGINX, follow these steps:\n\n1. **Clone the Repository:**\n   ```bash\n   git clone https://github.com/The-Old-Castle-Defense/burnfomo.git\n   cd burnfomo-tracker\n   ```\n\n2. **Install Dependencies:**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Run FastAPI with Uvicorn:**\n   ```bash\n   uvicorn main:app --host 0.0.0.0 --port 9999\n   ```\n\n4. **Set Up NGINX:**\n   Edit your NGINX configuration to include:\n   ```nginx\n   server {\n       listen 443 ssl;\n       listen [::]:443 ssl;\n\n       ssl_certificate /etc/nginx/ssl/ssl.pem;\n       ssl_certificate_key /etc/nginx/ssl/ssl.key;\n       server_name burnfomo.theoldcastle.xyz;\n\n       location /api/ {\n           proxy_pass http://127.0.0.1:9999;\n           proxy_set_header Host $host;\n           proxy_set_header X-Real-IP $remote_addr;\n           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n           proxy_set_header X-Forwarded-Proto $scheme;\n       }\n   }\n   ```\n\n5. **Restart NGINX:**\n   ```bash\n   sudo systemctl restart nginx\n   ```\n"
  },
  "The-Old-Castle-Defense/DRS": {
    "fetchedAt": "2025-11-12T22:59:58.725Z",
    "content": "# Decentralized Referral System (DRS)\nThe Decentralized Referral System (DRS) is a unique and transparent referral system that is completely decentralized and allows you to track referrals instantly by paying rewards in your smart contract. \nThis means that the program participants are guaranteed and will immediately receive 10% of the commission fees paid by the invited user.\n\n* **Smart payments**\n: Payments are made by smart contracts automatically after each user transaction to a non-custodial wallet.\n\n* **Transparency**\n: NO SCAM ANYMORE! All transactions are completely transparent and guaranteed through the use of smart contracts.\n\n* **Earning Opportunity**\n: Users can earn real money by inviting new friends or users.\n\n# How it works\n## Implementation example for ETH Lisbon ticket sale\nYou can test DRS right here and now and make sure it is revolutionary and transparent.\n1. Go to the web page: https://theoldcastle.xyz/drs\n2. Buy a ticket to the ETH Lisbon event to log in to the system;\n\n<figure><img src=\"./content/ticket_step_1.jpg\" alt=\"\"><figcaption></figcaption></figure>\n\n3. Copy your referral link (It looks like this: https://theoldcastle.xyz/?referral=[your_referral_id];\n\n<figure><img src=\"./content/ticket_step_2.jpg\" alt=\"\"><figcaption></figcaption></figure>\n\n4. Share the referral link to get 10% for each user transaction. **When the invited user buys a ticket for $10, you will receive $1**\n\n<figure><img src=\"./content/transaction_example.png\" alt=\"\"><figcaption>Example of the referral reward payment <a href=\"https://subnets-test.avax.network/en/beam/tx/0xcfe3301b68822280d67e1574465476a170bb6e041a4bcff304a386d60b3f4de1\">transaction</a> when your friends invest.</figcaption></figure>\n\n\n## Implementation examples for The Old Castle Defense\n### Example 1:\n1. Alice sends her referral link to her friend Bob;\n2. Bob follows the link and logs in;\n3. Bob performs a $1,000 transaction;\n4. The smart contract takes a commission of 6% from $1,000, that is $60;\n5. Of this $60, the smart contract sends 10% (i.e. $6) directly to Alice's wallet;\n\n### Example 2:\n1. Alice sends a referral link to her 1,000 followers on the blog;\n2. Each subscriber performs a $500 transaction;\n3. The smart contract takes a commission of 6% from every $500, that is $30;\n4. Alice receives 10% of this commission, i.e. $3, in her wallet;\n5. In total, Alice received $3,000 with the help of DRS.\n\n# DRS flexibility\n1. You can use DRS in any of your projects!\n2. Adjust the percentage of remuneration for invited users!\n3. Run DRS on any blockchain!\n4. Call it whatever you want. Perhaps it's more convenient for you to call it an \"on-chain cashback system\" or \"Decentralized Referral Protocol\"?\n"
  },
  "The-Old-Castle-Defense/docs": {
    "fetchedAt": "2025-11-12T22:59:59.098Z",
    "content": "# Variables, tags, and documentation markup rules\n\n## Variables\n- **{blockchain}**: The name of Blockchain;\n- **{block_explorer}**: The link to block explorer of the blockchain;\n- **{bps}**: The number of blocks per second in the current blockchain;\n- **{token}**: The Treasury token on Blockchain\n- **{battle_duration}**: Time until the start of the next battle in the current blockchain;\n- **{transactions}**: The link to a transaction of a decentralized referral system in the current blockchain;\n- **{knights_market_link}**: The link to the marketplace with Knights NFTs;\n- **{creatures_market_link}**: The link to the marketplace with Creatures NFTs;\n- **{bank_address}**: The address with treasury pool.\n\n## Editing the main documentation page\nThe data from the main documentation page is stored in the \"_docs Menu.json\" file. \nThe \"_\" in front of the file name indicates that this page does not need to be specified in the navigation\n\n## Tags and rules\n\n### A separate block of text\nEach separate block of text must be marked with a <div> tag, **skipping the line after the opening tag.** \nExample:\n```\n<div>\n\nHello, world!\n</div>\n```\n\n### Information cards\nTo highlight information that requires special attention, the \"card_info\" or \"card_warning\" tag is used. Example:\n```\n::card_info\nThis is additional information or a hint.\n::\n```\n```\n::card_warning\nThis is information that requires special attention\n::\n```\n\n### Adding Images\nAll images must be stored in a folder along the path: \".gitbook/assets/i_am_here.png\"\nFor an image that is suitable only for a specific blockchain, it is required to specify the name of the blockchain and the token's treasury through the \"_\" symbol.\n\n**Example of the image name:**\n```\ni_am_here_Beam Mainnet_BEAM.png\n```\n**Example of embedding an image:**\n```\n<img src=\"/assets/docs/.gitbook/assets/i_am_here_{blockchain}_{token}.png\" alt=\"\">\n```\n\n### Embedded links\n```\n<a href=\"https://theoldcastle.xyz\" target=\"_blanc\" class=\"doc-link\">example</a>\n```\n\n### Formulas:\n```\n::card_formula  \n::formula  \n<MathFormula formula=\"RevCost=LVL+1\"/>,  \n::  \nwhere:  \n* **RevCost**: the cost of reviving in ${token};  \n* **LVL**: the level of NFT at the time of death.  \n::\n```\n\n### Navigation:\nTo comply with the required order of articles and sections, it is required to specify an additional block with a number at the beginning of the document\n```\n---\nnavigation  \n order: 2  \n---\n```\n\n### Buttons\nTo add a button leading to another document, you need to specify a block:\n```\n<a href=\"investors\" \n class=\"docs-item\">\n<span>üìà</span>\nInvestors</a>\n</div>\n```\n\n# Files\n\n## _<main|dev>NetDeploys.json\n\n### Data\n\n| **Attribute**       | **Type**   | **Description**                                                                                                                                                  |\n| :------------------ | :--------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| _id                 | int        | The unique identifier of the deployment                                                                                                                          |\n| deploy_id           | string     | The unique identifier of the deployment                                                                                                                          |\n| **chain**           | **object** | The object containing data about the chain                                                                                                                       |\n| chain.id            | int        | The unique identifier of the chain. Can be found here: https://chainlist.org/?chain=245022926&testnets=true&search=                                              |\n| chain.name          | string     | The name of the chain                                                                                                                                            |\n| **currency**        | **object** | The object containing information about the available token for this deployment                                                                                  |\n| currency.ticker     | string     | The name of the token that is available on this deployment                                                                                                       |\n| past_game_contracts | array      | Addresses of previous smart contracts of the game on this deployment                                                                                             |\n| game_contract       | string     | The address of the current smart contract of the game on this deployment                                                                                         |\n| start_block         | int        | The number of the blockchain block that will generate the first Siege on this deployment                                                                         |\n| gas_token           | string     | The name of the token that is used to confirm transactions                                                                                                       |\n| decimals            | int        | Determines how many decimal places are used to represent one unit of the token                                                                                   |\n| explorer_link       | string     | Determines how many decimal places to display for `currency.ticker`                                                                                              |\n| block_per_second    | int        | The average number of seconds for the formation of a new block of the blockchain. It is used for approximate calculation of the duration of the Battle and Siege |\n| nft_marketplace     | string     | A link to the TOCD NFT collection on the marketplace of this blockchain                                                                                          |\n| soon                | boolean    | TRUE - displays the inscription \"SOON\", shows access to the deployment. FALSE - the deployment is available for the game                                         |\n| hidden              | boolean    | TRUE - do not display the deployment in the drop-down link on the site. FALSE - the deployment is displayed                                                      |\n\n### Example\n\n```\n {\n    \"_id\": 2,\n    \"deploy_id\": \"2\",\n    \"chain\": { \n      \"id\": 4337,\n      \"name\": \"Beam Mainnet\"\n    },\n    \"currency\": {\n      \"ticker\": \"BEAM\"\n    },\n    \"past_game_contracts\": [],\n    \"game_contract\": \"0x0Ed8A7EBf16FBBD240D815F52DBe1c80F6663E73\",\n    \"start_block\": 1307379,\n    \"gas_token\": \"BEAM\",\n    \"decimals\": 4,\n    \"explorer_link\": \"https://snowtrace.io/\",\n    \"block_per_second\": 10,\n    \"nft_marketplace\": \"https://sphere.market/beam/collection/0x74d85442a7001e2594fb0947a6767fc1265c8c49\",\n    \"soon\": false,\n    \"hidden\": false\n  }\n```\n"
  },
  "pcaversaccio/createx": {
    "fetchedAt": "2025-11-12T23:00:07.204Z",
    "content": "# [`CreateX`](./src/CreateX.sol) ‚Äì A Trustless, Universal Contract Deployer <!-- omit from toc -->\n\n[![üïµÔ∏è‚Äç‚ôÇÔ∏è Test CreateX](https://github.com/pcaversaccio/createx/actions/workflows/test-createx.yml/badge.svg)](https://github.com/pcaversaccio/createx/actions/workflows/test-createx.yml)\n[![Test Coverage](https://img.shields.io/badge/Coverage-100%25-green)](#test-coverage)\n[![üëÆ‚Äç‚ôÇÔ∏è Sanity checks](https://github.com/pcaversaccio/createx/actions/workflows/checks.yml/badge.svg)](https://github.com/pcaversaccio/createx/actions/workflows/checks.yml)\n[![üöÄ UI deployment](https://github.com/pcaversaccio/createx/actions/workflows/deploy.yml/badge.svg)](https://github.com/pcaversaccio/createx/actions/workflows/deploy.yml)\n[![License: AGPL-3.0-only](https://img.shields.io/badge/License-AGPL--3.0--only-blue)](https://www.gnu.org/licenses/agpl-3.0)\n\n<img src=https://github-production-user-asset-6210df.s3.amazonaws.com/25297591/272914952-38a5989c-0113-427d-9158-47646971b7d8.png  width=\"1050\"/>\n\nFactory smart contract to make easier and safer usage of the [`CREATE`](https://www.evm.codes/#f0?fork=shanghai) and [`CREATE2`](https://www.evm.codes/#f5?fork=shanghai) EVM opcodes as well as of [`CREATE3`](https://github.com/ethereum/EIPs/pull/3171)-based (i.e. without an initcode factor) contract creations.\n\n> [!NOTE]\n> The [`CreateX`](./src/CreateX.sol) contract should be considered as maximally extensible. Be encouraged to build on top of it! The Solidity-based interface can be found [here](./src/ICreateX.sol).\n\n- [So What on Earth Is a Contract Factory?](#so-what-on-earth-is-a-contract-factory)\n- [Available Versatile Functions](#available-versatile-functions)\n- [Special Features](#special-features)\n  - [Permissioned Deploy Protection and Cross-Chain Redeploy Protection](#permissioned-deploy-protection-and-cross-chain-redeploy-protection)\n  - [Pseudo-Random Salt Value](#pseudo-random-salt-value)\n- [Design Principles](#design-principles)\n- [Security Considerations](#security-considerations)\n- [Tests](#tests)\n  - [Test Coverage](#test-coverage)\n- [ABI (Application Binary Interface)](#abi-application-binary-interface)\n- [New Deployment(s)](#new-deployments)\n  - [`ethers.js`](#ethersjs)\n  - [`cast`](#cast)\n  - [Contract Verification](#contract-verification)\n- [`CreateX` Deployments](#createx-deployments)\n  - [EVM-Based Production Networks](#evm-based-production-networks)\n  - [Ethereum Test Networks](#ethereum-test-networks)\n  - [Additional EVM-Based Test Networks](#additional-evm-based-test-networks)\n- [Integration With External Tooling](#integration-with-external-tooling)\n- [Community-Maintained Dune Dashboards](#community-maintained-dune-dashboards)\n- [üôèüèº Acknowledgement](#-acknowledgement)\n\n## So What on Earth Is a Contract Factory?\n\nIt is important to understand that Ethereum Virtual Machine (EVM) opcodes can only be called via a smart contract. A contract factory in the context of the EVM refers to a special smart contract that is used to create and deploy other smart contracts on EVM-compatible blockchains using contract creation opcodes (i.e. [`CREATE`](https://www.evm.codes/#f0?fork=shanghai) or [`CREATE2`](https://www.evm.codes/#f5?fork=shanghai)). Using a contract factory provides a flexible and efficient way to deploy and manage smart contracts that share similar functionalities but may have different configurations or settings.\n\nDifferent approaches can be used to create contracts using a factory contract, and this is exactly what [`CreateX`](./src/CreateX.sol) offers: _a comprehensive range of contract creation functions that are triggered by a smart contract itself_. It is worth emphasising the two differences in the address calculation of the opcodes [`CREATE`](https://www.evm.codes/#f0?fork=shanghai) and [`CREATE2`](https://www.evm.codes/#f5?fork=shanghai) (`||` stands for byte-wise concatenation, `[12:]` refers to the last 20 bytes of a 32-byte expression, and `rlp` is an abbreviation for Ethereum's \"Recursive Length Prefix\" serialisation scheme):\n\n- [`CREATE`](https://www.evm.codes/#f0?fork=shanghai): `address computedAddress = keccak256(rlpEncode([deployerAddress, deployerNonce]))[12:]`,\n- [`CREATE2`](https://www.evm.codes/#f5?fork=shanghai): `address computedAddress = keccak256(0xff||deployerAddress||salt||keccak256(initCode))[12:]`.\n\n## Available Versatile Functions\n\n```ml\nCreateX\n‚îú‚îÄ‚îÄ CREATE\n‚îÇ   ‚îú‚îÄ‚îÄ Read-Only Functions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ \"function computeCreateAddress(uint256) view returns (address)\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ \"function computeCreateAddress(address,uint256) view returns (address)\"\n‚îÇ   ‚îî‚îÄ‚îÄ Write Functions\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate(bytes) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreateAndInit(bytes,bytes,tuple(uint256,uint256)) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreateAndInit(bytes,bytes,tuple(uint256,uint256),address) payable returns (address)\"\n‚îÇ       ‚îî‚îÄ‚îÄ \"function deployCreateClone(address,bytes) payable returns (address)\"\n‚îú‚îÄ‚îÄ CREATE2\n‚îÇ   ‚îú‚îÄ‚îÄ Read-Only Functions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ \"function computeCreate2Address(bytes32,bytes32) view returns (address)\"\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ \"function computeCreate2Address(bytes32,bytes32,address) pure returns (address)\"\n‚îÇ   ‚îî‚îÄ‚îÄ Write Functions\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2(bytes) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2(bytes32,bytes) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2AndInit(bytes,bytes,tuple(uint256,uint256)) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2AndInit(bytes32,bytes,bytes,tuple(uint256,uint256)) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2AndInit(bytes,bytes,tuple(uint256,uint256),address) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2AndInit(bytes32,bytes,bytes,tuple(uint256,uint256),address) payable returns (address)\"\n‚îÇ       ‚îú‚îÄ‚îÄ \"function deployCreate2Clone(address,bytes) payable returns (address)\"\n‚îÇ       ‚îî‚îÄ‚îÄ \"function deployCreate2Clone(bytes32,address,bytes) payable returns (address)\"\n‚îî‚îÄ‚îÄ CREATE3\n    ‚îú‚îÄ‚îÄ Read-Only Functions\n    ‚îÇ   ‚îú‚îÄ‚îÄ \"function computeCreate3Address(bytes32) view returns (address)\"\n    ‚îÇ   ‚îî‚îÄ‚îÄ \"function computeCreate3Address(bytes32,address) pure returns (address)\"\n    ‚îî‚îÄ‚îÄ Write Functions\n        ‚îú‚îÄ‚îÄ \"function deployCreate3(bytes) payable returns (address)\"\n        ‚îú‚îÄ‚îÄ \"function deployCreate3(bytes32,bytes) payable returns (address)\"\n        ‚îú‚îÄ‚îÄ \"function deployCreate3AndInit(bytes,bytes,tuple(uint256,uint256)) payable returns (address)\"\n        ‚îú‚îÄ‚îÄ \"function deployCreate3AndInit(bytes32,bytes,bytes,tuple(uint256,uint256)) payable returns (address)\"\n        ‚îú‚îÄ‚îÄ \"function deployCreate3AndInit(bytes,bytes,tuple(uint256,uint256),address) payable returns (address)\"\n        ‚îî‚îÄ‚îÄ \"function deployCreate3AndInit(bytes32,bytes,bytes,tuple(uint256,uint256),address) payable returns (address)\"\n```\n\n<details>\n<summary> <a href=\"https://github.com/pcaversaccio/createx/blob/main/src/CreateX.sol#L302-L317\"><code>computeCreateAddress(uint256)</code></a> </summary>\n\nReturns the address where a contract will be stored if deployed via _this contract_ (i.e. [`CreateX`](./src/CreateX.sol)) using the [`CREATE`](https://www.evm.codes/#f0?fork=shanghai) opcode. For the specification of the Recursive Length Prefix (RLP) encoding scheme, please refer to p. 20 of the [Ethereum Yellow Paper](https://ethereum.github.io/yellowpaper/paper.pdf) and the [Ethereum Wiki](https://ethereum.org/developers/docs/data-structures-and-encoding/rlp/). Based on the [EIP-161](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-161.md) specification, all contract accounts on the Ethereum mainnet are initiated with `nonce = 1`. Thus, the first contract address created by another contract is calculated with a non-zero nonce.\n\n```yml\n# /*:¬∞‚Ä¢ Function Argument ‚Ä¢¬∞:*/ #\n- name: nonce\n  type: uint256\n  description: The next 32-byte nonce of this contract.\n\n# /*:¬∞‚Ä¢ Return Value ‚Ä¢¬∞:*/ #\n- name: computedAddress\n  type: address\n  description: The 20-byte address where a contract will be stored.\n```\n\n</details>\n\n\n\n[... truncated ...]"
  },
  "pcaversaccio/snekmate": {
    "fetchedAt": "2025-11-12T23:00:14.003Z",
    "content": "# üêç snekmate <!-- omit from toc -->\n\n[![üïµÔ∏è‚Äç‚ôÇÔ∏è Test smart contracts](https://github.com/pcaversaccio/snekmate/actions/workflows/test-contracts.yml/badge.svg)](https://github.com/pcaversaccio/snekmate/actions/workflows/test-contracts.yml)\n[![License: AGPL-3.0-only](https://img.shields.io/badge/License-AGPL--3.0--only-blue)](https://www.gnu.org/licenses/agpl-3.0)\n[![npm package](https://img.shields.io/npm/v/snekmate.svg?color=blue)](https://www.npmjs.com/package/snekmate)\n[![PyPI package](https://img.shields.io/pypi/v/snekmate?color=blue)](https://pypi.org/project/snekmate)\n\n<img src=https://github.com/pcaversaccio/snekmate/assets/25297591/a899251b-d22b-4cb3-8109-88facba53d6a width=\"1050\"/>\n\n**State-of-the-art**, **highly opinionated**, **hyper-optimised**, and **secure** üêçVyper smart contract building blocks.\n\n> [!WARNING]\n> This is **experimental software** and is provided on an \"as is\" and \"as available\" basis. We **do not give any warranties** and **will not be liable for any losses** incurred through any use of this code base.\n\n- [üìú Contracts](#-contracts)\n- [üéõ Installation](#-installation)\n  - [1Ô∏è‚É£ PyPI](#1Ô∏è‚É£-pypi)\n  - [2Ô∏è‚É£ Foundry](#2Ô∏è‚É£-foundry)\n  - [3Ô∏è‚É£ npm](#3Ô∏è‚É£-npm)\n- [üîß Usage](#-usage)\n- [üë©üèº‚Äç‚öñÔ∏è Tests](#Ô∏è-tests)\n- [üëÆ‚Äç‚ôÄÔ∏è Audits](#Ô∏è-audits)\n- [üôèüèº Acknowledgements](#-acknowledgements)\n- [ü´° Contributing](#-contributing)\n- [üí∏ Donation](#-donation)\n- [üìÑ Licence](#-licence)\n  - [‚öñÔ∏è Dual-Licensing Option](#Ô∏è-dual-licensing-option)\n  - [üì© Requesting an MIT License](#-requesting-an-mit-license)\n- [üí¢ Disclaimer](#-disclaimer)\n\n## üìú Contracts\n\n```ml\nsrc\n‚îî‚îÄ‚îÄ snekmate\n    ‚îú‚îÄ‚îÄ auth\n    ‚îÇ   ‚îú‚îÄ‚îÄ ownable ‚Äî \"Owner-Based Access Control Functions\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ ownable_2step ‚Äî \"2-Step Ownership Transfer Functions\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ access_control ‚Äî \"Multi-Role-Based Access Control Functions\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ interfaces\n    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ IAccessControl ‚Äî \"AccessControl Interface Definition\"\n    ‚îÇ   ‚îî‚îÄ‚îÄ mocks\n    ‚îÇ       ‚îú‚îÄ‚îÄ ownable_mock ‚Äî \"`ownable` Module Reference Implementation\"\n    ‚îÇ       ‚îú‚îÄ‚îÄ ownable_2step_mock ‚Äî \"`ownable_2step` Module Reference Implementation\"\n    ‚îÇ       ‚îî‚îÄ‚îÄ access_control_mock ‚Äî \"`access_control` Module Reference Implementation\"\n    ‚îú‚îÄ‚îÄ extensions\n    ‚îÇ   ‚îú‚îÄ‚îÄ erc2981 ‚Äî \"ERC-721 and ERC-1155 Compatible ERC-2981 Reference Implementation\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ erc4626 ‚Äî \"Modern and Gas-Efficient ERC-4626 Tokenised Vault Implementation\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ interfaces\n    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ IERC2981 ‚Äî \"EIP-2981 Interface Definition\"\n    ‚îÇ   ‚îî‚îÄ‚îÄ mocks\n    ‚îÇ       ‚îú‚îÄ‚îÄ erc2981_mock ‚Äî \"`erc2981` Module Reference Implementation\"\n    ‚îÇ       ‚îî‚îÄ‚îÄ erc4626_mock ‚Äî \"`erc4626` Module Reference Implementation\"\n    ‚îú‚îÄ‚îÄ governance\n    ‚îÇ   ‚îú‚îÄ‚îÄ timelock_controller ‚Äî \"Multi-Role-Based Timelock Controller Reference Implementation\"\n    ‚îÇ   ‚îî‚îÄ‚îÄ mocks\n    ‚îÇ       ‚îî‚îÄ‚îÄ timelock_controller_mock ‚Äî \"`timelock_controller` Module Reference Implementation\"\n    ‚îú‚îÄ‚îÄ tokens\n    ‚îÇ   ‚îú‚îÄ‚îÄ erc20 ‚Äî \"Modern and Gas-Efficient ERC-20 + EIP-2612 Implementation\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ erc721 ‚Äî \"Modern and Gas-Efficient ERC-721 + EIP-4494 Implementation\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ erc1155 ‚Äî \"Modern and Gas-Efficient ERC-1155 Implementation\"\n    ‚îÇ   ‚îú‚îÄ‚îÄ interfaces\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC20Permit ‚Äî \"EIP-2612 Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC721Enumerable ‚Äî \"EIP-721 Optional Enumeration Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC721Metadata ‚Äî \"EIP-721 Optional Metadata Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC721Permit ‚Äî \"EIP-4494 Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC721Receiver ‚Äî \"EIP-721 Token Receiver Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC1155 ‚Äî \"EIP-1155 Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC1155MetadataURI ‚Äî \"EIP-1155 Optional Metadata Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ IERC1155Receiver ‚Äî \"EIP-1155 Token Receiver Interface Definition\"\n    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ IERC4906 ‚Äî \"EIP-4906 Interface Definition\"\n    ‚îÇ   ‚îî‚îÄ‚îÄ mocks\n    ‚îÇ       ‚îú‚îÄ‚îÄ erc20_mock ‚Äî \"`erc20` Module Reference Implementation\"\n    ‚îÇ       ‚îú‚îÄ‚îÄ erc721_mock ‚Äî \"`erc721` Module Reference Implementation\"\n    ‚îÇ       ‚îî‚îÄ‚îÄ erc1155_mock ‚Äî \"`erc1155` Module Reference Implementation\"\n    ‚îî‚îÄ‚îÄ utils\n        ‚îú‚îÄ‚îÄ base64 ‚Äî \"Base64 Encoding and Decoding Functions\"\n        ‚îú‚îÄ‚îÄ batch_distributor ‚Äî \"Batch Sending Both Native and ERC-20 Tokens\"\n        ‚îú‚îÄ‚îÄ block_hash ‚Äî \"Utility Functions to Access Historical Block Hashes\"\n        ‚îú‚îÄ‚îÄ create ‚Äî \"`CREATE` EVM Opcode Utility Functions\"\n        ‚îú‚îÄ‚îÄ create2 ‚Äî \"`CREATE2` EVM Opcode Utility Functions\"\n        ‚îú‚îÄ‚îÄ create3 ‚Äî \"`CREATE3`-Based Utility Functions\"\n        ‚îú‚îÄ‚îÄ ecdsa ‚Äî \"Elliptic Curve Digital Signature Algorithm (ECDSA) Secp256k1-Based Functions\"\n        ‚îú‚îÄ‚îÄ p256 ‚Äî \"Elliptic Curve Digital Signature Algorithm (ECDSA) Secp256r1-Based Functions\"\n        ‚îú‚îÄ‚îÄ message_hash_utils ‚Äî \"Signature Message Hash Utility Functions\"\n        ‚îú‚îÄ‚îÄ signature_checker ‚Äî \"ECDSA and EIP-1271 Signature Verification Functions\"\n        ‚îú‚îÄ‚îÄ eip712_domain_separator ‚Äî \"EIP-712 Domain Separator\"\n        ‚îú‚îÄ‚îÄ eip7702_utils ‚Äî \"EIP-7702 Utility Functions\"\n        ‚îú‚îÄ‚îÄ math ‚Äî \"Standard Mathematical Utility Functions\"\n        ‚îú‚îÄ‚îÄ merkle_proof_verification ‚Äî \"Merkle Tree Proof Verification Functions\"\n        ‚îú‚îÄ‚îÄ multicall ‚Äî \"Multicall Functions\"\n        ‚îú‚îÄ‚îÄ pausable ‚Äî \"Pausable Functions\"\n        ‚îú‚îÄ‚îÄ interfaces\n        ‚îÇ   ‚îú‚îÄ‚îÄ IERC1271 ‚Äî \"EIP-1271 Interface Definition\"\n        ‚îÇ   ‚îî‚îÄ‚îÄ IERC5267 ‚Äî \"EIP-5267 Interface Definition\"\n        ‚îî‚îÄ‚îÄ mocks\n            ‚îú‚îÄ‚îÄ base64_mock ‚Äî \"`base64` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ batch_distributor_mock ‚Äî \"`batch_distributor` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ block_hash_mock ‚Äî \"`block_hash` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ create_mock ‚Äî \"`create` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ create2_mock ‚Äî \"`create2` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ create3_mock ‚Äî \"`create3` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ ecdsa_mock ‚Äî \"`ecdsa` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ p256_mock ‚Äî \"`p256` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ message_hash_utils_mock ‚Äî \"`message_hash_utils` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ signature_checker_mock ‚Äî \"`signature_checker` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ eip712_domain_separator_mock ‚Äî \"`eip712_domain_separator` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ eip7702_utils_mock ‚Äî \"`eip7702_utils` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ math_mock ‚Äî \"`math` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ merkle_proof_verification_mock ‚Äî \"`merkle_proof_verification` Module Reference Implementation\"\n            ‚îú‚îÄ‚îÄ multicall_mock ‚Äî \"`multicall` Module Reference Implementation\"\n            ‚îî‚îÄ‚îÄ pausable_mock ‚Äî \"`pausable` Module Reference Implementation\"\n```\n\n## üéõ Installation\n\n> [!IMPORTANT]  \n> üêç snekmate uses a [ZeroVer](https://0ver.org)-based versioning scheme. This means üêç snekmate's major version will never exceed the first and most important number in computing: zero.\n\nWe offer three convenient ways to install the üêç snekmate contracts:\n\n### 1Ô∏è‚É£ PyPI\n\nYou can install üêç snekmate from [PyPI](https://pypi.org/project/snekmate) with:\n\n```console\npip install snekmate\n```\n\n> When using the üêçVyper CLI, the search path [defaults](https://docs.vyperlang.org/en/latest/structure-of-a-contract.html#searching-for-imports) to the current working directory and the Python [`sys.path`](https://docs.python.org/3.14/library/sys.html#sys.path). As a result, all imported üêç snekmate contracts (e.g. `from snekmate.tokens import erc20`) are seamlessly located during compilation.\n\n### 2Ô∏è‚É£ Foundry\n\nYou can install üêç snekmate via submodules using [Foundry](https://github.com/foundry-rs/foundry) with:\n\n```console\nforge install pcaversaccio/snekmate\n```\n\n> [!NOTE]\n> If you want to leverage üêç snekmate's [`VyperDeployer`](./lib/utils/VyperDeployer.sol) contract for your own testing, ensure that you compile the üêçVyper contracts with the same EVM version as configured in your `foundry.toml` file. The [`VyperDeployer`](./lib/utils/VyperDeployer.sol) contract offers two overloaded `dep\n\n[... truncated ...]"
  },
  "blockflowlabs/cli-examples": {
    "fetchedAt": "2025-11-12T23:00:21.742Z",
    "content": "# cli-examples\n\nPublic repository of backend examples built on top of blockflow stack. \n\nThis repo is divided into folders, parent folder shows the type ex: Dex, Bridges, EIPs. Each folder contains a relevant protocol code inside it. \n"
  },
  "w3hc/pattini": {
    "fetchedAt": "2025-11-12T23:00:29.821Z",
    "content": "# Pattini\n\nPattini is a GitHub Action designed to incentivize and reward contributors of a GitHub project. When an issue is merged by a maintainer, the pull request author automatically receives a certain amount of ERC-20 (USDC, DAI, ...).\n\nWatch video: https://youtu.be/NbGHN4nkXLY\n\n## Install\n\n```\nnpm install\n```\n\n## Test\n\n```\nnpm test\n```\n\n## Build\n\n```\nnpm run bundle\n```\n\n## Use as a contributor\n\nWhen you create a branch from the issue, add your wallet address at the end of the name of the branch with a hyphen (-).\n\n```\n-0x8CCbFaAe6BC02a73BBe8d6d8017cC8313E4C90A7\n```\n\nYour branch name should look like this example: \n\n```\n15-Add-blog-page-to-website-0x8CCbFaAe6BC02a73BBe8d6d8017cC8313E4C90A7\n```\n\nThe payment will be triggered when the branch is merged to main. \n\nWatch video: https://youtu.be/NbGHN4nkXLY\n\nView a example directory that's using Pattini:\n[Fables de La Fontaine](https://github.com/w3hc/fables-de-lafontaine)\n\n_Mandatory format:_\n\n```\n<ISSUE_NUMBER>-<ISSUE_NAME>-<CONTRIBUTOR_WALLET_ADDRESS>\n```\n\n## Use Pattini as a repository maintainer\n\nThe repository maintainer should make sure that at least 1 review is required to allow merging.\n\nBefore merging, he should also verify if another no one else made a pull request before. \n\n### Config\n\nTo get Pattini up and running in your repository:\n\n1. Use this directory [Pattini Contracts](https://github.com/w3hc/pattini-contracts) to retrieve the code for the contract to be deployed\n\n2. Deploy the contract manually (in Hardhat: `pnpm deploy:sepolia`)\n\n3. Once the contract has been deployed, copy the content of the `Pattini.json` file located in `deployments/sepolia`. In the directory where you want to add Pattini, create the folder `.github/workflows`, create the file `pattini.config.json` and paste the content you copied earlier.\n\n4. In the same folder (`.github/workflows`), create the `pattini.yml` file and paste the following code:\n\n```yml\nname: Run Pattini\n\non:\n  pull_request:\n    types:\n      - closed\n  push:\n    branches:\n      - '*' \n\njobs:\n  branch-creation-check:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' && github.event.created\n    steps:\n      - name: Extract Issue Number\n        run: echo \"ISSUE_NUMBER=$(echo ${{ github.ref }} | awk -F/ '{print $3}')\" >> $GITHUB_ENV\n      - name: Pattini app\n        uses: w3hc/pattini@vTest\n        with:\n          PRIVATE_KEY: ${{ secrets.WALLET_OWNER_PRIVATE_KEY }}\n          ACTION: ${{ github.event_name }}\n          ISSUE_NUMBER: ${{ env.ISSUE_NUMBER }}\n          REPOSITORY: ${{ github.repository }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n  on-merge-pull-request:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request' && github.event.action == 'closed' && github.event.pull_request.merged\n    steps:\n      - name: Extract Merged Branch Name\n        id: extract-merged-branch\n        run: echo \"ISSUE_NUMBER=${{ github.event.pull_request.head.ref }}\" >> $GITHUB_ENV\n\n      - name: Pattini app\n        uses: w3hc/pattini@vTest\n        with:\n          PRIVATE_KEY: ${{ secrets.WALLET_OWNER_PRIVATE_KEY }}\n          ACTION: ${{ github.event_name }}\n          ISSUE_NUMBER: ${{ env.ISSUE_NUMBER }}\n          PULL_REQUEST_NUMBER: ${{ github.event.pull_request.number }}\n          REPOSITORY: ${{ github.repository }}\n```\n\n5. Create a secret variable in the GitHub parameters of your repository. This must be called `WALLET_OWNER_PRIVATE_KEY` and stores your wallet's private key, which will be used to pay the fees for the contract to interact with the blockchain.\n\n6. Once all these steps have been completed, the actions will be automatically executed each time a new branch is created and each time a branch is merged.\n\n## Authors\n\n- Julien BERANGER\n- Th√©o CLAUDEL\n\n"
  },
  "w3hc/gov": {
    "fetchedAt": "2025-11-12T23:00:30.193Z",
    "content": "# Gov\n\nA DAO framework built with Open Zeppelin's [Governor contract](https://docs.openzeppelin.com/contracts/4.x/governance#governor) in combination with NFTs.\n\n- [`Gov.sol`](https://github.com/web3-hackers-collective/dao-contracts/blob/main/contracts/Gov.sol) is the **Governor** contract\n- [`NFT.sol`](https://github.com/web3-hackers-collective/dao-contracts/blob/main/contracts/NFT.sol) is the **NFT** contract (ERC-721)\n\nSince `v0.10.0`, Gov is using non-tranferable membership NFTs (\"SBTs\"), it is also timestamp-based by default.\n\n## Motivation\n\nProvide a coordination tool that fits the needs of regular users. \n\n- [Documentation](https://w3hc.github.io/gov-docs/)\n- [Gov UI](https://gov-ui.netlify.app/)\n- [Gov UI repo](https://github.com/w3hc/gov-ui)\n- [Gov Deployer](https://gov-deployer.netlify.app/)\n- [Gov Deployer repo](https://github.com/w3hc/gov-deployer)\n- [Example DAO on Tally](https://www.tally.xyz/gov/web3-hackers-collective)\n\n## Install\n\n```js\npnpm install\n```\n\n## Test\n\n```js\npnpm test\n```\n\n## Deploy\n\nCreate a `.env` on the model of `.env.template`:\n\n```js\ncp .env.template .env\n```\n\n- Add your own keys in your `.env` file\n- Edit the `dao.config.ts` file (optional)\n- Check if the main account has a sufficient wallet balance: \n\n```\npnpm bal\n```\n\n- Then deploy to Sepolia:\n\n```bash\npnpm deploy:sepolia\n```\n\nThen you can add your DAO in [Tally](https://www.tally.xyz/) and/or spin up your own interface using [Gov UI](https://github.com/w3hc/gov-ui). \n\n## Security\n\nHere are the differences between the Governor/ERC-721 implementations suggested by Open Zeppelin and ours:\n\n### [Gov.sol](https://github.com/w3hc/gov/blob/main/contracts/Gov.sol)\n\nThe following function is `onlyGovernance`, meaning it can only be triggered by a vote.\n\n- `setManifesto()` updates the CID.\n\n### [NFT.sol](https://github.com/w3hc/gov/blob/main/contracts/NFT.sol)\n\nThe following functions are `onlyOwner`, and since the NFT contract ownership is transferred to the Gov contract, they can only be triggered by a vote.\n\n- `safeMint()` adds a new member.\n- `govBurn()` bans a member.\n- `setMetadata()` changes the tokenURI of a given NFT ID.\n\n## Supported Networks\n\n| Network | Chain ID | Documentation |\n|---------|----------|---------------|\n| Optimism Mainnet | 10 | [Documentation](https://docs.optimism.io/chain/networks#op-mainnet) |\n| Base Mainnet | 8453 | [Documentation](https://docs.base.org/docs/network-information#base-mainnet) |\n| Arbitrum One | 42161 | [Documentation](https://docs.arbitrum.io/welcome/get-started) |\n| Sepolia Testnet | 11155111 | [Documentation](https://ethereum.org/nb/developers/docs/networks/#sepolia) |\n| OP Sepolia Testnet | 11155420 | [Documentation](https://docs.optimism.io/chain/networks#op-sepolia) |\n| Base Sepolia Testnet | 84532 | [Documentation](https://docs.base.org/docs/network-information/#base-testnet-sepolia) |\n| Arbitrum Sepolia | 421614 | [Documentation](https://docs.arbitrum.io/welcome/get-started) |\n\n## Contract Verification\n\n| Network | Explorer URL | API URL | API Key Variable |\n|---------|--------------|---------|-----------------|\n| Optimism | https://optimistic.etherscan.io | https://api-optimistic.etherscan.io/api | OP_ETHERSCAN_API_KEY |\n| Base | https://basescan.org | https://api.basescan.org/api | BASE_ETHERSCAN_API_KEY |\n| Arbitrum One | https://arbiscan.io | https://api.arbiscan.io/api | ARBITRUM_ETHERSCAN_API_KEY |\n| Sepolia | https://sepolia.etherscan.io | https://api-sepolia.etherscan.io/api | ETHERSCAN_API_KEY |\n| OP Sepolia | https://sepolia-optimism.etherscan.io | https://api-sepolia-optimistic.etherscan.io/api | OP_ETHERSCAN_API_KEY |\n| Base Sepolia | https://sepolia.basescan.org | https://api-sepolia.basescan.org/api | BASE_ETHERSCAN_API_KEY |\n| Arbitrum Sepolia | https://sepolia.arbiscan.io | https://api-sepolia.arbiscan.io/api | ARBITRUM_ETHERSCAN_API_KEY |\n\n## Variants\n\n### Crosschain\n\n- Make sure the main account, as well as Alice and Bob accounts have a sufficient balance on OP Sepolia, Arbitrum Sepolia and Base Sepolia\n- Set the initial parameters of the test DAO in `dao.config.ts`\n- Run the `deploy-and-test.sh` script:\n\n```\nchmod +x scripts/deploy-and-test.sh\n./scripts/deploy-and-test.sh --salt \"<CUSTOM_SALT_HERE>\"\n```\n\n## Core Dependencies\n\n-   Node [v20.9.0](https://nodejs.org/uk/blog/release/v20.9.0/)\n-   PNPM [v9.10.0](https://pnpm.io/pnpm-vs-npm)\n-   Hardhat [v2.22.16](https://github.com/NomicFoundation/hardhat/releases/)\n-   OpenZeppelin Contracts [v5.1.0](https://github.com/OpenZeppelin/openzeppelin-contracts/releases/tag/v5.1.0)\n-   Ethers [v6.13.4](https://docs.ethers.org/v6/)\n\n## Support\n\nFeel free to reach out to [Julien](https://github.com/julienbrg) on [Farcaster](https://warpcast.com/julien-), [Element](https://matrix.to/#/@julienbrg:matrix.org), [Status](https://status.app/u/iwSACggKBkp1bGllbgM=#zQ3shmh1sbvE6qrGotuyNQB22XU5jTrZ2HFC8bA56d5kTS2fy), [Telegram](https://t.me/julienbrg), [Twitter](https://twitter.com/julienbrg), [Discord](https://discordapp.com/users/julienbrg), or [LinkedIn](https://www.linkedin.com/in/julienberanger/)."
  },
  "w3hc/w3hc-hardhat-template": {
    "fetchedAt": "2025-11-12T23:00:30.565Z",
    "content": "# W3HC Hardhat Template\n\nA comprehensive Solidity contract development environment using Hardhat.\n\n## Features\n\n-   [Typescript](https://www.typescriptlang.org/)\n-   [Ethers v6](https://docs.ethers.org/v6/)\n-   [OpenZeppelin Contracts v5.1.0](https://github.com/OpenZeppelin/openzeppelin-contracts/releases/tag/v5.1.0)\n-   [Hardhat Verify plugin](https://hardhat.org/hardhat-runner/plugins/nomicfoundation-hardhat-verify)\n-   [Hardhat Deploy plugin](https://github.com/wighawag/hardhat-deploy)\n\n## Supported Networks\n\n| Network | Chain ID | Documentation |\n|---------|----------|---------------|\n| Optimism Mainnet | 10 | [Documentation](https://docs.optimism.io/chain/networks#op-mainnet) |\n| Base Mainnet | 8453 | [Documentation](https://docs.base.org/docs/network-information#base-mainnet) |\n| Arbitrum One | 42161 | [Documentation](https://docs.arbitrum.io/welcome/get-started) |\n| Sepolia Testnet | 11155111 | [Documentation](https://ethereum.org/nb/developers/docs/networks/#sepolia) |\n| OP Sepolia Testnet | 11155420 | [Documentation](https://docs.optimism.io/chain/networks#op-sepolia) |\n| Base Sepolia Testnet | 84532 | [Documentation](https://docs.base.org/docs/network-information/#base-testnet-sepolia) |\n| Arbitrum Sepolia | 421614 | [Documentation](https://docs.arbitrum.io/welcome/get-started) |\n\n## Contract Verification\n\n| Network | Explorer URL | API URL | API Key Variable |\n|---------|--------------|---------|-----------------|\n| Optimism | https://optimistic.etherscan.io | https://api-optimistic.etherscan.io/api | OP_ETHERSCAN_API_KEY |\n| Base | https://basescan.org | https://api.basescan.org/api | BASE_ETHERSCAN_API_KEY |\n| Arbitrum One | https://arbiscan.io | https://api.arbiscan.io/api | ARBITRUM_ETHERSCAN_API_KEY |\n| Sepolia | https://sepolia.etherscan.io | https://api-sepolia.etherscan.io/api | ETHERSCAN_API_KEY |\n| OP Sepolia | https://sepolia-optimism.etherscan.io | https://api-sepolia-optimistic.etherscan.io/api | OP_ETHERSCAN_API_KEY |\n| Base Sepolia | https://sepolia.basescan.org | https://api-sepolia.basescan.org/api | BASE_ETHERSCAN_API_KEY |\n| Arbitrum Sepolia | https://sepolia.arbiscan.io | https://api-sepolia.arbiscan.io/api | ARBITRUM_ETHERSCAN_API_KEY |\n\n### Manual Contract Verification\n\n```bash\nnpx hardhat verify --network <NETWORK_NAME> <CONTRACT_ADDRESS> \"10000000000000000000000\"\n```\n\nWhere:\n- `<NETWORK_NAME>`: `optimism`, `base`, `arbitrum`, `sepolia`, `op-sepolia`, `base-sepolia`, `arbitrum-sepolia`\n- `<CONTRACT_ADDRESS>`: The address where your contract was deployed\n\n## Installation\n\n1. Install dependencies:\n```bash\npnpm install\n```\n\n2. Configure environment:\n```bash\ncp .env.template .env\n```\n\n3. Update `.env` with your configuration.\n\n## Usage\n\n### Testing\n\nExecute the test suite:\n```bash\npnpm test\n```\n\n### Deployment\n\nDeploy to supported networks:\n```bash\npnpm deploy:<network>\n```\nSupported values for `<network>`: `optimism`, `base`, `arbitrum`, `sepolia`, `op-sepolia`, `base-sepolia`, `arbitrum-sepolia`\n\n### Network Operations\n\nCheck wallet ETH balances:\n```bash\npnpm bal\n```\n\nMint tokens:\n```bash\npnpm mint:<network> <amount>\n```\n\nTransfer tokens:\n```bash\npnpm send:<network> <amount>\n```\n\n## Core Dependencies\n\n-   Node [v20.9.0](https://nodejs.org/uk/blog/release/v20.9.0/)\n-   PNPM [v9.10.0](https://pnpm.io/pnpm-vs-npm)\n-   Hardhat [v2.22.16](https://github.com/NomicFoundation/hardhat/releases/)\n-   OpenZeppelin Contracts [v5.1.0](https://github.com/OpenZeppelin/openzeppelin-contracts/releases/tag/v5.1.0)\n-   Ethers [v6.13.4](https://docs.ethers.org/v6/)\n\n## Support\n\nFeel free to reach out to [Julien](https://github.com/julienbrg) on [Farcaster](https://warpcast.com/julien-), [Element](https://matrix.to/#/@julienbrg:matrix.org), [Status](https://status.app/u/iwSACggKBkp1bGllbgM=#zQ3shmh1sbvE6qrGotuyNQB22XU5jTrZ2HFC8bA56d5kTS2fy), [Telegram](https://t.me/julienbrg), [Twitter](https://twitter.com/julienbrg), [Discord](https://discordapp.com/users/julienbrg), or [LinkedIn](https://www.linkedin.com/in/julienberanger/)."
  },
  "w3hc/web3dd": {
    "fetchedAt": "2025-11-12T23:00:30.946Z",
    "content": "# Web3 Decentralized Disk\n\nA classic file explorer to manage your files and directories in a safe and decentralized fashion.\n\n## Live demo\n\nWe're hosted by Fleek: \n\nhttps://disk.web3dd.net/ or https://web3dd.on-fleek.app/\n\n## Disk access\n\nYou can access your disk in several ways:\n\n- Web app ([view UI](https://disk.web3dd.net/))\n- From an on-chain contract\n\n## Install\n\n```shell\nnpm i\n```\n\n### Install for web disk\n\nYou can install the explorer locally and use the on-chain disk. Just run it (`npm start`) , you don't need to change anything.\n\nThe file explorer default network is Sepolia Testnet.\n\n### config/config.js\n\n```\nexport const ETH_CHAINS = [sepolia];\nexport const NETWORK_ID_SYMBOL = \"SEP\";\nexport const REGISTRY_ADDR = '0x4Bc81D37d5EE89c4186aF81d438B0a9AF34BD5c6';\n```\n\n### Local network setup\n\nDeploy the contracts on Ganache (read the [deploy](https://github.com/w3hc/web3dd?tab=readme-ov-file#deploy) section to learn more).\n\nSwitch to Ganache in **config/config.js**\n```\nexport const ETH_CHAINS = [localhost];\nexport const NETWORK_ID_SYMBOL = \"GETH\";\nexport const REGISTRY_ADDR = '<registry_address_on_ganache>';\n```\n\n## Run\n\n```shell\nnpm start\n```\n\n## Test contracts\n\n```shell\nnpx hardhat test\n```\n\n## Deploy\n\n- deploy the disk contract\n- deploy the registry contract\n- set the address of the disk contract in the registry (`setDiskContractAddress(<disk_address>)`)\n\n| :warning: Don't forget to copy your registry address in the `config/config.js` file! |\n| --- |\n\n\n## Update contract disk code\n\nIf you want to update the disk contract, deploy the new contract disk and set this new address in the registry.\n\n| :warning: the new code will only be active for the new disk created, the existing disks will keep the old code. |\n| --- |\n\n\n## Technologies use\n\n\t- solidity (0.8.25)\n    - wagmi\n    - connectkit\n    - react-accessible-treeview\n\n\n## Changelog\n\n### v0.1.0\n\n    Initial version\n\n\n## License\n\nMIT license\n\n\n## Support\n\nYou can contact us via [discord](https://discord.com/channels/753223385948880961/1224720192488210584)\n"
  },
  "bonadocs/protocol-registry": {
    "fetchedAt": "2025-11-12T23:00:39.749Z",
    "content": "# Bonadocs Protocol Registry\n\nThe protocol registry repository is a public open-source database to power the protocol search feature in Bonadocs,\nenabling public contribution while preserving accuracy guarantees.\n\n## How does it work?\n\nThe Protocol Registry is a GitHub repository indexed according to the rules defined in the [Indexing and Search](#indexing-and-search) section below.\nThis enables a publicly visible and verifiable record of protocols and their relevant metadata. The relatively small number of protocols\nmakes this approach sufficiently efficient.\n\n## How to add a protocol\n\nTo add a protocol to the database, fork this repository and make the following updates:\n- At the end of the `/names.txt` file, __APPEND__ the protocol name and slug in the following format: `slug: name`.\n- Leave an empty line at the end of the file.\n- The slug __MUST__ not have been used by a different protocol and must be reasonably similar to the protocol name.\n  For example, you cannot add `uniswap: Compound`. Your PR will be rejected if this is detected.\n- The slug __MUST__ include only lowercase letters of the English alphabet `(a-z)`, digits `(0-9)`, and can contain hyphens `(-)` in between one or more\n  letters and digits. The slug must match the regex: `^[a-z0-9]+(?:-[a-z0-9]+)*$`. Some (syntactically) valid slugs are `uniswap`, `uniswap-v2`, and `uniswap-v2-pilot`.\n  Note that slugs like `0123` would be syntactically valid but remember that the slug must be reasonably similar to the protocol name.\n- You __SHOULD__ __APPEND__ the slug to the relevant `/chains/evm[chainId].txt` files for each chain your protocol runs on.\n- The slug __MUST__ be included in at least one `/chains/evm[chainId].txt` file, corresponding to a chain the protocol\n  runs on.\n- You __SHOULD__ __APPEND__ the slug to the relevant `/tags/[tag].txt` files for each tag that applies to your protocol.\n- The metadata should be added to the `/data/[slug].json` file.\n  The format of the metadata is\n  \n  ````json\n  {\n     \"name\": \"user-readable protocol name\",\n     \"slug\": \"protocol-slug\",\n     \"owners\": \"comma,separated,github,usernames\",\n     \"tags\": \"comma,separated,tag,list\",\n     \"chains\": \"1,56,137\",\n     \"website\": \"https://url.of.main.website\",\n     \"links\": [\n        {\n           \"label\": \"Link Label\",\n           \"img\": \"ipfs://cid-of-square-svg-image-with-dimensions\",\n           \"link\": \"https://link-location\"\n        },\n        {\n           \"label\": \"Link Label 2\",\n           \"link\": \"https://link-location-2\"\n        }\n     ],\n     \"collection\": \"ipfs://cid-of-valid-collection-generated-by-bonadocs-editor\"\n  }\n  ````\n- Once done, you can submit a PR to commit your changes to the DB.\n- The owners list is a list of github usernames allowed to make changes to the protocol data. Any commits changing a protocol's metadata by anyone other than the owners will be rejected.\n- Your PR text should include a link to your protocol home page and your Bonadocs collection page.\n- Wait for your PR to be reviewed. We will do some due diligence to make sure you are not impersonating a protocol and using\n  fake data. If we have any questions or concerns, we will raise them on the PR thread.\n- Once your PR is reviewed, it will take some time for your changes to be broadcast because the files are cached on developers' devices. TTL is currently 2 hours.\n\n## Indexing and Search\n### Indexing\n\nWhen you add your protocol, you add the name to the `/names.txt` file and add the slugs to the relevant `/chains/evm[chainId].txt` files and `/tags/[tag].txt` files.\nThis is all the indexing that is necessary to enable the discovery of your protocol. Because of the relatively small number of protocols, this indexing\nsystem is good and fast enough to power the search tool for most developers.\n\n### Search\nThe search algorithm is simple. When a developer supplies a query text `q` optionally with tag `t` and/or chainId `c` on the search interface, the following things happen:\n- The `names.txt` file is searched for the text `q`. The names and slugs of the protocols containing `q` are added to a result list.\n- If a chainId `c` is supplied in the query, the `/chainId/evm{c}.txt` file is searched for the slugs. Only the slugs from the result list contained in the chain file are retained.\n- If a tag `t` is supplied in the query, the `/tags/{t}.txt` file is searched for the slugs. Only the slugs from the result list contained in the tag file are retained.\n- The final result list is returned for the query.\n\nTo pull the metadata for any protocol, the relevant metadata is downloaded from the `/data/[slug].json` file.\n\n## Why is Search powered by a GitHub Repository?\n\nWe want to ensure that the developers can trust the results of the search DB. We manually review each PR to add a protocol to the DB to achieve that.\nThe search feature is powered by protocol names and it is often impossible to verify that a contract deployed at a given address has any role in a protocol.\nThis means a fully open model would have significant risks that cannot be ignored. A fully decentralized process would require developing a protocol that\nmitigates the risks correctly and efficiently while considering other factors, such as cost.\n\nA manual review process that is open and public and can be verified by any interested parties is the compromise we have decided to make. If the DB grows\nsufficiently large to make the current GitHub-powered process inefficient, we would consider building a more decentralized protocol to handle the load.\n\n### Potential Limitations\n\n- __Manual review is slower__. It would take longer to add a protocol to the search tool or update protocol information. If the demand is high, we will\n  implement a solution to speed up update times for pre-reviewed protocols. Initial reviews will stay manual for the foreseeable future.\n- __Search can be inefficient as the DB grows__. Based on our estimate of fewer than 10000 web3 protocols with active users across EVM chains, the current\n  GitHub-based search solution is good enough to handle most users' needs.\n\n  ## üìú License\n\nThis project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.\n\nBy using, modifying, or distributing this software, you agree to comply with the terms of the **AGPL-3.0** license.\n\nFor more details, see the [LICENSE](LICENSE) file or visit:  \n[https://www.gnu.org/licenses/agpl-3.0.html](https://www.gnu.org/licenses/agpl-3.0.html)\n\n"
  },
  "bonadocs/protocol-registry-web": {
    "fetchedAt": "2025-11-12T23:00:40.157Z",
    "content": "This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\n\n## Getting Started\n\nFirst, run the development server:\n\n```bash\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n# or\nbun dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\n\nThis project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.\n\n## Learn More\n\nTo learn more about Next.js, take a look at the following resources:\n\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\n\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!\n\n## Deploy on Vercel\n\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\n\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.\n"
  },
  "bonadocs/docgen": {
    "fetchedAt": "2025-11-12T23:00:40.672Z",
    "content": "# `@bonadocs/docgen`\n\n__docgen is a program that extracts documentation for a Solidity project and generates an\ninteractive website from it using Docusaurus.__\n\n`@bonadocs/docgen` is based on `solidity-docgen`. If you already use `solidity-docgen`, you\nalready know how to use `@bonadocs/docgen`. Hmmm, maybe 90% of it. The two main differences are:\n\n- `@bonadocs/docgen` generates a website using Docusaurus, while `solidity-docgen` only generates\n  Markdown files. You can turn off the website generation if you want to use a different static site\n  generator and only markdown files will be generated, much like `solidity-docgen`. If you would like\n  to use include widgets that make your documentation interactive, then this is a great option.\n- `@bonadocs/docgen` generates widgets for deployed contracts, so developers can interact with the\n  contracts directly from the documentation website. This is better than sending them off to Etherscan\n  or worse, having them write their own scripts to interact with the contracts.\n\nThe markdown output is fully configurable through Handlebars templates, but the default templates should\ndo a good job of displaying all of the information in the source code in Markdown format. If you don't\nwant to generate a website, the generated Markdown files can be used with a static site generator \nsuch as Docusaurus, Vuepress, MkDocs, Jekyll (GitHub Pages), etc., in order to publish a documentation\nwebsite.\n\n## Widget?\n\nThe widgets are interactive components that allow users to interact with the contracts directly from\nthe documentation website. Widgets run simulations by default and enable developers to test without\npaying gas fees. Developers love to learn by doing, and this is the perfect way to let them do just that.\nThe widgets are generated using [`@bonadocs/widget`](https://github.com/bonadocs/widget).\n\n__Note: widgets will only be generated for contracts with their deployment addresses specified.\nRefer to the configuration below__\n\n## Usage\n\nInstall `@bonadocs/docgen` from npm.\n\n### Hardhat\n\nInclude the plugin in your Hardhat configuration.\n\n```diff\n // hardhat.config.ts\n+import '@bonadocs/docgen';\n\nexport default {\n+  docgen: {\n+    projectName: 'Your Protocol Name', // optional, a placeholder name will be used if omitted\n+    projectDescription: 'An awesome web3 protocol.', // optional, a placeholder description will be used if omitted\n+    deploymentAddresses: { // optional. If you want to generate widgets for deployed contracts\n+      FirstContractName: [\n+        {\n+          chainId: 1, // mainnet\n+          address: '0x...',\n+        },\n+        {\n+          chainId: 42161, // arbitrum\n+          address: '0x...',\n+        },\n+      ],\n+      SecondContractName: [\n+        {\n+          chainId: 1, // mainnet\n+          address: '0x...',\n+        },\n+        {\n+          chainId: 42161, // arbitrum\n+          address: '0x...',\n+        },\n+      ],\n+    },\n+  }, // if necessary to customize config\n};\n```\n\nThen run with `npx hardhat docgen`.\n\n### As a library\n\n```typescript\nimport { docgen } from '@bonadocs/docgen';\n\nabis = [\n  {\n    contractName: 'MyContract',\n    abi: '...'\n  }\n]\nawait docgen([{ output: solcOutput }], config, abis);\n```\n\n`solcOutput` must be the standard JSON output of the compiler, with at least the `ast` output. There can be more than one.\n\n`config` is an optional object with the values as specified below.\n\n## Config\n\nSee [`config.ts`](./src/lib/config.ts) for the list of options and their documentation.\n\n`abis` is an optional array of objects with the following properties:\n\n- `contractName`: the name of the contract\n- `abi`: the ABI of the contract\n"
  },
  "bonadocs/docs": {
    "fetchedAt": "2025-11-12T23:00:41.189Z",
    "content": "# Bonadocs Documentation\n\nBonadocs allows web3 engineering teams to collaborate and build applications in a very intuitive way. To simplify integrations, we've categorized our tooling as follows:\n\n* **Docgen**: Docgen allows developers to go from their codebase to beautiful and interactive documentation in seconds. Using our hardhat plugin, you can generate interactive documentation to query your contract methods.\n* **Widget**: Through our playground environment, you can generate widgets for your contract methods. These widgets can then be easily embedded in your docs or any react application for devs to query. This is instrumental for devrel teams, to help onboard external devs.\n* **Playground**: Our playground is a collaborative environment primarily for solidity and front-end devs to build applications. This can be used by internal engineering teams or teams across different organizations. Devrel teams can also take advantage of the playground to create a single source of truth for their protocol - making onboarding super easy for their developer community.\n* **Protocol Registry**: Our protocol registry is an open-source tool that allows you to find different popular protocols and their respective playgrounds.\n\nOn a high level, bonadocs are created to simplify the documentation, interaction, and integration of smart contracts.\n\n\n"
  },
  "bonadocs/cli": {
    "fetchedAt": "2025-11-12T23:00:41.612Z",
    "content": "# @bonadocs/cli\n\nBonadocs CLI lets you generate widgets for your solidity docs and interact with the\nprotocol registry. For a GUI interface, check out our editor at [bonadocs.com](https://bonadocs.com).\n\n## Installation\n\n```bash\nnpm install -g @bonadocs/cli\n```\n\n## Quick Usage Guide\n\n```bash\nbonadocs --help\n```\n\n### Generate a widget\n\n```bash\nbonadocs collections <collection> widget\n\n# Example\nbonadocs collections uniswap widget\n```\n\n\n### Find a protocol on the registry\n\n```bash\nbonadocs registry search -q <protocol>\n```\n\n### Open a protocol from the registry on your local device\n\n```bash\nbonadocs registry open -s <protocol>\n```\n\nFull documentation can be found at [bonadocs.com/docs](https://bonadocs.com/docs).\n"
  },
  "stargate-protocol/stargate": {
    "fetchedAt": "2025-11-12T23:00:50.680Z",
    "content": "# Stargate - Composable Native Asset Bridge\n\nStargate is a **composable** native asset bridge with **unified liquidity**  and **instant guaranteed finality**  built on top of the LayerZero protocol. The repository contains the smart contracts of the core protocol for stargate.\n\n\n### Setup\n- copy .env.example to .env and fill in variables\n- `yarn install`\n### Testing\n`yarn test`\n#### Single Test File\n`yarn test test/Pool.test.js`\n\n\n### Acknowledgements \n\nThank you to the core development team for helping build the Stargate smart contracts : Ryan Zarick, Isaac Zhang, Caleb Banister, Carmen Cheng and T. Riley Schwarz\n\n### LICENSING\n\nThe primary license for LayerZero is the Business Source License 1.1 (BUSL-1.1). see [`LICENSE`](./LICENSE).\n"
  },
  "Steemhunt/mint.club-v2-contract": {
    "fetchedAt": "2025-11-12T23:01:10.383Z",
    "content": "![image](https://github.com/Steemhunt/mint.club-v2-contract/assets/1332279/66ce69bd-7ebd-4d58-b064-f82053b51b5a)\n\n# Mint Club V2\n\n## Overview üëÄ\n\nMint Club is a bonding curve-based token (ERC20, ERC1155) creation and trading protocol. Users can create an asset with a custom bonding curve on top of any existing ERC20 token as collateral. By using a bonding curve, the new asset is immediately tradable without the need for liquidity creation on DEXs or CEXs.\n\n- Docs: https://docs.mint.club (V2 documentaion is in progress)\n- Demo Video: https://www.youtube.com/watch?v=BR_MJozU-DU\n\n## Security Audit üîí\n\n- [Audit Report by CertiK](https://github.com/Steemhunt/mint.club-v2-contract/blob/main/security-audits/CertiK-20240118.pdf)\n- [Skynet Monitoring](https://skynet.certik.com/ko/projects/mint-club)\n\n## Key features üóùÔ∏è\n\n1. **Token Creation (ERC20 or ERC1155)**\n\n   - Create a bonding curve token (ERC20) or NFT (ERC1155) by using another ERC20 token as the base asset for your token's bonding curve pool.\n   - Choose from curve types such as linear, exponential, or flat line, and adjust the price variation intervals for your token's journey.\n   - Set key token specifications like starting price, free minting allocation, maximum price, and supply.\n   - Deploy your asset on various Layer 1 and 2 networks.\n\n2. **Buy (= Mint) and Sell (= Burn) Bonding Curve Asset**\n\n   - When a bonding curve token is bought, the price curve determines the amount of the base token to be paid, enabling a swap. The paid base tokens are stored in the bonding curve pool, and an equivalent amount of the bonding curve tokens is minted to the buyer.\n   - Conversely, when a bonding curve token is sold, the curve calculates the amount of base tokens to be returned. These base tokens are then returned to the seller, and the equivalent bonding curve tokens are burned.\n\n3. **Airdrop Tool**\n\n   - Set up a public or private airdrop for ERC20 or ERC1155 (supports `id = 0` only) tokens.\n   - For private airdrops, Mint Club offers a merkleRoot-based whitelist feature.\n\n4. **Lock-up Tool**\n   - Create a contract-bound lock-up schedule for ERC20 or ERC1155 (supports `id = 0` only) tokens.\n   - Specify the unlock time and recipient address for after the lock-up period is completed.\n\n## Gloals and Objectives ‚õ≥Ô∏è\n\nMint Club aims to provide no-code, yet flexible, token creation tools for web3 creators who want to build their token economy. One of the biggest hurdles in building token economics is providing liquidity in the early stages, but this issue is eliminated with the Mint Club protocol.\n\n## Contract addresses üìú\n\n<table>\n   <thead>\n      <tr>\n         <th>Contract /  Chain</th>\n         <th><a href=\"https://etherscan.io\">Ethereum</a></th>\n         <th><a href=\"https://optimistic.etherscan.io\">Optimism</a></th>\n         <th><a href=\"https://arbiscan.io\">Arbitrum One</a></th>\n         <th><a href=\"https://basescan.org\">Base</a></th>\n         <th><a href=\"https://bscscan.com\">BNB Chain</a></th>\n         <th><a href=\"https://polygonscan.com\">Polygon (PoS)</a></th>\n      </tr>\n   </thead>\n   <tbody>\n      <tr>\n         <td>MCV2_Token</td>\n         <td colspan=\"6\">0xAa70bC79fD1cB4a6FBA717018351F0C3c64B79Df</td>\n      </tr>\n      <tr>\n         <td>MCV2_MultiToken</td>\n         <td colspan=\"6\">0x6c61918eECcC306D35247338FDcf025af0f6120A</td>\n      </tr>\n      <tr>\n         <td>MCV2_Bond</td>\n         <td colspan=\"6\">0xc5a076cad94176c2996B32d8466Be1cE757FAa27</td>\n      </tr>\n      <tr>\n         <td>MCV2_ZapV1</td>\n         <td colspan=\"6\">0x91523b39813F3F4E406ECe406D0bEAaA9dE251fa</td>\n      </tr>\n      <tr>\n         <td>Locker</td>\n         <td colspan=\"6\">0xA3dCf3Ca587D9929d540868c924f208726DC9aB6</td>\n      </tr>\n      <tr>\n         <td>MerkleDistributor</td>\n         <td colspan=\"6\">0x1349A9DdEe26Fe16D0D44E35B3CB9B0CA18213a4</td>\n      </tr>\n      <tr>\n         <td>MCV1_Wrapper</td>\n         <td colspan=\"6\">0x29b0E6D2C2884aEa3FB4CB5dD1C7002A8E10c724 (BNB Chain only)</td>\n      </tr>\n   </tbody>\n</table>\n<table>\n   <thead>\n      <tr>\n         <th>Contract /  Chain</th>\n         <th><a href=\"https://blastexplorer.io/\">Blast</a></th>\n      </tr>\n   </thead>\n   <tbody>\n      <tr>\n         <td>MCV2_Token</td>\n         <td>0x1349A9DdEe26Fe16D0D44E35B3CB9B0CA18213a4</td>\n      </tr>\n      <tr>\n         <td>MCV2_MultiToken</td>\n         <td>0x5DaE94e149CF2112Ec625D46670047814aA9aC2a</td>\n      </tr>\n      <tr>\n         <td>MCV2_Bond</td>\n         <td>0x621c335b4BD8f2165E120DC70d3AfcAfc6628681</td>\n      </tr>\n      <tr>\n         <td>MCV2_ZapV1</td>\n         <td>0x06FD26c092Db44E5491abB7cDC580CE24D93030c</td>\n      </tr>\n      <tr>\n         <td>Locker</td>\n         <td>0x3Fd5B4DcDa968C8e22898523f5343177F94ccfd1</td>\n      </tr>\n      <tr>\n         <td>MerkleDistributor</td>\n         <td>0x29b0E6D2C2884aEa3FB4CB5dD1C7002A8E10c724</td>\n      </tr>\n   </tbody>\n</table>\n<table>\n   <thead>\n      <tr>\n         <th>Contract /  Chain</th>\n         <th><a href=\"https://snowtrace.io\">Avalanche (C (C-Chain)-Chain)</a></th>\n      </tr>\n   </thead>\n   <tbody>\n      <tr>\n         <td>MCV2_Token</td>\n         <td>0x5DaE94e149CF2112Ec625D46670047814aA9aC2a</td>\n      </tr>\n      <tr>\n         <td>MCV2_MultiToken</td>\n         <td>0x621c335b4BD8f2165E120DC70d3AfcAfc6628681</td>\n      </tr>\n      <tr>\n         <td>MCV2_Bond</td>\n         <td>0x3Fd5B4DcDa968C8e22898523f5343177F94ccfd1</td>\n      </tr>\n      <tr>\n         <td>MCV2_ZapV1</td>\n         <td>0x29b0E6D2C2884aEa3FB4CB5dD1C7002A8E10c724</td>\n      </tr>\n      <tr>\n         <td>Locker</td>\n         <td>0x5b64cECC5cF3E4B1A668Abd895D16BdDC0c77a17</td>\n      </tr>\n      <tr>\n         <td>MerkleDistributor</td>\n         <td>0x841A2bD2fc97DCB865b4Ddb352540148Bad2dB09</td>\n      </tr>\n   </tbody>\n</table>\n<table>\n   <thead>\n      <tr>\n         <th>Contract /  Chain</th>\n         <th><a href=\"https://explorer.degen.tips\">Degen Chain</a></th>\n      </tr>\n   </thead>\n   <tbody>\n      <tr>\n         <td>MCV2_Token</td>\n         <td>0xaF987E88bf30581F7074E628c894A3FCbf4EE12e</td>\n      </tr>\n      <tr>\n         <td>MCV2_MultiToken</td>\n         <td>0x91523b39813F3F4E406ECe406D0bEAaA9dE251fa</td>\n      </tr>\n      <tr>\n         <td>MCV2_Bond</td>\n         <td>0x3bc6B601196752497a68B2625DB4f2205C3b150b</td>\n      </tr>\n      <tr>\n         <td>MCV2_ZapV1</td>\n         <td>0x1349A9DdEe26Fe16D0D44E35B3CB9B0CA18213a4</td>\n      </tr>\n      <tr>\n         <td>Locker</td>\n         <td>0xF44939c1613143ad587c79602182De7DcF593e33</td>\n      </tr>\n      <tr>\n         <td>MerkleDistributor</td>\n         <td>0x5DaE94e149CF2112Ec625D46670047814aA9aC2a</td>\n      </tr>\n   </tbody>\n</table>\n<table>\n   <thead>\n      <tr>\n         <th>Contract /  Chain</th>\n         <th><a href=\"https://explorer.zora.energy/\">Zora</a></th>\n         <th><a href=\"https://kaiascan.io/\">Kaia</a></th>\n         <th><a href=\"https://cyberscan.co/\">Cyber</a></th>\n         <th><a href=\"https://ham.calderaexplorer.xyz/\">Ham</a></th>\n         <th><a href=\"https://apescan.io/\">APEChain</a></th>\n         <th><a href=\"https://shibariumscan.io/\">Shibarium</a></th>\n         <th><a href=\"https://explorer.hsk.xyz/\">HashKey</a></th>\n         <th><a href=\"https://uniscan.xyz/\">Unichain</a></th>\n         <th><a href=\"https://scan.over.network/\">Over</a></th>\n      </tr>\n   </thead>\n   <tbody>\n      <tr>\n         <td>MCV2_Token</td>\n         <td colspan=\"9\">0xAa70bC79fD1cB4a6FBA717018351F0C3c64B79Df</td>\n      </tr>\n      <tr>\n         <td>MCV2_MultiToken</td>\n         <td colspan=\"9\">0x6c61918eECcC306D35247338FDcf025af0f6120A</td>\n      </tr>\n      <tr>\n         <td>MCV2_Bond</td>\n         <td colspan=\"9\">0xc5a076cad94176c2996B32d8466Be1cE757FAa27</td>\n      </tr>\n      <tr>\n         <td>MCV2_ZapV1</td>\n         <td colspan=\"9\">0x91523b39813F3F4E406ECe406D0bEAaA9dE251fa</td>\n      </tr>\n      <tr>\n         <td>Locker</td>\n         <td colspan=\"9\">0xA3dCf3Ca587D9929d540868c924f208726DC9aB6</td>\n      </tr>\n      <tr>\n         <td>MerkleDistri\n\n[... truncated ...]"
  },
  "Steemhunt/mint.club-v2-sdk": {
    "fetchedAt": "2025-11-12T23:01:10.785Z",
    "content": "# Mint Club V2 Bond Contract SDK\n\n```\n‚ö†Ô∏è\nNOTE: This SDK is still under construction and is subject to change any time.\n\nPLEASE USE WITH CAUTION\n```\n\nThis SDK enables seamless interaction with Mint Club's smart contracts, offering both read and write capabilities across multiple blockchain networks.\n\nCheck the docs here: https://sdk.mint.club\n\n```\n/************************\n           _       _\n _ __ ___ (_)_ __ | |_\n| '_ ` _ \\| | '_ \\| __|\n| | | | | | | | | | |_\n|_| |_| |_|_|_| |_|\\__|\n(_)__| |_   _| |__\n / __| | | | | '_ \\\n| (__| | |_| | |_) |\n \\___|_|\\__,_|_.__/\n\nMade with ‚òï\n\n**************************/\n```\n\n## Running tests\n\n```bash\nnpm i\n\nnpx hardhat compile\n\nnpm test\n```\n"
  },
  "llamasubs/contracts": {
    "fetchedAt": "2025-11-12T23:01:20.579Z",
    "content": "# Subscriptions\nContract for charging recurring subscriptions while having subscribers also earn yield on their deposits through ERC4626-compatible vaults.\n\nMain benefit of it is that it automates payments and, if users deposit enough money so that yield is higher than payments, the subscription actually becomes free. This doesn't require a lot of money, for a subscription of 5$/mo users would only need to deposit 1.2k for it to be free with sDAI yields.\n\nWhen a new subscription is created, the subscriber will be instantly charged pro-rata for the time left till the end of the period, afterwards they will be charged for a full period at the beginning of each period. If they unsubscribe they'll be returned the money for any periods left till their subscription expires, plus all the yield they've earned, however payment for the current period won't be returned.\n\nContract charges a 1% fee on volume that is paid through subscriptions, which is collected when the receiver of the subscription claims their earnings.\n\n## Design decisions\nAnother possible design would have been to have a liquidation system where bots could call accounts for which total paid in subscriptions is higher than their account balance, and remove their payments from `amountPerPeriod` of the receiver, thus ensuring that `amountPerPeriod` always only has subscriptions that are up to date. This system has a few benefits:\n- You don't need to handle cases where subscription ended some time ago (since subscriptions are terminated through a bot tx when they expire), so you don't need to track `sharesPerPeriod`, which makes operations always O(1) and bounded, eliminating the 10 years of inactivity problem\n- Reduces gas costs because you don't need to store `sharesPerPeriod` nor `receiverAmountToExpire`\n- Users can just top up all their streams in a single operation instead of having to top up streams one by one, also all streams feed from a single balance so there's no fragmentation, which provides a better UX\n\nHowever, the big issue is that if, for any reason, these liquidation bots stop working, it would be possible for an attacker to create an extremely expensive stream to itself and just let it run, since it wont get liquidated by bots it will keep going, transferring non-existing money to the receiver and allowing the attacker to drain the contract and steal from every other user.\n\nSo this design relies on these liquidation bots working all the time, otherwise contracts are drained. While it's possible to incentivize liqudations with a reward, these will likely be extremely small and there's a high probability that the only one running bots will be the team, making the whole thing very fragile. I've opted to use a different design for this reason, to remove the reliance on lively liquidation bots and ensure safety always.\n\n## Commands\n```shell\nnpm i\nnpm build\nnpm test\nREPORT_GAS=true npm test\nexport $(echo $(cat .env | sed 's/#.*//g'| xargs) | envsubst) && npx hardhat deploy --network optimism\nexport $(echo $(cat .env | sed 's/#.*//g'| xargs) | envsubst) && npx hardhat etherscan-verify --network optimism\nexport $(echo $(cat .env | sed 's/#.*//g'| xargs) | envsubst) && npx hardhat verify --network optimism DEPLOYED_CONTRACT_ADDRESS\nexport $(echo $(cat .env | sed 's/#.*//g'| xargs) | envsubst) && npx hardhat run scripts/liveTest.ts --network optimism\n```\n"
  },
  "LlamaPay/llamapay": {
    "fetchedAt": "2025-11-12T23:01:21.020Z",
    "content": "# LlamaPay\n\nAutomate salary txs, streaming them by the second so employees can withdraw whenever they want and you don't have to deal with sending txs manually.\n\nFeatures:\n- Easy top up for all streams in 1 operation\n- Low gas\n- Ability to trigger withdraws for someone else (for people that don't use metamask)\n- Open source & verified contracts\n- Fast UI\n- Available on all chains\n- No big precision errors\n- Works with all tokens\n- Deposits and withdrawals in 1 operation\n- Works with debt, if you forget to pay on time we keep track of everything you missed\n- No need to deposit all money at the start of the stream\n\n## Why?\nI used to handle payments by just sending transactions at the end of the month, however that soon turned into a pain and I started looking at alternatives that could automate it. Then I started using superfluid for that, and while the concept was great, there were many small execution problems that made using it very uncomfortable. Llamapay is my attempt at scratching my own itch, to build a system that exactly fits our needs at defillama, and, as I'm sure there's other teams that could benefit from it too, we plan to open source it and release it for everyone to use.\n\n## A note for integrations: decimals\nLlamaPay uses an internal representation with 20 decimals for all it's numbers. The reason for this is to prevent math precision errors which can end up being significant (eg: if we used native decimals, a 1k/mo USDC stream becomes 994/mo instead).\n\nThis has the issue that all integrations need to be mindful of that, so here are a list of methods and whether they use native token decimals or not:\n| Method | Decimals|\n|--------|---------|\n|getPayerBalance|native|\n|withdrawable|native|\n|deposit|native|\n|balances|1e20|\n|amountPerSec everywhere| 1e20|\n|createStream|1e20|\n|modifyStream|1e20|\n|withdrawPayer|1e20|\n\n> LlamaPay doesn't work with rebasing tokens or tokens that have fee-on-transfer\n\n## Features\n\n### Gas costs\nCost to create a stream:\n| Protocol | Cost (gas) |\n|----------|-------------|\n| LlamaPay | 69,963\n| Sablier | 240,070\n| SuperFluid | 279,992\n\nSo LlamaPay is 3.2x-3.7x cheaper than the competition!\n\n### No requirement on depositing all money needed for the stream\nSablier requires you to pick a duration for each stream and deposit all the money needed for the entirety of the stream at the start. This doesn't map well to salaries, since length is indeterminate.\n\nThis system forces you to keep creating new streams as the old ones die and you have to provide a large amount of capital that gets locked if you pick long durations. Instead a much better system is one where you create streams of indefinite duration and these just siphon money out of a pool, which makes it possible to top all streams up in a single operation and just provide money as it's needed to maintain them.\n\n### Withdrawals that anyone can trigger\nSome people will choose to provide an address that belongs to a CEX or a wallet that can't make ethereum calls. With current solutions this makes it impossible for them to claim their money, but llamapay allows anyone to trigger withdrawals, so it works in these cases too.\n\nThey can just set a CEX address and have someone else trigger withdrawals or trigger them themselves using another wallet. This greatly simplifies operations and possible problems.\n\n### Available on all chains\nAfter our public release, llamapay will be available on all EVM chains and all the contracts will share the same address across chains.\n\n### No big precision errors\nSablier uses the same units as the underlying token when handling math for the stream. This means that for tokens that have a low number for decimals(), such as USDC, this causes precision errors. For example: if you stream 1000 USDC to an address, you'll instead end up streaming 997 USDC instead due to these errors.\n\nLlamaPay operates internally with 20 decimals, which keep precision errors to a minimum.\n\n### Works with all tokens\nUsing any token is very easy, which is not the case for superfluid.\n\n### Debt\nIn superfluid, if you forget to top up your balance and the streams deplete all your balance, a bot will send a tx that will cancel all your streams, and takes part of your money, which you just lose. To get it working again you need to:\n- Create all the streams from scratch again\n- Calculate how much money payees have lost while the streams were down and send it to them manually\n- Just accept the losses from the cancellations\n\nThis is not ideal because the whole reason you want this is to automate payments and the product should reduce your workload, not increase it like that.\n\nWith LlamaPay, when your balance gets depleted, all that happens is that the payer just starts incurring debt, and when there's a new deposit that debt is paid and streams keep working as usual. If the payer really meant to stop streams by just not depositing more, they can just not deposit any more (users will be able to withdraw the money they received up until the payer's balance was depleted), or cancel individual streams, which will remove their debt.\n\nPayer never has the option to remove money that has already been streamed, once it has been streamed it can only be withdrawn to the payee's wallet. This makes it equivalent to superfluid's system from the POV of the payee, the only difference is that LlamaPay gives the option to the payer to just resume streams and repay debt easily, greatly simplifying the process in case they forgot or couldn't top up in time.\n\nSuperfluid bot: https://polygonscan.com/address/0x759999a81fade877fe91ed4c09db45ee50db2044\n\n\n### Single-tx operations\nSuperfluid requires multiple operations for actions that are common (eg: withdraw money from a stream). LlamaPay simplifies these as maximum as possible and makes them available in a single tx.\n\n## Roadmap\n1. After UI is ready we'll deploy on mainnet and migrate all defillama payroll to it\n2. We'll use it ourselves and modify anything we don't like\n3. Remove rug code and release it publicly\n4. Build v2\n\n## V2\n- Earn yield while money is being streamed (I built a version with this under v2, but it's very complex so we aren't deploying it)\n- DCA with salary\n- Positions as NFTs to enable payees to use that on defi (eg: pawn it to get payment advances)\n\nMoonshots:\n- Privacy though zero knowledge proofs\n\n----\n\n## Development\n\n```shell\nnpm test\nnpx hardhat coverage\nnpx hardhat deploy --network rinkeby\nnpx hardhat etherscan-verify --network rinkeby\nnpx hardhat verify --network rinkeby DEPLOYED_CONTRACT_ADDRESS\n```\n"
  },
  "zkemail/email-recovery": {
    "fetchedAt": "2025-11-12T23:01:29.685Z",
    "content": "## ZK Email Recovery\n\n## Overview\n\nAccount recovery has traditionally been one of the most complex UX hurdles that account holders have to contend with. The ZK Email Recovery contracts provide a robust and simple mechanism for account holders to recover modular accounts via email guardians.\n\nModular accounts get account recovery for 'free' by using our pre-deployed universal email recovery module. Since Safe's can be made 7579 compatible, the following contracts also support Safe account recovery out of the box too. For older existing Safes that are not compatible with ERC4337 (and subsequenty ERC7579), we provide a native Safe module too.\n\nModular account developers can easily integrate email recovery with richer and more specific commands in the email body by writing their own command handler contracts, which are designed to be simple and contain the modular account-specific logic to recover an account.\n\n## Usage\n\n### Install dependencies\n\n```shell\npnpm install\n```\n\n### Build\n\n```shell\npnpm build\n# or\n# forge build\n```\n\n### Test\n\n```shell\npnpm test\n# or\n# forge test --match-path \"test/**/*.sol\" or\n```\n\n### Test for scripts\n\n```shell\npnpm test:script\n# or\n# forge test --match-path \"script/test/**/*.sol\" --threads 1\n```\n\n# ZK Email Recovery\n\n### EmailRecoveryManager.sol\n\n`EmailRecoveryManager.sol` is an abstract contract that defines the main logic for email-based recovery. It is designed to provide the core logic for email based account recovery that can be used across different modular account implementations. For the end user, the core `EmailRecoveryManager` contract aims to provide a robust and simple mechanism to recover accounts via email guardians.\n\nIt inherits from a ZK Email contract called `EmailAccountRecovery.sol` which defines some basic recovery logic that interacts with lower level ZK Email contracts. `EmailAccountRecovery.sol` holds the logic that interacts with the lower level ZK Email contracts `EmailAuth.sol`, verifier, dkim registry etc. More info on the underlying `EmailAccountRecovery.sol` contract can be found [here](https://github.com/zkemail/ether-email-auth/tree/main/packages/contracts#emailaccountrecovery-contract).\n\nThe guardians are represented onchain by `EmailAuth.sol` instances. `EmailAuth.sol` is designed to authenticate that a user is a correct holder of the specific email address and authorize anything described in the email. The guardians privacy is protected onchain, for more info on ZK Email privacy and EmailAuth - see the [ZK Email docs](https://zkemail.gitbook.io/zk-email).\n\nNote: `EmailAccountRecovery.sol` & `EmailAuth.sol` can be found in the [ether-email-auth](https://github.com/zkemail/ether-email-auth) repo\n\n`EmailRecoveryManager` relies on a dedicated recovery module to execute a recovery attempt - the recovery module inherits from the email recovery manager contract. The `EmailRecoveryManager` contract defines \"what a valid recovery attempt is for an account\", and the recovery module defines ‚Äúhow that recovery attempt is executed on the account‚Äù. One motivation for having the 7579 recovery module and the core `EmailRecoveryManager` contract being seperated is to allow the core recovery logic to be used across different account implementations and module standards. The core `EmailRecoveryManager.sol` contract is designed to be account implementation agnostic. For example, we have a native Safe module as well as two 7579 modules that use the same underlying manager. It's functionality can be extended by creating new command handler contracts such as `EmailRecoveryCommandHandler.sol`.\n\n## EmailRecoveryManager flow walkthrough\n\nThe core functions that must be called in the end-to-end flow for recovery are\n\n1. configureRecovery (does not need to be called again for subsequent recovery attempts)\n2. handleAcceptance - called for each guardian. Defined on `EmailAccountRecovery.sol`, calls acceptGuardian in this contract\n3. handleRecovery - called for each guardian. Defined on `EmailAccountRecovery.sol`, calls processRecovery in this contract\n4. completeRecovery\n\nBefore proceeding, ensure that you deploy the email recovery contracts via one of the email recovery factories.\n\n### Configure Recovery\n\nAfter deployment, this is the first core function in the recovery flow, setting up the recovery module, guardians, guardian weights, threshold, and delay/expiry. It only needs to be called once. The threshold must be set appropriately to balance security and usability. The same goes for the delay and expiry - there is a minimum recovery window time that protects against an account giving itself a prohibitively small window in which to complete a recovery attempt.\n\n`configureRecovery` is called during the installation phase of the recovery module. This ensures that a user cannot forget to install the recovery module, go to configure recovery, and end up with a broken recovery config.\n\n```ts\nfunction configureRecovery(\n    address[] memory guardians,\n    uint256[] memory weights,\n    uint256 threshold,\n    uint256 delay,\n    uint256 expiry\n) external;\n```\n\n### Handle Acceptance\n\nThis function handles the acceptance of each guardian. Each guardian must accept their role to be a part of the recovery process. This is an important step as it ensures that the guardian consents to the responsibility of being a guardian for a specific account, is in control of the specific email address, and protects against typos from entering the wrong email. Such a typo would render the guardian unusable. `handleAcceptance` must be called for each guardian until the threshold is reached.\n\n```ts\nfunction handleAcceptance(\n    address guardian,\n    uint256 templateIdx,\n    bytes[] memory commandParams,\n    bytes32\n) internal;\n```\n\n### Handle Recovery\n\nThis function processes each guardian's recovery request. A guardian can initiate a recovery request by replying to an email. The contract verifies the guardian's status and checks if the threshold is met. Once the threshold is met and the delay has passed, anyone can complete the recovery process. The recovery delay is a security feature that gives the wallet owner time to react to a recovery attempt in case of a malicious guardian or guardians. This is possible from guardians who act maliciously, but also from attackers who have access to a guardians email address. Although since guardian email privacy is preserved on chain, this reduces the attack surface further since someone with access to a someone elses email account would not automatically know if the email address is used in a recovery setup, or if they did, which account to target. They could find this information out by searching for recovery setup in the email inbox however. There is also an expiry time, which once expires, invalidates the recovery attempt. This encourages timely execution of recovery attempts and reduces the attack surface that could result from recovery attempts that have been stagnent and uncompleted for long periods of time.\n\n```ts\nfunction handleRecovery(\n    address guardian,\n    uint256 templateIdx,\n    bytes[] memory commandParams,\n    bytes32\n) internal;\n```\n\n### Complete Recovery\n\nThe final function to complete the recovery process. This function completes the recovery process by validating the recovery request and triggering the recovery module to perform the recovery on the account itself.\n\n```ts\nfunction completeRecovery(address account, bytes memory recoveryCalldata) public;\n```\n\n## Command Handlers\n\nCommand handlers define the commands for recovery emails and how they should be validated. They are designed to be simple and self-contained contracts that hold the modular account-specific logic needed for adding email recovery. We currently define three command handlers. We have a universal command handler which essentially gives 7579 module developers recovery for free that is generic to any validator (so long as the validator has functionality to recover itself). We provide a Safe account command handle\n\n[... truncated ...]"
  },
  "zkemail/zk-email-verify": {
    "fetchedAt": "2025-11-12T23:01:30.011Z",
    "content": "[![DOI](https://zenodo.org/badge/516236309.svg)](https://doi.org/10.5281/zenodo.15653239)\n\n# Welcome to ZK Email\n\n<p align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/logo-light.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"docs/logo-dark.svg\">\n    <img alt=\"zkemail.\" src=\"docs/logo-light.svg\">\n  </picture>\n</p>\n\nZK Email is an application that allows for anonymous verification of email signatures while masking specific data. It enables verification of emails to/from specific domains or subsets of domains, as well as verification based on specific text in the email body. Our core SDK comes with libraries to assist with circuit generation as well as utility templates for general zk applications.\n\n\n## Packages Overview\n\nThe ZK Email Verifier is built on three core packages:\n\n### @zk-email/helpers\nProvides utility functions for email verification and cryptographic operations, including RSA signatures, public keys, email bodies, and hashes. [Read more](/packages/helpers/README.md).\n\n### @zk-email/circuits\nOffers pre-built circuits for proof generation and DKIM signature verification. [Read more](/packages/circuits/README.md).\n\n### @zk-email/contracts\nContains Solidity contracts for email verification purposes. [Read more](/packages/contracts/README.md).\n\n## Demo\n\n[Proof of Twitter](https://github.com/zkemail/proof-of-twitter/) is a demo application built using ZK-Email where you can prove ownership of a Twitter account (and mint an NFT) using an email from Twitter.\n\nTry here: [https://twitter.zk.email/](https://twitter.zk.email/)\n\nYou can fork the project as a starting point for your own ZK-Email application.\n\nMoreover, for those interested in creating the Twitter circuit from scratch, our [Proof of Twitter guide](https://zk.email/blog/twitter) offers a step-by-step tutorial on utilizing our SDKs for circuit construction.\n\n## Audits\n\n  - Audit from [zkSecurity](https://zksecurity.xyz/) that cover both `zk-email-verify` and `zk-regex` - [Report](/audits/zksecurity-audit.pdf). Version [`6.1.0`](https://github.com/zkemail/zk-email-verify/releases/tag/v6.1.0) fixes the issues found in the audit.\n\n  - Audit from [yAcademy](https://yacademy.dev/) - [Report](/audits/yacademy-audit.pdf).\n\n## Contributors üí°\nFor each pull request that successfully merges and addresses an [open issue](https://github.com/zkemail/zk-email-verify/issues), we offer a $50 reward. Feel free to email support@zk.email to let us know. To learn more about how you can contribute to this project, please consult our [Contributing Guide](CONTRIBUTING.md). Thank you to all of our existing contributors!\n\n## Licensing\nEverything we write is MIT-licensed. Note that circom and circomlib is GPL. Broadly we are pro permissive open source usage with attribution! We hope that those who derive profit from this, contribute that money altruistically back to this technology and open source public goods.\n"
  },
  "zkemail/zk-email-sdk-js": {
    "fetchedAt": "2025-11-12T23:01:30.624Z",
    "content": "# ZKEmail SDK\n\nWith the ZKEmail SDK you can create proofs about emails using blueprints. You can create blueprints with this\nSDK (documentation pending), or using our [registry](https://registry.zk.email).\n\n## Install\n\nThe SDK works for all JavaScript environments. You can find\nexamples for server-side (Node, Deno, Bun) and client-side (Vite, Next.js) usage [here](https://github.com/zkemail/sdk-ts-demo).\n\nTo install run:\n\n```bash\nnpm i @zk-email/sdk\n```\n\n## Logging Configuration\n\nThe SDK includes comprehensive logging capabilities that are **silent by default**. You can configure logging when initializing the SDK:\n\n### Basic Usage\n\n```ts\nimport { initZkEmailSdk } from \"@zk-email/sdk\";\n\n// Silent by default (no logs)\nconst sdk = initZkEmailSdk();\n\n// Enable error-level logging only\nconst sdk = initZkEmailSdk({ logging: { enabled: true } });\n\n// Enable all logs including debug information\nconst sdk = initZkEmailSdk({ logging: { level: 'debug', enabled: true } });\n\n// Completely disable all logging\nconst sdk = initZkEmailSdk({ logging: { enabled: false } });\n```\n\n### Log Levels\n\nThe SDK supports the following log levels in order of verbosity:\n\n- `silent` - No logs (default)\n- `error` - Critical errors only\n- `warn` - Warnings and errors\n- `info` - General information, warnings, and errors\n- `debug` - All logs including timing information\n\n### Configuration Options\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `enabled` | boolean | `true` | Whether logging is enabled |\n| `level` | LogLevel | `'silent'` or `'error'`* | Maximum log level to show |\n\n*When `enabled: true` is specified without a level, it defaults to `'error'` level.\n\n### Examples\n\n```ts\n// Show only errors (recommended for production)\nconst sdk = initZkEmailSdk({ logging: { enabled: true } });\n\n// Show errors and warnings\nconst sdk = initZkEmailSdk({ logging: { level: 'warn', enabled: true } });\n\n// Show all logs for debugging\nconst sdk = initZkEmailSdk({ logging: { level: 'debug', enabled: true } });\n\n// Completely silent\nconst sdk = initZkEmailSdk({ logging: { enabled: false } });\n```\n\n## Create a blueprint\n\nGo to our [registry](https://registry.zk.email) and create a blueprint there. You can also create one with the SDK,\nwe will provide the documentation for this shortly.\n\n## Generate a proof\n\nInitialize the SDK:\n\n```ts\nimport { initZkEmailSdk } from \"@zk-email/sdk\";\nconst sdk = initZkEmailSdk();\n```\n\nNext, obtain the slug of the blueprint you want to create a proof for from our [registry](https://registry.zk.email).\n\n![Copy Slug](https://raw.githubusercontent.com/zkemail/zk-email-sdk-js/main/assets/copy_slug.png)\n\nUse the slug to get the blueprint:\n\n```ts\nconst blueprint = await sdk.getBlueprint(\"Bisht13/SuccinctZKResidencyInvite@v2\");\n```\n\nYou can optionally test first if the email can be used with the blueprint.\n\nYou can check out our [Next.js example](https://github.com/zkemail/sdk-ts-demo/tree/main/nextjs) to see how\na user can locally upload an email file.\n\n```ts\nconst isValid = await blueprint.validateEmail(emailStr);\n```\n\nCreate a prover. Here you can define whether the proof should be generated remotely (faster)\nor in the browser (slower but private).\nSet `isLocal` to `true` for proving in the browser.\n\n```ts\nconst prover = blueprint.createProver({ isLocal: true });\n```\n\nNow pass the email as a `string` to the prover to generate a proof.\n\nIf your blueprint requires external inputs, pass them as a second argument.\n\n```ts\n// 2. argument, externalInputs is only required if defined in the blueprint\nconst proof = await prover.generateProof(emailStr, [\n  { name: \"email\", value: \"a@b.de\", maxLength: 50 },\n]);\n\nconsole.log(\"Proof data: \", proof.props.proofData);\nconsole.log(\"Public data: \", proof.props.publicData);\n```\n\n## Verify a proof\n\n### Locally\n\nYou can verify a proof direclty using a instance of Proof.\n`verifyProof` will be true if the proof is valid and false if it is invalid.\n\n```ts\nconst verified = await blueprint.verifyProof(proof);\nconsole.log(\"Proof is valid: \", verified);\n```\n\nIf you only have the proof data, you can verify the proof like this:\n\n```ts\nconst verified = await blueprint.verifyProofData(\n  JSON.stringify(proof.props.publicOutputs),\n  JSON.stringify(proof.props.proofData)\n);\nconsole.log(\"Proof is valid: \", verified);\n```\n\n### On chain\n\nWe currently use a contract deployed to Base Sepolia for this.\n\n```ts\nconst isVerified = await blueprint.verifyProofOnChain(proof);\n```\n\n## Fetch emails with Gmail\n\nYou can use the sdks' `Gmail` utility class to fetch users emails according to the blueprints query.\n\n**NOTE:** This will only work if you approved your domain with us.\n\n```ts\nimport { initZkEmailSdk, Gmail } from \"@zk-email/sdk\";\n\nconst gmail = new Gmail();\nconst sdk = initZkEmailSdk();\n\n// optional - manually start Login with Google flow and authorize before fetching emails\nawait gmail.authorize();\n\n// Will start Login with Google flow if not already autorized\n// Fetches emails using the email queries given in the blueprints\nconst emails = await gmail.fetchEmails([blueprint]);\n\n// Will return an empty array if there are no more emails matching the blueprints query\nconst moreEmails = await gmail.fetchMore();\n\n// You can validate if an email is valid according to a blueprint\nconst isValid = await blueprint.validateEmail(emails[0].decodedContents);\nconsole.log(\"isValid: \", isValid);\n```\n"
  },
  "zkemail/zkemail.nr": {
    "fetchedAt": "2025-11-12T23:01:30.920Z",
    "content": "## ZKEmail.nr\nZKEmail written in [NoirLang](https://noir-lang.org/)\n\n## Using the Noir Library\n\nIn your Nargo.toml file, add the version of this library you would like to install under dependency:\n\n```toml\n[dependencies]\nzkemail = { tag = \"v0.4.2\", git = \"https://github.com/zkemail/zkemail.nr\", directory = \"lib\" }\n```\n\nThe library exports the following functions:\n- `dkim::RSAPubkey::verify_dkim_signature` -  for verifying DKIM signatures over an email header. This is needed for all email verifications.\n- `headers::body_hash::get_body_hash` - constrained access and decoding of the body hash from the header\n- `headers::email_address::get_email_address` - constrained extraction of to or from email addresses\n- `headers::constrain_header_field` - constrain an index/ length in the header to be the correct name, full, and uninterrupted\n- `partial_hash::partial_sha256_var_end` - finish a precomputed sha256 hash over the body\n- `masking::mask_text` - apply a byte mask to the header or body to selectively reveal parts of the entire email\n\nAdditionally, the `@zk-email/zkemail-nr` JS library exports an ergonomic API for easily deriving circuit inputs needed to utilize the Noir library.\n\nFor demonstrations of all functionality, see the [examples](./examples).\n\n### Basic Email Verification\nA basic email verifier will often look like this:\n```rust\nuse zkemail::{\n    KEY_LIMBS_1024, dkim::RSAPubkey, get_body_hash_by_index,     \n    base64::body_hash_base64_decode\n};\nuse std::hash::{sha256_var, pedersen_hash};\n\n// Somewhere in your function\n...\n  // verify the dkim signature over the asserted header\n  pubkey.verify_dkim_signature(header, signature);\n  // extract the body hash from the header\n  let signed_body_hash = get_body_hash(header, dkim_header_sequence, body_hash_index);\n  // compute the sha256 hash of the asserted body\n  let computed_body_hash: [u8; 32] = sha256_var(body.storage, body.len() as u64);\n  // constain the computed body hash to match the one found in the header\n  assert(\n    signed_body_hash == computed_body_hash,\n    \"SHA256 hash computed over body does not match body hash found in DKIM-signed header\"\n  );\n...\n```\nFrom here, you can operate on the header or body with guarantees that the accessed text was signed by the DKIM key.\n\nYou may also have an email where you need access to the header, but not the body. You can simply omit everything after `verify_dkim_signature` and proceed!\n\n### Usage with partial SHA\n\nYou can use partial hashing technique for email with large body when the part you want to constrain in the body is towards the end.\n\nSince SHA works in chunks of 64 bytes, we can hash the body up to the chunk from where we want to extract outside of the circuit and do the remaining hash in the circuit. This will save a lot of constraints as SHA is very expensive in circuit (~100 constraints/ byte).\n\n```rust\nuse zkemail::{\n    KEY_LIMBS_2048, dkim::RSAPubkey, headers::body_hash::get_body_hash,\n    partial_hash::partial_sha256_var_end\n};\n\n...\n  // verify the dkim signature over the asserted header\n  pubkey.verify_dkim_signature(header, signature);\n  // extract the body hash from the header\n  let signed_body_hash = get_body_hash(header, dkim_header_sequence, body_hash_index);\n  // finish the partial hash\n  let computed_body_hash = partial_sha256_var_end(partial_body_hash, body.storage(), body.len() as u64, partial_body_real_length);   \n  // constain the computed body hash to match the one found in the header\n  assert(\n    signed_body_hash == computed_body_hash,\n    \"SHA256 hash computed over body does not match body hash found in DKIM-signed header\"\n  );\n...\n```\n\n### Extracting Email Addresses\n\nTo and from email addresses can be extracted from the header with `get_email_address`\n```rust\nuse zkemail::get_email_address;\n...\n  // define the header field to access (set \"to\" or \"from\")\n  let to = comptime { \"to\".as_bytes() };\n  // constrained retrieval of the email header\n  let to_address = get_email_address(header, to_header_sequence, to_address_sequence, to);\n...\n```\n`to_address` is a \"BoundedVec\", meaning the output of a parsed email address \"zkemail@prove.email\" would export\n```json\n{\n  \"storage\": [122, 107, 101, 109,  97, 105, 108,  64, 112, 114, 111, 118, 101,  46, 101, 109,  97, 105, 108, 0, ..., 0],\n  \"len\": 19\n}\n```\nwhich is easily interpreted with `Buffer.from(output.storage.slice(0, output.storage.len)).toString()`. You can additionally perform your own transformations or commitments in-circuit.\n\n\n## Using the Input Generation JS Library\n\nInstall the library:\n```console\nyarn add @zk-email/zkemail-nr\n```\n\n### Usage\nSee the [witness simulation](./js/tests/circuits.test.ts) and [proving](./js/tests/proving.test.ts) tests for an in-depth demonstration of each use case.\n\n```js\n// example of generating inputs for a partial hash\nimport { generateEmailVerifierInputs } from \"@zk-email/zkemail-nr\";\n\nconst zkEmailInputs = await generateEmailVerifierInputs(emailContent, {\n  maxBodyLength: 1280,\n  maxHeadersLength: 1408,\n  shaPrecomputeSelector: \"some string in body up to which you want to hash outside circuit\",\n});\n\n```\n\n## Using ZKEmail.nr in EVM Smart Contracts\nTODO\n\n## Using ZKEmail.nr in Aztec Smart Contracts\nTODO\n\n## Todo\n - Expected InputGen testing\n - EVM Contract tests for email integration\n - Aztec Contract tests for email integration\n - 1024-bit key demo eml (current one is sensitive and cannot be provided in public repo)\n - Implementation with Regex\n - Add constraint estimations and benchmarking\n - Add native proving scripts\n - Macro Impl\n\nBy [Mach-34](https://mach34.space)\n"
  },
  "decentxyz/launch-nfts": {
    "fetchedAt": "2025-11-12T23:01:41.456Z",
    "content": "# Minting Page Starter ‚Äì Decent NFTs\n\nCustom NFT minting page starter repo built on [Next.js](https://nextjs.org/), [Tailwind](https://tailwindcss.com/docs/customizing-colors), and [Decent](http://decent.xyz/), deployed on [Vercel](https://vercel.com/).\n\n![](/public/images/example.png)\n\nThe purpose of this repository is to get you up & running quickly with a custom NFT minting page using [The Box](https://decent.xyz/box).  **The Box enables 1-click transactions using any token on any chain.  In this repo, The Box enables 1-click checkout for NFTs across primary and secondary sales.**  This repository is setup to handle any NFT, whether it was deployed through Decent or not - non-Decent NFTs are more likely to present UX bugs.\n\n## Deployment Instructions\n\nWe recommend starting with a Decent NFT, which you can deploy here: [Decent NFT](https://hq.decent.xyz/).  You will also need a [Decent API Key](https://docs.google.com/forms/d/e/1FAIpQLSdPBORZGU-JsMxwlhan9aUl01QCTgu2KJMEEPjhHC_9v1PQqA/viewform) and [Alchemy API Key](https://www.alchemy.com/) to use this starter. Run this repo locally by:\n\n1. Go to https://hq.decent.xyz/create/Editions and create a new NFT (skip to step 3 if you have an existing NFT you'd like to use)\n\n2. From the success page, copy the contract address and note the chain ID number.  You can deploy your NFT to Ethereum, Polygon, Arbitrum or Optimism.  These chains have the following IDs:\n\n| Chain       | ID Number   |\n| ----------- | ----------- |\n| Ethereum    | 1           |\n| Polygon     | 137         |\n| Arbitrum    | 42161       |\n| Optimism    | 10          |\n\nThe example uses an NFT on Optimism.  On the `index.tsx` page, enter your NFT's chain ID, contract address, token price, sale end date, and NFT max cap in `constants` within the `getStaticProps` request.\n\n3. Request a [Decent API Key](https://docs.google.com/forms/d/e/1FAIpQLSdPBORZGU-JsMxwlhan9aUl01QCTgu2KJMEEPjhHC_9v1PQqA/viewform) and add it to your .env file.  Once inputted, your minting page will automatically populate with your NFT's data and metadata.  If you would like to add or swap information, please visit [Decent's API Documentation](https://docs.decent.xyz/reference/get_contracts-chainid-address) to query for your contract and view the JSON response to see the available information.\n\n4. If you are using a Decent NFT, you will not need to update the props in the `Box.tsx` component.  If you are NOT using a Decent NFT, you will need to enter your contract's mint method signature in the `abi` and its corresponding parameters in `params`.  In either case, double check that the `nftParams` are correct for your contract & please visit our [Box Documentation](https://docs.decent.xyz/docs/overview) for further guidance on how to correctly install The Box.\n\n5. Create an Alchemy account and visit [your dashboard](https://dashboard.alchemy.com/) to create an Alchemy API key. Alchemy facilitates the connection between your application and the chain of your choice.\n\nReach out to [@cdurbinxyz](https://twitter.com/cdurbinxyz) on Twitter if you run into any issues.\n\n## To Run\n\nFirst, install dependencies using npm:\n\n```bash\nnpm i\n```\n\nNext, run `cp .env.example .env.local` to create your file to enter the information detailed above.  It should look like:\n\n```bash\nNEXT_PUBLIC_DECENT_API_KEY=<your-decent-api-key>\nNEXT_PUBLIC_ALCHEMY_API_KEY=<your-alchemy-api-key>\nNEXT_PUBLIC_WALLET_CONNECT_PROJECT_ID=<your-wallet-connect-project-id>\n```\n\nLastly, run the development server:\n\n```bash\nnpm run dev\n```\n\n## Demo\n\nhttps://minting-page-decent-webapp.vercel.app/\n\n## Tech Stack\n\n- [Next.js](https://nextjs.org/)\n- [Tailwind CSS](https://tailwindcss.com/)\n- [DecentSDK](https://www.npmjs.com/package/@decent.xyz/sdk)\n- [Decent API](https://docs.decent.xyz/reference/get_allowlists-merkleroot)\n- [Alchemy RPC + NFT API](https://docs.alchemy.com/reference/getnftmetadata)\n"
  },
  "decentxyz/decent-contracts-v3": {
    "fetchedAt": "2025-11-12T23:01:41.863Z",
    "content": "## Foundry\n\n**Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.**\n\nFoundry consists of:\n\n-   **Forge**: Ethereum testing framework (like Truffle, Hardhat and DappTools).\n-   **Cast**: Swiss army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n-   **Anvil**: Local Ethereum node, akin to Ganache, Hardhat Network.\n-   **Chisel**: Fast, utilitarian, and verbose solidity REPL.\n\n## Documentation\n\nhttps://book.getfoundry.sh/\n\n## Usage\n\n### Build\n\n```shell\n$ forge build\n```\n\n### Test\n\n```shell\n$ forge test\n```\n\n### Format\n\n```shell\n$ forge fmt\n```\n\n### Gas Snapshots\n\n```shell\n$ forge snapshot\n```\n\n### Anvil\n\n```shell\n$ anvil\n```\n\n### Deploy\n\n```shell\n$ forge script script/Counter.s.sol:CounterScript --rpc-url <your_rpc_url> --private-key <your_private_key>\n```\n\n### Cast\n\n```shell\n$ cast <subcommand>\n```\n\n### Help\n\n```shell\n$ forge --help\n$ anvil --help\n$ cast --help\n```\n"
  },
  "decentxyz/decentV2-contracts": {
    "fetchedAt": "2025-11-12T23:01:42.480Z",
    "content": "## Foundry\n\n**Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.**\n\nFoundry consists of:\n\n- **Forge**: Ethereum testing framework (like Truffle, Hardhat and DappTools).\n- **Cast**: Swiss army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n- **Anvil**: Local Ethereum node, akin to Ganache, Hardhat Network.\n- **Chisel**: Fast, utilitarian, and verbose solidity REPL.\n\n## Documentation\n\nhttps://book.getfoundry.sh/\n\n## Usage\n\n### Build\n\n```shell\n$ forge build\n```\n\n### Test\n\n```shell\n$ forge test\n```\n\n### Format\n\n```shell\n$ forge fmt\n```\n\n### Gas Snapshots\n\n```shell\n$ forge snapshot\n```\n\n### Anvil\n\n```shell\n$ anvil\n```\n\n### Deploy\n\n```shell\n$ forge script script/Counter.s.sol:CounterScript --rpc-url <your_rpc_url> --private-key <your_private_key>\n```\n\n### Cast\n\n```shell\n$ cast <subcommand>\n```\n\n### Help\n\n```shell\n$ forge --help\n$ anvil --help\n$ cast --help\n```\n"
  },
  "DefiLlama/defillama-app": {
    "fetchedAt": "2025-11-12T23:01:50.281Z",
    "content": "# DefiLlama\n\n[DefiLlama](https://defillama.com) is the leading DeFi analytics and insights platform, providing comprehensive data on total value locked (TVL), yields, stablecoins, and more across all blockchain ecosystems.\n\nCheck it out live at: https://defillama.com\n\n## Features\n\n- Real-time TVL tracking across 200+ chains and 3000+ protocols\n- DeFi yield aggregation and comparison\n- Stablecoin market analysis and tracking\n- Protocol metrics and historical data\n- Advanced search and filtering capabilities\n- Responsive design for all devices\n\n## Local Setup\n\n#### 1. Clone the repository:\n\n```bash\ngit clone https://github.com/DefiLlama/defillama-app.git\ncd defillama-app\n```\n\n#### 2. Install dependencies:\n\n```bash\nyarn\n```\n\n#### 3. Start the development server:\n\n```bash\nyarn dev\n```\n\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\n\n## Contributing\n\nContributions are welcome. New features, small fixes, docs updates, whatever helps.\n\nIf you're adding a protocol adapter, check out [DefiLlama-Adapters](https://github.com/DefiLlama/DefiLlama-Adapters).\n\nHere's how you can help:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\nBefore opening a PR:\n\n1. Make sure it builds and runs locally\n2. Keep changes focused and easy to review\n3. Use clear commit messages\n\n## Community\n\nJoin the conversation and stay up to date:\n\n- [X/Twitter](https://twitter.com/DefiLlama)\n- [Discord](https://discord.defillama.com/)\n- [Documentation](https://docs.llama.fi/)\n\n## License\n\n[GPL-3.0](./LICENSE)\n"
  },
  "DefiLlama/DefiLlama-Adapters": {
    "fetchedAt": "2025-11-12T23:01:50.543Z",
    "content": "# Defillama Adapters\n\nFollow [this guide](https://docs.llama.fi/submit-a-project) to create an adapter and submit a PR with it.\n\nAlso, don't hesitate to send a message on [our discord](https://discord.defillama.com/) if we're late to merge your PR.\n\n> If you would like to add a `volume` adapter please submit the PR [here](https://github.com/DefiLlama/adapters)\n> - If you would like to add a `liquidations` adapter, please refer to [this readme document](https://github.com/DefiLlama/DefiLlama-Adapters/tree/main/liquidations) for details.\n\n1. PLEASE PLEASE **enable \"Allow edits by maintainers\" while putting up the PR.**\n2. Once your adapter has been merged, it takes time to show on the UI. No need to notify us on Discord.\n3. TVL must be computed from blockchain data (reason: https://github.com/DefiLlama/DefiLlama-Adapters/discussions/432), if you have trouble with creating the adapter, please hop onto our discord, we are happy to assist you.\n4. **For updating listing info** It is a different repo, you can find your listing in this file: https://github.com/DefiLlama/defillama-server/blob/master/defi/src/protocols/data2.ts, you can  edit it there and put up a PR\n5. Do not edit/push `package-lock.json` file as part of your changes, we use lockfileVersion 2, and most use v1 and using that messes up our CI\n6. No need to go to our discord and announce that you've created a PR, we monitor all PRs and will review it asap\n\n## Getting listed\n\nPlease send answers to questions there https://github.com/DefiLlama/DefiLlama-Adapters/blob/main/pull_request_template.md when creating a PR.\n\n## Work in progress\n\nThis is a work in progress. DefiLlama aims to be transparent, accurate, and open source.\n\nIf you have any suggestions, want to contribute or want to chat, please join [our discord](https://discord.defillama.com/) and drop a message.\n\n## Testing adapters\n```bash\nnode test.js projects/pangolin/index.js\n# Add a timestamp at the end to run the adapter at a historical timestamp\nnode test.js projects/aave/v3.js 1729080692\n# or using YYYY-MM-DD\nnode test.js projects/aave/v3.js 2024-10-16\n```\n\n## Changing RPC providers\nIf you want to change RPC providers because you need archive node access or because the default ones don't work well enough you can do so by creating an `.env` file and filling it with the env variables to overwrite:\n```\nETHEREUM_RPC=\"...\"\nBSC_RPC=\"...\"\nPOLYGON_RPC=\"...\"\n```\n\nThe name of each rpc is `{CHAIN-NAME}_RPC`, and the name we use for each chain can be found [here](https://unpkg.com/@defillama/sdk@latest/build/providers.json). If you run into issues with a chain make sure to update the sdk with `npm update @defillama/sdk`.\n\n## Adapter rules\n- Never add extra npm packages, if you need a chain-level package for your chain, ask us, and we'll consider it, but we can't accept any npm package that is project-specific\n"
  },
  "0xngmi/llamazip": {
    "fetchedAt": "2025-11-12T23:01:50.962Z",
    "content": "## LlamaZip\n\nA swap router optimized for optimistic rollups"
  },
  "gitcoinco/id-staking-v2-app": {
    "fetchedAt": "2025-11-12T23:01:59.301Z",
    "content": "# id-staking-v2-app\nIdentity staking app\n"
  },
  "gitcoinco/passport-scorer": {
    "fetchedAt": "2025-11-12T23:01:59.986Z",
    "content": "# Passport XYZ's Scorer API\n\nThe Passport API allows developers to integrate identity verification functionality into their applications. The API provides a simple way to read and score the identities of Gitcoin Passport holders by applying scoring mechanisms to verifiable credentials.\n\nSocial organizations have a difficult time ensuring that each participant is unique: that they are in fact human (not a bot) and also a unique participant (not double counting). The Gitcoin Passport solves this by providing a solution that is decentralized and recognizes the intersectional and social nature of identity.\n\nThe Passport Scorer API (this repository) is a centralized service provided by Passport XYZ to make it easier to read and work with Passport scores.\n\n## Quick Links\n\n- [Passport Docs](https://docs.passport.xyz/)\n- [API Docs](https://api.scorer.gitcoin.co/docs)\n- [Official Website](https://www.passport.xyz?utm_source=scorer-api-repo&utm_medium=referral&utm_content=Passport)\n\n## Contributing\n\nWe welcome everyone to contribute to Passport and the Scorer API! Please review our [contributing guidelines](./CONTRIBUTING.md) before proceeding.\n\nYou can join our [Discord](https://discord.gg/passport) (just be sure to select the builder role when you join) to get help and discuss the project with the rest of the community.\n\nYou can also familiarize yourself with our near term project roadmap in the [project backlog](https://github.com/orgs/passportxyz/projects/1)\n\n## Setup\n\nInstructions are provided in the [`SETUP.md`](./SETUP.md) for getting the codebase up and running on your local machine. This project is under active development and has not been tested on every possible operating system. If you\nget stuck setting up this project, please file an issue.\n\n## [License](./LICENSE)\n\nAll code is licensed under MIT.\n"
  },
  "gitcoinco/eas-proxy": {
    "fetchedAt": "2025-11-12T23:02:00.761Z",
    "content": "# eas-proxy\n\nThis EAS proxy will be the attester who will write the stamps into EAS attestations\n\n## Deployments\n\nSee latest contract addresses and other deployment\ninfo&mdash;organized by chain ID&mdash;[here](deployments/onchainInfo.json).\n\n- Optimism (0xa)\n- Base Goerli (0x14a33)\n- Linea Goerli (0xe704)\n- Linea (0xe708)\n\nThe file has the following schema:\n\n_Fields marked with a pencil (‚úèÔ∏è) are manually filled out, the rest are\npopulated by scripts_\n\n```json\n{\n  \"[chainId]\": {\n    \"issuer\": {\n      \"address\": \"[‚úèÔ∏è test or production issuer address (see below)]\"\n    },\n    \"EAS\": {\n      \"address\": \"[‚úèÔ∏è address of the EAS contract]\"\n    },\n    \"GitcoinAttester\": {\n      \"address\": \"[address of the GitcoinAttester contract]\"\n    },\n    \"GitcoinVerifier\": {\n      \"address\": \"[address of the GitcoinVerifier contract]\"\n    },\n    \"GitcoinResolver\": {\n      \"address\": \"[address of the GitcoinResolver contract]\"\n    },\n    \"easSchemas\": {\n      \"passport\": {\n        \"uid\": \"[‚úèÔ∏è uid of the Passport EAS Schema]\"\n      },\n      \"score\": {\n        \"uid\": \"[‚úèÔ∏è uid of the Passport score EAS Schema]\"\n      },\n      \"scoreV2\": {\n        \"uid\": \"[‚úèÔ∏è uid of the Passport score V2 EAS Schema]\"\n      }\n    }\n  }\n}\n```\n\n## Issuers\n\nThese are the addresses signing attestation data, the verifier only accepts attestations\nsigned by the appropriate address.\n\nThe production address is used only in the production environment of the\nPassport app with mainnet chains.\nThe testnet address is used with all other environments.\n\n### Production\n\n0x804233b96cbd6d81efeb6517347177ef7bD488ED\n\n### Test\n\n0x5f603Ed913738d9105bAf3BD981AA4750016B167\n\n_Note: the issuer address is **not the attester address**_\n\n## Other Topics\n\n[Section 0: Onchain Data Overview](docs/00-onchain-data.md)\n\n[Section 1: Onchain Passport Attestation](docs/01-onchain-passport-attestation.md)\n\n[Section 2: Onchain Stamp Attestation ‚ö†Ô∏è _not used_ ‚ö†Ô∏è](docs/02-onchain-stamp-attestation.md)\n\n[Section 3: New Chain Deployment Process](docs/03-new-deployment.md)\n\n[Section 4: Deployment with Verax](docs/04-verax.md)\n\n[Section 5: Querying Passport Attestations Onchain](docs/05-querying-passport-attestations-onchain.md)\n\n[Section 6: Scoring Attestations Onchain](docs/06-scoring-attestations-onchain.md)\n"
  },
  "gitcoinco/id-staking-v2": {
    "fetchedAt": "2025-11-12T23:02:01.544Z",
    "content": "# Identity Staking V2\n\nThis repo contains the Identity Staking V2 contract. These were the goals when\nwriting this contract:\n\n- Allow users to stake on themselves and others for a given duration\n- Make staking and re-staking as gas-efficient as possible\n- Be able to determine the total GTC staked by a user (self + community)\n- Allow slashing of users who commit slash-able offenses\n- Allow slashing to be appealed, with a minimum appeal period of 90 days\n- Allow successfully appealed GTC to be released\n- GTC staked in this contract should only possibly be able to be...\n    1. Held by the contract (staked or frozen)\n    2. Burned\n    3. Returned to the original owner\n- Slashing, burning, and releasing must be gas-efficient enough to be practical\n- Events should be emitted to allow simple indexing of all activity\n\n## Audit\n\n- https://code4rena.com/reports/2024-03-gitcoin\n\n## Table of Contents\n\n1. [Working with the repo](#working-with-the-repo)\n2. [IdentityStaking.sol](#identitystakingsol)\n    1. [Methods](#methods)\n    2. [Events](#events)\n    3. [State](#state)\n    4. [Appendix A: Slashing Rounds](#appendix-a-slashing-rounds)\n    5. [Appendix B: Slashing in Consecutive Rounds](#appendix-b-slashing-in-consecutive-rounds)\n    6. [Appendix C: Diagrams](#appendix-c-diagrams)\n    7. [Appendix D: Security](#appendix-d-security)\n3. [IIdentityStaking.sol](#iidentitystakingsol)\n\n## Working with the repo\n\n```shell\nREPORT_GAS=true npx hardhat test\nnpx hardhat run scripts/deploy.ts --network <network>\n```\n\n## IdentityStaking.sol\n\n### Methods\n\n#### selfStake\n\n```solidity\nfunction selfStake(uint88 amount, uint64 duration) external whenNotPaused;\n```\n\nAdd `amount` GTC to your stake on yourself. Minimum `duration` is 12 weeks,\nmaximum `duration` is 104 weeks (2 years).\n\nIf you have an existing self-stake, then the `duration` must end later than the\nexisting self-stake's `unlockTime`.\n\nThe `unlockTime` of **all** of your self-stake will be extended to the end of\nthe new `duration`.\n\n#### extendSelfStake\n\n```solidity\nfunction extendSelfStake(uint64 duration) external whenNotPaused;\n```\n\nSet existing self-stake's unlock time to the end of `duration`. Minimum\n`duration` is 12 weeks, maximum `duration` is 104 weeks (2 years).\n\nThe `duration` must end later than the existing self-stake's `unlockTime`.\n\n#### withdrawSelfStake\n\n```solidity\nfunction withdrawSelfStake(uint88 amount) external whenNotPaused;\n```\n\nWithdraw `amount` GTC from your unlocked self-stake.\n\n#### communityStake\n\n```solidity\nfunction communityStake(address stakee, uint88 amount, uint64 duration) external whenNotPaused;\n```\n\nAdd `amount` GTC to your stake on `stakee`. Minimum `duration` is 12 weeks,\nmaximum `duration` is 104 weeks (2 years).\n\nIf you have an existing community-stake on `stakee`, then the `duration` must end\nlater than the existing community-stake's `unlockTime`.\n\nThe `unlockTime` of **all** of your community-stake on `stakee` will be\nextended to the end of the new `duration`.\n\n#### extendCommunityStake\n\n```solidity\nfunction extendCommunityStake(address stakee, uint64 duration) external whenNotPaused;\n```\n\nSet existing community-stake's unlock time to the end of `duration`. Minimum\n`duration` is 12 weeks, maximum `duration` is 104 weeks (2 years).\n\nThe `duration` must end later than the existing community-stake's `unlockTime`.\n\n#### withdrawCommunityStake\n\n```solidity\nfunction withdrawCommunityStake(address stakee, uint88 amount) external whenNotPaused;\n```\n\nWithdraw `amount` GTC from your unlocked community-stake on `stakee`.\n\n#### slash\n\n```solidity\nfunction slash(address[] selfStakers, address[] communityStakers, address[] communityStakees, uint64 percent) external onlyRole(SLASHER_ROLE) whenNotPaused;\n```\n\nSlash the provided addresses by `percent`. Addresses in `selfStakers` correspond\nto self-stakes to be slashed. The address in `communityStakers` and\n`communityStakees` correspond to community stakes to be slashed, such that\n`communityStakers[i]` has a community-stake on `communityStakees[i]`.\n\nThis function can only be called by an address with the `SLASHER_ROLE`.\n\n`percent` must be between 1 and 100.\n\n*Note: All staked GTC is liable to be slashed, even if it is past\nits unlockTime*\n\n#### lockAndBurn\n\n```solidity\nfunction lockAndBurn() external whenNotPaused;\n```\n\nThis function is to be called every three months (`burnRoundMinimumDuration`).\n\nWhen called this will lock the current round, burn the previous round, and\nstart a new round.\n\nAnyone can call this function. The `roundMinimumDuration` facilitates the\nlogic to keep everything in sync.\n\nSee [Appendix A: Slashing Rounds](./#appendix-a-slashing-rounds) for more details.\n\n#### release\n\n```solidity\nfunction release(address staker, address stakee, uint88 amountToRelease, uint16 slashRound) external onlyRole(RELEASER_ROLE) whenNotPaused;\n```\n\nRelease `amountToRelease` GTC from the community stake on `stakee` by `staker`.\nIf `staker` is the same as `stakee`, then this is a self-stake. If `slashRound`\nis two or more rounds previous to the current round, then the stake is\nalready burned and this function will fail.\n\nThis function can only be called by an address with the `RELEASER_ROLE`.\n\n#### pause\n\n```solidity\nfunction pause() external onlyRole(PAUSER_ROLE) whenNotPaused;\n```\n\nPause the contract. This function can only be called by an address with the\n`PAUSER_ROLE`.\n\n#### unpause\n\n```solidity\nfunction unpause() external onlyRole(PAUSER_ROLE) whenPaused;\n```\n\nUnpause the contract. This function can only be called by an address with the\n`PAUSER_ROLE`.\n\n### Events\n\n#### SelfStake\n\n```solidity\nevent SelfStake(address indexed staker, uint88 amount, uint64 unlockTime);\n```\n\nEmitted when a self-stake is added/increased/extended. `amount` is the additional\namount added for this particular transaction (could be `0` for an extension).\n`unlockTime` applies to the full self-stake amount for this `staker`.\n\n#### CommunityStake\n\n```solidity\nevent CommunityStake(address indexed staker, address indexed stakee, uint88 amount, uint64 unlockTime);\n```\n\nEmitted when a community-stake is added/increased/extended. `amount` is the\nadditional amount added for this particular transaction (could be `0` for an\nextension). `unlockTime` applies to the full community-stake amount for this\n`staker` on this `stakee`.\n\n#### SelfStakeWithdrawn\n\n```solidity\nevent SelfStakeWithdrawn(address indexed staker, uint88 amount);\n```\n\nEmitted when a self-stake is withdrawn. `amount` is the amount withdrawn in this\ntransaction.\n\n#### CommunityStakeWithdrawn\n\n```solidity\nevent CommunityStakeWithdrawn(address indexed staker, address indexed stakee, uint88 amount);\n```\n\nEmitted when a community-stake is withdrawn. `amount` is the amount withdrawn in\nthis transaction.\n\n#### Slash\n\n```solidity\nevent Slash(address indexed staker, uint88 amount, uint16 round);\n```\n\nEmitted when a slash occurs. `amount` is the total amount slashed in this\ntransaction. `round` is the round in which the slash occurred.\n\n#### LockAndBurn\n\n```solidity\nevent LockAndBurn(uint16 indexed round, uint88 amount);\n```\n\nEmitted when a lockAndBurn occurs. `round` is the round that was burned, and\n`amount` is the total amount burned in this transaction.\n\n### State\n\n#### SLASHER_ROLE\n\n```solidity\nbytes32 public constant SLASHER_ROLE = keccak256(\"SLASHER_ROLE\");\n```\n\nRole held by addresses which are permitted to submit a slash.\n\n#### RELEASER_ROLE\n\n```solidity\nbytes32 public constant RELEASER_ROLE = keccak256(\"RELEASER_ROLE\");\n```\n\nRole held by addresses which are permitted to release an un-burned slash.\n\n#### PAUSER_ROLE\n\n```solidity\nbytes32 public constant PAUSER_ROLE = keccak256(\"PAUSER_ROLE\");\n```\n\nRole held by addresses which are permitted to pause the contract.\n\n#### struct Stake\n\n```solidity\nstruct Stake {\n  uint64 unlockTime;\n  uint88 amount;\n  uint88 slashedAmount;\n  uint16 slashedInRound;\n}\n```\n\n- `unlockTime` is the unix time in seconds after which this stake can be\n  withdrawn.\n- `amount` is the amount of GTC \n\n[... truncated ...]"
  },
  "gitcoinco/passport": {
    "fetchedAt": "2025-11-12T23:02:02.118Z",
    "content": "# Passport XYZ\n\n## What is Passport?\n\nMany social organizations, online particularly, have difficulty ensuring that every participant is a unique human and does not have multiple participating accounts. Most existing digital identity solutions are either centralized (e.g., national identity cards) or individualistic (e.g., most ‚Äúself-sovereign‚Äù identity models). However, identity is naturally [intersectional and social](https://www.radicalxchange.org/concepts/intersectional-social-identity/); everybody shares different data and relationships with a unique set of others. Passport aims to provide a more collaborative and secure infrastructure for digital identity by capturing the richness of our diversely shared lives.\n\nPassport is an identity verification application. We have written software enabling people to grow personal collections of [verifiable credentials](https://decentralized-id.com/web-standards/w3c/wg/vc/verifiable-credentials/) about themselves and organizations to assess their identities to coordinate rights and responsibilities. The institutions define, verify, and utilize identity as functions of the networked records of the individuals. While we build the Passport agnostic to specific applications, we are actively exploring its benefits for [personhood proofs](https://en.wikipedia.org/wiki/Proof_of_personhood) and [plurality](https://www.radicalxchange.org/media/blog/why-i-am-a-pluralist/) in organizational designs.\n\n## Documentation\n\nCheck out our documentation at https://docs.passport.xyz\n\n## Contributing\n\nWe welcome everyone to contribute to Passport and the Scorer API! Please review our [contributing guidelines](./CONTRIBUTING.md) before proceeding.\n\nYou can join our [Discord](https://discord.gg/passport) (just be sure to select the builder role when you join) to get help and discuss the project with the rest of the community.\n\nYou can also familiarize yourself with our near term project roadmap in the passport [project backlog](https://github.com/orgs/passportxyz/projects/)\n\n## Reviewing Changes\n\nOnce a pull request is sent, the Passport team will review your changes. We outline our process below to clarify the roles of everyone involved.\n\nAll pull requests must be approved by two committers before being merged into the repository. If any changes are necessary, the team will leave appropriate comments requesting changes to the code. Unfortunately, we cannot guarantee a pull request will be merged, even when modifications are requested, as the Passport team will re-evaluate the contribution as it changes.\n\nCommitters may also push style changes directly to your branch. If you would rather manage all changes yourself, you can disable the \"Allow edits from maintainers\" feature when submitting your pull request.\n\nThe Passport team may optionally assign someone to review a pull request. If someone is assigned, they must explicitly approve the code before another team member can merge it.\n\nWhen the review finishes, your pull request will be squashed and merged into the repository. If you have carefully organized your commits and believe they should be merged without squashing, please mention it in a comment.\n\n## Quick Start\n\nPrerequisites: [Node (v20 LTS)](https://nodejs.org/en/download/) plus [Yarn](https://classic.yarnpkg.com/en/docs/install/) and [Git](https://git-scm.com/downloads)\n\n1. Install Passport (this will install all packages within the passport monorepo):\n\n```sh\ngit clone https://github.com/passportxyz/passport.git\ncd passport\nnpm install --global lerna\nyarn install\n```\n\n2. Create environment files, and replace environment variables with your own values\n\n```sh\ncp ./app/.env-example.env ./app/.env\ncp ./iam/.env-example.env ./iam/.env\n```\n\n3. Start iam, app, and ceramic services concurrently:\n\n```sh\n# remember to create .env files first\nyarn start\n```\n\n4. Run the [Passport Scorer API](https://github.com/passportxyz/passport-scorer/tree/main/api) locally. Set up instructions are [here](https://github.com/passportxyz/passport-scorer/blob/main/SETUP.md)\n\n## Passport Data\n\nA passport has two sources of data. The primary source is a postgres database that is hosted by Passport XYZ. To run the passport application locally you will need spin up the [Scorer API](https://github.com/passportxyz/passport-scorer/tree/main/api). All relevant instructions to run the scorer api can be found [here](https://github.com/passportxyz/passport-scorer/blob/main/SETUP.md). The sample environment variables in the .env-example.env files are configured to make requests to the scorer api running locally. Once the scorer api is running locally, you should have a reliable data source for development.\n\nA second source of data is the Ceramic network. No steps are needed to run the ceramic network locally. The sample environment variables in the .env-example.env files are configured to make requests to a test version of the ceramic network.\n\nThe third location is in onchain attestations that are made across about a dozen different networks. For more information on the onchain attestations, you can reference details [here](https://easscan.org/).\n\n## Background Knowledge\n\n- Know what a wallet is, how to create one, etc.\n- Know what a Verifiable Credential is\n- Know basics of Ceramic Network - interacting with DIDDatastore, Self.ID\n\n# Packages\n\n## app\n\nThe web app allowing users to interact with their Passport. [README](app/README.md)\n\n## database-client\n\nContains database connection implementations. Currently supports Ceramic Network. [README](database-client/README.md)\n\n## iam\n\nThe server handling incoming requests to issue credentials and process verifications. [README](iam/README.md)\n\n## identity\n\nThis is a helper package to compile Spruce DIDKit and export functions for use in `iam` and `app` packages.\n\n## infra\n\nHolds the Pulumi deployment configuration for this repository. [README](infra/README.md)\n\n## schemas\n\nCeramic schemas and model definitions, and scripts for creating and publishing these to the Ceramic Network. [README](schemas/README.md)\n\n## types\n\nShared type definitions. [README](types/README.md)\n"
  },
  "passportxyz/passport": {
    "fetchedAt": "2025-11-12T23:02:02.434Z",
    "content": "# Passport XYZ\n\n## What is Passport?\n\nMany social organizations, online particularly, have difficulty ensuring that every participant is a unique human and does not have multiple participating accounts. Most existing digital identity solutions are either centralized (e.g., national identity cards) or individualistic (e.g., most ‚Äúself-sovereign‚Äù identity models). However, identity is naturally [intersectional and social](https://www.radicalxchange.org/concepts/intersectional-social-identity/); everybody shares different data and relationships with a unique set of others. Passport aims to provide a more collaborative and secure infrastructure for digital identity by capturing the richness of our diversely shared lives.\n\nPassport is an identity verification application. We have written software enabling people to grow personal collections of [verifiable credentials](https://decentralized-id.com/web-standards/w3c/wg/vc/verifiable-credentials/) about themselves and organizations to assess their identities to coordinate rights and responsibilities. The institutions define, verify, and utilize identity as functions of the networked records of the individuals. While we build the Passport agnostic to specific applications, we are actively exploring its benefits for [personhood proofs](https://en.wikipedia.org/wiki/Proof_of_personhood) and [plurality](https://www.radicalxchange.org/media/blog/why-i-am-a-pluralist/) in organizational designs.\n\n## Documentation\n\nCheck out our documentation at https://docs.passport.xyz\n\n## Contributing\n\nWe welcome everyone to contribute to Passport and the Scorer API! Please review our [contributing guidelines](./CONTRIBUTING.md) before proceeding.\n\nYou can join our [Discord](https://discord.gg/passport) (just be sure to select the builder role when you join) to get help and discuss the project with the rest of the community.\n\nYou can also familiarize yourself with our near term project roadmap in the passport [project backlog](https://github.com/orgs/passportxyz/projects/)\n\n## Reviewing Changes\n\nOnce a pull request is sent, the Passport team will review your changes. We outline our process below to clarify the roles of everyone involved.\n\nAll pull requests must be approved by two committers before being merged into the repository. If any changes are necessary, the team will leave appropriate comments requesting changes to the code. Unfortunately, we cannot guarantee a pull request will be merged, even when modifications are requested, as the Passport team will re-evaluate the contribution as it changes.\n\nCommitters may also push style changes directly to your branch. If you would rather manage all changes yourself, you can disable the \"Allow edits from maintainers\" feature when submitting your pull request.\n\nThe Passport team may optionally assign someone to review a pull request. If someone is assigned, they must explicitly approve the code before another team member can merge it.\n\nWhen the review finishes, your pull request will be squashed and merged into the repository. If you have carefully organized your commits and believe they should be merged without squashing, please mention it in a comment.\n\n## Quick Start\n\nPrerequisites: [Node (v20 LTS)](https://nodejs.org/en/download/) plus [Yarn](https://classic.yarnpkg.com/en/docs/install/) and [Git](https://git-scm.com/downloads)\n\n1. Install Passport (this will install all packages within the passport monorepo):\n\n```sh\ngit clone https://github.com/passportxyz/passport.git\ncd passport\nnpm install --global lerna\nyarn install\n```\n\n2. Create environment files, and replace environment variables with your own values\n\n```sh\ncp ./app/.env-example.env ./app/.env\ncp ./iam/.env-example.env ./iam/.env\n```\n\n3. Start iam, app, and ceramic services concurrently:\n\n```sh\n# remember to create .env files first\nyarn start\n```\n\n4. Run the [Passport Scorer API](https://github.com/passportxyz/passport-scorer/tree/main/api) locally. Set up instructions are [here](https://github.com/passportxyz/passport-scorer/blob/main/SETUP.md)\n\n## Passport Data\n\nA passport has two sources of data. The primary source is a postgres database that is hosted by Passport XYZ. To run the passport application locally you will need spin up the [Scorer API](https://github.com/passportxyz/passport-scorer/tree/main/api). All relevant instructions to run the scorer api can be found [here](https://github.com/passportxyz/passport-scorer/blob/main/SETUP.md). The sample environment variables in the .env-example.env files are configured to make requests to the scorer api running locally. Once the scorer api is running locally, you should have a reliable data source for development.\n\nA second source of data is the Ceramic network. No steps are needed to run the ceramic network locally. The sample environment variables in the .env-example.env files are configured to make requests to a test version of the ceramic network.\n\nThe third location is in onchain attestations that are made across about a dozen different networks. For more information on the onchain attestations, you can reference details [here](https://easscan.org/).\n\n## Background Knowledge\n\n- Know what a wallet is, how to create one, etc.\n- Know what a Verifiable Credential is\n- Know basics of Ceramic Network - interacting with DIDDatastore, Self.ID\n\n# Packages\n\n## app\n\nThe web app allowing users to interact with their Passport. [README](app/README.md)\n\n## database-client\n\nContains database connection implementations. Currently supports Ceramic Network. [README](database-client/README.md)\n\n## iam\n\nThe server handling incoming requests to issue credentials and process verifications. [README](iam/README.md)\n\n## identity\n\nThis is a helper package to compile Spruce DIDKit and export functions for use in `iam` and `app` packages.\n\n## infra\n\nHolds the Pulumi deployment configuration for this repository. [README](infra/README.md)\n\n## schemas\n\nCeramic schemas and model definitions, and scripts for creating and publishing these to the Ceramic Network. [README](schemas/README.md)\n\n## types\n\nShared type definitions. [README](types/README.md)\n"
  },
  "passportxyz/passport-scorer": {
    "fetchedAt": "2025-11-12T23:02:02.837Z",
    "content": "# Passport XYZ's Scorer API\n\nThe Passport API allows developers to integrate identity verification functionality into their applications. The API provides a simple way to read and score the identities of Gitcoin Passport holders by applying scoring mechanisms to verifiable credentials.\n\nSocial organizations have a difficult time ensuring that each participant is unique: that they are in fact human (not a bot) and also a unique participant (not double counting). The Gitcoin Passport solves this by providing a solution that is decentralized and recognizes the intersectional and social nature of identity.\n\nThe Passport Scorer API (this repository) is a centralized service provided by Passport XYZ to make it easier to read and work with Passport scores.\n\n## Quick Links\n\n- [Passport Docs](https://docs.passport.xyz/)\n- [API Docs](https://api.scorer.gitcoin.co/docs)\n- [Official Website](https://www.passport.xyz?utm_source=scorer-api-repo&utm_medium=referral&utm_content=Passport)\n\n## Contributing\n\nWe welcome everyone to contribute to Passport and the Scorer API! Please review our [contributing guidelines](./CONTRIBUTING.md) before proceeding.\n\nYou can join our [Discord](https://discord.gg/passport) (just be sure to select the builder role when you join) to get help and discuss the project with the rest of the community.\n\nYou can also familiarize yourself with our near term project roadmap in the [project backlog](https://github.com/orgs/passportxyz/projects/1)\n\n## Setup\n\nInstructions are provided in the [`SETUP.md`](./SETUP.md) for getting the codebase up and running on your local machine. This project is under active development and has not been tested on every possible operating system. If you\nget stuck setting up this project, please file an issue.\n\n## [License](./LICENSE)\n\nAll code is licensed under MIT.\n"
  },
  "seamless-protocol/governance": {
    "fetchedAt": "2025-11-12T23:02:11.131Z",
    "content": "# Governance\n\n[![Foundry][foundry-badge]][foundry]\n\n[foundry]: https://getfoundry.sh/\n[foundry-badge]: https://img.shields.io/badge/Built%20with-Foundry-FFDB1C.svg\n\n## How to Compile\n\n`make build`\n\n## How to Lint\n\n`make fmt`\n\n## How to Test\n\n`make test`\n\n## How to Deploy\n\n1. `cp .env.example .env` and fill in values\n\n2. Update constants in `script/TokenDeploy.s.sol` if necessary.\n\n3. Deploy\n\nBase Testnet: `make deploy-base-testnet`\n\nBase Mainnet: `make deploy-base-mainnet`\n\nBase Tenderly Fork: `make deploy-base-tenderly`\n\n## Deployment Addresses\n\n### Base Testnet (Goerli)\n\n| Contract         | Proxy address                                | Implementation address                       |\n| ---------------- | -------------------------------------------- | -------------------------------------------- |\n| SEAM             | `0x8c0dE778f20e7D25E6E2AAc23d5Bee1d19Deb491` | `0x0F2B5682562E3743F68D106CDf9512a9cd70e62e` |\n| EscrowSEAM       | `0xcAFf1eb3eF39D665340c94c4C20660613D66c691` | `0x38405c502676152d4D4b9c04177b2b500b53202E` |\n| Timelock short   | `0x3456B1781A86df123aa9dCEeFA818E1E68a25a4E` | `0x341e372C091c93f73b451BDa20A3147A776fB3eb` |\n| Governor short   | `0xa83325c6c4E4D8FC07b1d79E93ff66Af7533B2Bf` | `0xE66d871C14af041cd7a77bfBc4E372dd1ec62BB8` |\n| Timelock long    | `0x565504FcD4A1552990CFC5569548e0929571A9E4` | `0x80e887428cCa630F75a2452D27AA9805E9D5a1d8` |\n| Governor long    | `0x42159A640De060a36fe574c2b336Ef2a752B1e88` | `0x28a43359BD4aB030d5884b3074B3d3418697Ab03` |\n| Emission manager | `0xB1EcA5e7541574798A9e4a58BfE9c78b622138e6` | `0x747e86e46e3E2a87B76da1D87D7E571C6f3D3E04` |\n| Airdrop          |                                              | `0xB402A4472103ce81195aEBD68237AbdFDfb8891b` |\n\n### Ethereum Testnet (Goerli)\n\nSEAML1: `0x4a46Ebdd35B12703717d6F4DfbF5db91E6Ac0660`\n\n### Base Testnet (Sepolia)\n\n| Contract         | Proxy address                                | Implementation address                       |\n| ---------------- | -------------------------------------------- | -------------------------------------------- |\n| SEAM             | `0x178898686F23a50CCAC17962df41395484804a6B` | `0x4a46Ebdd35B12703717d6F4DfbF5db91E6Ac0660` |\n\n### Ethereum Testnet (Sepolia)\n\nSEAML1: `0xF01901ad15fcd248a7175E03c0ecCC0fD1D943Eb`\n\n### Base Mainnet\n\n| Contract                   | Proxy address                                | Implementation address                       |\n| -------------------------- | -------------------------------------------- | -------------------------------------------- |\n| SEAM                       | `0x1C7a460413dD4e964f96D8dFC56E7223cE88CD85` | `0x57b4b7f830244FC854cD1123ff14AFd4C1AEfd3F` |\n| EscrowSEAM                 | `0x998e44232BEF4F8B033e5A5175BDC97F2B10d5e5` | `0x78423BfC5053102A3087DAA978c2117a6809fBB1` |\n| Timelock short             | `0x639d2dD24304aC2e6A691d8c1cFf4a2665925fee` | `0x13F5B49217f330167D6350530F6185A75Ab35e6F` |\n| Governor short             | `0x8768c789C6df8AF1a92d96dE823b4F80010Db294` | `0xC8A0E02878A4EF18fa260F0968cEcde8Eb607BFc` |\n| Timelock long              | `0xA96448469520666EDC351eff7676af2247b16718` | `0xBe170D7D3Cda6E9db39E012D0fE25aB83Fff790d` |\n| Governor long              | `0x04faA2826DbB38a7A4E9a5E3dB26b9E389E761B6` | `0x5acB96aAc90BF545500251D1eED10Bf47e996317` |\n| Airdrop                    |                                              | `0xB7A6531665c5e2B2d5b9Aa04636847c8F45c702B` |\n| Seam Emission Manager 1    | `0x57460DC21bf1574b8e6E00D372b8Ca5Ec41b3955` | `0x03eEEdf76A007Dce47B3a0044D9F0A04BaDD9CFA` |\n| Seam Emission Manager 2    | `0x785c979EE8709060b3f71aEf4f2C09229DB90778` | `0x1FDFC3872A70A7af5a818F27bb14fBEA4EE38f9c` |\n| SeamTransferStrategy       |                                              | `0x2b1bdeFCe33f34128759f71076eBd62637FD154C` |\n| EscrowSeamTransferStrategy |                                              | `0x2181be388ced00754E7c1Ee33DBcF78397DD89aC` |\n| ERC20TransferStrategy      |                                              | `0x003D47ddDdb070822B35ae5cc4F0066Cf9E89753` |\n\n### Ethereum Mainnet\n\nSeamL1: `0x6b66ccd1340c479B07B390d326eaDCbb84E726Ba`\n"
  },
  "ethereum-attestation-service/eas-contracts": {
    "fetchedAt": "2025-11-12T23:02:26.758Z",
    "content": "# Ethereum Attestation Service\n\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-blue)](https://eas.eth.link)\n[![NPM Package](https://img.shields.io/npm/v/@ethereum-attestation-service/eas-contracts.svg)](https://www.npmjs.org/package/@ethereum-attestation-service/eas-contracts)\n[![Test](https://github.com/ethereum-attestation-service/eas-contracts/actions/workflows/ci.yml/badge.svg)](https://github.com/ethereum-attestation-service/eas-contracts/actions/workflows/ci.yml)\n[![License](https://img.shields.io/github/license/ethereum-attestation-service/eas-contracts?style=flat-square)](https://github.com/ethereum-attestation-service/eas-contracts/blob/master/LICENSE)\n\n## Introduction\n\nThe Ethereum Attestation Service is a free and open protocol for on-chain attestations on EVM compatible blockchains. It is a generalized service that allows anyone to register a schema for their particular use case, and then make attestations following their schema.\n\nSchemas can be registered using the `SchemaRegistry.sol` contract, and attestations are made using the `EAS.sol` contract.\n\nIn addition, we provide a resolver contract for advanced use cases, such as on-chain verification of attestation data, and also attaching payments to attestations (which makes a new suite of powerful web3 applications possible).\n\nWe also provide an SDK for developers.\n\nOn-chain attestations will enable a powerful new range of web3 applications, including:\n\n* Identity\n* Trust Scores\n* Goodness Scores\n* Credit Scores\n* Clout\n* Land Registries\n* Social Networks\n* Portable Trust Layers\n* Retroactive Public Goods Funding\n* KYC Services\n* Uncollateralized Lending / Borrowing\n* Voting\n* Oracles (who can be atomically paid for making attestations inside the protocol)\n* Likes/Dislikes\n* Content Filtering\n* And many more!\n\n## Deployments\n\nPlease note that you can also import and use the addresses directly in your code using the `@ethereum-attestation-service/eas-contracts/deployments` deployment artifacts corresponding to your desired network.\n\n### Mainnets\n\n#### Ethereum\n\nVersion 0.26:\n\n* **EAS**:\n  * Contract: [0xA1207F3BBa224E2c9c3c6D5aF63D0eb1582Ce587](https://etherscan.io/address/0xA1207F3BBa224E2c9c3c6D5aF63D0eb1582Ce587)\n  * Deployment and ABI: [EAS.json](./deployments/mainnet/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0xA7b39296258348C78294F95B872b282326A97BDF](https://etherscan.io/address/0xA7b39296258348C78294F95B872b282326A97BDF)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/mainnet/SchemaRegistry.json)\n\n#### Optimism\n\nVersion 1.0.1:\n\n* **EAS**:\n  * Contract: [0x4200000000000000000000000000000000000021](https://optimistic.etherscan.io/address/0x4200000000000000000000000000000000000021)\n  * Deployment and ABI: [EAS.json](./deployments/optimism/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0x4200000000000000000000000000000000000020](https://optimistic.etherscan.io/address/0x4200000000000000000000000000000000000020)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/optimism/SchemaRegistry.json)\n\nVersion 1.2.0:\n\n* **EIP712Proxy**:\n  * Contract: [0xE132c2E90274B44FfD8090b58399D04ddc060AE1](https://optimistic.etherscan.io/address/0xE132c2E90274B44FfD8090b58399D04ddc060AE1)\n  * Deployment and ABI: [EIP712Proxy.json](./deployments/optimism/EIP712Proxy.json)\n* **Indexer**:\n  * Contract: [0x6dd0CB3C3711c8B5d03b3790e5339Bbc2Bbcf934](https://optimistic.etherscan.io/address/0x6dd0CB3C3711c8B5d03b3790e5339Bbc2Bbcf934)\n  * Deployment and ABI: [Indexer.json](./deployments/optimism/Indexer.json)\n\n#### Base\n\nVersion 1.0.1:\n\n* **EAS**:\n  * Contract: [0x4200000000000000000000000000000000000021](https://basescan.org/address/0x4200000000000000000000000000000000000021)\n  * Deployment and ABI: [EAS.json](./deployments/base/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0x4200000000000000000000000000000000000020](https://basescan.org/address/0x4200000000000000000000000000000000000020)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/base/SchemaRegistry.json)\n\nVersion 1.2.0:\n\n* **EIP712Proxy**:\n  * Contract: [0xF095fE4b23958b08D38e52d5d5674bBF0C03cbF6](https://basescan.org/address/0xF095fE4b23958b08D38e52d5d5674bBF0C03cbF6)\n  * Deployment and ABI: [EIP712Proxy.json](./deployments/base/EIP712Proxy.json)\n* **Indexer**:\n  * Contract: [0x37AC6006646f2e687B7fB379F549Dc7634dF5b84](https://basescan.org/address/0x37AC6006646f2e687B7fB379F549Dc7634dF5b84)\n  * Deployment and ABI: [Indexer.json](./deployments/base/Indexer.json)\n\n#### Arbitrum One\n\nVersion 0.26:\n\n* **EAS**:\n  * Contract: [0xbD75f629A22Dc1ceD33dDA0b68c546A1c035c458](https://arbiscan.io/address/0xbD75f629A22Dc1ceD33dDA0b68c546A1c035c458)\n  * Deployment and ABI: [EAS.json](./deployments/arbitrum-one/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0xA310da9c5B885E7fb3fbA9D66E9Ba6Df512b78eB](https://arbiscan.io/address/0xA310da9c5B885E7fb3fbA9D66E9Ba6Df512b78eB)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/arbitrum-one/SchemaRegistry.json)\n\n#### Arbitrum Nova\n\nVersion 1.3.0:\n\n* **EAS**:\n  * Contract: [0x6d3dC0Fe5351087E3Af3bDe8eB3F7350ed894fc3](https://nova.arbiscan.io/address/0x6d3dC0Fe5351087E3Af3bDe8eB3F7350ed894fc3)\n  * Deployment and ABI: [EAS.json](./deployments/arbitrum-nova/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0x49563d0DA8DF38ef2eBF9C1167270334D72cE0AE](https://nova.arbiscan.io/address/0x49563d0DA8DF38ef2eBF9C1167270334D72cE0AE)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/arbitrum-nova/SchemaRegistry.json)\n* **EIP712Proxy**:\n  * Contract: [0xEbf2DeeD690F8A68b8248d6a12231ee70ED2154A](https://nova.arbiscan.io/address/0xEbf2DeeD690F8A68b8248d6a12231ee70ED2154A)\n  * Deployment and ABI: [EIP712Proxy.json](./deployments/arbitrum-nova/EIP712Proxy.json)\n* **Indexer**:\n  * Contract: [0x7182Be5e84aFEe9Dc29C69D081F8A0FA834d6CB8](https://nova.arbiscan.io/address/0x7182Be5e84aFEe9Dc29C69D081F8A0FA834d6CB8)\n  * Deployment and ABI: [Indexer.json](./deployments/arbitrum-nova/Indexer.json)\n\n#### Polygon\n\nVersion 1.3.0:\n\n* **EAS**:\n  * Contract: [0x5E634ef5355f45A855d02D66eCD687b1502AF790](https://polygonscan.com/address/0x5E634ef5355f45A855d02D66eCD687b1502AF790)\n  * Deployment and ABI: [EAS.json](./deployments/polygon/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0x7876EEF51A891E737AF8ba5A5E0f0Fd29073D5a7](https://polygonscan.com/address/0x7876EEF51A891E737AF8ba5A5E0f0Fd29073D5a7)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/polygon/SchemaRegistry.json)\n* **EIP712Proxy**:\n  * Contract: [0x4be71865917C7907ccA531270181D9B7dD4f2733](https://polygonscan.com/address/0x4be71865917C7907ccA531270181D9B7dD4f2733)\n  * Deployment and ABI: [EIP712Proxy.json](./deployments/polygon/EIP712Proxy.json)\n* **Indexer**:\n  * Contract: [0x12d0f50Eb2d67b14293bdDA2C248358f3dfE5308](https://polygonscan.com/address/0x12d0f50Eb2d67b14293bdDA2C248358f3dfE5308)\n  * Deployment and ABI: [Indexer.json](./deployments/polygon/Indexer.json)\n\n#### Scroll\n\nVersion 1.3.0:\n\n* **EAS**:\n  * Contract: [0xC47300428b6AD2c7D03BB76D05A176058b47E6B0](https://scrollscan.com/address/0xC47300428b6AD2c7D03BB76D05A176058b47E6B0)\n  * Deployment and ABI: [EAS.json](./deployments/scroll/EAS.json)\n* **SchemaRegistry**:\n  * Contract: [0xD2CDF46556543316e7D34e8eDc4624e2bB95e3B6](https://scrollscan.com/address/0xD2CDF46556543316e7D34e8eDc4624e2bB95e3B6)\n  * Deployment and ABI: [SchemaRegistry.json](./deployments/scroll/SchemaRegistry.json)\n* **EIP712Proxy**:\n  * Contract: [0x77b7DA1c40762Cd8AFfE2069b575328EfD4D9801](https://scrollscan.com/address/0x77b7DA1c40762Cd8AFfE2069b575328EfD4D9801)\n  * Deployment and ABI: [EIP712Proxy.json](./deployments/scroll/EIP712Proxy.json)\n* **Indexer**:\n  * Contract: [0x8314bc1B2f7F286cb4f0323FE7119C0F99D4A083](https://scrollscan.com/address/0x8314bc1B2f7F286cb4f0323FE7119C0F99D4A083)\n  * Deployment and ABI: [Indexer.json](./deployments/scroll/Indexer.json)\n\n#### zkSync\n\nVersion 1.3.0:\n\n* **EAS**:\n  * Contract: [0x21d8d4eE83b80bc0Cc0f2B7df3117Cf212d02901](https://explorer.zksync.io/address/0x21\n\n[... truncated ...]"
  },
  "ethereum-attestation-service/eas-sdk": {
    "fetchedAt": "2025-11-12T23:02:27.130Z",
    "content": "# Ethereum Attestation Service - TypeScript/JavaScript SDK\n\n[![Docs](https://img.shields.io/badge/docs-%F0%9F%93%84-blue)](https://eas.eth.link)\n[![NPM Package](https://img.shields.io/npm/v/@ethereum-attestation-service/eas-sdk.svg)](https://www.npmjs.org/package/@ethereum-attestation-service/eas-sdk)\n[![Test](https://github.com/ethereum-attestation-service/eas-sdk/actions/workflows/ci.yml/badge.svg)](https://github.com/ethereum-attestation-service/eas-sdk/actions/workflows/ci.yml)\n\nThis repository contains the Ethereum Attestation Service SDK, used to interact with the Ethereum Attestation Service Protocol.\n\n## Table of Contents\n\n- [Installing the EAS SDK](#installing-the-eas-sdk)\n- [Using the EAS SDK](#using-the-eas-sdk)\n- [Getting an Attestation](#getting-an-attestation)\n- [Estimating Gas for Transactions](#estimating-gas-for-transactions)\n  - [Example: Estimating Gas for an Attestation](#example-estimating-gas-for-an-attestation)\n  - [Example: Estimating Gas for a Revocation](#example-estimating-gas-for-a-revocation)\n- [Creating Onchain Attestations](#creating-onchain-attestations)\n  - [Example: Creating Onchain Attestations](#example-creating-onchain-attestations)\n  - [Example: Creating Multi Onchain Attestations](#example-creating-multi-onchain-attestations)\n- [Revoking Onchain Attestations](#revoking-onchain-attestations)\n  - [Example: Revoking Onchain Attestations](#example-revoking-onchain-attestations)\n- [Creating Offchain Attestations](#creating-offchain-attestations)\n  - [Example: Creating Offchain Attestations](#example-creating-offchain-attestations)\n- [Creating Delegated Onchain Attestations](#creating-delegated-onchain-attestations)\n  - [Example: Creating Delegated Onchain Attestations](#example-creating-delegated-onchain-attestations)\n- [Revoking Delegated Onchain Attestations](#revoking-delegated-onchain-attestations)\n  - [Example: Revoking Delegated Onchain Attestations](#example-revoking-delegated-onchain-attestations)\n- [Creating Timestamps](#creating-timestamps)\n- [Revoking Offchain Attestations](#revoking-offchain-attestations)\n- [Verifying an Offchain Attestation](#verifying-an-offchain-attestation)\n- [Registering a Schema](#registering-a-schema)\n- [Getting Schema Information](#getting-schema-information)\n- [Using the PrivateData Class](#using-the-privatedata-class)\n  - [Creating Private Data](#creating-private-data)\n  - [Getting the Full Merkle Tree](#getting-the-full-merkle-tree)\n  - [Generating a Multi-Proof](#generating-a-multi-proof)\n  - [Verifying a Multi-Proof](#verifying-a-multi-proof)\n  - [Verifying the Full Tree](#verifying-the-full-tree)\n- [Example: Creating an Attestation with Private Data](#example-creating-an-attestation-with-private-data)\n\n## Installing the EAS SDK\n\nTo install the EAS SDK, run the following command within your project directory:\n\n```sh\nyarn add @ethereum-attestation-service/eas-sdk\n```\n\nOR\n\n```sh\nnpm install @ethereum-attestation-service/eas-sdk\n```\n\nOR\n\n```sh\npnpm add @ethereum-attestation-service/eas-sdk\n```\n\n## Using the EAS SDK\n\nImport and initialize the library:\n\n```javascript\nimport { EAS, Offchain, SchemaEncoder, SchemaRegistry } from '@ethereum-attestation-service/eas-sdk';\nimport { ethers } from 'ethers';\n\nexport const EASContractAddress = '0xC2679fBD37d54388Ce493F1DB75320D236e1815e'; // Sepolia v0.26\n\n// Initialize the SDK with the address of the EAS Schema contract address\nconst eas = new EAS(EASContractAddress);\n\n// Gets a default provider (in production use something else like infura/alchemy)\nconst provider = ethers.getDefaultProvider('sepolia');\n\n// Connects an ethers style provider/signingProvider to perform read/write functions.\n// MUST be a signer to do write operations!\neas.connect(provider);\n```\n\n### Getting an Attestation\n\nThe `getAttestation` function allows you to retrieve an on-chain attestation for a given UID. This function returns an attestation object containing information about the attestation, such as the schema, recipient, attester, and more.\n\n#### Usage\n\n```javascript\nimport { EAS, NO_EXPIRATION } from '@ethereum-attestation-service/eas-sdk';\n\nconst eas = new EAS(EASContractAddress);\neas.connect(provider);\n\nconst uid = '0xff08bbf3d3e6e0992fc70ab9b9370416be59e87897c3d42b20549901d2cccc3e';\n\nconst attestation = await eas.getAttestation(uid);\n\nconsole.log(attestation);\n```\n\n#### Output\n\nThe `getAttestation` function returns an attestation object with the following properties:\n\n- `uid`: The unique identifier of the attestation.\n- `schema`: The schema identifier associated with the attestation.\n- `refUID`: The reference UID of the attestation, if any.\n- `time`: The Unix timestamp when the attestation was created.\n- `expirationTime`: The Unix timestamp when the attestation expires (0 for no expiration).\n- `revocationTime`: The Unix timestamp when the attestation was revoked, if applicable.\n- `recipient`: The Ethereum address of the recipient of the attestation.\n- `attester`: The Ethereum address of the attester who created the attestation.\n- `revocable`: A boolean indicating whether the attestation is revocable or not.\n- `data`: The attestation data in bytes format.\n\nExample output:\n\n```javascript\n{\n    uid: '0x5134f511e0533f997e569dac711952dde21daf14b316f3cce23835defc82c065',\n    schema: '0x27d06e3659317e9a4f8154d1e849eb53d43d91fb4f219884d1684f86d797804a',\n    refUID: '0x0000000000000000000000000000000000000000000000000000000000000000',\n    time: 1671219600,\n    expirationTime: NO_EXPIRATION,\n    revocationTime: 1671219636,\n    recipient: '0xFD50b031E778fAb33DfD2Fc3Ca66a1EeF0652165',\n    attester: '0x1e3de6aE412cA218FD2ae3379750388D414532dc',\n    revocable: true,\n    data: '0x0000000000000000000000000000000000000000000000000000000000000000'\n}\n```\n\n### Estimating Gas for Transactions\n\nThe `estimateGas` method allows you to estimate the gas cost for any transaction before sending it. This is useful for determining the gas requirements and costs before executing transactions. The method is available on all transaction objects returned by EAS SDK methods.\n\n#### Example: Estimating Gas for an Attestation\n\n```javascript\nimport { EAS, NO_EXPIRATION, SchemaEncoder } from '@ethereum-attestation-service/eas-sdk';\n\nconst eas = new EAS(EASContractAddress);\neas.connect(signer);\n\n// Initialize SchemaEncoder with the schema string\nconst schemaEncoder = new SchemaEncoder('uint256 eventId, uint8 voteIndex');\nconst encodedData = schemaEncoder.encodeData([\n  { name: 'eventId', value: 1, type: 'uint256' },\n  { name: 'voteIndex', value: 1, type: 'uint8' }\n]);\n\nconst schemaUID = '0xb16fa048b0d597f5a821747eba64efa4762ee5143e9a80600d0005386edfc995';\n\nconst transaction = await eas.attest({\n  schema: schemaUID,\n  data: {\n    recipient: '0xFD50b031E778fAb33DfD2Fc3Ca66a1EeF0652165',\n    expirationTime: NO_EXPIRATION,\n    revocable: true,\n    data: encodedData\n  }\n});\n\n// Estimate gas before sending the transaction\nconst estimatedGas = await transaction.estimateGas();\nconsole.log('Estimated gas:', estimatedGas.toString());\n\n// Now send the transaction\nconst newAttestationUID = await transaction.wait();\nconsole.log('New attestation UID:', newAttestationUID);\n```\n\n#### Example: Estimating Gas for a Revocation\n\n```javascript\nconst transaction = await eas.revoke({\n  schema: '0x85500e806cf1e74844d51a20a6d893fe1ed6f6b0738b50e43d774827d08eca61',\n  data: { uid: '0x6776de8122c352b4d671003e58ca112aedb99f34c629a1d1fe3b332504e2943a' }\n});\n\n// Estimate gas before sending the transaction\nconst estimatedGas = await transaction.estimateGas();\nconsole.log('Estimated gas for revocation:', estimatedGas.toString());\n\n// Now send the transaction\nawait transaction.wait();\n```\n\n### Creating Onchain Attestations\n\nThe `attest` function allows you to create an on-chain attestation for a specific schema. This function takes an object with the following properties:\n\n- `schema`: The UID of the schema for which the attestation is being created.\n- `data`: An object containing the following properties:\n  - `recipient`: The Ethe\n\n[... truncated ...]"
  },
  "Hats-Protocol/multi-claims-hatter": {
    "fetchedAt": "2025-11-12T23:02:33.985Z",
    "content": "# MultiClaimsHatter\n\nA Hats Protocol hatter contract enabling explicitly eligible wearers to claim a hat.\n\n## Overview & Usage\n\nIn [Hats Protocol](https://github.com/hats-protocol/hats-protocol), hats are typically issued by admins minting them to wearers. While often that is the desired behavior, there are cases where it is desirable to allow wearers to claim a hat themselves, assuming they are eligible to wear them. MultiClaimsHatter enables DAOs to optionally make hats claimable by eligible wearers.\n\n### Prerequisites\n\nA MultiClaimsHatter instance can make multiple hats claimable. To do so, it has to be an admin of each of the hats. Thus, a claimable hat must have an admin hat that is worn by a MultiClaimsHatter instance.\nOne common option is creating a designated hat for the MultiClaimsHatter. Once the MultiClaimsHatter instance wears this hat, it can set any hats that are under its branch as claimable.\n\nFor example, if in normal operations a hat tree would look like this...\n\n```lua\n   +-------------+\n   | 1) Top Hat  |\n   +-------------+\n        |\n   +---------------+\n   | 1.1) Role Hat |\n   +---------------+\n```\n\n... then to make the Role Hat claimable, another hat needs to exist in between:\n\n```lua\n   +-------------+\n   | 1) Top Hat  |\n   +-------------+\n        |\n   +-----------------+\n   | 1.1) Hatter Hat |\n   +-----------------+\n        |\n   +---------------+\n   | 1.2) Role Hat |\n   +---------------+\n```\n\nSecond, each of the claimable hats must have a [mechanistic eligibility module](https://github.com/Hats-Protocol/hats-protocol/#eligibility), i.e. one that implements the [IHatsEligibility](https://github.com/Hats-Protocol/hats-protocol/blob/main/src/Interfaces/IHatsEligibility.sol) interface. Only such modules can create the required \"explicit eligibility\".\n\n### Creating a new MultiClaimsHatter instance\n\nNew instances of MultiClaimsHatter are deployed via the [HatsModuleFactory](https://github.com/Hats-Protocol/hats-module/blob/main/src/HatsModuleFactory.sol), by using the `createHatsModule` function.\nHatsModuleFactory is a clone factory that enables cheap creation of new module instances.\n\nThe MultiClaimsHatter instance can be optionally created with initial claimable hats, by using the `_initData` parameter:\n\n```solidity\nbytes memory _initData = abi.encode(initialHats, initialClaimTypes);\n```\n\nNote that MultiClaimsHatter doesn't use additional immutable arguments and so the `_otherImmutableArgs` parameter for the `createHatsModule` function should be empty.\n\n### Mint or transfer an admin hat of the claimable hats to the MultiClaimsHatter instance\n\nMultiClaimsHatter is a \"hatter\" contract, which is a type of contract designed to wear an admin hat. When wearing an admin hat (such as the \"Hatter Hat\" in the second diagram above), it gains admin authorities over the child hat(s) below it (such as the \"Role Hat\"). In MultiClaimsHatter's case, this includes the ability to mint those hat(s).\n\nTo enable MultiClaimsHatter to mint hats, it must be wearing an admin hat of the hat/s to claim. This can be done by minting (or transferring, as relevant) the admin hat to the MultiClaimsHatter instance.\n\n### Making hats claimable\n\nOnce the MultiClaimsHatter instance is setup and wears a proper admin hat, it can make any hats that it admins claimable. To do so, the following functions can be used:\n\n- `setHatClaimability` is used in order to make a signle hat claimable\n- `setHatsClaimability` is used in order to make multiple hats claimable in one transaction\n- `setHatClaimabilityAndCreateModule` is used in order to make a hat claimable and deploy a new eligibility module in one transaction\n- `setHatsClaimabilityAndCreateModules` is used in order to make multiple hats claimable and deploy new eligibility modules in one transaction\n\n### Claiming\n\nOnce a hat is made claimable, explicitly eligible wearers can now claim the hat! They can do this simply by calling the `claimHat` or `claimHats` functions with the desired hat/s as an argument.\n\n### Claiming on behalf of a wearer\n\nIn some cases, it may be desirable to allow a third party ‚Äî such as a bot network ‚Äî to claim a hat on behalf of a wearer. DAOs can optionally enable \"claiming for\" by setting the claimability type of hats as `ClaimType.ClaimableFor`.\n\nOnce set, anybody can then claim on behalf of eligible wearer/s by calling the `claimHatFor` or `claimHatsFor` functions, with the desired wearer/s and hat/s as arguments.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To compile the contracts, run `forge build`\n4. To test, run `forge test`\n"
  },
  "hats-protocol/hats-module": {
    "fetchedAt": "2025-11-12T23:02:34.353Z",
    "content": "# HatsModule\n\nHatsModule is a base contract for creating modules and hatter contracts for [Hats Protocol](https://github.com/hats-protocol/hats-protocol). Such modules are designed to be deployed as minimal proxy clones (with immutable args) via the included HatsModuleFactory.\n\n## HatsModule Details\n\nA HatsModule is a simple contract designed to be inherited by contracts that implement specific functionality for Hats Protocol. It exposes several functions for reading immutable storage related to the module:\n\n- `IMPLEMENTATION()`: The address of the implementation contract of which the module is a clone.\n- `HATS()`: The address of the Hats Protocol contract.\n- `hatId()`: The ID of the hat that the module is associated with. This could be 0 if the module is not associated with any hat.\n- `version()`: The version of the module.\n\n### HatsEligibilityModule\n\nAn abstract contract that inherits from HatsModule and implements the [IHatsEligibility](https://github.com/Hats-Protocol/hats-protocol/blob/main/src/Interfaces/IHatsEligibility.sol) interface. This contract is designed to be inherited by contracts that implement eligibility logic for Hats Protocol.\n\n### HatsToggleModule\n\nAn abstract contract that inherits from HatsModule and implements the [IHatsToggle](https://github.com/Hats-Protocol/hats-protocol/blob/main/src/Interfaces/IHatsToggle.sol) interface. This contract is designed to be inherited by contracts that implement toggle logic for Hats Protocol.\n\n## HatsModuleFactory\n\nThe HatsModuleFactory is a contract that deploys minimal proxy clones of HatsModules. It deploys clones of an implementation contract with customizable immutable args, and initializes the clones with the `setUp` function of the implementation contract.\n"
  },
  "Hats-Protocol/allowlist-eligibility": {
    "fetchedAt": "2025-11-12T23:02:34.761Z",
    "content": "# Allowlist Eligibility Module\n\nA [Hats Protocol](https://github.com/hats-protocol/hats-protocol) eligibility module that uses an allowlist to determine eligibility.\n\n## Overview and Usage\n\nThis module sets up a simple allowlist to determine eligibility for a hat. For a given account (i.e., potential hat wearer), the allowlist stores values for that account's eligibility and standing for the hat. The wearer(s) of the `ownerHat` can add or remove accounts from the allowlist. The wearer(s) of the `arbitratorHat` can set the standing of accounts.\n\nThis module serves as both a \"mechanistic\" and \"humanistic passthrough\" eligibility module.\n\n### Mechanistic Functionality\n\n- Wearer(s) of the `ownerHat` can simply add account(s) to the allowlist by calling `addAccount()` or `addAccounts()`.\n- Wearer(s) of the `ownerHat` can simply remove account(s) from the allowlist by calling `removeAccount()` or `removeAccounts()`.\n- Wearer(s) of the `arbitratorHat` can simply set the standing of account(s) by calling `setStandingForAccount()` or `setStandingForAccounts()`.\n\nIn each of these cases, Hats Protocol will *pull* eligibility and standing data from the module via `getWearerStatus()`. Hats Protocol will not emit an event with any of these eligibility and resulting wearer changes, so front ends pointing only at Hats Protocol events (or the [subgraph](https://github.com/hats-protocol/subgraph)) will not automatically reflect these changes.\n\n### Humanistic Functionality\n\n- Wearer(s) of the `ownerHat` can manually revoke an account's hat by calling `removeAccountAndBurnHat()`.\n- Wearer(s) of the `arbitratorHat` can manually put an account in bad standing and burn their hat `setStandingForAccountAndBurnHat()`.\n\nIn these cases, the module *pushes* eligibility and standing data to Hats Protocol, causing Hats Protocol to emit event(s) reflecting the eligibility and resulting wearer changes. Front ends pointing at Hats Protocol events (or the subgraph) *will* automatically reflect these changes.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n\n### IR-Optimized Builds\n\nThis repo also supports contracts compiled via IR. Since compiling all contracts via IR would slow down testing workflows, we only want to do this for our target contract(s), not anything in this `test` or `script` stack. We accomplish this by pre-compiled the target contract(s) and then loading the pre-compiled artifacts in the test suite.\n\nFirst, we compile the target contract(s) via IR by running`FOUNDRY_PROFILE=optimized forge build` (ensuring that FOUNDRY_PROFILE is not in our .env file)\n\nNext, ensure that tests are using the `DeployOptimized` script, and run `forge test` as normal.\n\nSee the wonderful [Seaport repo](https://github.com/ProjectOpenSea/seaport/blob/main/README.md#foundry-tests) for more details and options for this approach.\n"
  },
  "Hats-Protocol/hats-elections-eligibility": {
    "fetchedAt": "2025-11-12T23:02:35.132Z",
    "content": "# Hats Elections Eligibility\n\nA [Hats Protocol](https://github.com/hats-protocol/hats-protocol) eligibility module for elections.\n\n## Overview and Usage\n\nThis contract is an [Eligibility Module](https://docs.hatsprotocol.xyz/for-developers/hats-protocol-overview/eligibility-modules) for Hats Protocol. It receives the results of an election conducted elsewhere (eg another smart contract, or offchain) and sets the winning addresses as eligible to wear a specified hat for the course of a specified term. It can also receive the results of a recall election, which sets the recalled addresses as ineligible to wear the hat.\n\n### Roles and Configuration\n\nThis module operates on and with three roles, all represented by hats:\n\n- **Elected Role (hatId)**: The role that is elected by the election. The hat for this role is specified by the `hatId` constant set upon deployment of a module instance. This is the hat that `getWearerStatus()` for which eligibility is determined, provided that the module instance is set as the eligibility module for the hat.\n\n- **Ballot Box**: The submitter of election results. The hat for this role is specified by the `BALLOT_BOX_HAT` constant set upon deployment of a module instance. Only the wearer(s) of this hat are authorized to call `elect()` and `recall()`.\n\n- **Owner**: This role is responsible for setting the current and next election terms. The hat for this role is specified by the `OWNER_HAT` constant set upon deployment of a module instance. Only wearer(s) of this hat are authorized to call `setNextTerm()`.\n\nThe only other configuration required is the first term's end date.\n\n![An example Hats tree using Hats Elections Eligibility](ExampleHatTree.png)\n*An example Hats tree using Hats Elections Eligibility. Note that `BALLOT_BOX_HAT`, `OWNER_HAT`, and `hatId` are not required to be in this configuration.*\n\n### Elections\n\nThis module is designed to work with elections that are conducted elsewhere. Election results are submitted by calling `elect()`, with arguments for the relevant term and an array of winning addresses.\n\nOnly the wearer(s) of the `BALLOT_BOX_HAT` are authorized to call `elect()`. \"Ballot box\" is our label for the contract that submits the election results. If the election is conducted onchain, then the ballot box is likely the election conrtact itself. If the election is conducted offchain, then the ballot box is likely an oracle contract.\n\nThere are a couple other restrictions on `elect()`:\n\n- It cannot be called twice for the same term (see [Terms](#terms) below for more detail on terms).\n- The number of winning addresses must be no greater than the maxSupply of the hat representing the elected role.\n\n### Recall Elections\n\nThe inverse of an election is a recall election, where one or more of the elected addresses are recalled, i.e. removed from the role they were elected to. In this contract, recall elections are conducted by calling `recall()`, with arguments for the relevant term and an array of recalled addresses.\n\nOnly the wearer(s) of the `BALLOT_BOX_HAT` are authorized to call `recall()`.\n\nRecall elections can take place at any time, with no restriction.\n\n### Terms\n\nWhen an election is conducted, the winning addresses are set as eligible to wear the hat for a specified period of time, i.e. a \"term.\"\n\nIn this contract, a term is defined and identified by the uint128 unix timestamp of its end date. For gas optimization reasons, the timestamp actually used is the timestampe of the second immediately *following* the end of the term.\n\nThis module keeps track of two terms: the current term (`currentTermEnd`) and the next term (`nextTermEnd`).\n\nThe current term is the term that is currently in effect. The initial term is set when an instance of this module is deployed. Thereafter, wearer(s) of the `OWNER_HAT` can call `setNextTerm()` to set the next term.\n\nWhen the current term ends and the next term's election results have been submitted, the next term begins once anybody calls the poke function `startNextTerm()`.\n\n### Eligibility and `getWearerStatus()`\n\nHats Protocol [Eligibility Modules](https://docs.hatsprotocol.xyz/for-developers/hats-protocol-overview/eligibility-modules) are contracts that adhere to the [`IHatsEligibility` interface](https://github.com/Hats-Protocol/hats-protocol/blob/main/src/Interfaces/IHatsEligibility.sol), which defines a single function:\n\n```solidity\nfunction getWearerStatus(address wearer, uint256 hatId) external view returns (bool eligible, bool standing);\n```\n\nThis module doesn't touch on `standing`, and will always return true for `standing`. If desired, this module can be chained with other eligibility modules that do have `standing` logic.\n\nAccounts are eligible if they are elected for the current term. In other words, `getWearerStatus()` will return `eligible=true` for an account when the current term has not ended, and the account has been elected (and not recalled) for the current term.\n\nAs soon as the term ends, all accounts elected for that term will immediately cease to be eligible.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n\n### IR-Optimized Builds\n\nThis repo also supports contracts compiled via IR. Since compiling all contracts via IR would slow down testing workflows, we only want to do this for our target contract(s), not anything in this `test` or `script` stack. We accomplish this by pre-compiled the target contract(s) and then loading the pre-compiled artifacts in the test suite.\n\nFirst, we compile the target contract(s) via IR by running`FOUNDRY_PROFILE=optimized forge build` (ensuring that FOUNDRY_PROFILE is not in our .env file)\n\nNext, ensure that tests are using the `DeployOptimized` script, and run `forge test` as normal.\n\nSee the wonderful [Seaport repo](https://github.com/ProjectOpenSea/seaport/blob/main/README.md#foundry-tests) for more details and options for this approach.\n"
  },
  "Hats-Protocol/jokerace-eligibility": {
    "fetchedAt": "2025-11-12T23:02:35.622Z",
    "content": "# JokeraceEligibility\n\nJokeraceEligibility is an eligibility module for [Hats Protocol](https://github.com/hats-protocol/hats-protocol).\nIn general, the module defines eligibility for wearers according to a Jokerace\ncontest results. More specifically, the module supports multiple terms, each\ndefined by:\n\n- A Jokerace contest.\n- The number of winners in the contest (top K authors of the proposals\n  with the highest score).\n- The term duration, starting from the contest completion.\n\nEach module instance has its admin/s which can set a reelection (new term),\nonce the current term has ended.\n\n**NOTE**: Proposals ranking is only supported in Jokerace contests with\ndown-voting disabled. Thus only contests with down-voting disabled are\nsupported by this module.\n\n## JokeraceEligibility Details\n\nJokeraceEligibility inherits from the [HatsEligibilityModule](https://github.com/Hats-Protocol/hats-module#hatseligibilitymodule)\nbase contract, from which it receives two major properties:\n\n- It can be cheaply deployed via the minimal proxy factory[HatsModuleFactory](https://github.com/Hats-Protocol/hats-module#hatsmodulefactory)\n- It implements the interface [IHatsEligibility](https://github.com/Hats-Protocol/hats-protocol/blob/main/src/Interfaces/IHatsEligibility.sol)\n\n### Setup\n\nA JokeraceEligibility instance requires several parameters to be set at\ndeployment, passed to the `HatsModuleFactory.createHatsModule()` function in\nvarious ways.\n\n#### Immutable values\n\n- `hatId`: The id of the hat to which this instance will be attached as an\n  eligibility module, passed as itself\n- `ADMIN_HAT`: The id of the admin hat which can set reelections (new terms).\n  If set to zero, then the default admins are hatId's admins in Hats.\n  The parameter is abi-encoded (packed) and passed as `_otherImmutableArgs`\n\nThe following immutable values will also automatically be set within the\ninstance at deployment:\n\n- `IMPLEMENTATION`: The address of the JokeraceEligibility implementation\n  contract.\n- `HATS`: The address of the Hats Protocol contract\n\n#### Initial state values\n\nThe following are abi-encoded (unpacked) and then passed to the\n`HatsModuleFactory.createHatsModule()` function as `_initData`.\nThese values can be changed at each reelection:\n\n- `underlyingContest`: The Jokerace contest of the current term.\n- `termEnd`: The timestamp of the term ending time (first second in which the\n  term is considered as ended).\n- `topK`: The top K candidates with the highest scores will be eligible\n  wearers for the corresponding term.\n\n### Contest Results\n\nEach term starts at the current contest completion and ends according to\n`termEnd`. After contest completion, anyone can call the `pullElectionResults`\nfunction in order to pull its results and update the eligible wearers for the\ncurrent term. The eligible wearers are the authors of the `topK` proposals\nwith the highest scores.\n\n**NOTE**: Zero scores are not valid, meaning that proposals with a score\nof zero cannot be part of the top K winners.\n\n**NOTE**: In case there are no definite K winners, meaning that there is a tie\nbetween place K and K+1, then the term is considered invalid and no candidate\nwill be eligible. In this case, the module's admin/s can set a new election.\n\n### Reelection\n\nAfter the current term has ended, or in case the contest in the current term\nhas been canceled, a reelection can be set by an admin of the module. The\nreelection is defined with a new Jokerace contest, term ending timestamp\nand a top K parameter.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To compile the contracts, run `forge build`\n4. To test, run `forge test`\n"
  },
  "Hats-Protocol/agreement-eligibility": {
    "fetchedAt": "2025-11-12T23:02:36.016Z",
    "content": "# Agreement Eligibility\n\nThe Agreement Eligibility is a [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) [module](https://github.com/Hats-Protocol/hats-module) that a community or organization can use to enable individuals to join the community by signing an agreement.\n\nWhen an individual signs the agreement, they also receive a hat that grants them access to the community. If a new agreement is published, community members must sign the new agreement to continue to wear the hat and remain a member of the community.\n\n## Functionality and Usage\n\n### Deployment and Initialization\n\nThe module is deployed and initialized by the organization. As a Hats Protocol module, it can be deployed via the [Hats Module Factory](https://github.com/Hats-Protocol/hats-module#hatsmodulefactory). When the contract is deployed, the organization must specify the following parameters:\n\nImmutable parameters:\n\n- `hatId` ‚Äî¬†The hat id for the community hat\n\nMutable parameters:\n\n- `ownerHat` ‚Äî¬†The hat id for the owner hat, i.e., the hat whose wearer is authorized to publish new agreements\n- `arbitratorHat` ‚Äî The hat id for the arbitrator hat, i.e. the hat whose wearer is authorized to revoke the community hat from a given community member\n- `agreement` ‚Äî The initial agreement, in the form of a hash. This is typically a CID pointing to a file containing the plaintext of the agreement.\n\n### Signing the Agreement and Claiming the Community Hat (Anyone)\n\nAnyone can make themselves eligible for the hat by signing the agreement. There are two options of doing so:\n\n1. Signing the agreement and claiming the hat, in one transaction. Doing so involves calling the `signAgreementAndClaimHat` function. The function receives as an input a [Multi Claims Hatter](https://github.com/Hats-Protocol/multi-claims-hatter) instance, which will be used for claiming the hat.\n\n2. Only signing the agreement, using the `signAgreement` function.\n\n### Signing a New Agreement (Active Community Members Only)\n\nWhen a new agreement is published by the organization (see below), all current wearers of the community hat ‚Äî i.e., active members of the community ‚Äî must sign the new agreement within a specified time period to remain a member of the community.\n\nThis specified time period is called the \"grace period\" and is set by the wearer of the Owner Hat when publishing the new agreement.\n\nActive community members can sign the new agreement by calling the `signAgreement()` function, which emits an event reflecting the member's \"signature\" of the new agreement.\n\n### Publishing a New Agreement (Owner Only)\n\nThe wearer of the `ownerHat` can publish a new agreement by calling the `setAgreement()` function. Just like initialization, this involves passing both the `agreement` and `grace` parameters. This action also increments the `currentAgreementId`.\n\nOnce a new agreement is set, the grace period begins.\n\n### Revoking a Community Member's Hat (Arbitrator Only)\n\nThe wearer of the `arbitratorHat` can revoke a community member's hat by calling the `revoke()` function. This function takes a single parameter, `wearer`, which is the address of the community member whose hat is being revoked.\n\nWhen a hat is revoked, the hat is burned and the member is placed in badStanding within Hats Protocol. This means that the member is no longer eligible to wear the community hat and cannot re-claim the community hat until the arbitrator places them back in good standing.\n\n### Forgiving a Community Member (Arbitrator Only)\n\nIf an individual's community hat has been revoked, then they are in bad standing. If the wearer of the `arbitratorHat` believes that the individual has made up for the behavior that led to the revocation, they can call the `forgive()` function. This places the individual back in good standing, enabling them to claim the community hat again if they so choose.\n\n### Hat Eligibility\n\nThis contract also serves as an Eligibility module for the community hat. This means that it implements the `IHatsEligibility` interface, i.e. the `getWearerStatus()` function. This function returns the `eligible` and `standing` status for the given address.\n\nThese wearer statuses will differ depending on the scenario, as outlined in the table below.\n\n| Scenario | `eligible` | `standing` |\n| -------- | -------- | -------- |\n| Wearer has claimed the hat and signed the current agreement | true | true |\n| Wearer has claimed the hat; there is a new agreement that the wearer has not signed, but the grace period has not ended | true | true |\n| Wearer has claimed the hat; there is a new agreement that the wearer has not signed, and the grace period has ended | false | true |\n| Wearer has claimed the hat; there is a new agreement that the wearer has signed | true | true |\n| Arbitrator has `revoke()`d the wearer's hat, placing them in bad standing | false | false |\n| Arbitrator has `forgive()`n the wearer after revoking their hat, but they have have not reclaimed the hat | false | true |\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To compile the contracts, run `forge build`\n4. To test, run `forge test`\n"
  },
  "Hats-Protocol/hats-governor-votes": {
    "fetchedAt": "2025-11-12T23:02:36.422Z",
    "content": "# solidity-template\n\nTemplate repo for solidity projects\n\n## Overview and Usage\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n\n### IR-Optimized Builds\n\nThis repo also supports contracts compiled via IR. Since compiling all contracts via IR would slow down testing workflows, we only want to do this for our target contract(s), not anything in this `test` or `script` stack. We accomplish this by pre-compiled the target contract(s) and then loading the pre-compiled artifacts in the test suite.\n\nFirst, we compile the target contract(s) via IR by running`FOUNDRY_PROFILE=optimized forge build` (ensuring that FOUNDRY_PROFILE is not in our .env file)\n\nNext, ensure that tests are using the `DeployOptimized` script, and run `forge test` as normal.\n\nSee the wonderful [Seaport repo](https://github.com/ProjectOpenSea/seaport/blob/main/README.md#foundry-tests) for more details and options for this approach.\n"
  },
  "Hats-Protocol/chain-modules": {
    "fetchedAt": "2025-11-12T23:02:36.843Z",
    "content": "# Module Chains\n\nWhat if you want an eligibility criteria to be a combination of conditions implemented in separate modules? For example, to be eligible, a person has to own a certain NFT (e.g. representing a DAO membership) and additionally win an election? That's exactly what the eligibilities/toggles chain modules are for.\n\n## Overview\n\n[HatsEligibilitiesChain](https://github.com/Hats-Protocol/chain-modules/blob/main/src/HatsEligibilitiesChain.sol) is an eligibility module that composes any amount of eligibility modules with \"and\"/\"or\" logical operations. Similarly, [HatsTogglesChain](https://github.com/Hats-Protocol/chain-modules/blob/main/src/HatsTogglesChain.sol) is a toggle module that composes any amount of toggle modules.\n\nBoth of these modules have a similar structure. Modules are chained in a format of a disjunction of conjunction clauses. For example, \"(module1 && module2) || module3\" has 2 conjunction clauses:\n\n\"(module1 && module2)\n\n\"module3\"\n\nThese clauses are chained together with an \"or\" operation.\n\n## Deriving Wearer Eligibility\n\nFor the eligibilities chain module, a wearer's eligibility is derived by checking eligibility in each module and combining the results according to the chosen logical operations. However, if a wearer is in a bad standing according to any one of the modules, then the module will return a result of \"not eligible\" and \"is in bad standing\".\n\n## Deriving Hat Status\n\nFor the toggles chain module, a hat's status is derived by checking it's status in each module and combining the results according to the chosen logical operations.\n\n## Create New Eligibilities/Toggles Chain Instances\n\nThe module does not use any mutable storage variables and does not use initialization data. It only uses the following immutable variables, which are set at the module instance's creation time:\n\n1. Number of conjunction clauses.\n2. Conjunction clauses lengths.\n3. The list of eligibility/toggle modules.\n\nUsing the example above, here's an example immutable arguments that will be used for the module's deployment:\n\n```solidity\nbytes memory otherImmutableArgs = abi.encodePacked(2, [2,1], module1Address, module2Address, module3Address);\n```\n\nThe module includes the following getters for these immutable variables:\n\n```solidity\nfunction NUM_CONJUCTION_CLAUSES() public pure returns (uint256)\n\nfunction CONJUCTION_CLAUSE_LENGTHS() public pure returns (uint256[] memory)\n\nfunction MODULES() public pure returns (address[] memory)\n```\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n\n### IR-Optimized Builds\n\nThis repo also supports contracts compiled via IR. Since compiling all contracts via IR would slow down testing workflows, we only want to do this for our target contract(s), not anything in this `test` or `script` stack. We accomplish this by pre-compiled the target contract(s) and then loading the pre-compiled artifacts in the test suite.\n\nFirst, we compile the target contract(s) via IR by running`FOUNDRY_PROFILE=optimized forge build` (ensuring that FOUNDRY_PROFILE is not in our .env file)\n\nNext, ensure that tests are using the `DeployOptimized` script, and run `forge test` as normal.\n\nSee the wonderful [Seaport repo](https://github.com/ProjectOpenSea/seaport/blob/main/README.md#foundry-tests) for more details and options for this approach.\n"
  },
  "Hats-Protocol/subgraph-ancillary": {
    "fetchedAt": "2025-11-12T23:02:37.717Z",
    "content": "# Hats Ancillary Subgraph\n\n## Overview\n\nThis subgraph is used to track the ancillary contracts for Hats Protocol.\n\n## Build\n\nTo build the subgraph, run the following command:\n\n```bash\npnpm i # install dependencies\n\npnpm codegen # generate the types\n\npnpm run build --network <network> # build the subgraph\n```\n\n## Deployment\n\nTo deploy the subgraph, run the following command:\n\n```bash\npnpm deploy <subgraph-name>\n```\n\n"
  },
  "Hats-Protocol/farcaster-delegator": {
    "fetchedAt": "2025-11-12T23:02:38.150Z",
    "content": "# Farcaster Delegator\n\nA contract designed to own a [Farcaster](https://farcaster.xyz) id with the goal of delegating casting authority and other fid permissions to one or more individuals or groups.\n\nThis repo contains a generic abstract contract, [`FarcasterDelegator.sol`](#farcasterdelegatorsol), as well as an implementation powered by [Hats Protocol](https://github.com/hats-protocol/hats-protocol), [`HatsFarcasterDelegator.sol`](#hatsfarcasterdelegatorsol).\n\nIt can be useful to think about a FarcasterDelegator contract as a wrapper around an fid that adds more flexibility and control over who can cast from and administer the fid. For example, an organization could use a FarcasterDelegator contract to own an fid and share casting rights among a subset of its members. This use case is especially powerful with HatsFarcasterDelegator, since those rights can be programmed with the full flexibility of Hats Protocol, including programmatic granting and revocation.\n\nSee the [Diagrams](./diagrams/) directory for a visual representation of how HatsFarcasterDelegator can be used to delegate casting rights and to cast on behalf of an fid owned by a HatsFarcasterDelegator contract.\n\nThese docs are currently intended for smart contract developers and Farcaster client developers. Once support is added to at least one Farcaster client, we'll add docs for end users.\n\n## HatsFarcasterDelegator.sol\n\n[`HatsFarcasterDelegator.sol`](./src/HatsFarcasterDelegator.sol) inherits from [`FarcasterDelegator.sol`](#farcasterdelegatorsol) and implements the `_isValidSigner()` function to authorize signers for various functions via Hats Protocol hats.\n\n### Valid Signers\n\nHatsFarcasterDelegator contracts grant authorities to the wearers of two hats specified at deployment: the `ownerHat` and `casterHat`\n\nThe `ownerHat` grants authority for all functions. In other words, a user who wears the `ownerHat` is a valid signer for the following typehashes:\n\n- IdRegistry.TRANSFER_TYPEHASH()\n- IdGateway.REGISTER_TYPEHASH()\n- KeyGateway.ADD_TYPEHASH()\n- SignedKeyRequestValidator.METADATA_TYPEHASH()\n- KeyRegistry.REMOVE_TYPEHASH()\n- IdRegistry.CHANGE_RECOVERY_ADDRESS_TYPEHASH()\n\nThe `casterHat` ‚Äî¬†aka the `hatId` ‚Äî¬†grants authority to add a key to the contract's fid. This enables the wearer of the `casterHat` to publish casts from the fid. In other words, a user who wears the `casterHat` is a valid signer for the following typehashes:\n\n- KeyGateway.ADD_TYPEHASH()\n- SignedKeyRequestValidator.METADATA_TYPEHASH()\n\n## FarcasterDelegator.sol\n\n[`FarcasterDelegator.sol`](./src/FarcasterDelegator.sol) is an abstract contract designed to be used as a base for any contract that needs to own a Farcaster Id (fid) and grant casting and admin authorities to other actors.\n\nIt supports the following functions:\n\n| Function                                                        | Related Farcaster Typehashes                                             |\n| --------------------------------------------------------------- | ------------------------------------------------------------------------ |\n| 1. Receive an existing fid transferred from a different account | IdRegistry.TRANSFER_TYPEHASH()                                           |\n| 2. Register a new fid owned by itself                           | IdGateway.REGISTER_TYPEHASH()                                            |\n| 3. Add a key to the fid, e.g. to delegate casting authority     | KeyGateway.ADD_TYPEHASH(), SignedKeyRequestValidator.METADATA_TYPEHASH() |\n| 4. Remove a key from the fid                                    | KeyRegistry.REMOVE_TYPEHASH()                                            |\n| 5. Transfer ownership of the fid to another account             | IdRegistry.TRANSFER_TYPEHASH()                                           |\n| 6. Change the recovery address of the fid                       | IdRegistry.CHANGE_RECOVERY_ADDRESS_TYPEHASH()                            |\n\nSince the [Farcaster contract](https://github.com/farcasterxyz/contracts) functions all have corresponding `<function>For` flavors powered by EIP-712 signatures, each of the above actions can either be initiated by the FarcasterDelegator contract or by a user with a valid signature.\n\n### Valid Signers\n\nThis contract leaves the definition of a valid *signer* open to the implementer. In other words, the internal function `FarcasterDelegator._isValidSigner()` is virtual and unimplemented; implementers must override this function with their own logic.\n\n```solidity\nfunction _isValidSigner(bytes32 typehash, address signer) internal view virtual returns (bool);\n```\n\nThe `typehash` argument is the EIP-712 typehash corresponding to the Farcaster function being authorized. This enables implementers to authorize different signers for different functions.\n\n> [!NOTE]\n> For an example implementation of `FarcasterDelegator._isValidSigner()`, see the [HatsFarcasterDelegator implementation](https://github.com/Hats-Protocol/farcaster-delegator/blob/main/src/HatsFarcasterDelegator.sol#L119).\n\n### Valid Signatures\n\nThis contract, on the other hand, does specify the definition of a valid *signature*. The primary goal of the design is to enable granular authorization for as many of the above functions as the implementer would like.\n\n```solidity\nfunction isValidSignature(bytes32 hash, bytes calldata signature) public view returns (bytes4 magicValue);\n```\n\nSince `FarcasterDelegator.isValidSignature()` must conform to the above EIP-1271 standard function signature, we cannot explicitly pass it a `typehash` parameter for routing like we can with the `FarcasterDelegator._isValidSigner()`. To enable function-specific validation, then, we require the `typehash` be appended to the `signature` parameter so that we can extract it in the implementation.\n\nTo ensure that the `typehash` is valid for the function being called, we also require that the other EIP-712 typed data parameters be appended to the `signature` parameter. We can validate by extracting those parameters, recreating the correct typed hash using the EIP-712 domain separator from the relevant Farcaster contract, and comparing it to the `hash` parameter.\n\nIf this check passes, we can then validate the signature itself. Since a valid signature will always be 65 bytes long, the signature should be the first 65 bytes of the `signature` parameter. We then recover the signer from the signature and `hash`. If that signer is valid according to the logic in `FarcasterDelegator._isValidSigner()`, then the signature is deemed valid.\n\nIn summary, the `signature` parameter must be formatted as follows:\n\n| Offset | Length | Contents                                                                            |\n| ------ | ------ | ----------------------------------------------------------------------------------- |\n| 0      | 65     | The actual signature                                                                |\n| 65     | 32     | The EIP-712 typehash corresponding to the Farcaster function being authorized       |\n| 97     | varies | The other EIP-712 typed data parameters for the Farcaster function being authorized |\n\n### 1. Receiving an existing fid\n\nA FarcasterDelegator contract is only useful when it owns an fid. In order to receive an existing fid, a FarcasterDelegator contract must be able to produce a signature authorizing receipt, as required by the Farcaster protocol.\n\nThere are two way to have FarcasterDelegator produce a transfer-approval signature, both triggered by a valid signer: a) the valid signer can \"prepare\" the FarcasterDelegator to receive the fid, or b) the valid signer can produce a valid `TRANSFER_TYPEHASH`-related ECDSA signature.\n\n#### Receive Method A: using `prepareToReceive()`\n\nThis method is useful for signers authorized for the `TRANSFER_TYPEHASH` action but are not in a position to make a direct call to the FarcasterDelegator contract. Such as when using a Farcaster client that has not implemented specific support for Fa\n\n[... truncated ...]"
  },
  "Hats-Protocol/hat-wearing-eligibility": {
    "fetchedAt": "2025-11-12T23:02:38.547Z",
    "content": "# Hat Wearing Eligibility\n\nA [Hats Protocol](https://github.com/hats-protocol/hats-protocol) eligibility module that conditions eligibility for one hat based on wearing another hat.\n\n## Overview and Usage\n\nOne use of a hat is to serve as an encapsulation of a set of logic and conditions that serve as baseline eligibility criteria for other hats. This eligibility module builds on that idea by allowing a hat to be used as an eligibility criterion for another hat.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n"
  },
  "Hats-Protocol/passthrough-modules": {
    "fetchedAt": "2025-11-12T23:02:38.930Z",
    "content": "# Passthrough Modules\n\nThis repo contains two passthroughmodules for Hats Protocol:\n\n- [PassthroughModule](./src/PassthroughModule.sol): enables an authorized \"criterion\" hat to serve as the eligibility and/or toggle module for other hat(s), not compatible with module chaining.\n- [HatControlledModule](./src/HatControlledModule.sol): enables an authorized \"controller\" hat to serve as the eligibility and/or toggle module for other hat(s), compatible with module chaining.\n\n## 1. Passthrough Module\n\nIn Hats Protocol v1, eligibility and toggle modules are set as addresses. This creates a lot of flexibility, since addresses can be EOAs, multisigs, DAOs, or even other smart contracts. But hats themselves cannot be set explicitly as eligibility or toggle modules because hats are identified by a uint256 hatId, not an address.\n\nPassthrough Module is a contract that can be set as the eligibility and/or toggle module for a target hat, and allows the wearer(s) of another hat to call the eligibility and/or toggle functions of the target hat. This allows hats themselves to be used as eligibility and toggle modules.\n\n### Passthrough Eligibility\n\nTo use Passthrough Module as the eligibility module for a target hat, set Passthrough Module's address as the target hat's eligibility address.\n\nThen, the wearer(s) of Passthrough Module's authorized `CRITERION_HAT` can call the `PassthroughEligibility.setHatWearerStatus()` function ‚Äî which is a thin wrapper around `Hats.setHatWearerStatus()` ‚Äî to push eligibility data to Hats Protocol.\n\n### Passthrough Toggle\n\nTo use Passthrough Module as the toggle module for a target hat, set Passthrough Module's address as the target hat's toggle address.\n\nThen, the wearer(s) of Passthrough Module's authorized `CRITERION_HAT` can call the `PassthroughToggle.setHatWearerStatus()` function ‚Äî which is a thin wrapper around `Hats.setHatWearerStatus()` ‚Äî to push toggle data to Hats Protocol.\n\n## 2. Hat Controlled Module\n\nUnlike Passthrough Module, Hat Controlled Module is compatible with module chaining. It achieves this by enabling a \"controller\" hat to set wearer status and hat status for a given target hat in the Hat Controlled Module contract, which Hats Protocol then pulls in when checking for wearers or status of the target hat.\n\n### Hat Controlled Eligibility\n\nTo use Hat Controlled Module as the eligibility module for a target hat, set Hat Controlled Module's address as the target hat's eligibility address.\n\nThen, the wearer(s) of the \"controller\" hat can call the `HatControlledModule.setWearerStatus()` function to set eligibility data for the target hat for Hats Protocol to pull.\n\n### Hat Controlled Toggle\n\nTo use Hat Controlled Module as the toggle module for a target hat, set Hat Controlled Module's address as the target hat's toggle address.\n\nThen, the wearer(s) of the \"controller\" hat can call the `HatControlledModule.setHatStatus()` function to set the toggle data for the target hat for Hats Protocol to pull.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n"
  },
  "hats-protocol/hats-protocol": {
    "fetchedAt": "2025-11-12T23:02:39.331Z",
    "content": "<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->\n\n# <a name=\"readme-top\"></a>\n\n<!--\n*** Attribution: thanks to @othneildrew for the Readme template!)\n-->\n\n<!-- SHIELDS -->\n<!--\n*** I'm using markdown \"reference style\" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n[![Contributors][contributors-shield]][contributors-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![Twitter][twitter-shield]][twitter-url]\n\n<!-- LOGO -->\n<br />\n<div align=\"center\">\n  <a href=\"https://github.com/Hats-Protocol/hats-protocol\">\n    <img src=\"https://ipfs.io/ipfs/QmbQy4vsu4aAHuQwpHoHUsEURtiYKEbhv7ouumBXiierp9\" alt=\"Hats Hat\" width=\"300\" height=\"300\">\n  </a>\n\n  <h2 align=\"center\">Hats Protocol</h3>\n\n  <p align=\"center\">\n    How DAOs get things done\n    <br />\n    <br />\n    <a href=\"https://hatsprotocol.xyz\">Hats Protocol Website</a>\n    ¬∑\n    <a href=\"https://github.com/Hats-Protocol/hats-protocol/issues\">Report Bug</a>\n    ¬∑\n    <a href=\"https://github.com/Hats-Protocol/hats-protocol/issues\">Request Feature</a>\n  </p>\n</div>\n\n<!-- TABLE OF CONTENTS -->\n<details>\n  <summary>Table of Contents</summary>\n  <ol>\n    <li>\n      <a href=\"#about-the-project\">About The Project</a>\n      <ul>\n        <li><a href=\"#latest-deployments\">Deployments</a></li>\n        <li><a href=\"#security-audits\">Security Audits</a></li>\n      </ul>\n    </li>\n    <!-- <li><a href=\"#getting-started\">Getting Started</a></li>\n    <li><a href=\"#use-cases\">Use Cases</a></li> -->\n    <li><a href=\"#contributing\">Contributing</a></li>\n    <li><a href=\"#hats-protocol-docs\">Hats Protocol Docs</a></li>\n    <li><a href=\"#license\">License</a></li>\n    <li><a href=\"#contact\">Contact</a></li>\n  </ol>\n</details>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\n\nHats Protocol is a protocol for DAO-native roles and credentials that supports revocable delegation of authority and responsibility.\n\nHats are represented on-chain by non-transferable tokens that conform to the ERC1155 interface. An address with a balance of a given Hat token \"wears\" that hat, granting them the responsibilities and authorities that have been assigned to the Hat by the DAO.\n\n### Deployments\n\nFor information on Hats Protocol versions and deployments, see [Releases](https://github.com/Hats-Protocol/hats-protocol/releases).\n\n### Security Audits\n\nThis project has received two security audits, listed below. See the [audits](https://github.com/Hats-Protocol/hats-protocol/tree/main/audits) directory for the detailed reports.\n\n| Auditor | Report Date | Review Commit Hash | Notes |\n| --- | --- | --- | --- |\n| Trust Security | Feb 23, 2023 | [60f07df](https://github.com/Hats-Protocol/hats-protocol/commit/60f07df0679ba52d4ad818b1bb3700d2f4f5a63a) | Report also includes findings from [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) audit |\n| Sherlock | May 3, 2023 | [fafcfd](https://github.com/Hats-Protocol/hats-protocol/commit/fafcfdf046c0369c1f9e077eacd94a328f9d7af0) | Report also includes findings from [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) audit |\n\n<!-- CONTRIBUTING -->\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/Hats-Protocol/hats-protocol/blob/main/CONTRIBUTING.md) for details on how to contribute.\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- DOCUMENTATION -->\n<a name=\"documentation-top\"></a>\n\n## Hats Protocol Docs\n\n<!-- TABLE OF CONTENTS -->\n### Table of Contents\n\n<ol>\n  <li><a href=\"#authorities-in-hats-protocol\">Authorities in Hats Protocol</a></li>\n  <li><a href=\"#hats-logic\">Hats Logic</a></li>\n  <li><a href=\"#erc1155-compatibility\">ERC1155 Compatibility</a></li>\n  <li><a href=\"#wearing-a-hat\">Wearing a Hat</a></li>\n  <li><a href=\"#hat-admins\">Hat Admins</a></li>\n  <li><a href=\"#addressable-hat-ids\">Addressable Hat Ids</a></li>\n  <li><a href=\"#eligibility\">Eligibility</a></li>\n  <li><a href=\"#toggle\">Toggle</a></li>\n  <li><a href=\"#hat-mutability\">Hat Mutability</a></li>\n  <li><a href=\"#hat-image-uris\">Hat Image URIs</a></li>\n  <li><a href=\"#creating-a-hat\">Creating a Hat</a></li>\n  <li><a href=\"#minting-a-hat\">Minting a Hat</a> </li>\n  <li><a href=\"#transferring-a-hat\">Transferring a Hat</a></li>\n  <li><a href=\"#hat-tree-grafting\">Hat Tree Grafting</a></li>\n  <li><a href=\"#renouncing-a-hat\">Renouncing a Hat</a></li>\n</ol>\n\n### Authorities in Hats Protocol\n\nOne way to think about a Hat is as a primitive that creates a substrate onto which a DAO can attach authorities (e.g., access rights) and responsibilities via other tools (e.g., token-gating platforms).\n\nHats Protocol itself does not define mechanisms for how such authorities and responsibilities are associated with a Hat. All such associations are created external to the protocol.\n\nHere are a few examples of how a DAO might confer authorities and responsibilities to a Hat:\n\n| Authority | How is it attached to the Hat? |\n| --- | ---- |\n| Signer on a multisig | Using the Hat's ERC1155-similar token as a condition for membership in a Metropolis Pod |\n| Admin of the DAO's Github repo | Using the Hat's ERC1155-similar token as a condition for access via Lit Protocol |\n| Leadership of a working group | A social expectation |\n\nIn each case, the DAO uses a separate tool to attach the authority to the Hat.\n\nHats is designed to be highly composable -- it will work with any tool, application, or protocol that can interact with the ERC1155 interface. Further, it allows any number of such authorities or responsibilities to be attached to a single Hat, which greatly simplifies the process for DAOs of revoking those authorities as well as the process of role handoff.\n\n#### Exception: Hat Admins\n\nHat admins are the one (very important!) exception to the rule that authorities are external to the Hats Protocol. Refer to the Admins section below for more details.\n\n<p align=\"right\">(<a href=\"#table-of-contents\">back to contents</a>)</p>\n\n### ERC1155 Compatibility\n\nHats Protocol conforms fully to the ERC1155 interface. All external functions required by the [ERC1155 standard](https://eips.ethereum.org/EIPS/eip-1155) are exposed by Hats Protocol. This is how Hats can work out of the box with existing token-gating applications.\n\nHowever, Hats Protocol is not fully compliant with the ERC1155 standard. Since Hats are not transferable by their owners (aka \"wearers\"), there is little need for safe transfers and the `ERC1155TokenReceiver` logic. Developers building on top of Hats Protocol should note that mints and transfers of Hats will not, for example, include calls to `onERC1155Received`.\n\nTo avoid confusion, Hats Protocol does not claim to be ERC1155-compliant. Instead, we say that Hats Protocol has \"ERC1155-similar\" tokens. When referring specifically to the ERC1155 interface, however, we do say that Hats Protocol conforms fully.\n\n### Hats Logic\n\nEach Hat has several properties:\n\n* `id` - the integer identifier for the Hat, which also serves as the ERC1155-similar token id (see three paragraphs below)\n* `details` - metadata about the Hat; such as a name, description, and other properties like roles and responsibilities associated with the Hat. Should not exceed 7,000 characters.\n* `maxSupply` - the maximum number of addresses that can wear the Hat at once\n* `admin` - the Hat that controls who can wear the Hat\n* `eligibility` - the address that controls eligibility criteria and whether a given wearer of the Hat is in good standing\n* `toggle` - the address that controls whether the Hat is active\n* `mutable` - whether the hat's properties can be changed by the admin\n* `imageURI` - the URI for the image used in the Hat's ERC1155-similar token.\n\n[... truncated ...]"
  },
  "Hats-Protocol/subgraph": {
    "fetchedAt": "2025-11-12T23:02:39.683Z",
    "content": "# Hats-Protocol Subgraph\n\nThis is a subgraph for the [Hats-Protocol](https://www.hatsprotocol.xyz/) project.\n\n# Important Note:\n\nThe `status` and `badStandings` fields of a `Hat` entity, track the status and standing as currently recorded in the Hats contract. It is NOT tracking the eligibility and toggle modules in case they exist and thus only represent the last recorded state in the Hats contract. In case they depend on the state of external contracts, these fields in the subgraph may be out of sync with the onchain state.\n\n# Example Queries\n\n## Tree\n\nEvery hat belongs to a tree, which root is a top hat. The ID of a tree, is it's top hat domain (first 4 bytes of the top hat ID).\nThe following query will get all existing trees, and the hats that exist in each tree:\n\n```graphql\n{\n  trees {\n    id\n    hats {\n      id\n    }\n  }\n}\n```\n\nGet a specific tree:\n\n```graphql\n{\n  tree(id: \"0x00000001\") {\n    id\n    hats {\n      id\n    }\n  }\n}\n```\n\nIn case the tree was linked to another tree, get the parent tree:\n\n```graphql\n{\n  tree(id: \"0x00000001\") {\n    id\n    childOfTree {\n      id\n    }\n  }\n}\n```\n\nIn case the tree was linked to another tree, get the hat that the tree is linked to:\n\n```graphql\n{\n  tree(id: \"0x00000001\") {\n    id\n    linkedToHat {\n      id\n    }\n  }\n}\n```\n\nIn case the tree was linked to by other trees, get the trees that are linked directly to the tree:\n\n```graphql\n{\n  tree(id: \"0x00000001\") {\n    id\n    parentOfTrees {\n      id\n    }\n  }\n}\n```\n\n## Hat\n\nThe ID of the hat entity is the ID of the hat in hex format.\n\nAdditionally, the hat entity includes a \"prettyId\" field, which is formatted in an IP address style:\n\n- In hex, with the `0x` prefix\n- Periods between the hat levels\n- Only levels with non-zero values are shown\n  For example, the \"prettyId\" of a level 3 hat might look like this: `0x00000001.0001.0001`\n\nThe following query will get all the basic information of a hat:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    prettyId\n    status\n    details\n    eligibility\n    toggle\n    mutable\n    imageUri\n    createdAt\n    maxSupply\n    currentSupply\n    levelAtLocalTree\n  }\n}\n```\n\nThe following query will get the tree that the hat belongs to:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    tree {\n      id\n    }\n  }\n}\n```\n\nThe following query will get the admin of the hat:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    admin {\n      id\n    }\n  }\n}\n```\n\nThe following query will get the sub-hats that are one level deeper:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    subHats {\n      id\n    }\n  }\n}\n```\n\nThe following query will get the wearers of the hat:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    wearers {\n      id\n    }\n  }\n}\n```\n\nThe following query will get the all the wearers with a bad standing:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    badStandings {\n      id\n    }\n  }\n}\n```\n\nThe following query will get the all the trees that are linked to a hat:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    linkedTrees {\n      id\n    }\n  }\n}\n```\n\n## Wearer\n\nThe ID of the wearer is its address.\n\nThe following query will get all hats of a wearer:\n\n```graphql\n{\n  wearer(id: \"0xabcdabcdabcdabcdabcdabcdabcdabcdabcdabcd\") {\n    id\n    currentHats {\n      id\n    }\n  }\n}\n```\n\n## Events\n\nThe events are used to track the history of hats and wearers.\nThe event ID format is `<event name>-<block number>-<log index>`.\n\nThe following query will get the entire history of events in a specific tree:\n\n```graphql\n{\n  tree(id: \"0x00000001\") {\n    id\n    events {\n      id\n      blockNumber\n      timestamp\n      transactionID\n      tree {\n        id\n      }\n      hat {\n        id\n      }\n      ... on HatCreatedEvent {\n        hatDetails\n        hatMaxSupply\n        hatEligibility\n        hatToggle\n        hatMutable\n        hatImageUri\n      }\n      ... on HatMintedEvent {\n        wearer {\n          id\n        }\n        operator\n      }\n      ... on HatBurnedEvent {\n        wearer {\n          id\n        }\n        operator\n      }\n      ... on HatStatusChangedEvent {\n        hatNewStatus\n      }\n      ... on HatDetailsChangedEvent {\n        hatNewDetails\n      }\n      ... on HatEligibilityChangedEvent {\n        hatNewEligibility\n      }\n      ... on HatToggleChangedEvent {\n        hatNewToggle\n      }\n      ... on HatMutabilityChangedEvent {\n      }\n      ... on HatMaxSupplyChangedEvent {\n        hatNewMaxSupply\n      }\n      ... on HatImageURIChangedEvent {\n        hatNewImageURI\n      }\n      ... on TopHatLinkRequestedEvent {\n        newAdmin\n      }\n      ... on TopHatLinkedEvent {\n        newAdmin\n      }\n      ... on WearerStandingChangedEvent {\n        wearer {\n          id\n        }\n        wearerStanding\n      }\n    }\n  }\n}\n```\n\nThe following query will get the entire history of events in a specific hat:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    id\n    events {\n      id\n      blockNumber\n      timestamp\n      transactionID\n      ... on HatCreatedEvent {\n        hatId\n      }\n      ... on HatMintedEvent {\n        hatId\n        wearer {\n          id\n        }\n        operator\n      }\n      ... on HatBurnedEvent {\n        hatId\n        wearer {\n          id\n        }\n        operator\n      }\n      ... on HatStatusChangedEvent {\n        hatId\n        hatNewStatus\n      }\n      ... on HatDetailsChangedEvent {\n        hatId\n        hatNewDetails\n      }\n      ... on HatEligibilityChangedEvent {\n        hatId\n        hatNewEligibility\n      }\n      ... on HatToggleChangedEvent {\n        hatId\n        hatNewToggle\n      }\n      ... on HatMutabilityChangedEvent {\n        hatId\n      }\n      ... on HatMaxSupplyChangedEvent {\n        hatId\n        hatNewMaxSupply\n      }\n      ... on HatImageURIChangedEvent {\n        hatId\n        hatNewImageURI\n      }\n      ... on TopHatLinkRequestedEvent {\n        newAdmin\n      }\n      ... on TopHatLinkedEvent {\n        newAdmin\n      }\n      ... on WearerStandingChangedEvent {\n        wearer {\n          id\n        }\n        wearerStanding\n      }\n    }\n  }\n}\n```\n\nThe following query will get the history of hat mint and burn events for a specific wearer:\n\n```graphql\n{\n  wearer(id: \"0xabcdabcdabcdabcdabcdabcdabcdabcdabcdabcd\") {\n    id\n    mintEvent {\n      id\n      hatId\n      wearer {\n        id\n      }\n      operator\n    }\n    burnEvent {\n      id\n      hatId\n      wearer {\n        id\n      }\n      operator\n    }\n  }\n}\n```\n\n## Misc\n\nThe following query will get the siblings of a hat:\n\n```graphql\n{\n  hat(\n    id: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n  ) {\n    admin {\n      subHats {\n        id\n      }\n    }\n  }\n}\n```\n\nThe following query will get a sub tree, in which a specific hat is a root of:\n\n```graphql\n{\n  hats(\n    where: {\n      id_gte: \"0x0000000100010000000000000000000000000000000000000000000000000000\"\n      id_lt: \"0x0000000100020000000000000000000000000000000000000000000000000000\"\n    }\n  ) {\n    id\n  }\n}\n```\n\n### Publishing\n\nTo publish the subgraph, run the following command:\n\n```bash\ngraph publish --node https://api.studio.thegraph.com/deploy/ hats-protocol/hats-v1-mainnet\n```\n\n"
  },
  "Hats-Protocol/sdk-v1-core": {
    "fetchedAt": "2025-11-12T23:02:40.028Z",
    "content": "# Hats-Protocol SDK\n\nDeveloper tools for integrating with and/or building on top of Hats-Protocol.\n\n## Packages\n| Package                                                   | Description                                                                                                            |\n|-----------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------|\n| [Core](/packages/core)  | Core interactions with Hats-Protocol                                                                         |\n| [Subgraph](/packages/subgraph)      | Fetching from the Hats-Protocol Subgraphs                                                                    |\n\n"
  },
  "Hats-Protocol/colinks-eligibility": {
    "fetchedAt": "2025-11-12T23:02:40.507Z",
    "content": "# CoLinks Eligibility\n\nCoLinksEligibility is a [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) eligibility module that sets eligibility for a target hat based on the supply of a user's (aka \"wearer's\") [CoLinks](https://github.com/coordinape/coordinape-protocol/blob/main/contracts/colinks/CoLinks.sol) links.\n\nSince the supply of a user's links is a fuzzy-yet-credible signal of their reputation within the Coordinape and CoLinks ecosystem, this module can be used to help ensure that wearers of a given hat meet minimum reputation requirements. Similarly, it can also be used as a Sybil-resistance mechanism for the hat.\n\n## Usage\n\nThis module inherits from [HatsModule](https://github.com/Hats-Protocol/hats-module), which means that it is designed to be used by deploying a new instance (i.e. a minimal proxy clone) via the [HatsModuleFactory](https://github.com/Hats-Protocol/hats-module/blob/main/src/HatsModuleFactory.sol) and then attached to the target hat.\n\nThe module can be configured with a single parameter `threshold`, which is the minimum number of links that a wearer must have in order to be eligible for the hat. The module will then set the wearer's eligibility to `true` if they have at least `threshold` links, and `false` otherwise.\n\nThis module does not deal with the `standing` portion of Hats eligibility, so `standing` is always set to `true` for the wearer. However, this module can be [chained together](https://docs.hatsprotocol.xyz/for-developers/hats-modules/building-hats-modules/about-module-chains) with another eligibility module that does deal with `standing`.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n"
  },
  "Hats-Protocol/hats-auth": {
    "fetchedAt": "2025-11-12T23:02:40.927Z",
    "content": "# hats-auth\n\n[Hats Protocol](https://github.com/Hats-Protocol/hats-protocol)-enabled auth and ownable contract mix-ins\n\n## HatsOwned\n\nA fork of [solmate's `Owned.sol`](https://github.com/transmissions11/solmate/blob/main/src/auth/Owned.sol) that grants ownership of an inheriting contract to the wearer of a given [hat](https://github.com/Hats-Protocol/hats-protocol).\n\n`HatsOwned.sol` preserves the name of the `onlyOwner` modifier, so switching from `Owned.sol` only requires inhereting the new contract and adjusting the constructor to set `uint256 ownerHat` rather than `address owner`. No other code changes required.\n\n## HatsAccessControl\n\nA fork of OpenZeppelin's `AccessControl.sol` that grants access to various roles within an inheriting contract to the wearer of given [hats](https://github.com/Hats-Protocol/hats-protocol).\n\n### Differences compared to `AccessControl.sol`\n\n1. Assigns roles to `uint256 hat` rather than `address member`.\n\n2. Since a single hat can have multiple wearers (up to [`hat.maxSupply`](https://github.com/Hats-Protocol/hats-protocol#hats-logic), only a single hat can be granted a given role.\n\n3. No support for `renounceRole`. To renounce a role, the wearer of a given hat should renounce the hat itself.\n\nTODO\n\n- [x] contracts\n- [ ] tests\n"
  },
  "Hats-Protocol/modules-sdk": {
    "fetchedAt": "2025-11-12T23:02:41.422Z",
    "content": "# Hats-Protocol Modules SDK\n\n## Documentation\n\nDetailed documentation can be found [here](https://docs.hatsprotocol.xyz/for-developers/hats-modules/modules-sdk)\n\n## Contributing\n\nTests are run with Jest via `pnpm test`.\n\nTo run a specific test file, update the test script in `package.json` to include the test file name.\n\n`pnpm jest eligibilitiesChain.test.ts -i`\n\nTo run a specific test, update the test script in `package.json` to include the test file name and the test name with the `-t` flag.\n\n`pnpm jest withRegistry.test.ts -t 'Eligibility Client Tests Test create all modules' -i`\n\n## Actions\n\nAccepted contributions need to match the passing tests. The action is run on PR branches to ensure this.\n"
  },
  "Hats-Protocol/hsg-sdk": {
    "fetchedAt": "2025-11-12T23:02:41.781Z",
    "content": "# Hats Signer Gate SDK\n\n## Documentation\n\nDetailed documentation can be found [here](https://docs.hatsprotocol.xyz/for-developers/hats-signer-gate-sdk).\n"
  },
  "Hats-Protocol/hats-account": {
    "fetchedAt": "2025-11-12T23:02:42.210Z",
    "content": "# HatsAccount\n\nHatsAccount is a smart contract account for every hat in [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol).\n\nThis repo contains three contracts:\n\n1. [HatsAccountBase](#HatsAccountbase), an abstract contract designed to be inherited by various flavors of HatsAccount\n2. [HatsAccount1ofN](#HatsAccount1ofn), a flavor of HatsAccount that mirrors the typical 1-of-n security model of hat-based role and permission management\n3. [HatsAccountMofN](#HatsAccountmofn), a flavor of HatsAccount that supports m-of-n security models, somewhat like a multisig of hat wearers\n\n## Overview\n\nHatsAccount gives every Hats Protocol hat a smart contract account. Each hat can have multiple flavors of HatsAccount, each following the ERC6551 standard and designed to be deployed via the ERC6551Registry factory.\n\nHatsAccount gives every hat the ability to do the following:\n\n- Send ETH, ERC20, ERC721, and ERC1155 tokens\n- Sign ERC1271-compatible messages, e.g. as a signer on a multisig\n- Become a member of a DAO and make/vote on proposals, e.g. in a Moloch DAO\n- Call functions on other contracts\n- `Delegatecall` to other contracts, via [tokenbound](https://github.com/tokenbound/contracts)'s [sandbox](https://github.com/jaydenwindle/delegatecall-sandbox/) concept\n- Be assigned permissions in address-based onchain access control schemes\n\nApart from the first and last, all of these actions are performed by the hat's wearer(s), with the security model determined by the flavor of HatsAccount.\n\n## HatsAccountBase\n\nHatsAccountBase is an abstract contract built with [tokenbound's library](https://github.com/tokenbound/contracts)  that provides the following common functionality for all other HatsAccount flavors:\n\n- Ability to receive ETH (or other EVM chain-native tokens), ERC20, ERC721, and ERC1155 tokens\n- Implementation of the `IERC6551Account` interface, including / as well as getter functions for the account deployment parameters\n  - `salt()`\n  - `HATS()` ‚Äî¬†the address of the Hats Protocol contract, aka the `IERC6551Account.token.tokenContract`\n  - `hat()` ‚Äî¬†the id of the hat that this HatsAccount represents, aka the `IERC6551Account.token.tokenId`\n  - `IMPLEMENTATION()` ‚Äî¬†the address of the implementation contract for the inheriting flavor of HatsAccount\n- Implementation of `IERC6551Account.isValidSigner` that sets wearers of the `hat()` as valid signers\n- Internal `_updateState` function adhering to the `IERC6551Account` standard\n- EIP-721-compliant message-hashing function for use in signing and verifying messages by inheriting HatsAccount flavors\n- [tokenbound](https://github.com/tokenbound/contracts)'s `BaseExecutor`, for use in executing transactions by inheriting HatsAccount flavors\n\n### Delegatecalls\n\nFor safety, HatsAccountBase constrains `delegatecall`s, only executing them from a special sandbox account coupled with the HatsAccount1ofN instance. This protects the HatsAccount from storage collision and self-destruct from malicious target contracts, with the tradeoff that the target contract must know ‚Äî¬†or be told about ‚Äî¬†the sandbox pattern in order for the `delegatecall` to succeed.\n\nSee the [delegatecall-sandbox docs](https://github.com/jaydenwindle/delegatecall-sandbox/) for more details.\n\n## HatsAccount1ofN\n\nHatsAccount1ofN is a flavor of HatsAccount that mirrors the typical 1-of-n security model of hat-based role and permission management. Any single wearer of a HatsAccount1ofN instance's hat has full control over that HatsAccount. If a hat has multiple wearers, they each individually have full control.\n\n### 1ofN: Executing Transactions\n\nAny single wearer of the hat can execute transactions under the hat's authority. For individual transactions, this is done by calling the `execute()` function, which conforms to the `ERC6551Executable` interface and takes the following arguments:\n\n- `to` ‚Äî the address of the contract to call\n- `value` ‚Äî the amount of ETH to send with the call\n- `data` ‚Äî the calldata to send with the call, which encodes the target function signature and arguments\n- `operation` ‚Äî the type of call to make, either `call` (0), or `delegatecall` (1) ‚Äî¬†other operations are disallowed\n\nFor multiple transactions, this is done by calling the `executeBatch()` function, which takes as its sole argument an array of `Operations`. An `Operation` is a struct containing the same properties as the arguments of the `execute()` function above.\n\nIf execution succeeds, the HatsAccount's `state` is updated in compliance with the ERC6551 standard.\n\n### 1ofN: Signing Messages\n\nAny single wearer of the hat can also sign messages on the hat's behalf. Other applications or contracts can verify that such signatures are valid by calling the `isValidSignature()` function, which takes the following arguments:\n\n- `hash` ‚Äî the keccak256 hash of the signed message, which can optionally be calculated with the `HatsAccountBase.getMessageHash()` function for compatibility with EIP-712.\n- `signature` ‚Äî¬†the signature to verify\n\nThe signature is considered valid as long as it is either...\n\n- a valid ECDSA signature by a wearer of the hat, or\n- a valid EIP-1271 signature by a wearer of the hat\n\nThis design follows [Gnosis Mech](https://github.com/gnosis/mech)'s approach, and creates flexibility for recursive validation of nested signatures. See [their docs for more details](https://github.com/gnosis/mech/tree/main#eip-1271-signatures).\n\n## HatsAccountMofN\n\nHatsAccountMofN is a flavor of HatsAccount that supports m-of-n security models, somewhat like a multisig of hat wearers. To take any action with HatsAccount, m of the n present wearers of the hat must approve the action.\n\n### M of N Security Model\n\nThe specific security model of a given HatsAccountMofN instance is determined by a) the number of present wearers of the hat (ie the hat's supply), and b) the `THRESHOLD_RANGE` configured for that instance. As the supply of the hat changes, the required number of approvals to execute actions ‚Äî¬†given by `getThreshold()` ‚Äî¬†will move within the `THRESHOLD_RANGE`.\n\nThese parameters are encoded at deployment time in the `salt` parameter of the `IERC6551Registry.deployAccount` function.\n\n- `MIN_THRESHOLD` ‚Äî¬†the first (leftmost) byte of the `salt` parameter\n- `MAX_THRESHOLD` ‚Äî¬†the second byte of the `salt` parameter\n\nFor example, a `MIN_THRESHOLD` of 2 and a `MAX_THRESHOLD` of 5 would result in a `salt` value of `0x0205000000000000000000000000000000000000000000000000000000000000`. The actual threshold at any given time ‚Äî¬†the value returned by `getThreshold()` ‚Äî¬†is a function of the hat's present supply:\n\n- When supply is less than `MIN_THRESHOLD`, the threshold is `MIN_THRESHOLD`\n- When supply is greater than `MAX_THRESHOLD`, the threshold is `MAX_THRESHOLD`\n- When supply is between `MIN_THRESHOLD` and `MAX_THRESHOLD`, the threshold is the supply\n\n### MofN: Executing Transactions\n\nM of the n wearers of the hat can execute transactions under the hat's authority. This is done with a simple onchain proposal and voting system:\n\n- Any wearer of the hat can propose a transaction\n- Any account can vote on a proposal, but only votes from wearers of the at *at execution time* count\n- Like a multisig, there is no voting period ‚Äî¬†a proposal can be executed as soon as it has enough approvals\n- Unlike some multisig and DAO contracts, proposals can be executed in any order\n\n#### Proposing Transactions\n\nAny wearer of the hat can propose a transaction by calling the `propose()` function, which takes the following arguments:\n\n- `operations` ‚Äî¬†an array of `Operations`, the same struct used in [`HatsAccount1ofN.executeBatch()`](#1ofn-executing-transactions)\n- `expiration` ‚Äî¬†a uint32 timestamp after which the proposal will be not be executable even if it has enough approvals, similar to how [MolochV3](https://github.com/HausDAO/Baal/) handles proposal expiration.\n- `descriptionHash` ‚Äî¬†a bytes32 hash of the proposal description, similar to Governor's descriptionHash parameter. Beyond a commitme\n\n[... truncated ...]"
  },
  "Hats-Protocol/create-hats-app": {
    "fetchedAt": "2025-11-12T23:02:42.655Z",
    "content": "# Create Hats App\n\nCreate Hats App will get you building in the Hats ecosystem quickly.\n\nRunning `pnpm create hats-app` (or via `npx create-hats-app`) initializes a new app for builders who can choose an app name, a supported framework to use for their template.\n\n![](https://ipfs.io/ipfs/QmQe9PrVRVfeTGkcw71MrAtUZ9KD2L79wzqoRRRTYxxLXz)\n\nSee the templates live:\n- [Next Template Demo](https://create-hats-next-app.vercel.app/)\n- [Vite Template Demo](https://create-hats-vite-app.vercel.app/)\n- [Remix Template Demo](https://create-hats-remix-vite-app.vercel.app/)\n\n## Prerequisites\n\nBefore you begin, ensure you have [Node.js](https://nodejs.org/en/) version 18 or later installed on your machine. Note that the Vite template may work best with 20+.\n\n## Getting Started\n\nQuickly bootstrap a Hats app with the following command:\n\n```bash\nnpx create-hats-app\n```\n\nYou'll be prompted to enter the name of your app, select a framework and then the app will be created in a new directory with that name.\n\nOnce the process finishes, navigate into your app directory and get started.\n\n## Available Templates\n\nThe templates (and generated starter apps) focus on enabling core functionality and are designed to be forked and extended. The templates handle the scaffolding for each of the supported frameworks, and the data reads and writes are implemented by following the commonly accepted approaches specific to each framework. Each template leverages learnings and solves pain points of spinning up onchain projects. The Vite template includes minimal, lightweight polyfills that are required for building onchain apps using Vite whereas the Next.js template is structured to fully utilize React Server Components and the associated data loading strategies used in the Next.js app router paradigm.\n\n- [Next App Template](./templates/next/)\n- [Vite App Template](./templates/vite/)\n- [Remix/Vite App Template](./templates/remix-vite/)\n\nThe README in each template contains more details and information.\n\n### Common Tooling\n\nEach template includes the same functionality and leverages the Hats Modules SDK, v1 Core SDK, and v1 Subgraph SDK to provide a ‚Äúplayground‚Äù for exploring commonly used Hats Protocol reads and writes.\n\nOur goal is for each template to be as similar as possible, with complete feature parity while preserving the nuances of each framework. The templates strike a balance by being opinionated in their initial configuration setup while also remaining flexible and extendable, allowing them to grow into fully fledged independent apps within the Hats ecosystem.\n\n- [Hats Core SDK](https://github.com/Hats-Protocol/sdk-v1-core)\n- [Hats Subgraph SDK](https://github.com/Hats-Protocol/sdk-v1-core/tree/main/packages/subgraph)\n- [Hats Modules SDK](https://github.com/Hats-Protocol/modules-sdk)\n- [RainbowKit](https://www.rainbowkit.com/)\n- [Wagmi](https://wagmi.sh/)\n- [Viem](https://viem.sh/)\n- [Tanstack Query](https://tanstack.com/query/latest/docs)\n- [React Hook Form](https://react-hook-form.com/)\n- [Zod](https://github.com/colinhacks/zod)\n- [Shadcn/UI](https://ui.shadcn.com/)\n- [Tailwind](https://tailwindcss.com/)\n- [RadixUI](https://www.radix-ui.com/)\n- [Sonner](https://sonner.emilkowal.ski/getting-started)\n\n### Choosing Your Template\n\nThe Next and Remix templates optimize for loading data on the server and passing to the client, whereas the Vite template is entirely client-side and can be deployed without a server. These options represent the extreme sides of a spectrum, allowing builders to decide which entry point aligns with their project goals.\n\n## Community Resources\n\n- [Hats Site](https://www.hatsprotocol.xyz/)\n- [Hats Documentation](https://docs.hatsprotocol.xyz/)\n"
  },
  "Hats-Protocol/hats-zodiac": {
    "fetchedAt": "2025-11-12T23:02:43.151Z",
    "content": "# Hats Signer Gate\n\nThis repo holds a [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol)-enabled [Zodiac](https://github.com/gnosis/zodiac) contract called Hats Signer Gate (HSG).\n\n## Hats Signer Gate v2\n\nA contract that grants multisig signing rights to addresses wearing a given hats, enabling on-chain organizations (such as DAOs) to revocably delegate to individuals constrained authority and responsibility to operate an account (i.e. a Safe) owned by the organization.\n\n### Overview\n\n#### Zodiac Module\n\n[HatsSignerGate.sol](./src/HatsSignerGate.sol) is a **Zodiac module** that...\n\n1. Grants multisig signing rights to addresses based on whether they are wearing the appropriate Hat(s).\n2. Removes signers who are no long valid (i.e. no longer wearing the signer Hat)\n3. Manages the multisig threshold within the [owner](#contract-ownership)-specified range as new signers are added or removed.\n\n#### Zodiac Guard\n\nSince Hat-wearing is dynamic ‚Äî Hats can be programmatically revoked from wearers ‚Äî this contract also services as a **Zodiac guard** to ensure that:\n\nA) **Only valid signers can execute transactions**, i.e. only signatures made by accounts currently wearing a valid signer Hat count towards the threshold.\n\nB) **Signers cannot execute transactions that remove the constraint in (A)**. Specifically, this contract guards against signers...\n\n1. Removing the contract as a guard on the multisig\n2. Removing the contract as a module on the multisig ‚Äî or removing/changing/adding any other modules\n3. Changing the multisig threshold\n4. Changing the multisig owners\n5. Making delegatecalls to any target not approved by the owner\n\n> **Warning**\n> Protections against (3) and (4) above only hold if the Safe does not have any authority over the signer Hat(s). If it does ‚Äî e.g. it wears an admin Hat of the signer Hat(s) or is an eligibility or toggle module on the signer Hat(s) ‚Äî then in some cases the signers may be able to change the multisig threshold or owners.\n>\n> Proceed with caution if granting such authority to a Safe attached to HatsSignerGate.\n\n### Signer Management\n\nHats Signer Gate provides several ways to manage Safe signers based on their hat-wearing status:\n\n#### Claiming Signer Rights\n\n- Individual hat wearers can claim their own signing rights via `claimSigner()`\n- Must be wearing a valid signer hat at time of claim\n- Each signer's hat ID is registered and tracked for future validation\n\n#### Claiming for Others\n\nWhen enabled by the owner (`claimableFor = true`):\n\n- Anyone can claim signing rights on behalf of valid hat wearers via `claimSignerFor()` or `claimSignersFor()`\n- Useful for batch onboarding of signers\n- Prevents re-registration if signer is still wearing their currently registered hat\n\n#### Signer Removal\n\n- Signers who no longer wear their registered hat can be removed via `removeSigner()`\n- Threshold automatically adjusts according to the threshold configuration\n- If the removed signer was the last valid signer, the contract itself becomes the sole owner\n\n### Threshold Configuration\n\nThe threshold (number of required signatures) is managed dynamically based on the `ThresholdConfig`:\n\n#### Threshold Types\n\n1. **ABSOLUTE**\n\n   - Sets a fixed target number of required signatures\n   - Example: Always require exactly 3 signatures\n   - Bounded by min threshold and number of valid signers\n\n2. **PROPORTIONAL**\n\n   - Sets a percentage of total signers required (in basis points)\n   - Example: Require 51% of signers (5100 basis points)\n   - Actual number of required signatures rounds up\n   - Still bounded by min threshold\n\n#### Configuration Parameters\n\n- `min`: Minimum number of required signatures (must be > 0)\n- `target`: Either fixed number (ABSOLUTE) or percentage in basis points (PROPORTIONAL)\n- `thresholdType`: ABSOLUTE (0) or PROPORTIONAL (1)\n\nThe Safe's threshold is automatically adjusted when:\n\n- New signers are added\n- Existing signers are removed\n- Threshold configuration is changed\n\n### Delegatecall Targets\n\nHSG restricts delegatecalls to protect the Safe from unauthorized modifications. Only approved targets can receive delegatecalls.\n\n#### Default Enabled Targets\n\nThe following MultiSend libraries are enabled by default:\n\n| Address | Version | Type |\n| --- | --- | --- |\n| `0x40A2aCCbd92BCA938b02010E17A5b8929b49130D` | v1.3.0 | canonical |\n| `0xA1dabEF33b3B82c7814B6D82A79e50F4AC44102B` | v1.3.0 | eip155 |\n| `0x9641d764fc13c8B624c04430C7356C1C7C8102e2` | v1.4.1 | canonical |\n\nSee [safe-deployments](https://github.com/safe-global/safe-deployments/tree/main/src/assets) for more information.\n\n#### Security Considerations\n\n- Delegatecalls can modify Safe state if not properly restricted. Owners should NOT approve delegatecall targets that enable the following:\n  - Directly modifying any of the Safe's state, including the Safe's nonce.\n  - Additional delegatecalls. For example, the [MultiSend.sol](https://github.com/safe-global/safe-smart-account/blob/v1.4.1-3/contracts/libraries/MultiSend.sol) library that is *not* \"call only\" should not be approved. The [MultiSendCallOnly.sol](https://github.com/safe-global/safe-smart-account/blob/v1.4.1-3/contracts/libraries/MultiSendCallOnly.sol) is approved by default.\n- HSG validates that approved delegatecalls don't modify critical Safe parameters, but relies on the Safe' nonce to do so.\n- Direct calls to the Safe are always prohibited\n- When detaching HSG from a Safe ‚Äî¬†i.e. when calling `detach()` ‚Äî¬†the owner must trust that admin(s) of the signer Hat(s) will not front-run the detachment to add arbitrary signers. Since admins in Hats Protocol are already trusted (and can be revoked, held accountable, etc.) this is not an additional risk, but HSG owners should nonetheless be aware of this risk.\n\n### Contract Ownership\n\nThe wearer of the `ownerHat` can make the following changes to Hats Signer Gate:\n\n1. \"Transfer\" ownership to a new Hat by changing the `ownerHat`\n2. Change the threshold configuration\n3. Enable other Zodiac modules on HSG itself\n4. Enable another Zodiac guard on HSG itself\n5. Add other Hats as valid signer Hats\n6. Enable or disable the ability for others to claim signer rights on behalf of valid hat wearers (`claimableFor`)\n7. Detach HatsSignerGate from the Safe (removing it as both guard and module)\n8. Migrate to a new HatsSignerGate instance\n9. Enable or disable specific delegatecall targets\n10. Lock the contract permanently, preventing any further owner changes\n\n### Deploying New Instances\n\nInstances of HSG can be created via the [Zodiac module proxy factory](https://github.com/gnosisguild/zodiac/blob/18b7575bb342424537883f7ebe0a94cd7f3ec4f6/contracts/factory/ModuleProxyFactory.sol).\n\nInstances can be created for an existing Safe by passing the Safe address on initialization, or for a new Safe to be deployed from within HSG's initialization.\n\n### Security Audits\n\n#### v1\n\nv1 of this project has received the following security audits. See the [v1 audits directory](./docs/audit-v1/) for the detailed reports.\n\n| Auditor | Report Date | Commit Hash | Notes |\n| --- | --- | --- | --- |\n| Trust Security | Feb 23, 2023 | [b9b7fcf](https://github.com/Hats-Protocol/hats-zodiac/commit/b9b7fcf22fd5cbb98c7d93dead590e80bf9c780a) | Report also includes findings from [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) audit |\n| Sherlock | May 3, 2023 | [9455c0](https://github.com/Hats-Protocol/hats-zodiac/commit/9455cc0957762f5dbbd8e62063d970199109b977) | Report also includes findings from [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) audit |\n\n#### v2\n\nv2 ‚Äî the present version ‚Äî¬†has received the following security audits. See the [v2 audits directory](./docs/audit-v2/) for the detailed reports.\n\n| Auditor | Report Date | Commit Hash | Notes |\n| --- | --- | --- | --- |\n| Sherlock | December 13, 2024 | [a9e3f4f](https://github.com/Hats-Protocol/hats-zodiac/commit/a9e3f4f0e968fb332800a468eddcb993fc6d5cd2) | 166 auditors participated |\n\n> **Note**\n> Since t\n\n[... truncated ...]"
  },
  "Hats-Protocol/hats-module-template": {
    "fetchedAt": "2025-11-12T23:02:43.540Z",
    "content": "# hats-module-template\n\nTemplate repo for Hats Module projects.\n\n## Overview and Usage\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To install dependencies, run `forge install`\n4. To compile the contracts, run `forge build`\n5. To test, run `forge test`\n\n### IR-Optimized Builds\n\nThis repo also supports contracts compiled via IR. Since compiling all contracts via IR would slow down testing workflows, we only want to do this for our target contract(s), not anything in this `test` or `script` stack. We accomplish this by pre-compiled the target contract(s) and then loading the pre-compiled artifacts in the test suite.\n\nFirst, we compile the target contract(s) via IR by running`FOUNDRY_PROFILE=optimized forge build` (ensuring that FOUNDRY_PROFILE is not in our .env file)\n\nNext, ensure that tests are using the `DeployOptimized` script, and run `forge test` as normal.\n\nSee the wonderful [Seaport repo](https://github.com/ProjectOpenSea/seaport/blob/main/README.md#foundry-tests) for more details and options for this approach.\n"
  },
  "Hats-Protocol/season-toggle": {
    "fetchedAt": "2025-11-12T23:02:43.945Z",
    "content": "# SeasonToggle\n\nA mechanistic [Hats Protocol](https://github.com/Hats-Protocol/hats-protocol) Toggle module ‚Äî i.e. a contract that implements the [`IHatsToggle` interface](https://github.com/Hats-Protocol/hats-protocol/src/Interfaces/IHatsToggle.sol) ‚Äî that allows an organization to configure certain hats to be automatically toggled off after a given interval, i.e. a \"season\".\n\nOrganizational structure should not be permanent. By automatically turning off hats by default, SeasonToggle helps ensure that organizations continuously and explicitly revisit their own structure.\n\n## Overview & Usage\n\nIn Hats Protocol, hats can be configured with Toggle modules that programmatically control whether and when the hat is active or inactive. SeasonToggle adds an automatic expiry for a group of hats within a given branch of an organization's hat tree, unless an admin of that branch explicitly extends it to a new season.\n\nUsage of SeasonToggle involves the following phases:\n\n1. **Setup**: create a new instance of SeasonToggle for the relevant branch of the hat tree\n2. **Extension**: renew the branch of hats for a new season\n\nOnce in operation, Hats Protocol will retrieve hat status (active or inactive) from an instance of SeasonToggle by calling the `SeasonToggle.getHatStatus()` function.\n\n### Phase 1: Setup\n\nA given branch of hats is defined by its `branchRoot`, which is the id of the hat that is the root of the branch. Any hat that is a descendant of the `branchRoot` is considered to be part of the branch. All hats are `branchRoot`s of their own branch.\n\n#### Deploy a new SeasonToggle instance\n\nFor each `branchRoot`, there is a corresponding SeasonToggle contract instance. These contracts are created via the [SeasonToggleFactory](./src/SeasonToggleFactory.sol) contract. For cheap deployment, each instance is a clone of an implementation contract. To create a new instance, call the `SeasonToggleFactory.createSeasonToggle()` function, passing in the `branchRoot` ‚Äî and two other parameters; see below ‚Äî as an argument. If a SeasonToggle instance already exists for `branchRoot`, the call will fail; otherwise, the new instance will be deployed.\n\nThe `SeasonToggleFactory.createSeasonToggle()` function takes two parameters in addition to the `branchRoot`:\n\n- `seasonDuration`: the length of the first season, in seconds. This value must not be less than 1 hour, or 3600 seconds.\n- `extensionDelay`: the proportion of the season that must elapse before the branch can be extended to a new season. This value is input as the numerator of the expression `extensionDelay / 10,000`, so a value of 0 corresponds to a delay of 0% and a value of 10,000 corresponds to a delay of 100% of the season. This value must be less than 10,000. See the [Extension phase](#phase-2-extension) below for more on the extension delay.\n\n#### Set the SeasonToggle as the toggle for the hats in the branch\n\nTo enable SeasonToggle for the hats in the branch, the SeasonToggle instance must be set as the toggle module for each hat. For existing (mutable) hats in the branch, an admin can do so by calling `Hats.changeToggleModule()`, passing in the SeasonToggle instance as the new toggle module. For new hats in the branch, the SeasonToggle instance can be set as the toggle module when the hat is created.\n\nSince SeasonToggle instance contract addresses are deterministic, the address can be set as the toggle module on hats even before the SeasonToggle instance is deployed. However, the SeasonToggle instance must be deployed before it can be used to toggle hats.\n\n> **Warning**\n> There is no explicit restriction on setting the SeasonToggle instance as the toggle module for hats outside of the branch. Such hats will be subject to the SeasonToggle's expiry logic, but their admins will not have the ability to control the season extension, which may result in unexpected behavior. **It is recommended that the SeasonToggle instance be set as the toggle module only for hats in the branch.**\n\n### Phase 2: Extension\n\nAn admin of a given `branchRoot` can extend it to a new season by calling the `SeasonToggle.extend()` function on its corresponding instance.\n\nExtension is only allowed after `extensionDelay` has elapsed since the start of the current season. The intent here is to ensure that the organization can only extend to a new season once it has sufficent information about how the next season should proceed. The longer the `extensionDelay`, the more likely the organization will be able to make an informed decision about its structure for the next season.\n\nThe exact time at which the `extensionDelay` will elapse can be read from the `SeasonToggle.extensionThreshold()` function, and whether the branch can be extended at the present time can be read from the `SeasonToggle.extendable()` function.\n\nThe `SeasonToggle.extend()` function takes two optional arguments, `seasonDuration` and `extensionDelay`. If these values are non-zero, they will be set as the new `seasonDuration` and `extensionDelay` for the next season. If they are zero, the values from the present season will be used again.\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To compile the contracts, run `forge build`\n4. To test, run `forge test`\n"
  },
  "Hats-Protocol/staking-eligibility": {
    "fetchedAt": "2025-11-12T23:02:44.491Z",
    "content": "# StakingEligibility\n\nStakingEligibility is an eligibility module for [Hats Protocol](https://github.com/hats-protocol/hats-protocol). It requires wearers of a given Hat to stake a minimum amount of a specified token in order to be eligible, and enables others in the hat tree's organization to slash the stake of a wearer who is behaving badly.\n\n## StakingEligibility Details\n\nStakingEligibility inherits from the [HatsEligibilityModule](https://github.com/Hats-Protocol/hats-module#hatseligibilitymodule) base contract, from which it receives two major properties:\n\n- It can be cheaply deployed via the [HatsModuleFactory](https://github.com/Hats-Protocol/hats-module#hatsmodulefactory) minimal proxy factory, and\n- It implements the [IHatsEligibility](https://github.com/Hats-Protocol/hats-protocol/blob/main/src/Interfaces/IHatsEligibility.sol) interface\n\n### Setup\n\nA StakingEligibility instance requires several parameters to be set at deployment, passed to the `HatsModuleFactory.createHatsModule()` function in various ways.\n\n#### Immutable values\n\n- `hatId`: The id of the hat to which this the instance will be attached as an eligibility module, passed as itself\n- `TOKEN`: The address of the ERC20-compatible staking token, abi-encoded (packed) and passed as `_otherImmutableArgs`\n\nThe following immutable values will also automatically be set within the instance at deployment:\n\n- `IMPLEMENTATION`: The address of the StakingEligibility implementation contract\n- `HATS`: The address of the Hats Protocol contract\n\n#### Initial state values\n\nThe following are abi-encoded (unpacked) and then passed to the `HatsModuleFactory.createHatsModule()` function as `_initData`. These values can be changed after deployment by an admin of the `hatId` hat.\n\n- `minStake`: The minimum amount of the staking token that must be staked in order to be eligible for the hat\n- `judgeHat`: The id of the hat that has the authority to slash stakes\n- `recipientHat`: The id of the hat that receives\n- `cooldownPeriod`: The amount of time that must pass between beginning an unstaking process and completing it. This is to give the wearer of the `judgeHat` time to slash the stake of a misbehaving wearer before they can remove their stake, so it should be long enough to allow for that based on the governance process of the wearer of the `judgeHat`.\n\n### Staking\n\nIn order to be eligible for a hat, a user must stake at least the `minStake` amount of the staking token. This is done by calling the `stake()` function, which transfers the staking token from the caller to the StakingEligibility instance. The caller must have approved the StakingEligibility instance to transfer at least the `minStake` amount of the staking token.\n\n### Unstaking\n\nUnstaking involves two steps: (1) beginning an unstaking cooldown period, and then (2) completing the unstaking process once the cooldown period has ended. This cooldown period exists to give a wearer of the `judgeHat` (see [Slashing](#slashing)) enough time to slash the stake of a misbehaving wearer before they can remove their stake.\n\n1. `beginUnstake()`: This initiates the unstaking process and begins a cooldown period. It does not transfer any tokens, but it removes the specified amount from the caller's stake. If this drops the caller's stake below the `minStake`, they will immediately lose their eligibility. A staker cannot have two concurrent unstaking cooldown periods, so this function reverts if the caller already is in a cooldown period.\n\n2. `completeUnstake()`: Once the cooldown period ends, this function can be called to finish the unstaking process. It transfers the amount of tokens specified in (1) from the StakingEligibility instance to the specified staker, and then clears the cooldown data. This function reverts if the caller is not in a cooldown period.\n\n### Slashing\n\nA staker's stake can be slashed by calling the `slash()` function. This updates internal balances within StakingEligibility, removing the staker's entire stake and any pending unstaking amount. The slashed staker will lose their eligibility, and will also be placed in bad standing; they will not be able to stake again unless a judge calls the `forgive()` function.\n\nOnly a wearer of the `judgeHat` can slash.\n\n### Forgiving\n\nA slashed staker can be forgiven by calling the `forgive()` function. This does not unslash the staker, but it brings them out of bad standing and allows them to stake again if they wish.\n\nOnly a wearer of the `judgeHat` can forgive.\n\n### Withdrawal\n\nSlashed stakes can be withdrawn by calling the `withdraw()` function. This transfers the full `totalSlashedStakes` balance to the (specified) wearer of the `recipientHat`, and removes the slashed stake from the internal balances of StakingEligibility.\n\nAnybody can execute a withdrawal, but the tokens will always be transferred to the specified wearer of the `recipientHat`.\n\n### Changing Parameters\n\nThe following parameters can be changed after deployment by an admin of the `hatId` hat. Changes are only allowed while the `hatId` is mutable.\n\n- `minStake`, by calling the `changeMinStake()` function\n- `cooldownPeriod`, by calling the `changeCooldownPeriod()` function\n- `judgeHat`, by calling the `changeJudgeHat()` function\n- `recipientHat`, by calling the `changeRecipientHat()` function\n\n## Development\n\nThis repo uses Foundry for development and testing. To get started:\n\n1. Fork the project\n2. Install [Foundry](https://book.getfoundry.sh/getting-started/installation)\n3. To compile the contracts, run `forge build`\n4. To test, run `forge test`\n"
  },
  "openocean-finance/OpenOceanExchangeV2": {
    "fetchedAt": "2025-11-12T23:02:52.069Z",
    "content": "# OpenOcean Exchange V2\n\nThe OpenOcean Exchange V2, OpenOcean's latest DEX aggregator router, leverages a next-gen routing algorithm that supports multi-route aggregation from various liquidity sources ensuring the best swap rates across 40+ blockchains including EVM compatible chains and non-EVM chains in DeFi. The OpenOcean aggregator router requires users to give permission to spend the specific amount of crypto assets they wish to trade. Once the tokens are successfully approved, users can execute the swaps and are guaranteed to receive the maximum token amount in return within the slippage they set.\n\n\n## Features\n### Gasless swapping:\nOpenOcean's gasless swaps simplify DeFi trading by making it faster, more accessible, especially for those trading across multiple chains or new to the space. With gasless swaps, users benefit from fast settlement, secured by Permit2, and built-in MEV protection. Based on Uniswap's Permit2 standards, gasless swaps allow secure token approvals without extra on-chain transactions - users only need to sign and swap. Additionally, users don‚Äôt need native tokens like ETH or BNB for gas fees; the gas cost is abstracted and covered as part of the transaction.\n\n### Referrals & Monetization\nIf you are building DeFi products, trading bots, or arbitrage strategies on top of OpenOcean Exchange V2, you can easily monetize your flow using our built-in referral system. The router supports referral parameters /referrer and /referrerFee, which can be added directly to the request URL to apply an additional fee.\n\nThe referrer parameter is simply an EOA address that you control, making it straightforward to manage. With this setup, you can track your swap activity via OpenOcean analytics dashboard. This allows developers and integrators to generate passive income from DeFi trades while leveraging OpenOcean‚Äôs next-generation DEX aggregation infrastructure.\n\n\n\n## Contracts of Chains(EVM Chains)\n\n### **OpenOcean‚Äôs current contract addresses:**&#x20;\n\n\n**Ethereum:**[ **0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://etherscan.io/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**BNB Chain:**[ **0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://bscscan.com/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Polygon:**[ **0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://polygonscan.com/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Avalanche:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://snowtrace.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Fantom:**[ **0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.fantom.network/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Arbitrum:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://arbiscan.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Optimism:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://optimistic.etherscan.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**zkSync Era:** [**0x36A1aCbbCAfca2468b85011DDD16E7Cb4d673230**](https://explorer.zksync.io/address/0x36A1aCbbCAfca2468b85011DDD16E7Cb4d673230)\n\n**Base:** [**0x6352a56caadc4f1e25cd6c75970fa768a3304e64**](https://basescan.org/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**opBNB:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://opbnbscan.com/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Linea:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.linea.build/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Mantle:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.mantle.xyz/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Manta:**[ **0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://pacific-explorer.manta.network/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Telos:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://www.teloscan.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Scroll:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://scrollscan.com/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Gnosis:**[ **0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://blockscout.com/xdai/mainnet/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64/transactions)\n\n**Cronos:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://cronos.org/explorer/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Harmony:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.harmony.one/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Blast:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://blastscan.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Mode:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.mode.network/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Rootstock(RSK):**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.rootstock.io/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Sei:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://seitrace.com/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64?chain=pacific-1)\n\n**Gravity**: [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.gravity.xyz/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Kava:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://www.mintscan.io/kava/evm/contract/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Metis:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://andromeda-explorer.metis.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Celo:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.celo.org/mainnet/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**Polygon zkEVM:** [**0x6dd434082EAB5Cd134B33719ec1FF05fE985B97b**](https://zkevm.polygonscan.com/address/0x6dd434082EAB5Cd134B33719ec1FF05fE985B97b)\n\n**Moonriver:**[**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://moonriver.moonscan.io/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Aurora:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://aurorascan.dev/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**APE:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://apescan.io/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Sonic:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://sonicscan.org/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Berachain:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://berascan.com/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Monad Testnet:** [**0x6352a56caadc4f1e25cd6c75970fa768a3304e64**](https://monad-testnet.socialscan.io/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**UniChain:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://uniscan.xyz/address/0x6352a56caadc4f1e25cd6c75970fa768a3304e64)\n\n**Flare:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://flare-explorer.flare.network/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**SwellChain:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://swellchainscan.io/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n**HyperEVM:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://purrsec.com/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64/transactions)\n\n**Plume:** [**0x6352a56caadC4F1E25CD6c75970Fa768A3304e64**](https://explorer.plume.org/address/0x6352a56caadC4F1E25CD6c75970Fa768A3304e64)\n\n\n\n\n\n\n\n\n"
  },
  "lifinance/sdk": {
    "fetchedAt": "2025-11-12T23:02:58.884Z",
    "content": "<div align=\"center\">\n\n[![license](https://img.shields.io/github/license/lifinance/sdk)](/LICENSE)\n[![npm latest package](https://img.shields.io/npm/v/@lifi/sdk/latest.svg)](https://www.npmjs.com/package/@lifi/sdk)\n[![npm downloads](https://img.shields.io/npm/dm/@lifi/sdk.svg)](https://www.npmjs.com/package/@lifi/sdk)\n[![Follow on Twitter](https://img.shields.io/twitter/follow/lifiprotocol.svg?label=follow+LI.FI)](https://twitter.com/lifiprotocol)\n\n</div>\n\n<h1 align=\"center\">LI.FI SDK</h1>\n\n[**LI.FI SDK**](https://docs.li.fi/sdk/overview) provides a powerful toolkit for developers to enable seamless cross-chain and on-chain swaps and bridging within their applications. Our JavaScript/TypeScript SDK can be implemented in front-end or back-end environments, allowing you to build robust UX/UI around our advanced bridge and swap functionalities. LI.FI SDK efficiently manages all communications between our smart routing API and smart contracts and ensures optimal performance, security, and scalability for your cross-chain and on-chain needs.\n\n[**LI.FI SDK**](https://docs.li.fi/sdk/overview) features include:\n\n- All ecosystems, chains, bridges, exchanges, and solvers that [LI.FI](https://docs.li.fi/introduction/chains) supports\n- Complete functionality covering full-cycle from obtaining routes/quotes to executing transactions\n- Easy tracking of the route and quote execution through the robust event and hooks handling\n- Highly customizable settings to tailor the SDK to your specific needs including configuration of RPCs and options to allow or deny certain chains, tokens, bridges, exchanges, solvers\n- Supports widely adopted industry standards, including [EIP-5792](https://eips.ethereum.org/EIPS/eip-5792), [ERC-2612](https://eips.ethereum.org/EIPS/eip-2612), [EIP-712](https://eips.ethereum.org/EIPS/eip-712), and [Permit2](https://github.com/Uniswap/permit2)\n- SDK ecosystem providers are based on industry-standard libraries ([Viem](https://viem.sh/), [Wallet Standard](https://github.com/wallet-standard/wallet-standard), [Bigmi](https://github.com/lifinance/bigmi))\n- Support for arbitrary contract calls on the destination chain\n- Designed for optimal performance with tree-shaking and dead-code elimination, ensuring minimal bundle sizes and faster page load times in front-end environments\n- Compatibility tested with Node.js and popular front-end tools like Vite\n\n## Installation\n\n```bash\npnpm add @lifi/sdk\n```\n\nor\n\n```bash\nnpm install --save @lifi/sdk\n```\n\n## Quick Start\n\n### Set up the SDK\n\nFirstly, create SDK config with your integrator string.\n\n```ts\nimport { createConfig } from '@lifi/sdk'\n\ncreateConfig({\n  integrator: 'Your dApp/company name',\n})\n```\n\n### Request a Quote\n\nNow you can interact with the SDK and for example request a quote.\n\n```ts\nimport { ChainId, getQuote } from '@lifi/sdk'\n\nconst quote = await getQuote({\n  fromAddress: '0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045',\n  fromChain: ChainId.ARB,\n  toChain: ChainId.OPT,\n  fromToken: '0x0000000000000000000000000000000000000000',\n  toToken: '0x0000000000000000000000000000000000000000',\n  fromAmount: '1000000000000000000',\n})\n```\n\n## Examples\n\nSee [examples](/examples) folder in this repository.\n\n## Documentation\n\nPlease checkout the [SDK documentation](https://docs.li.fi/sdk/overview) and our [API reference](https://docs.li.fi/api-reference/introduction) for further information.\n\n## Changelog\n\nThe [changelog](/CHANGELOG.md) is regularly updated to reflect what's changed in each new release.\n"
  },
  "lifinance/widget": {
    "fetchedAt": "2025-11-12T23:02:59.221Z",
    "content": "<div align=\"center\">\n\n[![license](https://img.shields.io/github/license/lifinance/widget)](/LICENSE)\n[![npm latest package](https://img.shields.io/npm/v/@lifi/widget/latest.svg)](https://www.npmjs.com/package/@lifi/widget)\n[![npm downloads](https://img.shields.io/npm/dm/@lifi/widget.svg)](https://www.npmjs.com/package/@lifi/widget)\n[![Crowdin](https://badges.crowdin.net/lifi-widget/localized.svg)](https://crowdin.com/project/lifi-widget)\n[![Follow on Twitter](https://img.shields.io/twitter/follow/lifiprotocol.svg?label=follow+LI.FI)](https://twitter.com/lifiprotocol)\n\n</div>\n\n<h1 align=\"center\">LI.FI Widget</h1>\n\n![GitHub_Repo_Card](https://github.com/user-attachments/assets/fc08ab8c-d7fb-41de-b478-c1e69c631a23)\n\n[**LI.FI Widget**](https://docs.li.fi/widget/overview) is a set of prebuilt UI components for secure cross-chain bridging and swapping. The widget can be customized to match your web app's design and helps drive your multi-chain strategy by attracting users from all ecosystems.\n\n[**LI.FI Widget**](https://docs.li.fi/widget/overview) features include:\n\n- All ecosystems, chains, bridges, exchanges, and solvers that [LI.FI](https://docs.li.fi/introduction/chains) supports\n- Embeddable variants - compact, wide, and drawer\n- Options to allow or deny certain chains, tokens, bridges, and exchanges\n- Pre-configured themes and lots of customization options with dark mode support so you can match the look and feel of your web app \n- Wallet management UI with the option to opt-out and use your own ([Wagmi](https://wagmi.sh/), [Bigmi](https://github.com/lifinance/bigmi) and [Wallet Standard](https://github.com/wallet-standard/wallet-standard) support)\n- Supports widely adopted industry standards, including [EIP-5792](https://eips.ethereum.org/EIPS/eip-5792), [ERC-2612](https://eips.ethereum.org/EIPS/eip-2612), [EIP-712](https://eips.ethereum.org/EIPS/eip-712), [EIP-6963](https://eips.ethereum.org/EIPS/eip-6963), and [Permit2](https://github.com/Uniswap/permit2)\n- View of transactions in progress and transaction history\n- Curated wallet lists and wallet bookmarks\n- Route settings for advanced users (stored locally)\n- Complete UI translations to match your customer‚Äôs preferred language\n- Compatibility tested with React, Next.js, Vue, Nuxt.js, Svelte, Remix, Gatsby, Vite, RainbowKit, Reown AppKit, Privy, Dynamic\n\n## Installation\n\n### LI.FI Widget\n\nLI.FI Widget is available as an [npm package](https://www.npmjs.com/package/@lifi/widget).\n\n**pnpm:**\n\n```sh\npnpm add @lifi/widget wagmi @bigmi/react @solana/wallet-adapter-react @tanstack/react-query @mysten/dapp-kit\n```\n\n**npm:**\n\n```sh\nnpm install @lifi/widget wagmi @bigmi/react @solana/wallet-adapter-react @tanstack/react-query @mysten/dapp-kit\n```\n\n**yarn:**\n\n```sh\nyarn add @lifi/widget wagmi @bigmi/react @solana/wallet-adapter-react @tanstack/react-query @mysten/dapp-kit\n```\n\n- [Wagmi](https://wagmi.sh/) is type safe, extensible, and modular library for building Ethereum apps.\n- [Bigmi](https://github.com/lifinance/bigmi) is modular TypeScript library that provides reactive primitives for building Bitcoin applications.\n- [@solana/wallet-adapter-react](https://github.com/anza-xyz/wallet-adapter) is modular TypeScript wallet adapters and components for Solana applications.\n- [TanStack Query](https://tanstack.com/query/v5) is an async state manager that handles requests, caching, and more.\n- [@mysten/dapp-kit](https://sdk.mystenlabs.com/dapp-kit) provides React tools for wallet integration and data access in Sui blockchain dApps.\n\n### LI.FI Wallet Management\n\nLI.FI Wallet Management is available as an [npm package](https://www.npmjs.com/package/@lifi/wallet-management).\n\n**pnpm:**\n\n```sh\npnpm add @lifi/wallet-management\n```\n\n**npm:**\n\n```sh\nnpm install @lifi/wallet-management\n```\n\n**yarn:**\n\n```sh\nyarn add @lifi/wallet-management\n```\n\n## Getting started with LI.FI Widget\n\nHere is an example of a basic app using LI.FI Widget:\n\n```tsx\nimport { LiFiWidget, WidgetConfig } from '@lifi/widget';\n\nconst widgetConfig: WidgetConfig = {\n  theme: {\n    container: {\n      border: '1px solid rgb(234, 234, 234)',\n      borderRadius: '16px',\n    },\n  },\n};\n\nexport const WidgetPage = () => {\n  return (\n    <LiFiWidget integrator=\"Your dApp/company name\" config={widgetConfig} />\n  );\n};\n```\n\nPlease refer to our [documentation](https://docs.li.fi/widget/compatibility) if you encounter any issues with importing.\n\nYou can also refer to the [examples](/examples) folder in this repository to see how to import the widget in your specific context.\n\n## Examples\n\nVisit our [playground](https://playground.li.fi) to see how you can customize your [LI.FI Widget](https://www.npmjs.com/package/@lifi/widget) experience. Additionally, see [examples](/examples) folder in this repository.\n\n## Documentation\n\nPlease visit [LI.FI Widget Documentation](https://docs.li.fi/widget/install-widget).\n\n## Contributing Translations\n\nWe appreciate your interest in helping translate our project!\n\nIf you'd like to contribute translations, please visit our Crowdin project page at [Crowdin LI.FI Widget](https://crowdin.com/project/lifi-widget). Register on Crowdin and you can start translating the project into your preferred language. Your contributions will help make our project accessible to a wider audience around the world.\n\nThank you for your support!\n\n## Changelog\n\nThe [changelog](/CHANGELOG.md) is regularly updated to reflect what's changed in each new release.\n"
  },
  "lifinance/contracts": {
    "fetchedAt": "2025-11-12T23:02:59.548Z",
    "content": "[![Forge](https://github.com/lifinance/contracts/actions/workflows/forge.yml/badge.svg)](https://github.com/lifinance/contracts/actions/workflows/forge.yml)\n\n# LI.FI Smart Contracts\n\nYou can find the ABI of LifiDiamond in our auto generated [lifi-contract-types repository](https://github.com/lifinance/lifi-contract-types/blob/main/dist/diamond.json).\n\n## Table of contents\n\n1. [General](#general)\n2. [Why LI.FI?](#why)\n   1. [Our Thesis](#thesis)\n   2. [Ecosystem Problems](#ecosystem-problems)\n   3. [Developer Problems](#developer-problems)\n   4. [Solution](#solution)\n3. [How It Works](#how-it-works)\n4. [Architecture](#architecture)\n   1. [Contract Flow](#contract-flow)\n   2. [Diamond Helper Contracts](#diamond-helper-contracts)\n5. [Repository Structure](#repository-structure)\n6. [Getting Started](#getting-started)\n   1. [Prerequisites](#prerequisites)\n   2. [Development Environment](#development-environment)\n   3. [Cursor IDE Setup](#cursor-setup)\n7. [Development Workflow](#development-workflow)\n8. [Code Quality & Standards](#code-quality)\n9. [More Information](#more-information)\n\n## General<a name=\"general\"></a>\n\nOur vision is to create a middle layer between DeFi infrastructure and the application layer.\nLI.FI aims to aggregate and abstract away the most important bridges and connect them to DEXs and DEX aggregators on each chain to facilitate cross-chain any-2-any swaps.\n\nTo decide which bridge to use, we assess and measure the degree of decentralization, trust assumptions, fees, gas efficiency, speed, and other qualitative and quantitative factors.\nThen, we use the thresholds and preferences of our integration partners and end-users to select the right path.\n\n## Why LI.FI?<a name=\"why\"></a>\n\n### Our Thesis<a name=\"thesis\"></a>\n\n- The future is multi-chain\n- Cross-chain bridging solutions will play a major role on infrastructure level\n- Aggregation will pave the way for mass adoption\n\n### Ecosystem Problems<a name=\"ecosystem-problems\"></a>\n\n**dApps**: Many users come across a new interesting dApp on a chain they don't have funds in and struggle to get their funds there. This is significant friction in user onboarding as they have to research and find bridges to that chain to start using the dApp.\n\n**Yield Aggregators**: There are definitely protocols with better yield on new L2/side-chains but there isn't a secure, reliable way to transfer your funds.\n\n**Wallets**: Multichain wallets want to compete with CEXes, but they don't have a way to allow easy swap between assets like CEXes.\n\n**DeFi Protocols**: DeFi Dashboards, lending protocols, yield farms, etc., that are present on new chains create a need to do cross-chain swaps, but their users have to wander the ecosystem to quench this need.\n\n### Developer Problems<a name=\"developer-problems\"></a>\n\n**Too many bridges** to educate yourself about.\nIt'd be good to have access to all of them and getting good guidance from people and algorithms that are specialized.\n\n‚ûî LI.FI does that.\n\n**Bridges are still immature** so it's good to have not only one bridge but fallback solutions in place.\nImmaturity comes with security risks, insufficient liquidity and a lot of maintenance overhead.\n\n‚ûî LI.FI maintains all bridge connections, gives you access to multiple ones and handles fallbacks and decision-making programmatically.\n\n**Bridges are most often not enough**.\nYou also need DEXes/DEX aggregators as bridges are limited to stable-coins and native currencies.\n\n‚ûî LI.FI not only aggregates bridges, but also connects to sorts of DEX aggregators and if not available, the DEXs directly in order to find the best swap possible to arrive at the desired token and to allow to start the whole process with any asset.\n\n### Solution<a name=\"solution\"></a>\n\nA data mesh of cross-chain liquidity sources: cross-chain liquidity networks, bridges, DEXes, bridges, and lending protocols.\n\nAs a bridge and DEX aggregator, LI.FI can route any asset on any chain to the desired asset on the desired chain, thus providing a remarkable UX to their users.\n\nAll of this will be made available on an API/Contract level which comes as SDK, iFrame solution, and as a widget for other developers to plug directly into their products.\nNo need for users to leave your dApps anymore.\n\n## How It Works<a name=\"how-it-works\"></a>\n\nOur [API](https://apidocs.li.fi/) and [SDK](https://docs.li.fi/products/integrate-li.fi-js-sdk/install-li.fi-sdk) allow dApps and dApp developers to request the best routes for a desired cross-chain swap.\nOur backend will calculate the best possible routes based on the transaction fees, gas costs and execution duration.\n\nThe then returned routes contain already populated transactions which can directly be sent via the user's wallet to our contracts.\nA single transaction can contain multiple steps (e.g. AAVE on Polygon -> DAI on Polygon using Paraswap -> DAI on Avalanche using Stargate -> SPELL on Avalanche using Paraswap) which will be executed by our contract.\nFinally, the final amount of the requested token is sent to the user's wallet.\n\n## Architecture<a name=\"architecture\"></a>\n\nThe LI.FI Contract is built using the EIP-2535 (Multi-facet Proxy) standard. The contract logic lives behind a single contract that in turn uses DELEGATECALL to call **facet** contracts that contain the business logic.\n\nAll business logic is built using **facet** contracts which live in `src/Facets`.\n\nFor more information on EIP-2535 you can view the entire EIP [here](https://eips.ethereum.org/EIPS/eip-2535).\n\n### Contract Flow<a name=\"contract-flow\"></a>\n\nA basic example would be a user bridging from one chain to another using Hop Protocol. The user would interact with the LI.FIDiamond contract which would pass the Hop specific call to the HopFacet which then passes required calls + parameters to Hop Protocol's contracts.\n\nThe basic flow is illustrated below.\n\n```mermaid\ngraph TD;\n    D{LiFiDiamond}-- DELEGATECALL -->HopFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->AnyswapFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->CBridgeFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->HyphenFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->StargateFacet;\n```\n\n### Diamond Helper Contracts<a name=\"diamond-helper-contracts\"></a>\n\nThe LiFiDiamond contract is deployed along with some helper contracts that facilitate things like upgrading facet contracts, look-ups for methods on facet contracts, ownership checking and withdrawals of funds. For specific details please check out [EIP-2535](https://eips.ethereum.org/EIPS/eip-2535).\n\n```mermaid\ngraph TD;\n    D{LiFiDiamond}-- DELEGATECALL -->DiamondCutFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->DiamondLoupeFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->OwnershipFacet;\n    D{LiFiDiamond}-- DELEGATECALL -->WithdrawFacet;\n```\n\n## Repository Structure<a name=\"repository-structure\"></a>\n\n```\ncontracts\n‚îÇ README.md                   // you are here\n‚îÇ ...                         // setup and development configuration files\n‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ config                   // service configuration files\n‚îú‚îÄ‚îÄ‚îÄ constants                // general constants\n‚îú‚îÄ‚îÄ‚îÄ deploy                   // deployment scripts\n‚îú‚îÄ‚îÄ‚îÄ diamondABI               // Diamond ABI definition\n‚îú‚îÄ‚îÄ‚îÄ export                   // deployed results\n‚îú‚îÄ‚îÄ‚îÄ scripts                  // scripts containing sample calls for demonstration\n‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ src                      // the contract code\n‚îÇ   ‚îú‚îÄ‚îÄ Facets                // service facets\n‚îÇ   ‚îú‚îÄ‚îÄ Interfaces            // interface definitions\n‚îÇ   ‚îî‚îÄ‚îÄ Libraries             // library definitions\n‚îÇ\n‚îú‚îÄ‚îÄ‚îÄtasks\n‚îÇ   ‚îÇ generateDiamondABI.ts   // script to generate Diamond ABI including all facets\n‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ test                     // contract unit tests\n‚îÇ   ‚îú‚îÄ‚îÄ‚îÄ facets               // facet tests\n‚îÇ   ‚îú‚îÄ‚îÄ‚îÄ fixtures             // service fixtures for running the tests\n‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ utils                // testing utility functions\n‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ utils                    // utility scripts\n```\n\n## Getting Started<a name=\"getting-started\"></a>\n\n### Prerequisites<a name=\"prerequisites\"></a>\n\n\n\n[... truncated ...]"
  },
  "router-protocol/router-contracts": {
    "fetchedAt": "2025-11-12T23:03:08.131Z",
    "content": "# router-contracts\n"
  },
  "PartyDAO/party-protocol": {
    "fetchedAt": "2025-11-12T23:03:16.271Z",
    "content": "![Party Protocol](.github/assets/banner.png)\n\n[![Version][version-badge]][version-link]\n[![License][license-badge]][license-link]\n[![Test][ci-badge]][ci-link]\n[![Docs][docs-badge]][docs-link]\n[![Discussions][discussions-badge]][discussions-link]\n[![Discord][discord-badge]][discord-link]\n\n[version-badge]: https://img.shields.io/github/release/PartyDAO/party-protocol?label=version\n[version-link]: https://github.com/PartyDAO/party-protocol/releases\n[license-badge]: https://img.shields.io/github/license/PartyDAO/party-protocol\n[license-link]: https://github.com/PartyDAO/party-protocol/blob/main/LICENSE\n[ci-badge]: https://github.com/PartyDAO/party-protocol/actions/workflows/ci.yml/badge.svg\n[ci-link]: https://github.com/PartyDAO/party-protocol/actions/workflows/ci.yml\n[docs-badge]: https://img.shields.io/badge/Party-documentation-informational\n[docs-link]: https://github.com/PartyDAO/party-protocol/tree/main/docs\n[discussions-badge]: https://img.shields.io/badge/Party-discussions-blueviolet\n[discussions-link]: https://github.com/PartyDAO/party-protocol/discussions\n[discord-badge]: https://img.shields.io/static/v1?logo=discord&label=discord&message=join&color=blue\n[discord-link]: https://discord.gg/zUeXpDX8HA\n\n# Party Protocol\n\nA protocol for _group coordination_. The Party Protocol provides on-chain functionality for group formation, coordination, and distribution, with the goal of making Ethereum multiplayer.\n\nThe Party Protocol powers secure commercial transactions through crowdfunding, on-chain payments and transactions, and distributions to Party members.\n\n## Table of Contents\n\n- [Party Protocol](https://github.com/PartyDAO/party-protocol#party-protocol)\n  - [Table of Contents](https://github.com/PartyDAO/party-protocol#table-of-contents)\n  - [Documentation](https://github.com/PartyDAO/party-protocol#documentation)\n  - [Contributing](https://github.com/PartyDAO/party-protocol#contributing)\n  - [Layout](https://github.com/PartyDAO/party-protocol#layout)\n  - [Deployments](https://github.com/PartyDAO/party-protocol#deployments)\n  - [Install](https://github.com/PartyDAO/party-protocol#install)\n  - [Testing](https://github.com/PartyDAO/party-protocol#testing)\n  - [Audits](https://github.com/PartyDAO/party-protocol#audits)\n  - [Bug Bounty](https://github.com/PartyDAO/party-protocol#bug-bounty)\n  - [License](https://github.com/PartyDAO/party-protocol#license)\n\n## Documentation\n\nFor more information on Party Protocol, see the documentation [here](https://docs.partydao.org).\n\n## Contributing\n\nThis is an open protocol, so if you are interested in contributing see [here](./CONTRIBUTING.md) for more details about how you could get involved.\n\n## Layout\n\n```\ndocs/ # Start here\n‚îú‚îÄ‚îÄ overview.md\n‚îú‚îÄ‚îÄ crowdfund.md\n‚îî‚îÄ‚îÄ governance.md\ncontracts/\n‚îÇ   # Used during the crowdfund phase\n‚îú‚îÄ‚îÄ crowdfund/\n‚îú‚îÄ‚îÄ gatekeepers/\n‚îú‚îÄ‚îÄ globals/\n‚îÇ   # Used during the governance phase\n‚îú‚îÄ‚îÄ party/\n‚îú‚îÄ‚îÄ proposals/\n‚îú‚îÄ‚îÄ distribution/\n|   # Used to render crowdfund and governance NFTs\n‚îî‚îÄ‚îÄ renderers/\ntest/ # Foundry tests\n```\n\n## Deployments\n\nBelow are the latest deployments of each contract of the Party Protocol. For addresses of previous releases, see [here](https://github.com/PartyDAO/party-addresses).\n\n| Contract                      | Ethereum                                                                                                              | Goerli                                                                                                                       | Base                                                                                                                  | Base Goerli                                                                                                                  |\n| ----------------------------- | --------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| `Globals`                     | [0x1ca20040ce6ad406bc2a6c89976388829e7fbade](https://etherscan.io/address/0x1ca20040ce6ad406bc2a6c89976388829e7fbade) | [0x753e22d4e112a4d8b07df9c4c578b116e3b48792](https://goerli.etherscan.io/address/0x753e22d4e112a4d8b07df9c4c578b116e3b48792) | [0xcEDe25DF327bD1619Fe25CDa2292e14edAC30717](https://basescan.org/address/0xcEDe25DF327bD1619Fe25CDa2292e14edAC30717) | [0x1b0e8E8DC71b29CE49038569dEF1B3Bc0120F602](https://goerli.basescan.org/address/0x1b0e8E8DC71b29CE49038569dEF1B3Bc0120F602) |\n| `TokenDistributor`            | [0x0b7b86DCEAa8015CeD8F625d3b7A961b31fB05FE](https://etherscan.io/address/0x0b7b86DCEAa8015CeD8F625d3b7A961b31fB05FE) | [0x510c2F7e19a8f2537A3fe3Cf847e6583b993FA60](https://goerli.etherscan.io/address/0x510c2F7e19a8f2537A3fe3Cf847e6583b993FA60) | [0x65778953D291DD1e3a97c6b4d8BEea188B650077](https://basescan.org/address/0x65778953D291DD1e3a97c6b4d8BEea188B650077) | [0x1b5cB8bb71edA9059d39c98348095B008b67e734](https://goerli.basescan.org/address/0x1b5cB8bb71edA9059d39c98348095B008b67e734) |\n| `ProposalExecutionEngine`     | [0xdf6a4d97dd2aa32a54b8a2b2711f210b711f28f0](https://etherscan.io/address/0xdf6a4d97dd2aa32a54b8a2b2711f210b711f28f0) | [0xc148E6f886CccdA5dEBbBA10d864d007E0C74c85](https://goerli.etherscan.io/address/0xc148E6f886CccdA5dEBbBA10d864d007E0C74c85) | [0xaec4D40045DaF91Bc3049ea9136C7dF04bD8a6af](https://basescan.org/address/0xaec4D40045DaF91Bc3049ea9136C7dF04bD8a6af) | [0xafE8265538F97e9F2Ff459F4aD871892a292419b](https://goerli.basescan.org/address/0xafE8265538F97e9F2Ff459F4aD871892a292419b) |\n| `Party`                       | [0xb676cfeeed5c7b739452a502f1eff9ab684a56da](https://etherscan.io/address/0xb676cfeeed5c7b739452a502f1eff9ab684a56da) | [0x72a4b63eceA9465e3984CDEe1354b9CF9030c043](https://goerli.etherscan.io/address/0x72a4b63eceA9465e3984CDEe1354b9CF9030c043) | [0x65EBb1f88AA377ee56E8114234d5721eb4C5BAfd](https://basescan.org/address/0x65EBb1f88AA377ee56E8114234d5721eb4C5BAfd) | [0xe46b1B3D7eF3421D96F06D13d641dD702d44904e](https://goerli.basescan.org/address/0xe46b1B3D7eF3421D96F06D13d641dD702d44904e) |\n| `PartyFactory`                | [0x2dFA21A5EbF5CcBE62566458A1baEC6B1F33f292](https://etherscan.io/address/0x2dFA21A5EbF5CcBE62566458A1baEC6B1F33f292) | [0x83e63E8bAba6C6dcb9F3F4324bEfA72AD8f43e44](https://goerli.etherscan.io/address/0x83e63E8bAba6C6dcb9F3F4324bEfA72AD8f43e44) | [0xF8c8fC091C0Cc94a9029d6443050bDfF9097E38A](https://basescan.org/address/0xF8c8fC091C0Cc94a9029d6443050bDfF9097E38A) | [0xa7C2ede6A4ebdE4EE86E600D339F9F236B8C1275](https://goerli.basescan.org/address/0xa7C2ede6A4ebdE4EE86E600D339F9F236B8C1275) |\n| `AuctionCrowdfund`            | [0xcf8ab207e1b055871dfa9be2a0cf3acaf2d1b3a7](https://etherscan.io/address/0xcf8ab207e1b055871dfa9be2a0cf3acaf2d1b3a7) | [0x631D392073330f0573AD18Fc64305768657D0D60](https://goerli.etherscan.io/address/0x631D392073330f0573AD18Fc64305768657D0D60) | [0xcF8ab207E1b055871dfa9be2a0Cf3acAf2d1b3A7](https://basescan.org/address/0xcF8ab207E1b055871dfa9be2a0Cf3acAf2d1b3A7) | [0x70a842F6131031266438171731f1d2ACfd9EC891](https://goerli.basescan.org/address/0x70a842F6131031266438171731f1d2ACfd9EC891) |\n| `RollingAuctionCrowdfund`     | [0x1b5cb8bb71eda9059d39c98348095b008b67e734](https://etherscan.io/address/0x1b5cb8bb71eda9059d39c98348095b008b67e734) | [0x989Fb364065a80d732837742f960924f343C6E04](https://goerli.etherscan.io/address/0x989Fb364065a80d732837742f960924f343C6E04) | [0x2e8920950677F8545B4Ef80315f48E161CB02D1C](https://basescan.org/address/0x2e8920950677F8545B4Ef80315f48E161CB02D1C) | [0x73B66c97e53301651E69D10743352B411d480c3f](https://goerli.basescan.org/address/0x73B66c97e53301651E69D10743352B411d480c3f) |\n| `BuyCrowdfund`                \n\n[... truncated ...]"
  },
  "velodrome-finance/superchain-contracts": {
    "fetchedAt": "2025-11-12T23:03:26.471Z",
    "content": "# Velodrome Superchain Contracts\n\nCore smart contracts for the Velodrome Superchain. This includes the Superchain\nspecific contracts (message passing, xERC20, etc) as well as the base v2 contracts.\n\nFor information on specific contracts, see `SPECIFICATION.md.`. Integrators should\nrefer to the integrators section below.\n\n## Installation\n\nThis repository depends on:\n\nnode v20 (recommend managing node versions using nvm)\nfoundry\nyarn\n\nTo install & run:\n\n```\nyarn install\nforge b\n\nforge t -vv\n```\n\nThis repository uses `forge fmt` to format code and bulloak for test layouts.\n\n## Deployment\n\nPopulate `foundry.toml` with the environment variables required for RPC and contract verification.\n\nRun the following commands to check that the CreateX factory has the correct code. See [here](https://github.com/pcaversaccio/createx/blob/43adf407f1313c5975c7db106092c3b636323ef6/README.md?plain=1#L844) for more information. This is now done in the script, but feel free to check.\n\n```\n[[ $(cast keccak $(cast code 0xba5Ed099633D3B313e4D5F7bdc1305d3c28ba5Ed --rpc-url {RPC_URL})) == \"0xbd8a7ea8cfca7b4e5f5041d7d4b17bc317c5ce42cfbc42066a00cf26b43eb53f\" ]] && echo \"Hash Matches\" || echo \"Hash Does Not Match\"\n```\n\nDeploy Root contracts first:\n\n```\nforge script script/deployParameters/optimism/DeployRootBase.s.sol:DeployRootBase --slow --rpc-url optimism -vvvv\nforge script script/deployParameters/optimism/DeployRootBase.s.sol:DeployRootBase --slow --rpc-url optimism --broadcast --verify -vvvv\n```\n\nDeploy Leaf contracts next:\n\nReplace `leaf` with the chain you are deploying to.\n\n```\nforge script script/deployParameters/leaf/DeployBase.s.sol:DeployBase --slow --rpc-url leaf -vvvv\nforge script script/deployParameters/leaf/DeployBase.s.sol:DeployBase --slow --rpc-url leaf --broadcast --verify -vvvv\n```\n\nIf there is a verification failure, simply remove `--broadcast` and add `--resume`.\n\n## Verification\n\nFor verifications, fill out the verifier config in `foundry.toml`.\n\nFor blockscout verifications, append `--verifier blockscout` after `--verify`\n\n## Integrators\n\nExisting contracts that manage nfts that vote on Velodrome must add support for additional logic in \norder to be able to participate in Superchain Velodrome.\n\nSome additional information for developers building contracts that interact with Superchain Velodrome:\n- Contracts that wish to vote for a certain chain must explicitly set a rewards recipient for that chain by calling `setRecipient` on\n the `RootVotingRewardsFactory` contract.\n- Users interacting with smart contracts that are voting cross chain must approve a small amount of\n WETH to the `RootMessageBridge` as payment for gas.\n- The token bridge may be sunset in the future in favor of alternate token bridging mechanisms.\n    - The interface will remain the same, but the implementation will change and be deployed as a new contract.\n\n## xERC20\n\nThe xERC20 implementation in this repository has been modified lightly from \nthe moonwell xERC20 implementation to support native Superchain interop in the future.\n\n## Licensing\n\nThis project follows the [Apache Foundation](https://infra.apache.org/licensing-howto.html)\nguideline for licensing. See LICENSE and NOTICE files.\n\n## Bug Bounty\nVelodrome has a live bug bounty hosted on ([Immunefi](https://immunefi.com/bounty/velodromefinance/)).\n\n## Deployments\n\n| Chain      | Addresses          | Deployment Commit |\n|------------|--------------------|-------------------|\n| Optimism   | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/optimism.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      |\n| Mode       | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/mode.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      |\n| Lisk       | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/lisk.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      |\n| Fraxtal    | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/fraxtal.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      |\n| Metal    | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/metal.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      | \n| Superseed  | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/superseed.json)         | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      |\n| Ink      | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/ink.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      | \n| Soneium  | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/soneium.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      | \n| Swell    | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/swell.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      | \n| Unichain | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/unichain.json)           | [v1.0](https://github.com/velodrome-finance/superchain-contracts/commit/a739cdd788673d5fb08736e456fd8ec15d262dc7)      | \n| Celo     | [Addresses](https://github.com/velodrome-finance/superchain-contracts/blob/main/deployment-addresses/celo.json)           | [v1.1](https://github.com/velodrome-finance/superchain-contracts/commit/b0e98b33519ca3ee17e64147eb81162ec4c67479)      | \n\nOptimism contains the root deployment contracts, and these factory addresses are \nused by all leaf chains."
  },
  "velodrome-finance/sugar": {
    "fetchedAt": "2025-11-12T23:03:26.745Z",
    "content": "![Sugar](https://github.com/user-attachments/assets/f670631c-6d22-4434-865e-20f1ba93b9cd)\n\n# Sugar\n\nOnchain API for Velodrome and Aerodrome developers!\n\n## How come?!\n\nThe idea is pretty simple, instead of relying on our API for a structured\ndata set of liquidity pool data, these contracts can be called in an\nefficient way to directly fetch the same data off-chain.\n\nWhat normally would require:\n  1. fetching the number of liquidity pools\n  2. querying every pool address at it's index\n  3. querying pool tokens data\n  4. querying gauge addresses and reward rate\n\nTakes a single call with _sugar_!\n\nMore importantly, the response can be paginated.\n\nMain goals of this little project are:\n  * to maximize the developers UX of working with our protocol\n  * simplify complexity\n  * document and test everything\n\n## But how?\n\nOn-chain data is organized for transaction cost and efficiency. We think\nwe can hide a lot of the complexity by leveraging `structs` to present the data\nand normalize it based on it's relevancy.\n\n## Usage\n\nBelow is the list of datasets we support.\n\n### Liquidity Pools Data\n\nIt allows fetching on-chain pools data.\nThe returned data/struct of type `Lp` values represent:\n\n * `lp` - pool contract address\n * `symbol` - pool symbol\n * `decimals` - pool decimals\n * `liquidity` - pool tokens supply\n * `type` - tick spacing on CL pools, 0/-1 for stable/volatile on v2 pools\n * `tick` - current tick on CL pools, 0 on v2 pools\n * `sqrt_ratio` - pool sqrt ratio X96 on CL pools, 0 on v2 pools\n * `token0` - pool 1st token address\n * `reserve0` - pool 1st token reserves (nr. of tokens in the contract)\n * `staked0` - pool 1st token staked amount\n * `token1` - pool 2nd token address\n * `reserve1` - pool 2nd token reserves (nr. of tokens in the contract)\n * `staked1` - pool 2nd token staked amount\n * `gauge` - pool gauge address\n * `gauge_liquidity` - pool staked tokens (less/eq than/to pool total supply)\n * `gauge_alive` - indicates if the gauge is still active\n * `fee` - pool gauge fees contract address, CL pools use hundredths of a bip (i.e. 1e-6)\n * `bribe` - pool gauge bribes contract address\n * `factory` - pool factory address\n * `emissions` - pool emissions (per second)\n * `emissions_token` - pool emissions token address\n * `emissions_cap` - pool emissions cap measured in bps of weekly emissions\n * `pool_fee` - pool swap fee (percentage)\n * `unstaked_fee` - unstaked fee percentage on CL pools, 0 on v2 pools\n * `token0_fees` - current epoch token0 accrued fees (next week gauge fees)\n * `token1_fees` - current epoch token1 accrued fees (next week gauge fees)\n * `locked` - pool total locked liquidity amount\n * `emerging` - indicates if the pool is emerging\n * `created_at` - pool creation timestamp\n * `nfpm` - pool non-fungible position manager contract address\n * `alm` - pool ALM vault contract address\n * `root` - root (placeholder) pool, for (non-canonical) leaf chain pools\n\n---\n\nThe available methods are:\n * `LpSugar.all(_limit: uint256, _offset: uint256) -> Lp[]` -\n   returns a paginated list of `Lp` structs.\n * `LpSugar.byIndex(_index: uint256) -> Lp` - returns the\n   `Lp` data for a specific index of a pool.\n * `LpSugar.byAddress(_pool: address) -> Lp` - returns the\n   `Lp` data for a specific pool address.\n * `LpSugar.count() -> uint256` - returns the total number of pools.\n\n---\n\nTo get the positions of an account, use this function:\n * `LpSugar.positions(_limit, _offset, _account) -> Position[]`\n * `LpSugar.positionsUnstakedConcentrated(_limit, _offset, _account) -> Position[]`\n\nThe later call is required for deployments prior to Superchain release.\n\nThe returned data is a struct of type `Position` with the following values:\n  * `id` - NFT ID on CL pools, 0 on v2 pools\n  * `lp` - liquidity pool contract address\n  * `liquidity` - liquidity amount on CL, deposited LP tokens on v2\n  * `staked` -  staked/unstaked liquidity amount on CL, amount of staked tokens on v2\n  * `amount0` - amount of unstaked token0 in the position\n  * `amount1` - amount of unstaked token1 in the position\n  * `staked0` - amount of staked token0 in the position\n  * `staked1` - amount of staked token1 in the position\n  * `unstaked_earned0` - unstaked token0 fees earned\n  * `unstaked_earned1` - unstaked token1 fees earned\n  * `emissions_earned` - emissions earned from staked position\n  * `tick_lower` - lower tick of position on CL, 0 on v2\n  * `tick_upper` - upper tick of position on CL, 0 on v2\n  * `sqrt_ratio_lower` - sqrt ratio X96 at lower tick on CL, 0 on v2\n  * `sqrt_ratio_upper` - sqrt ratio X96 at upper tick on CL, 0 on v2\n  * `locker` - locker address for locked launcher liquidity, 0 otherwise\n  * `unlocks_at` - unlock timestamp for locked launcher liquidity, 0 otherwise\n  * `alm` - pool ALM vault contract address\n\n---\n\nThe pools token list (compiled from all the pools `token0`/`token1`) uses the type\n`Token` with the following values:\n\n * `token_address` - the token address\n * `symbol` - the token symbol\n * `decimals` - the token decimals\n * `account_balance` - the provided account/wallet balance\n * `listed` - indicates if the token was listed for gauge voting rewards\n * `emerging` - indicates if the token is an emerging token from the launcher\n\nTo fetch the token list this method is available:\n\n * `LpSugar.tokens(_limit: uint256, _offset: uint256, _account: address, _oracle: address, _oracle_connectors: address[]) -> Token[]`\n\n### veNFT and Pool Rewards Data\n\nFor the pool epoch data we return, starting with most recent epoch, a struct of\ntype `LpEpoch` with the following values:\n\n * `ts` - the start of the epoch/week timestamp\n * `lp` - the pool address\n * `votes` - the amount of the votes for that epoch/week\n * `emissions` - emissions per second for that epoch/week\n * `bribes` - a list of bribes data, it is a struct of type `LpEpochBribe` with\n   the following values:\n    * `token` - bribe token address\n    * `amount` - bribe amount\n * `fees` - a list of fees data, it is a struct of type `LpEpochBribe`,\n   just like the `bribes` list\n\nTo fetch a list of epochs for a specific pool, this method is available:\n\n * `RewardsSugar.epochsByAddress(_limit: uint256, _offset: uint256, _address: address) -> LpEpoch[]`\n\nTo fetch a list of latest epochs data for a every pool, this method is available:\n\n * `RewardsSugar.epochsLatest(_limit: uint256, _offset: uint256) -> LpEpoch[]`\n\n---\n\nFor the rewards, we return a struct of type `Reward` with the following\nvalues:\n\n * `venft_id` - the veNFT id it belongs to\n * `lp` - the pool address representing the source of the reward\n * `amount` - the amount of the tokens accrued\n * `token` - the reward token address\n * `fee` - the fee contract address (if the reward comes from fees)\n * `bribe` - the bribe contract address (if the reward comes from bribes)\n\nTo fetch a list of rewards for a specific veNFT, this method is available:\n\n * `RewardsSugar.rewards(_limit: uint256, _offset: uint256, _venft_id: uint256) -> Reward[]`\n * `RewardsSugar.rewardsByAddress(_venft_id: uint256, _pool: address) -> Reward[]`\n\n### Vote-Escrow Locked NFT (veNFT) Data\n\nIt allows fetching on-chain veNFT data (including the rewards accrued).\nThe returned data/struct of type `VeNFT` values represent:\n\n  * `id` - veNFT token ID\n  * `account` - veNFT token account address\n  * `decimals` - veNFT token decimals\n  * `amount` - veNFT locked amount\n  * `voting_amount` - veNFT voting power\n  * `governance_amount` - veNFT voting power in governance\n  * `rebase_amount` - veNFT accrued reabses amount\n  * `expires_at` - veNFT lock expiration timestamp\n  * `voted_at` - veNFT last vote timestamp\n  * `votes` - veNFT list of pools with vote weights casted in the form of\n    `LpVotes`\n  * `token` - veNFT locked token address\n  * `permanent` - veNFT permanent lock enabled flag\n  * `delegate_id` - token ID of the veNFT being delegated to\n\nThe pool votes struct values represent:\n  * `lp` - the pool address\n  * `weight` - the vote weights of the vote for the pool\n\n---\n\nThe available methods \n\n[... truncated ...]"
  },
  "velodrome-finance/universal-router": {
    "fetchedAt": "2025-11-12T23:03:27.072Z",
    "content": "# Universal Router\n\nThe Uniswap Universal Router was adapted to work with the Velodrome ecosystem. This router allows a single swap to be routed through both Velodrome Finance pools and Uniswap pools.\n\nTo see the commit of the smart contracts that was used in the latest deployment, see branch `deployed-commit`. To see the addresses of this latest deployment on each network, see folder `deploy-addresses`.\n\n## High-Level Overview\n\nThe Universal Router is a ERC20 and NFT swap router that allows users greater flexibility when performing trades across multiple token types.\n\nOur flexible command style allows us to provide users with:\n\n- Splitting and interleaving of Uniswap trades\n- Purchases of NFTs across 8 marketplaces\n- Partial fills of trades\n- Wrapping and Unwrapping of ETH\n- Time-bound, signature controlled token approvals using [Permit2](https://github.com/Uniswap/permit2)\n\nTransactions are encoded using a string of commands, allowing users to have maximum flexibility over what they want to perform. With all of these features available in a single transaction, the possibilities available to users are endless\n\n## Contract Overview\n\nThe Universal Router codebase consists of the `UniversalRouter` contract, and all of its dependencies. The purpose of the `UniversalRouter` is to allow users to unify Uniswap ERC20 swaps (on V2 and V3) with NFT purchases across 8 marketplaces, in a single transaction.\n\n`UniversalRouter` integrates with [Permit2](https://github.com/Uniswap/permit2), to enable users to have more safety, flexibility, and control over their ERC20 token approvals.\n\n### UniversalRouter command encoding\n\nCalls to `UniversalRouter.execute`, the entrypoint to the contracts, provide 2 main parameters:\n\n- `bytes commands`: A bytes string. Each individual byte represents 1 command that the transaction will execute.\n- `bytes[] inputs`: An array of bytes strings. Each element in the array is the encoded parameters for a command.\n\n`commands[i]` is the command that will use `inputs[i]` as its encoded input parameters.\n\nThrough function overloading there is also an optional third parameter for the `execute` function:\n\n- `uint256 deadline`: The timestamp deadline by which this transaction must be executed. Transactions executed after this specified deadline will revert.\n\n#### How the command byte is structured\n\nEach command is a `bytes1` containing the following 8 bits:\n\n```\n 0 1 2 3 4 5 6 7\n‚îå‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇf‚îÇr|  command  ‚îÇ\n‚îî‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n- `f` is a single bit flag, that signals whether or not the command should be allowed to revert. If `f` is `false`, and the command reverts, then the entire transaction will revert. If `f` is `true` and the command reverts then the transaction will continue, allowing us to achieve partial fills. If using this flag, be careful to include further commands that will remove any funds that could be left unused in the `UniversalRouter` contract.\n\n- `r` is one bit of reserved space. This will allow us to increase the space used for commands, or add new flags in future.\n\n- `command` is a 6 bit unique identifier for the command that should be carried out. The values of these commands can be found within Commands.sol, or can be viewed in the table below.\n\n```\n   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n   ‚îÇ 0x00 ‚îÇ  V3_SWAP_EXACT_IN             ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x01 ‚îÇ  V3_SWAP_EXACT_OUT            ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x02 ‚îÇ  PERMIT2_TRANSFER_FROM        ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x03 ‚îÇ  PERMIT2_PERMIT_BATCH         ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x04 ‚îÇ  SWEEP                        ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x05 ‚îÇ  TRANSFER                     ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x06 ‚îÇ  PAY_PORTION                  ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x07 ‚îÇ  -------                      ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x08 ‚îÇ  V2_SWAP_EXACT_IN             ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x09 ‚îÇ  V2_SWAP_EXACT_OUT            ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x0a ‚îÇ  PERMIT2_PERMIT               ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x0b ‚îÇ  WRAP_ETH                     ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x0c ‚îÇ  UNWRAP_WETH                  ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x0d ‚îÇ  PERMIT2_TRANSFER_FROM_BATCH  ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x0e-‚îÇ  -------                      ‚îÇ\n   ‚îÇ 0x20 ‚îÇ                               ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x21 ‚îÇ  EXECUTE_SUB_PLAN             ‚îÇ\n   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n   ‚îÇ 0x22-‚îÇ  -------                      ‚îÇ\n   ‚îÇ 0x3f ‚îÇ                               ‚îÇ\n   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nNote that some of the commands in the middle of the series are unused. These gaps allowed us to create gas-efficiencies when selecting which command to execute.\n\n#### How the input bytes are structured\n\nEach input bytes string is merely the abi encoding of a set of parameters. Depending on the command chosen, the input bytes string will be different. For example:\n\nThe inputs for `V3_SWAP_EXACT_IN` is the encoding of 5 parameters:\n\n- `address` The recipient of the output of the trade\n- `uint256` The amount of input tokens for the trade\n- `uint256` The minimum amount of output tokens the user wants\n- `bytes` The UniswapV3 path you want to trade along\n- `bool` A flag for whether the input funds should come from the caller (through Permit2) or whether the funds are already in the UniversalRouter\n- `bool` A flag for whether the swap should be executed using UniV3 or Slipstream pools\n\nWhereas in contrast `CRYPTOPUNKS` has just 3 parameters encoded:\n\n- `uint256` The ID of the punk you wish to purchase\n- `address` The recipient of the punk\n- `uint256` The amount of ETH to pay for the punk\n\nEncoding parameters in a bytes string in this way gives us maximum flexiblity to be able to support many commands which require different datatypes in a gas-efficient way.\n\nFor a more detailed breakdown of which parameters you should provide for each command take a look at the `Dispatcher.dispatch` function, or alternatively at the `ABI_DEFINITION` mapping in `planner.ts`.\n\nDeveloper documentation to give a detailed explanation of the inputs for every command will be coming soon!\n\n## Usage\n\n### To Compile and Run Tests\n\n1. Clone the repository with all submodules\n\nClone the repository with:\n```\ngit clone --recurse-submodules https://github.com/Uniswap/universal-router.git\n```\n\n2. Create `.env` file with a complete fork url.\n\n```\nOPTIMISM_RPC_URL=''\n```\n\n3. Run yarn commands to compile and test\n\n### To Run Hardhat Tests\n\n```console\nyarn install\nyarn compile\nyarn test\n```\n\nIf you run into an issue on `yarn compile` where it cannot find the dependencies in the lib folder try to clone all the submodules with:\n```\ngit submodule update --init --recursive\n```\n\n#### To Update Hardhat Gas Snapshots\n\n```console\nyarn test:gas\n```\n\n### To Run Forge Tests\n\n```console\nforge install\nforge build\nforge test\n```\n## Integrating\n\n1. Install the latest version of `@uniswap/universal-router` package.\n2. Add git submodules for contracts that aren't a node package. Make sure there's an empty `.gitmodules` file. Then run:\n    ```bash\n      git submodule add https://github.com/transmissions11/solmate\n      git submodule add https://github.com/Uniswap/permit2\n    ```\n3. You should now be able to import contracts from universal-router and compile.\n\n## Contributions\nBefore you submit your PR, run all of the following and commit the changes:\n```bash\n# make sure all tests pass this will also update gas snapshots\nyarn test:all\n\n# lint code\nyarn prettier:fix\n```\n\nIf you are only concerned with investigating gas diffs, you can run this command to only run gas tests\n```bash\nyarn test:gas\n```\n\n### To Deploy\n\nFill out par\n\n[... truncated ...]"
  },
  "velodrome-finance/slipstream": {
    "fetchedAt": "2025-11-12T23:03:27.415Z",
    "content": "# Slipstream\n\nThis repository contains the smart contracts for the Slipstream Concentrated Liquidity contracts. It contains\nthe core concentrated liquidity contracts, adapted from UniswapV3's core contracts. It contains the higher level\nperiphery contracts, adapted from UniswapV3's periphery contracts. It also contains gauges designed to operate\nwithin the Velodrome ecosystem.  \n\nSee `SPECIFICATION.md` and `CHANGELOG.md` for more information. \n\n## Installation\n\nThis repository is a hybrid hardhat and foundry repository.\n\nInstall hardhat dependencies with `yarn install`.\nInstall foundry dependencies with `forge install`.\n\nRun hardhat tests with `yarn test`.\nRun forge tests with `forge test`.\n\n## Testing\n\n### Invariants\n\nTo run the invariant tests, echidna must be installed. The following instructions require additional installations (e.g. of solc-select). \n\n```\nechidna test/invariants/E2E_mint_burn.sol --config test/invariants/E2E_mint_burn.config.yaml --contract E2E_mint_burn\nechidna test/invariants/E2E_swap.sol --config test/invariants/E2E_swap.config.yaml --contract E2E_swap\n```\n\n## Licensing\n\nAs this repository depends on the UniswapV3 `v3-core` and `v3-periphery` repository, the contracts in the \n`contracts/core` and  `contracts/periphery` folders are licensed under `GPL-2.0-or-later` or alternative \nlicenses (as indicated in their SPDX headers).\n\nFiles in the `contracts/gauge` folder are licensed under the Business Source License 1.1 (`BUSL-1.1`).\n\n## Bug Bounty\nVelodrome has a live bug bounty hosted on ([Immunefi](https://immunefi.com/bounty/velodromefinance/)).\n\n## Deployment\n\n| Name               | Address                                                                                                                               |\n| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------ |\n| GaugeFactory               | [0x327147eE440252b893A771345025B41A267Ad985](https://optimistic.etherscan.io/address/0x327147eE440252b893A771345025B41A267Ad985#code) |\n| GaugeImplementation               | [0x7155b84A704F0657975827c65Ff6fe42e3A962bb](https://optimistic.etherscan.io/address/0x7155b84A704F0657975827c65Ff6fe42e3A962bb#code) |\n| MixedQuoter               | [0xFF79ec912bA114FD7989b9A2b90C65f0c1b44722](https://optimistic.etherscan.io/address/0xFF79ec912bA114FD7989b9A2b90C65f0c1b44722#code) |\n| NonfungiblePositionManager               | [0x416b433906b1B72FA758e166e239c43d68dC6F29](https://optimistic.etherscan.io/address/0x416b433906b1B72FA758e166e239c43d68dC6F29#code) |\n| NonfungibleTokenPositionDescriptor               | [0xccDf417f49a14bC2b23c71684de0304C56DEA165](https://optimistic.etherscan.io/address/0xccDf417f49a14bC2b23c71684de0304C56DEA165#code) |\n| PoolFactory               | [0xCc0bDDB707055e04e497aB22a59c2aF4391cd12F](https://optimistic.etherscan.io/address/0xCc0bDDB707055e04e497aB22a59c2aF4391cd12F#code) |\n| PoolImplementation               | [0xc28aD28853A547556780BEBF7847628501A3bCbb](https://optimistic.etherscan.io/address/0xc28aD28853A547556780BEBF7847628501A3bCbb#code) |\n| QuoterV2               | [0x89D8218ed5fF1e46d8dcd33fb0bbeE3be1621466](https://optimistic.etherscan.io/address/0x89D8218ed5fF1e46d8dcd33fb0bbeE3be1621466#code) |\n| CustomSwapFeeModule               | [0x7361E9079920fb75496E9764A2665d8ee5049D5f](https://optimistic.etherscan.io/address/0x7361E9079920fb75496E9764A2665d8ee5049D5f#code) |\n| CustomUnstakedFeeModule               | [0xC565F7ba9c56b157Da983c4Db30e13F5f06C59D9](https://optimistic.etherscan.io/address/0xC565F7ba9c56b157Da983c4Db30e13F5f06C59D9#code) |\n| Swap Router               | [0x0792a633F0c19c351081CF4B211F68F79bCc9676](http://optimistic.etherscan.io/address/0x0792a633F0c19c351081CF4B211F68F79bCc9676#code) |\n| LpMigrator                | [0x3Fdb481B25b24824A2339a4A1AbD0B0BC7534e71](http://optimistic.etherscan.io/address/0x3Fdb481B25b24824A2339a4A1AbD0B0BC7534e71#code) |"
  },
  "velodrome-finance/relay": {
    "fetchedAt": "2025-11-12T23:03:27.758Z",
    "content": "# Relay\n\nIntroduced in Velodrome V2 is a new type of veNFT called a \"managed NFT\" (also known as \"(m)veNFT\").\nA (m)veNFT aggregates veNFT voting power into a single NFT, with rewards accrued by the NFT going to\nthe owner of the (m)veNFT. The (m)veNFT votes for pools in the same way a normal veNFT votes, with\nthe exception that its' voting power is this aggregated voting power.\n\nThe challenge arises when a (m)veNFT has earned rewards from a voting period. Does the (m)veNFT\nowner keep the rewards for themselves, distribute the rewards back to the veNFT depositors (either\nas the reward token or as VELO), or do something else with these rewards? The Velodrome team\nprovides a working MVP to solve this.\n\n## Challenge\n\nProvide a trusted and automated solution to distribute rewards earned by a (m)veNFT back to its'\ndepositors.\n\n## Solution\n\nAn automated contract to convert rewards earned by a (m)veNFT back into the intended token.\nAutocompounder will convert it to VELO and then deposit into the (m)veNFT. Autoconverter will only\nconvert it to the Autoconverter token. The autocompounder's (m)veNFT voting power increases from\nthese VELO deposits, further increasing the rewards earned. When a normal veNFT holder who\npreviously deposited into this (m)veNFT withdraws their veNFT from the (m)veNFT back to their\nwallet, they receive their initial deposit back, as well as their proportional share of all\ncompounded rewards.\n\n## Features\n\nThere are two types of Relays with similar functionalities:\n\n|                           | Autocompounder                      | Autoconverter                         |\n| ------------------------- | ----------------------------------- | ------------------------------------- |\n| Claim Rewards             | Yes                                 | Yes                                   |\n| Swap                      | Yes (only to VELO)                  | Yes (only to the Autoconverter token) |\n| Compound                  | Yes                                 | No                                    |\n| Reward paid to caller[^1] | Yes                                 | No                                    |\n| Sweep tokens              | Yes (if not a high liquidity token) | Yes (any token)                       |\n| Vote                      | Yes                                 | Yes                                   |\n| Increase rewards          | Yes                                 | No                                    |\n| Set caller reward amount  | Yes                                 | No                                    |\n| Add high liquidity tokens | Yes                                 | Yes                                   |\n| Add/remove Keepers        | Yes                                 | Yes                                   |\n\n## Implementation\n\nThere are several key components of the `Relay`:\n\n-   Access control / trust levels\n-   Time windows of access\n-   (m)veNFT design considerations\n\n## Access Control / Trust levels\n\nThere are degrees of trust and access given to various groups. The groups are:\n\n-   Public\n-   Keepers\n-   Allowed callers\n-   Relay Admins\n-   Velodrome team\n\n### Public\n\nCan be any EOA or contract. Are allowed to claim rewards, swap (and compound - for autocompounders)\nwithin the last 24 hours of an epoch. Swap routes are determined using a fixed optimizer contract,\nalthough callers can provide their own custom route provided there is a better return. The optional\nswap route provided must only route through high liquidity tokens, as added by team. In the\nautocompounder, Public callers are rewarded based on the amount compounded - they receive a minimum\nof either (a) 1% of the VELO converted from swaps (rounded down) or (b) the constant VELO reward set\nby the team.\n\n### Keepers\n\nAddresses authorized by Velodrome team to claim rewards (and compound - for autocompounders)\nstarting one hour after epoch flips. Keepers are trusted to swap rewarded tokens using the routes\nthey determine (as long as they are better than the routes provided by the optimizer) which is then\ndeposited into the (m)veNFT.\n\n### Allowed Callers\n\nAddresses authorized by the Relay admin to vote for gauges and send additional VELO rewards to the\n(m)veNFT to be distributed among veNFTs who have locked into the (m)veNFT.\n\n### Relay Admins\n\nAn initial admin is set on Relay creation who can then add/remove other admins, as well as revoke\ntheir own admin role. Admins can also add/remove Allowed Callers. Within the first 24 hours after an\nepoch flip, an admin can claim and sweep reward tokens to any recipients.\n\n### Velodrome Team\n\nThe team can set the VELO reward amount for public callers, add high liquidity tokens, and\nadd/remove keepers.\n\n## Roles\n\n|                           | Public | Keeper | Allowed Caller | Admin                               | Velodrome Team |\n| ------------------------- | ------ | ------ | -------------- | ----------------------------------- | -------------- |\n| Claim Rewards             | Yes    | Yes    |                | Yes                                 |                |\n| Swap and Compound         | Yes    | Yes    |                | Yes                                 |                |\n| Reward paid to caller[^1] | Yes    |        |                |                                     |                |\n| Sweep tokens              |        |        |                | Yes (if not a high liquidity token) |                |\n| Vote & increase rewards   |        |        | Yes            |                                     |                |\n| Set caller reward amount  |        |        |                |                                     | Yes            |\n| Add high liquidity tokens |        |        |                |                                     | Yes            |\n| Add/remove Keepers        |        |        |                |                                     | Yes            |\n\n## Time Windows of Access\n\n| Who             | First hour | Middle[^2] | Last 24 Hours |\n| --------------- | ---------- | ---------- | ------------- |\n| Public          |            |            | X             |\n| Keeper          |            | X          | X             |\n| Allowed Callers | X          | X          | X             |\n| Admin           | X          | X          | X             |\n| Team            | X          | X          | X             |\n\n## (m)veNFT Design Considerations\n\n### Who can create a Relay?\n\nAnyone who owns a (m)veNFT can create a Relay. Only the `allowedManager` role within VotingEscrow\nand the `governor` role within Voter have permission to create a (m)veNFT. The (m)veNFT is sent to\nthe Relay in creation where it will permanently reside.\n\n### Lack of Governance voting ability\n\nAnyone with a normal veNFT can deposit into a (m)veNFT. Therefore, we expect to see (m)veNFTs\ncontrolled with the aggregate voting power of hundreds normal veNFTs or more. The motivation in\ndepositing a normal veNFT is to earn passive rewards, not to delegate voting power for governance.\nHowever, the cumulative voting power of the (m)veNFT could be significant enough to influence\nVelodrome governance proposals. Therefore, the Relay is designed:\n\n-   Without governance voting functionality\n-   No ability to withdraw the (m)veNFT\n\nSo, once a (m)veNFT is deposited into a Relay, it will stay there permanently.\n\n### Leaving the (m)veNFT\n\nWhat happens if a (m)veNFT is deactivated by the team? What happens if the controllers for the\n(m)veNFT can no longer be trusted to act in the best interest of the veNFT depositors? What happens\nif a veNFT depositor finds a different (m)veNFT to deposit into, or if they decide to vote from\ntheir own veNFT again? The answer to these questions is the same:\n\n**At any time, a normal veNFT can be withdrawn from its' deposited (m)veNFT, as long as it has _not_\nbeen deposited within the same epoch**.\n\n### What if Keepers provide less-than-optimal routes to extract value?\n\nThe routes provided by \n\n[... truncated ...]"
  },
  "velodrome-finance/oracle": {
    "fetchedAt": "2025-11-12T23:03:28.137Z",
    "content": "# Optimism Prices\n\nThe Optimism Prices contracts are a lightweight, trustless, and reliable method of pricing tokens on Optimism. \n\n# Explanation\n\nThe current state of token price APIs is not suitable for today's increasingly complex DeFi use cases. Many dapps and services need to be able to quickly and reliably price arbitrary ERC20 tokens, but centralized price APIs don't offer full coverage, frequently failing to price or mispricing illiquid tokens. The Optimism Prices contracts address this. Optimism Prices returns token price data in one smart contract call, and can price any ERC20 against another, while also allowing developers to specify which \"hop\" assets they want the contract to check to determine the most liquid route from point A to point B.\n\n# Usage\n\nOptimism Prices is currently deployed at `0x395942C2049604a314d39F370Dfb8D87AAC89e16`. \n\nTo retrieve the price of tokens denominated in another token, you'll need to call the `getManyRatesWithConnectors` function.\n`getManyRatesWithConnnectors` accepts two arguments, `src_len`, an integer representing the number of tokens to price, and `connectors`, an array with the tokens that you want to price at the front, the connector tokens to use as hops in the middle, and the denominator token as the last element. \n\nIf a user wants to price WETH, SNX, LDO, and WBTC in USDC denomination, and they want to check common liquid routes, they would make a call such as `getManyRatesWithConnectors(4, [WETH, SNX, LDO, WBTC, OP, WETH, sUSD, DAI, wstETH, USDC])`. In this case, OP, WETH, sUSD, DAI, and wstETH are being used as connector tokens to check the most liquid routes between the tokens we're trying to price and the denominator token. All of the tokens in the middle of the array should be tokens that you want the contract to check for liquid routes. If you know that there are a few specific assets that your src tokens are often paired against, try adding those tokens in the middle of the array. If you're calling the function for many arbitrary tokens as part of your dapp, we recommend always making calls with common pair tokens in the middle of the `connnectors` array, such as WETH, USDC, and OP.\n\n# To-do\n\n- [x] Get Optimism Prices indexed by Dune to support full price coverage of all tokens in liquidity pools on Optimism *(Now being indexed as of July 2023 via automaed calling of PriceFetcher.sol's `fetchPrices` function)*\n- Add TWAP support to allow for Optimism Prices contracts to be used in cases where short term price manipulation of tokens is undesired\n"
  },
  "velodrome-finance/contracts": {
    "fetchedAt": "2025-11-12T23:03:28.447Z",
    "content": "# Velodrome\n\nV2 contracts for Velodrome Finance, an AMM on Optimism inspired by Solidly.\n\nSee `SPECIFICATION.md` for more detail.\n\n## Protocol Overview\n\n### AMM contracts\n\n| Filename | Description |\n| --- | --- |\n| `Pool.sol` | AMM constant-product implementation similar to Uniswap V2 liquidity pools |\n| `Router.sol` | Handles multi-pool swaps, deposit/withdrawal, similar to Uniswap V2 Router interface |\n| `PoolFees.sol` | Stores the liquidity pool trading fees, these are kept separate from the reserves |\n| `VelodromeLibrary.sol` | Provides router-related helpers, eg. for price-impact calculations |\n| `FactoryRegistry.sol` | Registry of factories approved for creation of pools, gauges, incentives and managed rewards. |\n\n### Tokenomy contracts\n\n| Filename | Description |\n| --- | --- |\n| `Velo.sol` | Protocol ERC20 token |\n| `VotingEscrow.sol` | Protocol ERC-721 (ve)NFT representing the protocol vote-escrow lock. Beyond standard ve-type functions, there is also the ability to merge, split and create managed nfts. |\n| `Minter.sol` | Protocol token minter. Distributes emissions to `Voter.sol` and rebases to `RewardsDistributor.sol`. |\n| `RewardsDistributor.sol` | Is used to handle the rebases distribution for (ve)NFTs/lockers. |\n| `VeArtProxy.sol` | (ve)NFT art proxy contract, exists for upgradability purposes |\n\n### Protocol mechanics contracts\n\n| Filename | Description |\n| --- | --- |\n| `Voter.sol` | Handles votes for the current epoch, gauge and voting reward creation as well as emission distribution to `Gauge.sol` contracts. |\n| `Gauge.sol` | Gauges are attached to a Pool and based on the (ve)NFT votes it receives, it distributes proportional emissions in the form of protocol tokens. Deposits to the gauge take the form of LP tokens for the Pool. In exchange for receiving protocol emissions, claims on fees from the pool are relinquished to the gauge. Standard rewards contract. |\n| `rewards/` | |\n| `Reward.sol` | Base reward contract to be inherited for distribution of rewards to stakers.\n| `VotingReward.sol` | Rewards contracts used by `FeesVotingReward.sol` and `IncentiveVotingReward.sol` which inherits `Reward.sol`. Rewards are distributed in the following epoch proportionally based on the last checkpoint created by the user, and are earned through \"voting\" for a pool or gauge. |\n| `FeesVotingReward.sol` | Stores LP fees (from the gauge via `PoolFees.sol`) to be distributed for the current voting epoch to it's voters. |\n| `IncentiveVotingReward.sol` | Stores the users/externally provided rewards for the current voting epoch to it's voters. These are deposited externally every week. |\n| `ManagedReward.sol` | Staking implementation for managed veNFTs used by `LockedManagedReward.sol` and `FreeManagedReward.sol` which inherits `Reward.sol`.  Rewards can be earned passively by veNFTs who delegate their voting power to a \"managed\" veNFT.\n| `LockedManagedReward.sol` | Handles \"locked\" rewards (i.e. Velo rewards / rebases that are compounded) for managed NFTs. Rewards are not distributed and only returned to `VotingEscrow.sol` when the user withdraws from the managed NFT. | \n| `FreeManagedReward.sol` | Handles \"free\" (i.e. unlocked) rewards for managed NFTs. Any rewards earned by a managed NFT that a manager passes on will be distributed to the users that deposited into the managed NFT. | \n\n### Governance contracts\n\n| Filename | Description |\n| --- | --- |\n| `VeloGovernor.sol` | OpenZeppelin's Governor contracts used in protocol-wide access control to whitelist tokens for trade  within Velodrome, update minting emissions, and create managed veNFTs. |\n| `EpochGovernor.sol` | A simple epoch-based governance contract used exclusively for adjusting emissions. |\n\n\n## Testing\n\nThis repository uses Foundry for testing and deployment. \n\nFoundry Setup\n\n```\nforge install\nforge build\nforge test\n```\n\n## Optimism Mainnet Fork Tests\n\nIn order to run mainnet fork tests against optimism, inherit `BaseTest` in `BaseTest.sol` in your new class and set the `deploymentType` variable to `Deployment.FORK`. The `OPTIMISM_RPC_URL` field must be set in `.env`. Optionally, `BLOCK_NUMBER` can be set in the `.env` file or in the test file if you wish to test against a consistent fork state (this will make tests faster).\n\n\n## Lint\n\n`yarn format` to run prettier.\n\n`yarn lint` to run solhint (currently disabled in CI).\n\n## Deployment\n\nSee `script/README.md` for more detail.\n\n## Security\n\nFor general information about security include audits, bug bounty and deployed contracts, go [here](https://velodrome.finance/security).\n\n### Access Control\nSee `PERMISSIONS.md` for more detail.\n### Bug Bounty\nVelodrome has a live bug bounty hosted on ([Immunefi](https://immunefi.com/bounty/velodromefinance/)).\n\n## Licensing\n\nThis project follows the [Apache Foundation](https://infra.apache.org/licensing-howto.html)\nguideline for licensing. See LICENSE and NOTICE files.\n\n## Deployment\n\n| Name               | Address                                                                                                                               |\n| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------ |\n| ArtProxy               | [0x4A9eA0dd5649eC4B6745c60d1769e2184C1782DD](https://optimistic.etherscan.io/address/0x4A9eA0dd5649eC4B6745c60d1769e2184C1782DD#code) |\n| RewardsDistributor               | [0x9D4736EC60715e71aFe72973f7885DCBC21EA99b](https://optimistic.etherscan.io/address/0x9D4736EC60715e71aFe72973f7885DCBC21EA99b#code) |\n| FactoryRegistry               | [0xF4c67CdEAaB8360370F41514d06e32CcD8aA1d7B](https://optimistic.etherscan.io/address/0xF4c67CdEAaB8360370F41514d06e32CcD8aA1d7B#code) |\n| Forwarder               | [0x06824df38D1D77eADEB6baFCB03904E27429Ab74](https://optimistic.etherscan.io/address/0x06824df38D1D77eADEB6baFCB03904E27429Ab74#code) |\n| GaugeFactory               | [0x8391fE399640E7228A059f8Fa104b8a7B4835071](https://optimistic.etherscan.io/address/0x8391fE399640E7228A059f8Fa104b8a7B4835071#code) |\n| ManagedRewardsFactory               | [0x3F468e35f5c262a6E796bfe3be831Bf8b9142e9c](https://optimistic.etherscan.io/address/0x3F468e35f5c262a6E796bfe3be831Bf8b9142e9c#code) |\n| Minter               | [0x6dc9E1C04eE59ed3531d73a72256C0da46D10982](https://optimistic.etherscan.io/address/0x6dc9E1C04eE59ed3531d73a72256C0da46D10982#code) |\n| PoolFactory               | [0xF1046053aa5682b4F9a81b5481394DA16BE5FF5a](https://optimistic.etherscan.io/address/0xF1046053aa5682b4F9a81b5481394DA16BE5FF5a#code) |\n| Router               | [0xa062aE8A9c5e11aaA026fc2670B0D65cCc8B2858](https://optimistic.etherscan.io/address/0xa062aE8A9c5e11aaA026fc2670B0D65cCc8B2858#code) |\n| VELO               | [0x9560e827aF36c94D2Ac33a39bCE1Fe78631088Db](https://optimistic.etherscan.io/address/0x9560e827aF36c94D2Ac33a39bCE1Fe78631088Db#code) |\n| Voter               | [0x41C914ee0c7E1A5edCD0295623e6dC557B5aBf3C](https://optimistic.etherscan.io/address/0x41C914ee0c7E1A5edCD0295623e6dC557B5aBf3C#code) |\n| VotingEscrow               | [0xFAf8FD17D9840595845582fCB047DF13f006787d](https://optimistic.etherscan.io/address/0xFAf8FD17D9840595845582fCB047DF13f006787d#code) |\n| VotingRewardsFactory               | [0x756E7C245C69d351FfFBfb88bA234aa395AdA8ec](https://optimistic.etherscan.io/address/0x756E7C245C69d351FfFBfb88bA234aa395AdA8ec#code) |\n| Pool               | [0x95885af5492195f0754be71ad1545fe81364e531](https://optimistic.etherscan.io/address/0x95885af5492195f0754be71ad1545fe81364e531#code) |\n| SinkGauge               | [0x3B59a6B600f912260048a0f3a834C1039aEcD367](https://optimistic.etherscan.io/address/0x3B59a6B600f912260048a0f3a834C1039aEcD367#code) |\n| SinkGaugeFactory               | [0xe62b4BC24eB6446675A1cB3facA2339676E9e5a2](https://optimistic.etherscan.io/address/0xe62b4BC24eB6446675A1cB3facA2339676E9e5a2#code) |\n| SinkPool               | [0x333030A736B47D20346d82A473680658ac1C2b88](https://optimistic.etherscan.\n\n[... truncated ...]"
  },
  "velodrome-finance/sugar-sdk": {
    "fetchedAt": "2025-11-12T23:03:28.783Z",
    "content": "# Sugar SDK\n\n<p align=\"center\">  \n    <img src=\"/sugar.png\" alt=\"Sugar SDK\" />\n</p>\n\nSugar makes Velodrome and Aerodrome devs life sweeter üç≠\n\n## Contents\n\n- [Using Sugar](#using-sugar)\n- [Base Quickstart](#base-quickstart)\n- [OP Quickstart](#op-quickstart)\n- [Pools](#pools)\n- [Fees and Incentives](#fees-and-incentives)\n- [Swaps](#swaps)\n- [Configuration](#configuration)\n- [Contributing to Sugar](#contributing-to-sugar)\n- [Useful Links](#useful-links)\n\n## Using Sugar\n\n``` bash\npip install git+https://github.com/velodrome-finance/sugar-sdk.git@v0.3.1\n```\n\nYou can take it for a spin on\n[CodeSandbox](https://codesandbox.io/p/sandbox/sugar-sdk-playground-7c4z7g)\n\n## Base Quickstart\n\nGetting started with Sugar on Base network:\n\n``` python\nfrom sugar.chains import BaseChain, AsyncBaseChain\n\n# async version\nasync with AsyncBaseChain() as chain:\n    prices = await chain.get_prices(await chain.get_all_tokens())\n    for p in prices[:5]:\n        print(f\"{p.token.symbol} price: {p.price}\")\n\n# sync version\nwith BaseChain() as chain:\n    for p in chain.get_prices(chain.get_all_tokens())[:5]:\n        print(f\"{p.token.symbol} price: {p.price}\")\n```\n\n## OP Quickstart\n\nGetting started with Sugar on OP network:\n\n``` python\nfrom sugar.chains import AsyncOPChain, OPChain\n\nasync with AsyncOPChain() as chain:\n    prices = await chain.get_prices(await chain.get_all_tokens())\n    for p in prices[:5]:\n        print(f\"{p.token.symbol} price: {p.price}\")\n\nwith OPChain() as chain:\n    for p in chain.get_prices(chain.get_all_tokens())[:5]:\n        print(f\"{p.token.symbol} price: {p.price}\")\n```\n\n## Pools\n\nGetting information about pools:\n\n``` python\nfrom sugar.chains import AsyncOPChain, OPChain\n\nasync with AsyncOPChain() as chain:\n    pools = await chain.get_pools()\n    usdc_velo = next(iter([p for p in pools if p.token0.token_address == OPChain.usdc.token_address and p.token1.token_address == OPChain.velo.token_address]), None)\n    print(f\"{usdc_velo.symbol}\")\n    print(\"-----------------------\")\n    print(f\"Volume: {usdc_velo.token0_volume} {usdc_velo.token0.symbol} | {usdc_velo.token1_volume} {usdc_velo.token1.symbol} | ${usdc_velo.volume}\")\n    print(f\"Fees: {usdc_velo.token0_fees.amount} {usdc_velo.token0.symbol} | {usdc_velo.token1_fees.amount} {usdc_velo.token1.symbol} | ${usdc_velo.total_fees}\")\n    print(f\"TVL: {usdc_velo.reserve0.amount} {usdc_velo.token0.symbol} | {usdc_velo.reserve1.amount} {usdc_velo.token1.symbol} | ${usdc_velo.tvl}\")\n    print(f\"APR: {usdc_velo.apr}%\")\n\nwith OPChain() as chain:\n    pools = chain.get_pools()\n    usdc_velo = next(iter([p for p in pools if p.token0.token_address == OPChain.usdc.token_address and p.token1.token_address == OPChain.velo.token_address]), None)\n    print(f\"{usdc_velo.symbol}\")\n    print(\"-----------------------\")\n    print(f\"Volume: {usdc_velo.token0_volume} {usdc_velo.token0.symbol} | {usdc_velo.token1_volume} {usdc_velo.token1.symbol} | ${usdc_velo.volume}\")\n    print(f\"Fees: {usdc_velo.token0_fees.amount} {usdc_velo.token0.symbol} | {usdc_velo.token1_fees.amount} {usdc_velo.token1.symbol} | ${usdc_velo.total_fees}\")\n    print(f\"TVL: {usdc_velo.reserve0.amount} {usdc_velo.token0.symbol} | {usdc_velo.reserve1.amount} {usdc_velo.token1.symbol} | ${usdc_velo.tvl}\")\n    print(f\"APR: {usdc_velo.apr}%\")\n```\n\n## Fees and Incentives\n\nTo get information for the latest epochs across all the pools:\n\n``` python\nasync with AsyncOPChain() as chain:\n    epochs = await chain.get_latest_pool_epochs()\n    ep = epochs[0]\n    print(f\"{ep.pool.symbol}\")\n    print(f\"Epoch date: {ep.epoch_date}\")\n    print(f\"Fees: {' '.join([f'{fee.amount} {fee.token.symbol}' for fee in ep.fees])} {ep.total_fees}\")\n    print(f\"Incentives: {' '.join([f'{incentive.amount} {incentive.token.symbol}' for incentive in ep.incentives])} {ep.total_incentives}\")\n```\n\nYou can also get epochs for a specific pool using its address:\n\n``` python\nasync with AsyncOPChain() as chain:\n    epochs = await chain.get_pool_epochs(\"0x7A7f1187c4710010DB17d0a9ad3fcE85e6ecD90a\")\n    ep = epochs[0]\n    print(f\"{ep.pool.symbol}\")\n    print(f\"Epoch date: {ep.epoch_date}\")\n    print(f\"Fees: {' '.join([f'{fee.amount} {fee.token.symbol}' for fee in ep.fees])} {ep.total_fees}\")\n    print(f\"Incentives: {' '.join([f'{incentive.amount} {incentive.token.symbol}' for incentive in ep.incentives])} {ep.total_incentives}\")\n```\n\n## Swaps\n\nGet a quote and swap:\n\n``` python\nfrom sugar.chains import AsyncOPChain\n\nasync with AsyncOPChain() as op:\n    quote = await op.get_quote(from_token=AsyncOPChain.velo, to_token=AsyncOPChain.eth, amount=AsyncOPChain.velo.parse_units(10))\n    if not quote:\n        # no quote found \n    # check quote.amount_out\n    await op.swap_from_quote(quote)\n```\n\n‚ÄúI am Feeling lucky‚Äù swap:\n\n``` python\nfrom sugar.chains import AsyncOPChain\n\nasync with AsyncOPChain() as op:\n    await op.swap(from_token=velo, to_token=eth, amount=velo.parse_units(10))\n```\n\n## Superswaps\n\n```python\nfrom sugar import OPChain, LiskChain, Superswap\n\nsuperswap = Superswap()\nquote = superswap.get_super_quote(from_token=OPChain.velo, to_token=LiskChain.lsk, amount=OPChain.velo.parse_units(100))\nsuperswap.swap_from_quote(quote)\n\n# feeling lucky Superswap\nSuperswap().swap(from_token=OPChain.velo, to_token=LiskChain.lsk, amount=OPChain.velo.parse_units(100))\n```\n\nAs always, async version is also available\n\n```python\nfrom sugar import OPChain, LiskChain, AsyncSuperswap\n\nsuperswap = AsyncSuperswap()\nquote = await superswap.get_super_quote(from_token=OPChain.velo, to_token=LiskChain.lsk, amount=OPChain.velo.parse_units(100))\nawait superswap.swap_from_quote(quote)\n\n# feeling lucky Superswap\nawait AsyncSuperswap().swap(from_token=OPChain.velo, to_token=LiskChain.lsk, amount=OPChain.velo.parse_units(100))\n```\n\n## Configuration\n\nFull list of configuration parameters for Sugar. Chain IDs can be found\n[here](https://chainlist.org/). Sugar uses decimal versions: Base is\n`8453`, OP is `10`.\n\n| config | env | default value |\n|----|----|----|\n| native_token_symbol |  | ETH |\n| native_token_decimals |  | 18 |\n| wrapped_native_token_addr | `SUGAR_WRAPPED_NATIVE_TOKEN_ADDR_<CHAIN_ID>` | chain specific |\n| rpc_uri | `SUGAR_RPC_URI_<CHAIN_ID>` | chain specific |\n| sugar_contract_addr | `SUGAR_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| slipstream_contract_addr | `SUGAR_SLIPSTREAM_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| nfpm_contract_addr | `SUGAR_NFPM_CONTRACT_ADDR` | chain specific |\n| price_oracle_contract_addr | `SUGAR_PRICE_ORACLE_ADDR_<CHAIN_ID>` | chain specific |\n| router_contract_addr | `SUGAR_ROUTER_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| swapper_contract_addr | `SUGAR_ROUTER_SWAPPER_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| swap_slippage | `SUGAR_SWAP_SLIPPAGE_<CHAIN_ID>` | 0.01 |\n| token_addr | `SUGAR_TOKEN_ADDR_<CHAIN_ID>` | chain specific |\n| stable_token_addr | `SUGAR_STABLE_TOKEN_ADDR_<CHAIN_ID>` | chain specific |\n| connector_tokens_addrs | `SUGAR_CONNECTOR_TOKENS_ADDRS_<CHAIN_ID>` | chain specific |\n| excluded_tokens_addrs | `SUGAR_EXCLUDED_TOKENS_ADDRS_<CHAIN_ID>` | chain specific |\n| price_batch_size | `SUGAR_PRICE_BATCH_SIZE` | 40 |\n| price_threshold_filter | `SUGAR_PRICE_THRESHOLD_FILTER` | 10 |\n| interchain_router_contract_addr | `SUGAR_INTERCHAIN_ROUTER_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| bridge_contract_addr | `SUGAR_BRIDGE_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| bridge_token_addr | `SUGAR_BRIDGE_TOKEN_ADDR_<CHAIN_ID>` | chain specific |\n| message_module_contract_addr | `SUGAR_MESSAGE_MODULE_CONTRACT_ADDR_<CHAIN_ID>` | chain specific |\n| pool_page_size | `SUGAR_POOL_PAGE_SIZE` | 500 |\n| pools_count_upper_bound | `POOLS_COUNT_UPPER_BOUND_<CHAIN_ID>` | 2500 |\n| pagination_limit | `SUGAR_PAGINATION_LIMIT` | 2000 |\n| pricing_cache_timeout_seconds | `SUGAR_PRICING_CACHE_TIMEOUT_SECONDS_<CHAIN_ID>` | 5 |\n| threading_max_workers | `SUGAR_THREADING_MAX_WORKERS_<CHAIN_ID>` | 5 |\n\nIn order to write to Sugar contracts, you need to set your wallet\nprivate key using env var `SUG\n\n[... truncated ...]"
  },
  "velodrome-finance/superchain-slipstream": {
    "fetchedAt": "2025-11-12T23:03:29.177Z",
    "content": "# Velodrome Superchain Slipstream Contracts\n\nThis repository contains the smart contracts for the Velodrome Superchain Slipstream. It is adapted from the original Slipstream contracts for use on the Velodrome Superchain.\n\nSee `SPECIFICATION.md` for more information. See the original [Slipstream](https://github.com/velodrome-finance/slipstream) repository for more information about Slipstream.\n\n## Installation\n\nThis repository is a hybrid hardhat and foundry repository.\n\nInstall hardhat dependencies with `yarn install`.\nInstall foundry dependencies with `forge install`.\n\nRun hardhat tests with `yarn test`.\nRun forge tests with `forge test`.\n\n## Testing\n\n### Invariants\n\nTo run the invariant tests, echidna must be installed. The following instructions require additional installations (e.g. of solc-select). \n\n```\nechidna test/invariants/E2E_mint_burn.sol --config test/invariants/E2E_mint_burn.config.yaml --contract E2E_mint_burn\nechidna test/invariants/E2E_swap.sol --config test/invariants/E2E_swap.config.yaml --contract E2E_swap\n```\n\n## Deployment\n\nSee `script/README.md` for deployment instructions.\n\n## Licensing\n\nThis project follows the [Apache Foundation](https://infra.apache.org/licensing-howto.html)\nguideline for licensing. See LICENSE and NOTICE files.\n\n## Bug Bounty\nVelodrome has a live bug bounty hosted on ([Immunefi](https://immunefi.com/bounty/velodromefinance/)).\n\n## Deployment\n\n| Chain      | Addresses          | Deployment Commit |\n|------------|--------------------|-------------------|\n| Optimism   | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/root-optimism.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      |\n| Mode       | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/mode.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      |\n| Lisk       | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/lisk.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      |\n| Fraxtal    | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/fraxtal.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      |\n| Metal      | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/metal.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      | \n| Superseed  | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/superseed.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      |\n| Ink        | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/ink.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      | \n| Soneium    | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/soneium.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      | \n| Swell      | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/swell.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      | \n| Unichain   | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/unichain.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      | \n| Celo   | [Addresses](https://github.com/velodrome-finance/superchain-slipstream/blob/main/deployment-addresses/celo.json)           | [v1.0](https://github.com/velodrome-finance/superchain-slipstream/commit/63b2e08a11f42d91dc6f8487643ecb3d79e745c4)      | \n\nSee the main [Superchain repository](https://github.com/velodrome-finance/superchain-contracts) for the core root contracts.\n"
  },
  "0xSplits/splits-oracle": {
    "fetchedAt": "2025-11-12T23:03:35.673Z",
    "content": "# splits-oracle\n\n[Docs](https://docs.0xsplits.xyz/core/oracle)\n\n## What\n\nOracle provides a generic interface (IOracle) allowing for modular integrations of other onchain oracles (see [Swapper](https://github.com/0xSplits/splits-swapper) for an example integration)\n\n`UniV3OracleImpl` - provides per-pair customization layer (pool, period) on top of Uniswap v3's TWAP oracle\n\n`ChainlinkOracleImpl` - provides per-pair customization layer (path, staleAfter) on top of Chainlink's data feed oracle\n\n## Why\n\nMany onchain value flows require fair pricing for token pairs\n\n## How\n\n[![UniV3OracleImpl sequence diagram](https://mermaid.ink/svg/pako:eNqNkl9PwjAUxb9KU7PsQUiIG4zsgWRDlvhg1Bh52stlu2Bj187uDl0M3939EWFAjC_tTfs7p7c354snOkXuc8v6ihVjQgnyWVsyZtMrZmj7zF5Bgfbg-HQJRsBKYmH_4u3lWiuKIBOyanQNJPfCToyfNNdSm-b6ahJ6N9NRD8iNyMBUByZyIjeaXGJCbVI0f7oVmGiV9vwmi4UXepepU8eR603HfRYSElsgodU_YEJDovd6MA7daH4ROvVzHWc6D-yO3DVbvewsK1axKvC9RJXgrYCNgYyxjgqkSHA4m12_KLF0HgwkEu-yXPpsg_RUasIg06WiosOl1jlbbNFULAdhDj2dyH8ciw_Il86j1rLwWT2xopTU0xwBtWR41gSJ5K0ToEq74vylYfsJn0HXKR_wDE0GIq1T2iYt5m0CY-7XZYpraNrg9WhqFErSz5VKuE-mxAEv8xRoP6X9IaaCtLnvgt_mf_cNmXTr8A)](https://mermaid.live/edit#pako:eNqNk01PAjEQhv9KU0P2ICTEXT7SAwmLbOLBqDFy2suwO2Bjt13bWZQY_rv7IcICMV7aSfu870wn0y-emBS54J3OV6wZk1qSYHXImEevmKEnmLcEh173-HQBVsJSofN-8fpyZTRFkEm1rXQVpPbCRoyfNDPK2Or6ahiObsb9FpBbmYHdHpjIj4JoeIkJjU3R_unmMDE6bfkN5_NROLpMnTr2g9F40GYhIbkBkkb_Aya0JFvZp4MwiGYXoVO_wPfHs6nXkLtqK5ddpxPrWDt8L1AneCthbSFjrKGmSibYm0yuX7Rc-A8WEoV3Wa4EWyM9FYZwmplCk2twZUzO5hu0W5aDtIeaTuQ_ju4D8oX_aIxygpUdc4WiluYIKCW9syJIJm-NAHXaBOeZevUjBIOmUt7lGdoMZFpOaT1pMa8nMOaiDFNcQVUGL1tTolCQed7qhAuyBXZ5kadA-y5xsQLlylNMJRl730x-_QF234Rk7Ds)\n\n### How does it determine fair pricing?\n\n`UniV3OracleImpl` uses Uniswap v3's TWAP oracle. The owner must set per-pair reference pools & may set default & per-pair TWAP periods.\n\n`ChainlinkOracleImpl` - uses Chainlink's data feed oracle. The owner must set per-pair data feed paths.\n\n### How is it governed?\n\nPlease be aware, an Oracle's owner has _SIGNIFICANT CONTROL_ (depending on the implementation) of the deployment. It may, at any time for any reason, change the quote pair uniswap pools & TWAP periods. In situations where flows ultimately belong to or benefit more than a single person & immutability is a nonstarter, we strongly recommend using a multisig or DAO for governance.\n\n## Lint\n\n`forge fmt`\n\n## Setup & test\n\n`forge i` - install dependencies\n\n`forge b` - compile the contracts\n\n`forge t` - compile & test the contracts\n\n`forge t -vvv` - produces a trace of any failing tests\n\n## Natspec\n\n`forge doc --serve --port 4000` - serves natspec docs at http://localhost:4000/\n"
  },
  "0xSplits/splits-diversifier": {
    "fetchedAt": "2025-11-12T23:03:36.164Z",
    "content": "# splits-diversifier\n\n[Docs](https://docs.0xsplits.xyz/templates/diversifier)\n\n## What\n\nDiversifier is a Splits' template to diversify onchain revenue\n\n![](https://docs.0xsplits.xyz/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdiversifier_diagram.9dfbf3b2.png&w=3840&q=75)\n\n## Why\n\nMany onchain entities (e.g. creators, collectives, DAOs, businesses) generate onchain revenues in tokens that don't match the denominations of their expenses (e.g. salaries, taxes) resulting in [asset-liability currency mismatch](https://en.wikipedia.org/wiki/Asset%E2%80%93liability_mismatch#Currency_Mismatch).\nMore generally, diversifying onchain revenue is an easy, efficient, & trustless way to build & manage onchain wallets & treasuries for high performance across a variety of crypto-market conditions.\n\n## How\n\n[![Diversifier flow chart](https://mermaid.ink/svg/pako:eNqNk8tuwjAQRX_FcoWyIRIlvJRFJV7ZVapK1W6yGZIBRnLsyJlAEeLfmxhoG0RRN37ce-ZalscHmZgUZSh93481EysMxYy2aAtaEdpYOyPWrdYh1kKQJg6FWwrh8QYz9ELhLaFAr_1bfQdLsFRYeN-4M1dGcwQZqX1dV0PqUuh8RRqnRhlb2w-DybA76jQAxk--C-SWMrD7HyYKol40uMVMjE3R3k0rMDE6beQN5vPhZHibuk7s9IajfpOFhGkLTEb_A2a0TI3Tx_1JL5rehK7zekEwmo69E3msp2o4tlr1e66U2SUbsHxyX6Ao3jbWlOvNByiFLHz_SSxyRVzTNeI2Tn7FhHJCzY_XzmIHeY62-4cenPUz1QzrNsygaVaVsi0ztBlQWrWra6lYulaLZVgtU1xBqTiW1RUrFEo2i71OZMi2xLYs8xQYZwRrC9lFxJTY2OfTD3Af4fgF-uvqYg)](https://mermaid.live/edit#pako:eNqNk0lrwzAQhf-KUAm-xJDG2fChkM23QmlKe_FlYo-TAVky8jhpCPnvtZVuDmnoRct73zwhNDrKxKQoQ-n7fqyZWGEoFrRDW1JGaGPtjFh3OsdYC0GaOBRuKYTHW8zRC4W3hhK97m_1FSzBWmHpfePOzIzmCHJSh6augdRXofMVaZwbZWxj341m4_6k1wIY3_kmUFjKwR5-mCiIBtHoGjMzNkV7M63ExOi0lTdaLsez8XXqMrE3GE-GbRYSph0wGf0PmNEytU6fDmeDaH4VuswbBMFkPvXO5KmZ6uHU6TTvmSmzT7Zg-ew-QVm-bK2pNts3UApZ-P6DWBWKuKEbxG2c_IwJFYSa7y-d1R6KAm3_Dz341D-pdli_ZQZts66UXZmjzYHSul1dS8XStVosw3qZYgaV4ljWV6xRqNisDjqRIdsKu7IqUmBcEGws5DLMQJW1iimxsY_nL-B-wukD5E3qrQ)\n\n### How does it diversify onchain revenue?\n\nA [Split](https://github.com/0xSplits/splits-contracts) with one or more [Swappers](https://github.com/0xSplits/splits-swapper) underneath (all controlled/owned by a [PassThroughWallet](https://github.com/0xSplits/splits-pass-through-wallet) sitting on top).\n\n### How is it governed?\n\nA Diversifier's owner, if set, has _FULL CONTROL_ of the deployment.\nIt may, at any time for any reason, change any mutable storage in any of the underlying components, as well as execute arbitrary calls on behalf of the Diversifier.\nIn situations where flows ultimately belong to or benefit more than a single person & immutability is a nonstarter, we strongly recommend using a multisig or DAO for governance.\nTo the extent your Oracle or any other submodule has a separate owner as well, similar logic applies.\n\n## Lint\n\n`forge fmt`\n\n## Setup & test\n\n`forge i` - install dependencies\n\n`forge b` - compile the contracts\n\n`forge t` - compile & test the contracts\n\n`forge t -vvv` - produces a trace of any failing tests\n\n## Natspec\n\n`forge doc --serve --port 4000` - serves natspec docs at http://localhost:4000/\n"
  },
  "0xSplits/splits-contracts": {
    "fetchedAt": "2025-11-12T23:03:36.546Z",
    "content": "# splits-contracts\n\n[![codecov](https://codecov.io/gh/0xSplits/splits-contracts/branch/main/graph/badge.svg?token=ERFQOFF0L7)](https://codecov.io/gh/0xSplits/splits-contracts)\n\n## Run locally\n```\nyarn hardhat node\n```\n\n## Metamask network config\n- Network name: `Localhost`\n- New RPC URL: `http://{{LOCALHOST URL - ie 127.0.0.1}}:8545`\n- Chain ID: `1337`\n\n## Dev Setup\nMake sure to have node installed, need >= 12. Can find the installation\n[here](https://nodejs.org/en/download/). A node version manager can also\nbe useful, you can read more about it [here](https://github.com/nvm-sh/nvm).\n\nInstall yarn: `npm install --global yarn`  \nConfirm the installation: `yarn --version`\n\nRun `yarn install` to add packages\n\nFollow the hardhat network setup instructions in the Metamask network config section up above.\nIf you do not have metamask installed, you can find it [here](https://metamask.io/).\n\nAdd funds to your wallet, you can find the instructions below in the Commands section.\n\nSetup your .env.local file. Copy over the .env.local.sample file and fill in the values. Message someone else to get the values.\n\n## Common Errors\nIf you are getting an error on the `yarn hardhat node` command, you may need to clear out the artifacts/cache. Run `yarn hardhat clean`, then try again.\n\n# Commands\n```\n// Send funds to local wallet\nyarn hardhat seedAccount --network localhost {{YOUR_WALLET_ADDRESS}}\n\n// Create split with random recipients\nyarn hardhat createSplit --network localhost --size {{SIZE}}\n```\n"
  },
  "0xSplits/splits-swapper": {
    "fetchedAt": "2025-11-12T23:03:36.886Z",
    "content": "# splits-swapper\n\n[Docs](https://docs.0xsplits.xyz/core/swapper)\n\n## What\n\nSwapper is a payments module that trustlessly & automatically transforms multi-token revenue into a single output token\n![](https://docs.0xsplits.xyz/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fswapper_diagram.2f2890db.png&w=3840&q=75)\n\n## Why\n\nMany onchain entities (e.g. creators, collectives, DAOs, businesses) generate onchain revenues in tokens that don't match the denominations of their expenses (e.g. salaries, taxes) resulting in [asset-liability currency mismatch](https://en.wikipedia.org/wiki/Asset%E2%80%93liability_mismatch#Currency_Mismatch).\nMore generally, many onchain value flows benefit technically and financially from the ability to curate the denomination.\n\n## How\n\n[![Sequence diagram of successful example call to Swapper#flash](https://mermaid.ink/svg/pako:eNqNlE2P0zAQhv-KZVQFRCuqbbetclipCY3EASHYFRfCYZpMd6117GBPFqpV_zt2rG6bJqy45MPzzDvz-uuZF7pEHvPR6DlXjAklKGbtJ2MRPWCFUcyiLViMxuej38EI2Eq00QveBndaUQaVkHuf5yF5TAzJ-IdSLbXx4TeLZHm1mnaA2ogKzP7EZLNsni2GmESbEs2rahYLrcqO3mKzWSbLYepScTpfrq67LBQknoCEVv8BExoSnerr62SepYPQpd58Nlul6yiQB_9yj8NolKtcWfzVoCrwo4B7A5UnAndnwIlMbm7e3_6GukbzSRE6hLSJ29XNJNiHwPaIs7SY7XqgD38xUEiM2T3S10YTrivdKLKBC0GHTV5U4Dx-1HHEQHc_GBlQdoeG-f3GSD-iemvfsZ-9LgaybRhq7aUg5RaKx3_ZPNX3VTff0qspc79GPyH7wGrY--SLsp1ZOvnrGUtQ4U4UfkE7llo3d_os3Pc1GfBFmkB28l5pK6x-zPiYV2gqEKU72u3xzHl7bHPuWuZ-enPuNpPjoCF9u1cFj8k0OOZNXQId99VxEEvhKnwOV0V7Yxz-An7IWig)](https://mermaid.live/edit#pako:eNqNlMtu2zAQRX-FYGGoRW3UiB3b0CKApVpAFkGQJuim6mIsjRIiFKmSo7RG4H8vKcGxZalBN3pwztyZy9crz3SOPOSj0WuqGBNKUMiaT8YCesISg5AFW7AYjE9Hv4MRsJVogze8CRZaUQKlkDuf5yF5SGyT8Q_FWmrjwx8W0fJiNe0AlRElmN2RSWbJPFkMMZE2OZp31SxmWuUdvcVms4yWw9S54nS-XF12WchIvAAJrf4DJjQkOtXXl9E8iQehc735bLaK10FL7v3LPfajUapSZfFXjSrDrwIeDZSeaLkHA05kcnX1-f43VBWaa0XoENImbFY3kWCfWrZHnKSFrOiBPnxrIJMYskeku1oTrktdK7It1wYdNnlTgdP4QccRA939YGRA2QIN8_uNkX5G9dF-Yj97XQxk23aosReDlFvInv9l81jfV918iy-mzP0a_YLsC6tg55PPynZm6eivZyxChYXI_IJ2LDVuHvRJuO9rMuCLNIHs5L3TVrv6IeNjXqIpQeTuaDfHM-XNsU25a5n76U2520yOg5r0_U5lPCRT45jXVQ502Fc8LEBaN4q5cCVu2ruiuTL2fwHX4Vpz)\n\n### How does it swap?\n\nDirectly with traders via integration contracts required to handle `#flash`'s callback `#swapperFlashCallback`.\n\n### How does it price swaps?\n\nModularly, via each Swapper's designated [IOracle](https://github.com/0xSplits/splits-oracle).\nEach Swapper may also apply it's own default & quote-specific scaling factors to said oracle's pricing.\n\n### How is it governed?\n\nA Swapper's owner, if set, has _FULL CONTROL_ of the deployment.\nIt may, at any time for any reason, change the `beneficiary`, `tokenToBeneficiary`, `oracle`, `defaultOfferScaledFactor`, `pairScaledOfferFactors`, as well as execute arbitrary calls on behalf of the Swapper.\nIn situations where flows ultimately belong to or benefit more than a single person & immutability is a nonstarter, we strongly recommend using a multisig or DAO for governance.\nTo the extent your Oracle has an owner as well, this same logic applies.\n\n## Lint\n\n`forge fmt`\n\n## Setup & test\n\n`forge i` - install dependencies\n\n`forge b` - compile the contracts\n\n`forge t` - compile & test the contracts\n\n`forge t -vvv` - produces a trace of any failing tests\n\n## Natspec\n\n`forge doc --serve --port 4000` - serves natspec docs at http://localhost:4000/\n"
  },
  "0xSplits/splits-sdk": {
    "fetchedAt": "2025-11-12T23:03:37.195Z",
    "content": "# Splits SDK\n\nDeveloper tools for integrating with the 0xSplits contracts and subgraph data\n\n## Packages\n\n| Package                                        | Description                                      |\n| ---------------------------------------------- | :----------------------------------------------- |\n| [splits-sdk](/packages/splits-sdk)             | Core package for integrating with 0xSplits       |\n| [splits-sdk-react](/packages/splits-sdk-react) | A wrapper of splits-sdk with helpful React Hooks |\n| [splits-kit](/packages/splits-kit)             | Pre-built React components for 0xSplits          |\n\n## Testing\n\nUpdate the `.env` file with appropriate values for the variables present [here](packages/splits-sdk/.env.sample). If you see any failing forked tests it could be because of the outdated block number, make sure to update it to the most recent one. This should be automated in the future.\n\nRun mocked tests with `pnpm run test`.\nRun forked tests with `pnpm run vitest`.\n\nnote: when writing forked tests make sure to add fork in the test file name. e.g. `my-test-fork.test.ts`.\n\n## Local development\n\n### Build the packages\n\nFrom the root directory:\n\n```bash\npnpm install\npnpm run lerna-build\n```\n\n### Local linking\n\nCan use yalc to link the locally built sdk to other projects.\n\n```bash\npnpm install -g yalc\n```\n\nIn the package you want to link, run:\n\n```bash\nyalc publish\n```\n\nIn the project you want to link to, run (replace @0xsplits/splits-sdk with whatever package you are linking to the local package):\n\n```bash\nyalc add @0xsplits/splits-sdk\n```\n\nTo unlink the package, run:\n\n```bash\nyalc remove @0xsplits/splits-sdk\n```\n\n\n### Update versions and prepare for npm publish\n\nFrom the root directory:\n\n```bash\npnpm run lerna-version\n```\n\n### Publish to npm\n\nFrom each package directory that you want to publish:\n\n```bash\npnpm publish\n```\n\nIf you want to publish an alpha/beta version, apply the appropriate tag:\n\n```bash\npnpm publish --tag beta\n```\n\n### Creating a Release\n\nOnce you are done publishing all the packages, create a release on GitHub. The release version should match the version you published to npm. Use the `Generate release notes` button to automatically generate the release notes.\n\n### Configuring npm for publishing\n\n1. You will need to be added to the `0xsplits` npm organization to publish packages. Ask a team member to add you.\n2. You will need to be logged in to npm on your local machine. Run `npm login` and enter your credentials.\n3. Set the scope to `@0xsplits` by running `npm config set scope 0xsplits`\n"
  },
  "0xSplits/splits-contracts-monorepo": {
    "fetchedAt": "2025-11-12T23:03:37.479Z",
    "content": "# Splits contracts monorepo\n\nThis is a mono-repository for the Splits contracts. Current packages in this repository include:\n\n- [Splits - v2](./packages/splits-v2/README.md)\n- [Splits Smart Vaults](./packages/smart-vaults/README.md)\n\n## Installation\n\nThe mono repo uses turborepo and pnpm. To install turbo repo, run the following command:\n\n`pnpm install turbo --global`\n\nTo install pnpm run the following command:\n\n`npm install pnpm --global` or checkout the [pnpm installation guide](https://pnpm.io/installation)\n\nTo install dependencies for all packages, run the following command:\n\n`pnpm install`\n\n### Build\n\nTo build all packages, run the following command:\n\n`pnpm build`\n\n### Test\n\nTo test all packages, run the following command:\n\n`pnpm test`\n\n### Lint\n\nTo lint all packages, run the following command:\n\n`pnpm lint`\n\n### Deployment\n\nTo deploy contracts, please refer to the README in the respective package.\n\n### Disclaimer\n\nThis project is provided \"as is\" with no warranties or guarantees of any kind, express or implied. The developers make\nno claims about the suitability, reliability, availability, timeliness, security or accuracy of the software or its\nrelated documentation. The use of this software is at your own risk.\n\nThe developers will not be liable for any damages or losses, whether direct, indirect, incidental or consequential,\narising from the use of or inability to use this software or its related documentation, even if advised of the\npossibility of such damages.\n\n### Acknowledgements\n\nShout out to the following projects for inspiration and guidance:\n\n- [jtriley](https://github.com/jtriley-eth/ERC-6909)\n- [frangio](https://github.com/frangio/erc6909-extensions)\n- [Solady](https://github.com/vectorized/solady)\n- [OpenZeppelin Contracts](https://github.com/OpenZeppelin/openzeppelin-contracts)\n- [Zora Protocol](https://github.com/ourzora/zora-protocol)\n- [Solmate](https://github.com/transmissions11/solmate)\n- [PaulRBerg's Foundry Template](https://github.com/PaulRBerg/foundry-template)\n- [Uniswap's Permit2](https://github.com/Uniswap/permit2)\n- [Coinbase Smart Wallet](https://github.com/coinbase/smart-wallet)\n"
  },
  "0xSplits/splits-waterfall": {
    "fetchedAt": "2025-11-12T23:03:37.911Z",
    "content": "# splits-waterfall\n\n[Docs](https://docs.splits.org/core/waterfall)\n\nInstall [foundry](https://github.com/foundry-rs/foundry#installation), then run `forge install` and `forge build` to compile the contracts.\n\n## lint\n\n`forge fmt`\n\n## test\n\n`forge test` - compile & test the contracts\n\n`forge t -vvv` - produces a trace of any failing tests\n"
  },
  "0xSplits/splits-vesting": {
    "fetchedAt": "2025-11-12T23:03:38.333Z",
    "content": "# splits-vesting\n\n[Docs](https://docs.0xsplits.xyz/modules/vesting)\n\nInstall [foundry](https://github.com/gakonst/foundry#installation), then run `forge install` and `make build` to compile the contracts. See package.json & makefile for the full list of commands/scripts\n\n## lint\n\n`make lint`\n\n## test\n\n`make test` - compile & test the contracts\n\n`make trace` - produces a trace of any failing tests\n\n## other tests\n\n### slither\n\n`slither src/VestingModule.sol`\n\n`slither src/VestingModuleFactory.sol`\n\n### mythril\n\n`docker run -it --rm -v$(pwd):/home/mythril mythril/myth -v4 analyze src/VestingModule.sol --solc-json mythril.config.json --solv 0.8.13`\n\n`docker run -it --rm -v$(pwd):/home/mythril mythril/myth -v4 analyze src/VestingModuleFactory.sol --solc-json mythril.config.json --solv 0.8.13`\n"
  },
  "0xSplits/splits-liquid": {
    "fetchedAt": "2025-11-12T23:03:38.728Z",
    "content": "# splits-liquid\n\n## What\n\nLiquid splits are splits where ownership is represented by NFTs (e.g. 721s or 1155s).\n\n## Why\n\nThis design gives ~control of the split to the recipients themselves, allowing the transfer or sale of ownership.\n\n## Notes\n\n1. `LiquidSplitFactory.sol` powers liquid splits offered at app.0xsplits.xyz\n2. To add to your own project, fork our [Liquid Splits template](https://github.com/0xSplits/splits-liquid-template) & inherit `LiquidSplit.sol`\n"
  },
  "0xSplits/splits-utils": {
    "fetchedAt": "2025-11-12T23:03:39.116Z",
    "content": "# splits-utils\n\n## What\n\nUtilities re-used across the splits ecosystem\n\n```\nAddressUtils - helper functions on addresses\nConvertedQuotePair - sort converted quotes\nLibClone - modified minimal clone\nLibQuotes - sort & convert quotes\nLibRecipients - efficiently sorting splits' recipients onchain\nOwnableImpl - minimal ownable clone-implementation\nPausableImpl - minimal pausable clone-implementation\nTokenUtils - helper functions on tokens (including ETH as 0x0)\nWalletImpl - minimal smart wallet clone-implementation\n```\n\n## Why\n\nTo ease external integrations and re-use frequent development / testing patterns\n\n## Lint\n\n`forge fmt`\n\n## Setup & test\n\n`forge i` - install dependencies\n\n`forge b` - compile the contracts\n\n`forge t` - compile & test the contracts\n\n`forge t -vvv` - produce traces for any failing tests\n\n### Natspec\n\n`forge doc --serve --port 4000` - serves natspec docs at http://localhost:4000/\n"
  },
  "Vectorized/multicaller": {
    "fetchedAt": "2025-11-12T23:03:47.856Z",
    "content": "# Multicaller\n\n[![NPM][npm-shield]][npm-url]\n[![CI][ci-shield]][ci-url]\n[![Solidity][solidity-shield]][solidity-ci-url]\n\nEfficiently call multiple contracts in a single transaction.\n\nEnables \"forwarding\" of `msg.sender` to the contracts called.\n\n## Deployments\n\nPlease open an issue if you need help to deploy to an EVM chain of your choice.\n\n- Ethereum \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://etherscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://etherscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://etherscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Goerli \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://goerli.etherscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://goerli.etherscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://goerli.etherscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Sepolia \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://sepolia.etherscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://sepolia.etherscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://sepolia.etherscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Holesky \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://holesky.etherscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://holesky.etherscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://holesky.etherscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Polygon \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://polygonscan.com/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://polygonscan.com/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://polygonscan.com/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Mumbai \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://mumbai.polygonscan.com/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://mumbai.polygonscan.com/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://mumbai.polygonscan.com/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Optimism \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://optimistic.etherscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://optimistic.etherscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://optimistic.etherscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Arbitrum \n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://arbiscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://arbiscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://arbiscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Base\n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://basescan.org/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://basescan.org/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://basescan.org/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n- Blast\n  - Multicaller: [`0x0000000000002Bdbf1Bf3279983603Ec279CC6dF`](https://blastscan.io/address/0x0000000000002Bdbf1Bf3279983603Ec279CC6dF)\n  - MulticallerWithSender: [`0x00000000002Fd5Aeb385D324B580FCa7c83823A0`](https://blastscan.io/address/0x00000000002Fd5Aeb385D324B580FCa7c83823A0)\n  - MulticallerWithSigner: [`0x000000000000D9ECebf3C23529de49815Dac1c4c`](https://blastscan.io/address/0x000000000000D9ECebf3C23529de49815Dac1c4c)\n\n## Contracts\n\n```ml\nsrc\n‚îú‚îÄ Multicaller.sol ‚Äî \"The multicaller contract\"\n‚îú‚îÄ MulticallerWithSender.sol ‚Äî \"The multicaller with sender contract\"\n‚îú‚îÄ MulticallerWithSigner.sol ‚Äî \"The multicaller with signer contract\"\n‚îî‚îÄ LibMulticaller.sol ‚Äî \"Library to read the multicaller contracts\"\n``` \n\n## Installation\n\nYou can use the [`src/LibMulticaller.sol`](./src/LibMulticaller.sol) library in your contracts to query the multicaller with sender contract efficiently.\n\nTo install with [**Foundry**](https://github.com/gakonst/foundry):\n\n```sh\nforge install vectorized/multicaller\n```\n\nTo install with [**Hardhat**](https://github.com/nomiclabs/hardhat) or [**Truffle**](https://github.com/trufflesuite/truffle):\n\n```sh\nnpm install multicaller\n```\n\n## API\n\n[The API docs](API.md).\n\n## Design\n\nThe contracts are designed with a priority on efficiency and minimalism. \n\n## Safety\n\nWe **do not give any warranties** and **will not be liable for any loss** incurred through any use of this codebase.\n\nPlease read the API docs / Natspec, test with your code, and get additional security reviews to make sure that any usage is done safely.\n\n## Acknowledgments\n\nMulticaller is inspired by and directly modified from:\n\n- [Solady](https://github.com/vectorized/solady)\n- [MakerDao's Multicall](https://github.com/makerdao/multicall)\n\nThis project is a public good initiative of [sound.xyz](https://sound.xyz) and Solady.\n\nWe would like to thank our [reviewers and contributors](credits.txt) for their invaluable help.\n\n[npm-shield]: https://img.shields.io/npm/v/multicaller.svg\n[npm-url]: https://www.npmjs.com/package/multicaller\n\n[ci-shield]: https://img.shields.io/github/actions/workflow/status/vectorized/multicaller/ci.yml?label=build&branch=main\n[ci-url]: https://github.com/vectorized/multicaller/actions/workflows/ci.yml\n\n[solidity-shield]: https://img.shields.io/badge/solidity-%3E=0.8.10%20%3C=0.8.25-aa6746\n[solidity-ci-url]: https://github.com/Vectorized/solady/actions/workflows/ci-all-via-ir.yml\n"
  },
  "debridge-finance/dln-taker": {
    "fetchedAt": "2025-11-12T23:04:05.768Z",
    "content": "# Archival Notice\n\nThis repository was a home for the reference implementation of the engine built to automatically execute profitable orders placed on the [deBridge Liquidity Network](https://docs.debridge.finance/dln-the-debridge-liquidity-network-protocol/introduction) (DLN) protocol. Since 2024, the DLN protocol has become a highly competitive market, with many solvers competing to be the first to take each new profitable order using highly efficient custom-built engines, while the current implementation remains conservative.\n\nSo we decided to stop active development of this product and archive the repository. It would remain public and open to anyone who wants to have example of some basic implementation of solver, and build your own implementation that will be able to compete for speed with other solvers. We can't provide support for it.\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\nLicense: see [LICENSE](./LICENSE)\n\n\n# `dln-taker`\n\n[<img src=\"https://user-images.githubusercontent.com/31035222/204026000-2f1950b0-104e-4491-a4ed-00d98cd54d46.png\" height=\"50\" />](https://github.com/debridge-finance/debridge-security/blob/master/DeBridge_DLN_Taker_Code_Security_Assessment_Report_Halborn_Final.pdf)\n\n`dln-taker` is the rule-based daemon service built to automatically execute profitable orders placed on the deSwap Liquidity Network (DLN) across supported blockchains.\n\n- [TL;DR](#tldr)\n- [About DLN](#about-dln)\n- [How `dln-taker` works?](#how-dln-taker-works)\n- [Installation](#installation)\n  - [Preparing the environment](#preparing-the-environment)\n  - [Obtaining an API token for 1inch.io API](#obtaining-an-api-token-for-1inchio-api)\n  - [Understanding reserve funds](#understanding-reserve-funds)\n  - [Deploying reserve funds](#deploying-reserve-funds)\n- [Managing cross-chain risk/reward ratio](#managing-cross-chain-riskreward-ratio)\n  - [Reducing transaction finality constraint](#reducing-transaction-finality-constraint)\n  - [Setting a TVL budget](#setting-a-tvl-budget)\n  - [Setting throughput](#setting-throughput)\n  - [Delayed fulfillments](#delayed-fulfillments)\n- [Testing the order execution flow in the wild](#testing-the-order-execution-flow-in-the-wild)\n  - [Restricting orders from fulfillment](#restricting-orders-from-fulfillment)\n  - [Placing new orders](#placing-new-orders)\n- [Smart contract addresses](#smart-contract-addresses)\n- [Miscellaneous](#miscellaneous)\n  - [Disable OP Horizon campaign](#disable-op-horizon-campaign)\n  - [Fine-tuning](#fine-tuning)\n  - [Development](#development)\n\n## TL;DR\n\n- Make a new directory:\n```sh\nmkdir dln-taker-env\n```\n- `cd` to the directory and install necessary production dependencies:\n```sh\ncd dln-taker-env\nnpm i --save typescript ts-node @debridge-finance/dln-taker\n```\n- Create a configuration file called `executor.config.ts` based on sample:\n```sh\nwget https://raw.githubusercontent.com/debridge-finance/dln-taker/main/sample.config.ts\nmv sample.config.ts executor.config.ts\n```\n- Create a secrets file called `.env` based on sample:\n```sh\nwget https://raw.githubusercontent.com/debridge-finance/dln-taker/main/sample.env\nmv sample.env .env\n```\n- Set the values to variables defined in the secrets `.env` file ([more info](#preparing-the-environment))\n- Deploy reserve funds to the addresses you have defined in the secrets `.env` file ([more info](#deploying-reserve-funds))\n- Launch `dln-taker` via `npx`:\n```sh\nnpx dln-taker executor.config.ts\n```\n- You would see how `dln-taker` executes orders being placed on the DLN\n\n## About DLN\n\nDLN is an on-chain system of smart contracts where users (we call them *makers*) place their cross-chain limit orders, giving a specific amount of input token on the source chain (`giveAmount` of the `giveToken` on the `giveChain`) and specifying the outcome they are willing to take on the destination chain (`takeAmount` of the `takeToken` on the `takeChain`). The given amount is being locked by the DLN smart contract on the source chain, and anyone with enough liquidity (called *takers*) can attempt to fulfill the order by calling the DLN smart contract on the destination chain supplying requested amount of tokens the *maker* is willing to take. After the order is being fulfilled, a cross-chain message is being sent to the source chain via the deBridge protocol to unlock the funds, effectively completing the order.\n\n\n## How `dln-taker` works?\n\nFrom the high level perspective, `dln-taker` automates the process of order estimation and execution: it\n- **captures new orders** being placed onto DLN by subscribing to the deBridge-managed websocket service which monitors the smart contracts under its hood,\n- **filters out orders satisfying custom criteria** defined in the config (e.g., amount cap, target recipient, etc),\n- **asserts necessary conditions** to be met (e.g., minimum block confirmations, minimum required profitability), postponing those that don't,\n- attempts to **fulfill the order** supplying the requested amount of tokens,\n- and **unlocks the funds** upon successful order execution (making this in batches of 10 orders per every supported chain combination),\n- regularly **gets back to orders** previously postponed due to being unprofitable.\n\n\n## Installation\n\nSee [TL;DR section](#tldr) for quick install.\n\n### Preparing the environment\n\nThe [`sample.config.ts` file](./sample.config.ts) already defines all blockchains where DLN is operational:\n1. Arbitrum\n1. Avalanche\n1. Base\n1. BNB Chain\n1. Ethereum\n1. Fantom\n1. Linea\n1. Optimism\n1. Polygon\n1. Solana\n\nso you don't have to describe them explicitly. However, the sample config uses references to the environment variables (via the `${process.env.*}` notation) where sensitive or private data is involved: for example, an API key to access deBridge-managed websocket, or private keys to wallets with reserve funds for order fulfillment are designed to be accessed by the configuration file as environment variables.\n\nFor the sake of simplicity, all variables requested by the `sample.config.ts` are listed in the [`sample.env` file](./sample.env). You can use it as the foundation to create an `.env` file to store your secrets, or reuse it in a hardened way (involving vaults, e.g. Github Secrets or 1password Secrets Automation).\n\nCreate an `.env` file using the contents of the [`sample.env` file](./sample.env) file, and set values for all variables for every chain you wish to support, as follows:\n\n> **Caution!** Properties from this section define sensitive data used by `dln-taker` to operate reserve funds.\n\n- `<CHAIN>_RPC` variable defines a URL to the RPC node of the chain.\n- `<CHAIN>_TAKER_PRIVATE_KEY` variable defines the private key of the address where the reserve funds available for orders fulfillment. `dln-taker` will sign transactions on behalf of this address, effectively setting approval, transferring funds, performing swaps and fulfillments.\n- `<CHAIN>_UNLOCK_AUTHORITY_PRIVATE_KEY` variable defines the private key of the address used to unlock successfully fulfilled orders. `dln-taker` will sign transactions on behalf of this address, effectively unlocking the orders.\n- `<CHAIN>_BENEFICIARY` variable defines taker controlled address where the orders-locked funds (fulfilled on the other chains) would be unlocked to. For this you can use the address which corresponds to the private key specified as the `<CHAIN>_TAKER_PRIVATE_KEY`, so funds unlocked by fulfilling the orders would be automatically available as the reserve funds.\n\n> ‚ö†Ô∏è Th\n\n[... truncated ...]"
  },
  "debridge-finance/hardhat-debridge": {
    "fetchedAt": "2025-11-12T23:04:06.143Z",
    "content": "# hardhat-debridge\n\n**Easily test your integrations with [deBridge](https://debridge.finance).** A plugin for [Hardhat](https://hardhat.org) provides the toolkit to test and emulate dApps built on top of deBridge protocol.\n\n![deBridge emulator schema](Schema.png)\n\n## Rationale\n\n[deBridge](https://debridge.finance) is a generic messaging and cross-chain interoperability protocol that enables decentralized transfers of arbitrary data and assets between various blockchains. Given the complexity of the protocol itself and the number of different components involved in the flow, **integration development** and its sufficient **unit testing** may by very tricky as it typically requires a complete infrastructure setup.\n\n`hardhat-debridge` provides the toolkit for creating lightweight and blazing-fast emulation environment on top of [hardhat network](https://hardhat.org/hardhat-network), behaving close to how the mainnet setup of the deBridge infrastructure does.\n\nIn a nutshell, this plugin is suitable to validate cross-chain interactions as follows:\n- developing **unit test cases** for your contracts, or developing **integration test cases** to validate the behavior and the interaction between the contracts intended to reside on the different chains and communicate through the deBridge gate: deBridge infrastructure emulator is a part of a runtime (runtime emulation);\n- performing **functional tests** on the deBridge infrastructure emulator running as a local process.\n\n## Installation\n\nInstall the package:\n\n```bash\nnpm i --save-dev @debridge-finance/hardhat-debridge\n```\n\nImport the plugin in your `hardhat.config.ts`:\n\n```ts\nimport \"@debridge-finance/hardhat-debridge\";\n```\n\n## Examples\n\nConsider looking into [`debridge-finance/debridge-cross-chain-dapp-example`](https://github.com/debridge-finance/debridge-cross-chain-dapp-example) repo representing a complete example of a fictional cross-chain dApp which leverages the deBridge protocol to send calls between its contracts across chains. Under the hood, that example if excessively covered with simple units tests made possible with the help of this `hardhat-debridge` plugin.\n\n## Writing tests\n\nAfter this plugin is being installed, import `deBridge` object into your test file:\n\n```ts\nimport { deBridge } from \"hardhat\";\n```\n\nUse `deBridge.emulation.deployGate()` to deploy the deBridgeGate emulation contract to the current hardhat network; then you can point your contracts (that are responsible for invoking `deBridgeGate` contract to pass messages to other chains) to this deployed contract.\n\nUse `deBridge.emulation.autoClaim()` to invoke the emulation of the bridging process: this will construct the claim txn (intended to be broadcasted to the destination chain) and execute it immediately.\n\nExample:\n\n```ts\ndescribe(\"Test Suite #1\", function () {\n\n    let gate: any;\n    let senderContractChainA: any;\n    let calleeContractChainB: any;\n\n    before(async () => {\n        //\n        // deploy emulation contract\n        //\n        gate = await deBridge.emulator.deployGate();\n\n        //\n        // deploy the contracts you are willing to test\n        //\n        senderContractChainA = await deploySenderContract();\n        calleeContractChainB = await deployCalleeContract(senderContractChainA.address);\n    })\n\n    it(\"Test Case #1\", async () => {\n        // Call the sender contract which interacts with the deBridgeGate under the hood\n        // asking it to broadcast a message. A message is an instruction to call\n        // the callee contract. A call may contain arbitrary values, if the callee\n        // contract's ABI is expects them.\n        await senderContractChainA.sendValue(senderContractChainA.VALUE_1, {\n            value: await gate.globalFixedNativeFee()\n        });\n\n        // Invoke the bridging emulation (claim tnx has to be executed automatically)\n        // Here, the message constructed by the sender contract will be\n        // broadcasted to the same chain and executed by deBridgeGate. During the\n        // execution of the message, the deBridgeGate will call the callee contract\n        // via deBridgeGate's CallProxy contract.\n        await deBridge.emulator.autoClaim();\n\n        // validate that callee contract has been called and received a value\n        expect(await calleeContractChainB.receivedValue())\n            .to.be.eq(senderContractChainA.VALUE_1)\n    });\n});\n```\n\n## Running the emulator daemon\n\n`hardhat-debridge` plugin comes with the emulator, which deploys the loopback bridge to the currently running node and starts bridging messages coming to bridge back to the same chain.\n\nTo create your local test bench:\n\n1. Run the local node in the first terminal, e.g.:\n```\n‚ùØ‚ùØ‚ùØ npx hardhat node\nStarted HTTP and WebSocket JSON-RPC server at http://127.0.0.1:8545/\n...\n```\n2. Run the deBridge emulator in the second terminal, it will deploy a configured loopback bridge and print its address first:\n```\n‚ùØ‚ùØ‚ùØ npx hardhat debridge-run-emulator --network localhost\nDeBridgeGate emulator contract has been deployed at 0xCf7Ed3AccA5a467e9e704C703E8D87F634fB0Fc9\nDeBridge emulator is waiting for events...\n...\n```\n3. In the third terminal, deploy your sender and receiver contracts to the same local node. Of course, these contracts are intended to reside on different chains, but for emulation purposes we use a loopback bridge, which assumes sender and receiver are on the same chain still communicating though the `deBridgeGate` contract.\n\nStart calling your sender contract: you'll see transactions being printed in the first terminal while messages coming to the `deBridgeGate` contract being captured and bridged back in the second terminal.\n\n## deSDK-friendly! üê∂\n\nThe emulator itself is based on vanilla contracts that implement the core deBridge protocol, introducing some handy automation for it under the hood. This means that you can use the emulator along with the deBridge SDK and send and track submissions and claims explicitly when necessary.\n\nThe only thing to remember is to pass the corresponding context where the emulator is being deployed.\n\n[Consider looking](test/project.test.ts#L165-L186) into how this feature is used by the test cases for the `debridge-hardhat` itself, or inspect the following example:\n\n```ts\n// deploy the gate\nconst gate = await deBridge.emulator.deployGate();\n\n// configure sender and callee contracts\n// [...]\n\n// call the contract that interacts with the gate. Mind that we keep\n// the transaction hash where the call occurs to find a cross-chain submission\nconst tx = await senderContractChainA.sendValue(/*[...]*/);\nconst rcp = await tx.wait();\n\n// NOW,\n// instead of calling deBridge.emulator.autoClaim(),\n// we are going to manage the submission explicitly\n\n// craft the context deSDK shall work within\nconst evmContext = {\n    // pass the current hardhat network. deSDK is ready to accept it\n    provider: hre,\n\n    // pass the custom address of the gate we are interacting with\n    deBridgeGateAddress: gate.address,\n\n    // emulated gate works without signatures, so pass a dummy\n    signatureStorage: new evm.DummySignatureStorage()\n}\n\n// find all submissions that may have occurred within a transaction\nconst submissions = await evm.Submission.findAll(\n    rcp.transactionHash, // <!-- provide the tx hash where the call occurred\n    evmContext\n);\n\n// we know our contract made only one submission to the gate ,\n// but in real life there can be multiple submissions (e.g. send to different\n// chains) within one single transactions\nconst [submission] = submissions;\n\n// claim this submission explicitly\nconst claim = await submission.toEVMClaim(evmContext);\nconst args = await claim.getClaimArgs();\nawait gate.claim(...args);\n```\n\n## Questions?\n\nWelcome to the [`#developers-chat`](https://discord.com/channels/875308315700264970/876748142777864202) at the deBridge Discord server.\n"
  },
  "debridge-finance/dln-contracts": {
    "fetchedAt": "2025-11-12T23:04:06.460Z",
    "content": "#  DLN\r\n\r\nDLN is a high-performance cross-chain trading infrastructure that consists of two layers:\r\nProtocol layer: on-chain smart contracts\r\nInfrastructure layer: Takers that perform off-chain matching and on-chain settlement of trades\r\nThe DLN protocol layer is represented by a set of smart contracts that can be called by any on-chain address (named a Maker) to create limit orders for cross-chain trades. When an order is created, the maker provides a specific amount of an input token on the source chain and specifies the parameters of the order, such as the token address and the amount the maker accepts to receive in the destination chain. The given amount is then temporarily locked by the DLN smart contract on the source chain, and any on-chain address with sufficient liquidity (named a Taker) can attempt to fulfill the order by calling the DLN smart contract on the destination chain and supplying the corresponding amount of token as requested by the maker. After the order is fulfilled, a cross-chain message is sent by the smart contract to the source chain via the deBridge messaging infrastructure to unlock the funds on the source chain to the taker‚Äôs address, effectively completing the order. Below is a graphic outlining the process:\r\n\r\n![tg_image_226044199](https://github.com/debridge-finance/dln-contracts/assets/29544129/d17a30a4-3186-4601-850c-1a30b6bc4ef6)\r\n\r\nMore information about the project can be also found in the [documentation portal](https://docs.dln.trade/the-core-protocol/dln-overview)  \r\nUI deployed on [app.debridge.finance](https://app.debridge.finance/)\r\n\r\n## DLN Smart Contracts\r\nThe contracts' directory contains the following subfolders:\r\n\r\ncontracts/  \r\n\tDLN/ - dln contracts  \r\n\tinterfaces/ - contains interfaces of the project contracts  \r\n\tlibraries/ - libraries created for the project  \r\n\tmock/ - contracts for tests  \r\n        \r\n## Prod addresses\r\n| contract  | address \r\n| -- | -- |\r\n| DlnSource|0xeF4fB24aD0916217251F553c0596F8Edc630EB66\r\n| DlnDestination |0xE7351Fd770A37282b91D153Ee690B63579D6dd7f\r\n        \r\n## Deployed Chains\r\n- 1,56,137,250,42161,43114,59144,10,8453,100000001,100000002,100000003,100000004\r\n- ETH, BNB, POLYGON, FANTOM, ARBITRUM, AVALANCHE, LINEA, OPTIMISM, BASE, NEON, GNOSIS, LIGHTLINK, METIS\r\n"
  },
  "debridge-finance/debridge-contracts-v1": {
    "fetchedAt": "2025-11-12T23:04:06.818Z",
    "content": "<br/>\n<p align=\"center\">\n<a href=\"https://debridge.finance/\" target=\"_blank\">\n<img src=\"https://github.com/user-attachments/assets/01c30bd5-2a18-470f-9df8-c9ac77a2a4c4\" width=\"225\" alt=\"logo\">\n</a>\n</p>\n<br/>\n\n[deBridge](https://debridge.finance/) ‚Äî cross-chain interoperability\n and liquidity transfer protocol that allows the truly decentralized transfer of data and assets between various blockchains. deBridge protocol is an infrastructure platform and a hooking service which aims to become a standard for:\n- cross-chain composability of smart contracts\n- cross-chain swaps\n- bridging of any arbitrary asset\n- interoperability and bridging of NFTs\n\nMore information about the project can be also found in the [documentation portal](https://docs.debridge.finance/)\n<br/>\nUI deployed on [app.debridge.finance](https://app.debridge.finance/)\n\n# Debridge Smart Contracts\n\n\nThe contracts' directory contains the following subfolders:\n\n```\ncontracts/\n\tinterfaces/ - contains interfaces of the project contracts\n\tlibraries/ - libraries created for the project\n\tmock/ - contracts for tests\n\tperiphery/ - periphery contracts\n\ttransfers/ - related to core cross-chain functionality\n```\nThe detailed methods' description can be found in the contracts themselves or in the [documentation](https://docs.debridge.finance/).\n\n<!-- Part between CONTRACTS_AUTOGENERATED_DESCRIPTION* is autogenerated. Do no remove CONTRACTS_AUTOGENERATED_DESCRIPTION* -->\n<!-- CONTRACTS_AUTOGENERATED_DESCRIPTION_START -->\n## Periphery\n### CallProxy\nProxy to execute the other contract calls.\nThis contract is used when a user requests transfer with specific call of other contract.\n### DeBridgeToken\nERC20 token that is used as wrapped asset to represent the native token value on the other chains.\n### DeBridgeTokenProxy\nThis contract implements a proxy that gets the implementation address for each call\nfrom DeBridgeTokenDeployer. It's deployed by DeBridgeTokenDeployer.\nImplementation is DeBridgeToken.\n### SimpleFeeProxy\nHelper to withdraw fees from DeBridgeGate and transfer them to a treasury.\n## Transfers\n### DeBridgeGate\nContract for assets transfers. The user can transfer the asset to any of the approved chains.\nThe admin manages the assets, fees and other important protocol parameters.\n### DeBridgeTokenDeployer\nDeploys a deToken(DeBridgeTokenProxy) for an asset.\n### OraclesManager\nThe base contract for oracles management. Allows adding/removing oracles,\nmanaging the minimal required amount of confirmations.\n### SignatureVerifier\nIt's used to verify that a transfer is signed by oracles.\n### WethGate\nUpgradable contracts cannot receive ether via `transfer` because of increased SLOAD gas cost.\nWe use this non-upgradeable contract as the recipient and then immediately transfer to an upgradable contract.\nMore details about this issue can be found\n[here](https://forum.openzeppelin.com/t/openzeppelin-upgradeable-contracts-affected-by-istanbul-hardfork/1616).\n\n<!-- CONTRACTS_AUTOGENERATED_DESCRIPTION_END -->\n\n## [How Transfers Works](https://docs.debridge.finance/the-core-protocol/transfers)\n\n## Test\nCreate a .env file with the content below (all are default values from ganache)\n```dotenv\nTEST_BSC_PROVIDER=https://bsc-dataseed.binance.org/\nTEST_ORACLE_KEYS=[\"0x512aba028561d58c914fdcb31cc7f4dd9a433cb3672eb9eaf44302eb097ec3bc\",\"0x79b2a2a43a1e9f325920f99a720605c9c563c61fb5ae3ebe483f83f1230512d3\",\"0xefb1529474de412cfeb875bc13c47fe3032202bdf777f350415c877eddad62ba\",\"0xed4a4d31740e08e1f30854271fdc31758349b89c9ae9da86711ed3001f1dc409\",\"0x49378a90c0b6c07c5cadcfcb13222bd12eebb4e96455ff48b57e54baa12c91c1\",\"0x1029e16ddabd4f7f38a175464eba097aea1173840f4286551ec435903823e94a\",\"0xf4d8a0f92a47559cd2fb91ae67fe1c36de46b577695f4a44ce026b59b01289c6\",\"0x6f3255cdf01eee387574036f0183c6b024dadc6aa4e5bb272d0564403e2e579f\",\"0x40775e39b578b0ab1603f87636c9fac9697487d918d4647df7f8549c6eff3d09\",\"0x3ecd7955f78fbd0c9025a742f778d8b292fb3c8544a17c1adb77fbe20f21bb63\"]\nMNEMONIC=\"cactus require cushion flavor mobile behave pole time wasp silk moon correct\"\nDEPLOYER_PRIVATE_KEY=\"0x512aba028561d58c914fdcb31cc7f4dd9a433cb3672eb9eaf44302eb097ec3bc\"\nDEPLOYER_ACCOUNT=\"0x6AFb86b6eE3A6a3F42Ae2526157f753DDdbd2f1E\"\nMULTISIG_ACCOUNT=\"0xe13E4F9441a381F54eD969c768713157D125e216\"\nINFURA_ID=xxx # Change to your infura id\n```\nthen run `yarn test`\n\n## Docs generation\n`yarn docs`\n\n## Troubleshooting\n###  Cannot find module '../typechain-types' or its corresponding type declarations.\n`hardhat clean`\n>> https://github.com/dethcrypto/TypeChain/tree/master/packages/hardhat#installation\n> \n>Warning: before running it for the first time you need to do hardhat clean, otherwise TypeChain will think that there is no need to generate any typings. This is because this plugin will attempt to do incremental generation and generate typings only for changed contracts. You should also do hardhat clean if you change any TypeChain related config option.\n\n\n## Verify contract\n\nAdd ETHERSCAN_API_KEY variable to your .env file before running `npx hardhat verify ...`\n"
  },
  "debridge-finance/debridge-node": {
    "fetchedAt": "2025-11-12T23:04:07.184Z",
    "content": "<br/>\n<p align=\"center\">\n<a href=\"https://debridge.finance/\" target=\"_blank\">\n<img src=\"https://github.com/user-attachments/assets/e7f6f6b3-cc6d-4003-bd1c-8d7c882ea995\" width=\"225\" alt=\"logo\">\n</a>\n</p>\n<br/>\n\n[deBridge](https://debridge.finance/) ‚Äî cross-chain interoperability\n and liquidity transfer protocol that allows the truly decentralized transfer of data and assets between various blockchains. deBridge protocol is an infrastructure platform and a hooking service which aims to become a standard for:\n- cross-chain composability of smart contracts\n- cross-chain swaps\n- bridging of any arbitrary asset\n- interoperability and bridging of NFTs\n\nMore information about the project can be also found in the [documentation portal](https://docs.debridge.finance/)\n\ndeBridge node is a software that is run by deBridge validators who were elected by the protocol governance and perform validation of all cross-chain transactions passed through the protocol. All active validators are listening for events emitted by transactions that pass through deBridge smart contract and once an event achieves its finality validator signs the unique id of the event by private key and stores signature to Bundlr. In order to have transaction executed in the target chain user or arbitrary keeper needs to collect minimal required signatures of deBridge validators from IPFS and pass them alongside all transaction parameters to the deBridge smart contract in the target chain. The smart contract will validate all signatures and execute message/data passed in the transaction\n\nIn order to set up the validation node, the following steps should be performed:\n\n\n## Install prerequisite packages on your server:\n\n  1. docker\n    - https://docs.docker.com/engine/install/ubuntu/\n  2. docker-compose\n    - https://docs.docker.com/compose/install/\n  3. nodejs\n    - https://github.com/nodesource/distributions/blob/master/README.md\n  5. psql\n    ``` sudo apt-get install postgresql-client```\n\n### Check that your version of docker-compose not older than\n\n```\ndocker-compose --version\ndocker-compose version 1.29.2\n```\n\n## Set up the blockchain infrastructure:\n1. Install full mainnet nodes\n  - [Ethereum](https://ethereum.org/en/developers/docs/nodes-and-clients/run-a-node/)\n  - [BSC](https://docs.binance.org/smart-chain/developer/fullnode.html)\n  - [HECO](https://docs.hecochain.com/#/en-us/dev/deploy)\n  - Arbitrum\n  - [Polygon](https://docs.polygon.technology/docs/validate/technical-requirements/)\n  - Avalanche\n  - Fantom\n  - Solana\n\n\n2. Update configs\n   1. Make a copy of the default config:\n    ```shell\n    cp ./config/chains_config_default.json ./config/chains_config.json\n    ```\n   2. Update HTTP RPC URL in /config/chains_config.json (solana config needs no change)\n\n3. Copy `.default.env` file and rename it to `.env`. Change default POSTGRES_PASSWORD, POSTGRES_USER credentials in .env file. During the first run (point 9) Postgres database will be automatically created with these credentials.\ndeBridge node has an embedded API through which node operator can authorize, query last scanned blocks, or rescan blockchain from the specific block. By default deBridge node is deployed on DEBRIDGE_NODE_PORT from .env file. Update JWT_SECRET, API_LOGIN, API_PASSWORD to randomly generated ones. If you use sentry to track any errors of the node, please update SENTRY_DSN/SOLANA_DATA_READER_API_SENTRY_DSN at .env file.\nSet DEBRIDGE_PK, SETTINGS_PK in .env (ask deBridge team to get mainnet programs addresses)\nSet SOLANA_RPC in .env to your solana RPC\nSet API_BASE_URL (ask deBridge team to get mainnet URL)\n\n4. Create a keystore file for the validation node. Script from `generate-keystore` folder can be used. To start generating new keystore info:\n  - npm i\n  - node index.js\n\nThe script will show the newly generated Ethereum address, private key, password for keystore, and keystore info. Copy password to `.env KEYSTORE_PASSWORD`, keystore info to /`secrets/keystore.json`\n\n5. Put the keystore file under `secrets/keystore.json`.\n6. Paste the password from `keystore` file into KEYSTORE_PASSWORD field of .env file\n7. Contact deBridge team  to make your wallet address to be whitelisted by deBridge governance\n8. Run the command `docker-compose up --build -d`.\n9. If there is a need to start multiple instances of the node (e.g. one for testnet and one for mainnet) on one server you can:\n  - checkout or copy repo to the new directory\n  - change DOCKER_ID variable in .env\n  - start as described above\n10. debridge_node allow to save signatures in the arweave. To enable this feature need to generate arweave wallet and fill balance. \nGenerate [arweave](https://www.arweave.org/) wallet\n```\ncd generate-arweave-wallet\nnpm i\nnode index.js\n```\nCopy private key to secrets/bundlr_wallet.json\n\n## Update debridge node to the latest version\n```shell\n# Get latest changes from git\ngit pull\n\n# Run debridge node\ndocker-compose up -d --remove-orphans\n```\n\n# [Changelog](./changelog.md)\n\n\n# Config\n\n## Working with multi-rpc nodes config\n\n1. For each RPC node in the list:\n    * Try to get the last block from the RPC node.\n    * If the operation succeeds, return the RPC node.\n    * Otherwise, mark the RPC node as not working and move it to the end of the list.\n2. If we reach this point, all RPC nodes are not working.\n    * Raise an exception.\n\nThis function first iterates over the list of RPC nodes. For each RPC node, it tries to get the last block from the node. If the operation succeeds, the function returns the RPC node. Otherwise, the function marks the RPC node as not working and moves it to the end of the list.\nIf the function reaches the end of the list without finding a working RPC node, it raises an exception. This indicates that all RPC nodes are not working.\n![Working with multi-rpc nodes config](https://github.com/debridge-finance/debridge-node/assets/98714075/64bbf9ef-b838-4e8b-9eab-8519c645e568)\n\n\n"
  },
  "Opti-domains/dispute-game-lookup": {
    "fetchedAt": "2025-11-12T23:04:15.292Z",
    "content": "## Foundry\n\n**Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.**\n\nFoundry consists of:\n\n-   **Forge**: Ethereum testing framework (like Truffle, Hardhat and DappTools).\n-   **Cast**: Swiss army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n-   **Anvil**: Local Ethereum node, akin to Ganache, Hardhat Network.\n-   **Chisel**: Fast, utilitarian, and verbose solidity REPL.\n\n### Transactions\n\nOPOutputLookup: 0x475dc200b71dbd9776518C299e281766FaDf4A30\n\nDeterministic Deployment Proxy: 0x4e59b44847b379578588920ca78fbf26c0b4956c\n\n```\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\n\n[... truncated ...]"
  },
  "Opti-domains/optidomains-ens-contracts": {
    "fetchedAt": "2025-11-12T23:04:15.773Z",
    "content": "# ENS\n\n[![Build Status](https://travis-ci.org/ensdomains/ens-contracts.svg?branch=master)](https://travis-ci.org/ensdomains/ens-contracts)\n\nFor documentation of the ENS system, see [docs.ens.domains](https://docs.ens.domains/).\n\n## npm package\n\nThis repo doubles as an npm package with the compiled JSON contracts\n\n```js\nimport {\n  BaseRegistrar,\n  BaseRegistrarImplementation,\n  BulkRenewal,\n  ENS,\n  ENSRegistry,\n  ENSRegistryWithFallback,\n  ETHRegistrarController,\n  FIFSRegistrar,\n  LinearPremiumPriceOracle,\n  PriceOracle,\n  PublicResolver,\n  Resolver,\n  ReverseRegistrar,\n  StablePriceOracle,\n  TestRegistrar,\n} from '@ensdomains/ens-contracts'\n```\n\n## Importing from solidity\n\n```\n// Registry\nimport '@ensdomains/ens-contracts/contracts/registry/ENS.sol';\nimport '@ensdomains/ens-contracts/contracts/registry/ENSRegistry.sol';\nimport '@ensdomains/ens-contracts/contracts/registry/ENSRegistryWithFallback.sol';\nimport '@ensdomains/ens-contracts/contracts/registry/ReverseRegistrar.sol';\nimport '@ensdomains/ens-contracts/contracts/registry/TestRegistrar.sol';\n// EthRegistrar\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/BaseRegistrar.sol';\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/BaseRegistrarImplementation.sol';\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/BulkRenewal.sol';\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/ETHRegistrarController.sol';\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/LinearPremiumPriceOracle.sol';\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/PriceOracle.sol';\nimport '@ensdomains/ens-contracts/contracts/ethregistrar/StablePriceOracle.sol';\n// Resolvers\nimport '@ensdomains/ens-contracts/contracts/resolvers/PublicResolver.sol';\nimport '@ensdomains/ens-contracts/contracts/resolvers/Resolver.sol';\n```\n\n## Accessing to binary file.\n\nIf your environment does not have compiler, you can access to the raw hardhat artifacts files at `node_modules/@ensdomains/ens-contracts/artifacts/contracts/${modName}/${contractName}.sol/${contractName}.json`\n\n## Contracts\n\n## Registry\n\nThe ENS registry is the core contract that lies at the heart of ENS resolution. All ENS lookups start by querying the registry. The registry maintains a list of domains, recording the owner, resolver, and TTL for each, and allows the owner of a domain to make changes to that data. It also includes some generic registrars.\n\n### ENS.sol\n\nInterface of the ENS Registry.\n\n### ENSRegistry\n\nImplementation of the ENS Registry, the central contract used to look up resolvers and owners for domains.\n\n### ENSRegistryWithFallback\n\nThe new implementation of the ENS Registry after [the 2020 ENS Registry Migration](https://docs.ens.domains/ens-migration-february-2020/technical-description#new-ens-deployment).\n\n### FIFSRegistrar\n\nImplementation of a simple first-in-first-served registrar, which issues (sub-)domains to the first account to request them.\n\n### ReverseRegistrar\n\nImplementation of the reverse registrar responsible for managing reverse resolution via the .addr.reverse special-purpose TLD.\n\n### TestRegistrar\n\nImplementation of the `.test` registrar facilitates easy testing of ENS on the Ethereum test networks. Currently deployed on Ropsten network, it provides functionality to instantly claim a domain for test purposes, which expires 28 days after it was claimed.\n\n## EthRegistrar\n\nImplements an [ENS](https://ens.domains/) registrar intended for the .eth TLD.\n\nThese contracts were audited by ConsenSys Diligence; the audit report is available [here](https://github.com/ConsenSys/ens-audit-report-2019-02).\n\n### BaseRegistrar\n\nBaseRegistrar is the contract that owns the TLD in the ENS registry. This contract implements a minimal set of functionality:\n\n- The owner of the registrar may add and remove controllers.\n- Controllers may register new domains and extend the expiry of (renew) existing domains. They can not change the ownership or reduce the expiration time of existing domains.\n- Name owners may transfer ownership to another address.\n- Name owners may reclaim ownership in the ENS registry if they have lost it.\n- Owners of names in the interim registrar may transfer them to the new registrar, during the 1 year transition period. When they do so, their deposit is returned to them in its entirety.\n\nThis separation of concerns provides name owners strong guarantees over continued ownership of their existing names, while still permitting innovation and change in the way names are registered and renewed via the controller mechanism.\n\n### EthRegistrarController\n\nEthRegistrarController is the first implementation of a registration controller for the new registrar. This contract implements the following functionality:\n\n- The owner of the registrar may set a price oracle contract, which determines the cost of registrations and renewals based on the name and the desired registration or renewal duration.\n- The owner of the registrar may withdraw any collected funds to their account.\n- Users can register new names using a commit/reveal process and by paying the appropriate registration fee.\n- Users can renew a name by paying the appropriate fee. Any user may renew a domain, not just the name's owner.\n\nThe commit/reveal process is used to avoid frontrunning, and operates as follows:\n\n1.  A user commits to a hash, the preimage of which contains the name to be registered and a secret value.\n2.  After a minimum delay period and before the commitment expires, the user calls the register function with the name to register and the secret value from the commitment. If a valid commitment is found and the other preconditions are met, the name is registered.\n\nThe minimum delay and expiry for commitments exist to prevent miners or other users from effectively frontrunning registrations.\n\n### SimplePriceOracle\n\nSimplePriceOracle is a trivial implementation of the pricing oracle for the EthRegistrarController that always returns a fixed price per domain per year, determined by the contract owner.\n\n### StablePriceOracle\n\nStablePriceOracle is a price oracle implementation that allows the contract owner to specify pricing based on the length of a name, and uses a fiat currency oracle to set a fixed price in fiat per name.\n\n## Resolvers\n\nResolver implements a general-purpose ENS resolver that is suitable for most standard ENS use cases. The public resolver permits updates to ENS records by the owner of the corresponding name.\n\nPublicResolver includes the following profiles that implements different EIPs.\n\n- ABIResolver = EIP 205 - ABI support (`ABI()`).\n- AddrResolver = EIP 137 - Contract address interface. EIP 2304 - Multicoin support (`addr()`).\n- ContentHashResolver = EIP 1577 - Content hash support (`contenthash()`).\n- InterfaceResolver = EIP 165 - Interface Detection (`supportsInterface()`).\n- NameResolver = EIP 181 - Reverse resolution (`name()`).\n- PubkeyResolver = EIP 619 - SECP256k1 public keys (`pubkey()`).\n- TextResolver = EIP 634 - Text records (`text()`).\n- DNSResolver = Experimental support is available for hosting DNS domains on the Ethereum blockchain via ENS. [The more detail](https://veox-ens.readthedocs.io/en/latest/dns.html) is on the old ENS doc.\n\n## Developer guide\n\n### Prettier pre-commit hook\n\nThis repo runs a husky precommit to prettify all contract files to keep them consistent. Add new folder/files to `prettier format` script in package.json. If you need to add other tasks to the pre-commit script, add them to `.husky/pre-commit`\n\n### How to setup\n\n```\ngit clone https://github.com/ensdomains/ens-contracts\ncd ens-contracts\nyarn\n```\n\n### How to run tests\n\n```\nyarn test\n```\n\n### How to publish\n\n```\nyarn pub\n```\n\n### Release flow\n\nSmart contract development tends to take a long release cycle. To prevent unnecessary dependency conflicts, please create a feature branch (`features/$BRNACH_NAME`) and raise a PR against the feature branch. The feature branch must be merged into master only after the smart contracts are depl\n\n[... truncated ...]"
  },
  "Opti-domains/modular-ens-contracts": {
    "fetchedAt": "2025-11-12T23:04:16.182Z",
    "content": "## Foundry\n\n**Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.**\n\nFoundry consists of:\n\n- **Forge**: Ethereum testing framework (like Truffle, Hardhat and DappTools).\n- **Cast**: Swiss army knife for interacting with EVM smart contracts, sending transactions and getting chain data.\n- **Anvil**: Local Ethereum node, akin to Ganache, Hardhat Network.\n- **Chisel**: Fast, utilitarian, and verbose solidity REPL.\n\n## Documentation\n\nhttps://book.getfoundry.sh/\n\n## Usage\n\n### Build\n\n```shell\n$ forge build\n```\n\n### Test\n\n```shell\n$ forge test\n```\n\n### Format\n\n```shell\n$ forge fmt\n```\n\n### Gas Snapshots\n\n```shell\n$ forge snapshot\n```\n\n### Anvil\n\n```shell\n$ source .env && anvil --fork-url $FORK_URL\n```\n\n### Deploy\n\n```shell\n$ source .env && forge script script/DeployDev.s.sol:DeployDevScript --rpc-url $RPC_URL --private-key $PRIVATE_KEY --broadcast\n```\n\n### Deploy Dev\n\n```shell\n$ source .env && forge script script/DeployDev.s.sol:DeployDevScript --rpc-url $RPC_URL --private-key $PRIVATE_KEY --optimize --broadcast\n```\n\n### Deploy to Optimism\n\n```shell\n$ source .env && forge script script/DeployDev.s.sol:DeployDevScript --rpc-url $RPC_URL --private-key $PRIVATE_KEY --optimize --verify --with-gas-price 10000000 --gas-price 10000000 --broadcast\n```\n\n### Cast\n\n```shell\n$ cast <subcommand>\n```\n\n### Help\n\n```shell\n$ forge --help\n$ anvil --help\n$ cast --help\n```\n"
  },
  "Opti-domains/evmgateway": {
    "fetchedAt": "2025-11-12T23:04:16.643Z",
    "content": "# EVM CCIP-Read Gateway\nThis repository implements a generic CCIP-Read gateway framework for fetching state proofs of data on other EVM chains. This allows L1 smart contracts to fetch and verify state from L2s. The library is built to be as modular and interchangeable as possible. This means:\n\n - Anyone can operate their own gateway, but...\n - Only one gateway needs to be operated for each chain, regardless of the applications requesting data from it.\n - Gateways do not need to be trusted; their responses are fully verified on L1.\n - Contracts can fetch L2 state using a simple builder interface and callbacks.\n - Contracts can change targets (eg, a different L2) just by swapping out the address of a verifier contract for another.\n\nWhile this functionality is written primarily with read calls in mind, it also functions for transactions; using a compliant\nlibrary like Ethers, a transaction that includes relevant L2 proofs can be generated and signed.\n\n\n\n## Usage\n\n 1. Have your contract extend `EVMFetcher`.\n 2. In a view/pure context, use `EVMFetcher` to fetch the value of slots from another contract (potentially on another chain). Calling `EVMFetcher.fetch()` terminates execution and generates a callback to the same contract on a function you specify.\n 3. In the callback function, use the information from the relevant slots as you see fit.\n\n## Example\n\nThe example below fetches another contract's storage value `testUint`.\n\n```\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.17;\n\nimport { EVMFetcher } from '@ensdomains/evm-verifier/contracts/EVMFetcher.sol';\nimport { EVMFetchTarget } from '@ensdomains/evm-verifier/contracts/EVMFetchTarget.sol';\nimport { IEVMVerifier } from '@ensdomains/evm-verifier/contracts/IEVMVerifier.sol';\n\ncontract TestL2 {\n    uint256 testUint; // Slot 0\n    \n    constructor() {\n        testUint = 42;\n    }\n}\n\ncontract TestL1 is EVMFetchTarget {\n    using EVMFetcher for EVMFetcher.EVMFetchRequest;\n\n    IEVMVerifier verifier;\n    address target;\n\n    constructor(IEVMVerifier _verifier, address _target) {\n        verifier = _verifier;\n        target = _target;\n    }\n\n    function getTestUint() public view returns(uint256) {\n        EVMFetcher.newFetchRequest(verifier, target)\n            .getStatic(0)\n            .fetch(this.getSingleStorageSlotCallback.selector, \"\");\n    }\n\n    function getSingleStorageSlotCallback(bytes[] memory values, bytes memory) public pure returns(uint256) {\n        return uint256(bytes32(values[0]));\n    }\n}\n```\n\n## Packages\n\nThis is a monorepo divided up into several packages:\n\n### [evm-gateway](/evm-gateway/)\nA framework for constructing generic CCIP-Read gateways targeting different EVM-compatible chains. This repository\nimplements all the functionality required to fetch and verify multiple storage slots from an EVM-compatible chain,\nomitting only the L2-specific logic of determining a block to target, and verifying the root of the generated proof.\n\n### [l1-gateway](/l1-gateway/)\nAn instantiation of `evm-gateway` that targets Ethereum L1 - that is, it implements a CCIP-Read gateway that generates\nproofs of contract state on L1.\n\nThis may at first seem useless, but as the simplest possible practical EVM gateway implementation, it acts as an excellent\ntarget for testing the entire framework end-to-end.\n\nIt may also prove useful for contracts that wish to trustlessly establish the content of storage variables of other contracts,\nor historic values for storage variables of any contract.\n\n### [evm-verifier](/evm-verifier/)\nA Solidity library that verifies state proofs generated by an `evm-gateway` instance. This library implements all the\nfunctionality required make CCIP-Read calls to an EVM gateway and verify the responses, except for verifying the root of the\nproof. This library is intended to be used by libraries for specific EVM-compatible chains that implement the missing \nfunctionality.\n\n### [l1-verifier](/l1-verifier/)\nA complete Solidity library that facilitates sending CCIP-Read requests for L1 state, and verifying the responses.\n\nThis repository also contains the end-to-end tests for the entire stack.\n\n### [op-gateway](/op-gateway/)\nAn instantiation of `evm-gateway` that targets Optimism. Combined with `op-verifier`, makes it possible for L1 contracts to fetch contract state data from Optimism.\n\n### [op-verifier](/op-verifier/)\nA complete Solidity library that facilitates sending CCIP-Read requests for Optimism state, and verifying the responses.\n\n### [arb-gateway](/arb-gateway/)\nAn instantiation of `evm-gateway` that targets Arbitrum. Combined with `arb-verifier`, makes it possible for L1 contracts to fetch contract state data from Arbitrum.\n\n### [arb-verifier](/arb-verifier/)\nA complete Solidity library that facilitates sending CCIP-Read requests for Arbitrum state, and verifying the responses.\n\n### [scroll-gateway](/scroll-gateway/)\nAn instantiation of `evm-gateway` that targets Scroll. Combined with `scroll-verifier`, makes it possible for L1 contracts to fetch contract state data from Scroll.\n\n### [scroll-verifier](/scroll-verifier/)\nA complete Solidity library that facilitates sending CCIP-Read requests for Scroll state, and verifying the responses.\n\n## How to setup locally\n\n```\ngh repo clone ensdomains/evmgateway\nbun install # `@ensdomains/@ensdomains` not found error will be thrown\nbun run workspace evm-gateway build\nbun install\nbun run test\n```\n\n## Troubleshooting\n\n### Error HH12: Trying to use a non-local installation of Hardhat, which is not supported.\n\n`yarn test` spawns `hardhat test` in the forked process. When `hardhat` command is installed under the node_modules of under each workspace, it complains that it's using locally installed hardhat. Remove hardhat from local node_modules and make sure it's only installed under the root `node_modules`\n\n```\nrm -rf *-*/node_modules/hardhat\nrm bun.lockb\nbun install\n```\n\n## A guide on adding new chains\n\nIn a L2 rollup system, state hashes are stored on-chain, along with the transaction calls and arguments logged as calldata. a rollup has a mechanism to verify the state of their chain on L1, either instantly or optimistically.\n\nENS integration utilizes this mechanism in the gateway. The gateway retrieves the data from L2 along side with the proof (often via `eth_getProof`) and returns back to the caller. The caller passes the data to L1 resolver contract to verify its state and data([more detail](https://medium.com/the-ethereum-name-service/mvp-of-ens-on-l2-with-optimism-demo-video-how-to-try-it-yourself-b44c390cbd67)). As long as L1 contract can verify the state and storage of the L2 data, users no longer need to trust the gateway itself. If a gateway service is compromised, the worst can happen is that the gateway stops responding data ( when that happens, the owner of the resolver can simply startup new gateway and update the L1 contract to return the new gateway address). The parent owner does not even have to host the gateway services by themselves but can use third party gateway services.\n\nTo assess whether a L2 rollup system can integrate with ENS, please see the following steps.\n\n1. Does the new chain use [same address format as the ones used in Ethereum](https://info.etherscan.com/what-is-an-ethereum-address/)? = Some ZKRollup chains use different address format. If that's the case, you need to add the wallet address format into ENS multicoin type. Please refer to [Starknet support PR as a reference](https://github.com/ensdomains/address-encoder/pull/365).\n2. Does RPC of the chain return [`eth_getProof`](https://docs.alchemy.com/reference/eth-getproof)? If not, it requies a way to retrieve a storage proof to verify on Ethereum L1\n3. Does the rollup contract have a function to return information of the latest L2 block committed to Ethereum L1? For Optimistic Rollup, it needs both the committed and finalised (after challenge period) block information. The `blockhash` is required to call `eth_getProof` equivalent function on L2\n4. Is t\n\n[... truncated ...]"
  },
  "Opti-domains/ens-diamond-resolver-v1": {
    "fetchedAt": "2025-11-12T23:04:16.977Z",
    "content": "# Sample Hardhat Project\n\nThis project demonstrates a basic Hardhat use case. It comes with a sample contract, a test for that contract, and a script that deploys that contract.\n\nTry running some of the following tasks:\n\n```shell\nnpx hardhat help\nnpx hardhat test\nREPORT_GAS=true npx hardhat test\nnpx hardhat node\nnpx hardhat run scripts/deploy.ts\n```\n"
  },
  "openfort-xyz/openfort-js": {
    "fetchedAt": "2025-11-12T23:04:24.777Z",
    "content": "![Illustration_02](https://github.com/user-attachments/assets/7733bc34-9fa7-4e43-bde0-bbbf5518738c)\n\n\n<div align=\"center\">\n  <h4>\n    <a href=\"https://www.openfort.io/\">\n      Website\n    </a>\n    <span> | </span>\n    <a href=\"https://www.openfort.io/docs/products/embedded-wallet/javascript\">\n      Documentation\n    </a>\n    <span> | </span>\n    <a href=\"https://x.com/openfort_hq\">\n      X\n    </a>\n        <span> | </span>\n    <a href=\"https://create-next-app.openfort.io/\">\n      Demo\n    </a>\n  </h4>\n</div>\n\n[banner-image]: https://blog-cms.openfort.io/uploads/openfortjs_f52fdc3f2d.png\n\n# Openfort JavaScript SDK\n\n[![Downloads](https://img.shields.io/npm/dm/@openfort/openfort-kit.svg)](https://www.npmjs.com/package/@openfort/openfort-js)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)\n[![Documentation](https://img.shields.io/badge/docs-openfort.io-blue)](https://www.openfort.io/docs/products/embedded-wallet/javascript)\n[![Version](https://img.shields.io/npm/v/@openfort/openfort-js.svg)](https://www.npmjs.org/package/@openfort/openfort-js)\n\n**Build wallets in minutes, not months.** JavaScript SDK for embedded wallets, session keys, and gasless transactions.\n\n## Features\n- üîê **Session Keys** for gasless gaming experiences  \n- üíº **Embedded Wallets** for mainstream user onboarding\n- ‚ö° **Account Abstraction** for sponsored transactions\n- üîí **Non-custodial** wallet infrastructure with Shield encryption\n- üåê **Multi-chain** support (EVM and Solana)\n- üì± **Social Auth** with Google, Discord, Twitter integration\n- üí∏ **Gasless Transactions** with configurable gas policies\n- üîß **Developer-friendly** with TypeScript support\n- üìä **Analytics** and monitoring dashboard\n\n## Quick Start\n\n### 1. Install\n```bash\nnpm install @openfort/openfort-js\n```\n\n## Usage examples\n- [Openfort Auth + Embedded Wallet - Next.js](https://github.com/openfort-xyz/openfort-js/tree/main/examples/apps/auth-sample)\n- [Embedded Wallet Wagmi Next.js](https://github.com/openfort-xyz/openfort-js/tree/main/examples/apps/wallet-libraries/next-wagmi)\n- [Third-party auth + Embedded Wallet - Next.js Firebase](https://github.com/openfort-xyz/embedded-wallet-firebase-auth-sample-nextjs)\n\n<!--\n# vim: set tw=79:\n-->"
  },
  "openfort-xyz/openfort-chain-abstraction": {
    "fetchedAt": "2025-11-12T23:04:25.257Z",
    "content": "# Openfort Ecosystem Abstraction\n\n## Overview\n\nEcosystems are parent entities for groups of apps operating on different blockchains or standalone layer 2 networks. Openfort [**ecosystem wallets**](https://www.openfort.xyz/docs/guides/ecosystem) enable seamless interoperability between applications, allowing ecosystems to design their ideal, unified wallet experience. The next evolution is consolidating user liquidity across blockchains, providing a single, unified balance instantly spendable throughout the ecosystem. This vision will be powered by Openfort's chain abstraction implementation of [MagicSpend++](https://ethresear.ch/t/magicspend-spend-now-debit-later/19678/9) hosted in this repository.\n\nWith this setup, ecosystems can deploy tailor-made 4337 chain abstraction infrastructure.\nThey become Liquidity Providers (LPs) for their users, sharing with them the value that would otherwise have been captured by solvers/fillers.\nThey own their users' experience from the wallet to the chain.\n\n\n## System Architecture\n\nChain abstraction relies on resource locks to function effectively. In such systems, a third-party fronts fund and resource locks are counterparty guarantees, ensuring that liquidity providers (LPs) are refunded. There are many different ways to implement resource locks. Should the asset be locked in the account smart contract or a dedicated vault contract? Should users lock before every transaction for a short time, or lock once in a while?\n\nIn this system, locking is a one-time action, similar to having a spending account that generates yield and can be used across various platforms. The yield is enabled because resources are locked in dedicated vaults with different strategies.\n\nWith Openfort, the ecosystem itself serves as the third-party LP. Leveraging the ecosystem wallet, all apps within the ecosystem can detect the user‚Äôs locked balance, allowing for seamless token spending at the speed of the destination chain.\n\n![architecture](./assets/archi.jpg)\n\n## Zoom on the UserOperation paymasterAndData field\n\nAccording to the Account Abstraction [ERC-4337](https://eips.ethereum.org/EIPS/eip-4337) specification, <em>when the paymasterAndData field in the `UserOperation` is not empty, the `EntryPoint` implements a different flow for that `UserOperation`</em> to call the Paymaster before and after the `UserOperation` execution. We use this field to encode the repayment token paths - previously signed by the user as an [EIP-712](https://github.com/ethereum/EIPs/blob/master/EIPS/eip-712.md) message - along with the sponsor tokens (i.e., the tokens being fronted). Additionally, it includes the ecosystem's signature, which authorizes the `UserOperation` and is verified onchain by the CABPaymaster in the `validatePaymasterUserOp` hook.\n\nNote: the system supports native token, represented as `0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE`, following the [ERC-7528](https://eips.ethereum.org/EIPS/eip-7528) native asset convention.\n\n![paymasterAndData](./assets/paymasterAndData.png)\n\n## System Components\n\n### Time-locked Vault\n- Tokenized Vaults with a single underlying EIP-20 token\n- *Not* [4626](https://eips.ethereum.org/EIPS/eip-4626) compliant (does *not* implement EIP-20 to represent shares)\n- Only the VaultManager can interact with the Vault\n- Define locking period when initializing the Vault\n- Deploy on any supported source chains\n- Can be yield-bearing (e.g deposit to Aave or Morpho)\n\n_Note:_ \"Locking\" can be simplified into a *SEND* transaction from an EOA to the Smart Contract Account. A backend watcher listens for received events and automatically transfers the funds to a time-locked vault. This process requires users to sign a session key for the watcher service.\n\n### Vault Manager\n- Manage Vaults\n- Manage withdrawals and deposits\n\n### Invoice Manager\n- Settlement of invoices\n- Prevent double-repayment of invoices with state proof verification\n- authorize paymasters and paymaster verifiers\n\n### Chain Abstraction Paymaster (CABPaymaster)\n\nThe CABPaymaster fronts funds on the destination chain for the user if they _HAVE_ enough locked balance (checked by Openfort Backend).\n\nThe Paymaster contract will get repaid on the source chain(s). Ni1o: user has 100@A, 50@B, and spends 130@C\n\n- Set & update the Paymaster owner address (ecosystem *MUST* own the Paymaster)\n- Withdraw Paymaster balance (Openfort crafts the transaction, but the ecosystem owner *MUST* sign it)\n- Ragequit > owner withdraw all funds from all Paymasters with one signature\n\nPaymaster Owner can subscribe to webhook alerts when the Paymaster balance falls below a certain threshold, before automatic rebalancing is implemented.\n\n### Paymaster Verifiers\n- Permissionless verification of remote event (`InvoiceCreated`) or storage proof (`invoices` mapping in the `InvoiceManager`)\n- Permissionless verification of invoice\n\nAs part of chain abstraction activation, an account registers a Paymaster Verifier, which is subsequently called by the `InvoiceManager` to unlock repayments.\n\n\n## Trust assumptions\n\n- The system relies on cross-L2 execution proofs currently provided by [Polymer](https://docs.polymerlabs.org/docs/build/examples/chain_abstraction/), eliminating the need for users to trust Openfort or the Ecosystem. To repay the ecosystem on the source chain(s) with user assets locked in vaults, Openfort must prove the execution of the `UserOperation` on the destination chain. No refund occurs on the source chain without a corresponding execution proof on the remote chain. The `InvoiceManager` tracks invoices onchain to prevent double-refund.\n- The system supports [Hashi](https://crosschain-alliance.gitbook.io/hashi/introduction/what-is-hashi) as a fallback proving mechanism if Polymer or Openfort ceases operations. Liquidity providers (LPs) first generate a proof for their fronted funds by running a [Hashi RPC API locally](https://github.com/gnosis/hashi/tree/main/packages/rpc#getting-started), which conveniently wraps [eth_getProof](\nhttps://github.com/ethereum/EIPs/issues/1186) for storage proofs or `eth_getTransactionReceipt` for events proof in the receipt trie.\nThen, they call the `fallbackRepay` function of the `InvoiceManager` with the proof and the invoice. This enables refunds solely using public data, without relying on any third party. The fallback proving strategy may evolve, but it will always remain permissionless, as it ultimately determines the system's overall security.\n- Openfort does not have custody of funds in the Ecosystem Paymaster, as the `UserOperation` is co-signed within a secure enclave that enforces predefined policies set by the ecosystem. At any time, the ecosystem can disable a signer, immediately preventing any `UserOperation` from being sent.\n\n\nA key strength of the system is its modular approach to proof verification. With Ethereum interoperability advancing, more proof providers will emerge. The system‚Äôs design allows for seamless integration of new proof verification strategies, giving advanced users the flexibility to select the best fit for their use case. Polymer offers cheap and extremely fast proofs but requires trust in [sequencers](https://docs.polymerlabs.org/docs/learn/intro), whereas Hashi leverages multiple independent oracles to validate, verify, and relay block headers across different blockchains.\n\n\nThe trade-off is between trustlessness and efficiency. Hashi prioritizes decentralization but incurs higher gas costs due to its thorough verification process, with block headers taking up to 24 hours to become available. This makes it a perfect fallback repayment methods but not a serious candidat for real world interop use cases. In contrast, Polymer is optimized for efficiency with near block time proof availability (2-3 seconds), making it the preferred choice for day-to-day operations. Over time, this trade-off may become more nuanced and users will be able to fine-tune the system according to their preferences.\n\n\n![gas cost benchmark](.\n\n[... truncated ...]"
  },
  "openfort-xyz/openfort-contracts": {
    "fetchedAt": "2025-11-12T23:04:25.610Z",
    "content": "![Openfort Protocol][banner-image]\n\n<div align=\"center\">\n  <h4>\n    <a href=\"https://www.openfort.xyz/\">\n      Website\n    </a>\n    <span> | </span>\n    <a href=\"https://www.openfort.xyz/docs\">\n      Documentation\n    </a>\n    <span> | </span>\n    <a href=\"https://www.openfort.xyz/docs/api\">\n      API Docs\n    </a>\n    <span> | </span>\n    <a href=\"https://twitter.com/openfortxyz\">\n      Twitter\n    </a>\n  </h4>\n</div>\n\n[banner-image]: .github/img/OpenfortRed.png\n\n# Openfort Contracts\nOfficial Contracts of the Openfort Project.\n\nThe following standards are supported:\n- ERC-20, ERC-721, ERC-777 and ERC-1155 for different token handling.\n- ERC-173 for ownership standard.\n- EIP-712 and EIP-5267 for typed structured data hashing and signing.\n- ERC-1271 for standard signature validation.\n- ERC-1967 and ERC-1822 for proxies (upgradeable Openfort accounts).\n- EIP-1014 for generating counterfactual addresses using Openfort factories.\n- ERC-4337 for leveraging Account Abstraction using alternative mempools.\n- ERC-6551 for leveraging Token Bound Accounts \n\n## Development\n\n### Install [Foundry](https://github.com/foundry-rs/foundry#installation)\n```\n  curl -L https://foundry.paradigm.xyz | bash\n  foundryup\n```\n\n### Build and test\n```\n  git clone https://github.com/openfort-xyz/openfort-contracts.git && cd openfort-contracts\n  yarn\n  forge install\n  forge build\n  forge test\n```\n\n### Unit Test Coverage\n\nYou can use `Foundry` to get the unit test coverage.\nUse the `lcov` report format and `genhtml` to view the coverage data in a nice web interface.\n```\n  forge coverage --report lcov\n  genhtml -o report --branch-coverage lcov.info\n```\n\n\n## Use different built-in scripts\n\n> Before executing any of the scripts below, make sure you've properly configured your `.env` file.\n\n### Generate a gas report\n\n```\n./script/gasProfile.sh\n```\n\n### Deploy Upgradeable and Managed factories to all chains\n\n```\n./script/deployAllChains.sh\n```\n\n### Check paymaster's deposit and Patron's balance on different chains\n\n```\nforge script CheckDeposits --force\n```\n\n### Deploy one upgradeable factory and one account\n\nSimulation:\n\n```\nforge script --force script/deployManagedAccounts.s.sol -vvvvv --optimizer-runs 1000000 --slow --fork-url $<rpc_network>\n```\n\nActual deployment:\n```\nforge script --force script/deployManagedAccounts.s.sol  -vvvvv --optimizer-runs 1000000 --slow --fork-url $<rpc_network> --broadcast --verify --etherscan-api-key $<api_key>\n```\n\n### Compare gas costs\n\nYou can compare gas costs by running the following command against different gas reports:\n\n```\nforge snapshot --silent --diff gas_reports/2023-05-24_11:52.snap.out\n```\n\n## Static Analyzers\n\n### Static analysis using Slither\nIf you want to perform a static analysis of the smart contracts using Slither, you can run the following commands:\n\n```\n  pip3 install slither-analyzer\n  pip3 install solc-select\n  solc-select install 0.8.19\n  solc-select use 0.8.19\n  slither .\n```\n\n### Static analysis using Mythril\nIf you want to perform a static analysis of the smart contracts using Mythril, you can run the following commands:\n\n```\n  rustup default nightly\n  pip3 install mythril\n  myth analyze contracts/core/static/StaticOpenfortAccount.sol --solc-json mythril.config.json\n```\n\nIf you run into the error `ImportError: cannot import name 'getargspec' from 'inspect'` from Python3 running the commands above, please see the temporary fix [on this comment](https://github.com/ethereum/web3.py/issues/2704#issuecomment-1333163491).\n\n## Gas Stats\n\nThere are two different categories of benchmarks measured in this test: User Operation and Runtime.\n\n- User Operation: Fees are calculated based on the transaction receipt and the serialized signed EIP-1559 transaction for entryPoint.handleUserOp([userOp]). As multi-user-op bundles become more prevalent, we can expect actual fees to undercut the data presented here.\n- Runtime: Runtime transactions are defined as those performed outside of the user operation flow, with the owner key interacting directly with the account factory or account, akin to the way you might use MetaMask today to interact directly with smart contracts.\n\n## Runtime\n\n### Upgradeable Accounts\n|   Smart Contract   |    Description    |    # of deployments per game/ecosystem    |    Avg gas cost    |\n| :----------------- | :---------------------------------- | :---------------------------------- | :------------------------ |\n| UpgradeableOpenfortFactory | Deploy factory (containing UpgradeableOpenfortAccount's implementation) | 1 | ~3,250,000  |\n|   UpgradeableOpenfortAccount  | Create a new upgradeable account using the `createAccountWithNonce()` of the factory | indefinite | ~250,000 |\n|   UpgradeableOpenfortAccount  | Updating to a new implementation using `upgradeTo()` | indefinite | ~3,500  |\n\n\n### Paymaster\n|   Smart Contract   |    Description    |    # of deployments per game/ecosystem    |    Avg gas cost    |\n| :----------------- | :---------------------------------- | :---------------------------------- | :------------------------ |\n|   OpenfortPaymaster | Deploy Paymaster to pay gas in ERC20s | 1 | ~1,250,000  |\n\n## User Operation\n\n### Upgradeable Accounts\n|   Smart Contract   |    Description    |    # of deployments per game/ecosystem    |    Avg gas cost    |\n| :----------------- | :---------------------------------- | :---------------------------------- | :------------------------ |\n|   UpgradeableOpenfortAccount  | Create a new upgradeable account | indefinite | ~350,000 |\n|   UpgradeableOpenfortAccount  | Send native tokens | NA | ~170,000   |\n|   UpgradeableOpenfortAccount  | Send ERC20 tokens | NA | ~190,000  |\n\n\n## Gas Stats in USD\n\nAs of April 2024, the gas price range is reported as the daily average gas price for the first 90 days of 2023 ¬± one standard deviation.\n\n|   Blockchain   |    Gas Price Range    |    Token Price    |     Create an Upgradeable account   |    Native Transfer    |    ERC20 Transfer    |\n| :------------- | :-------------------- | :---------------- |  :------ | :-------------------- | :------------------ |\n| Arbitrum | 0.01 ¬±0.00001853 gwei | ~$3000 | $0.0103-$0.0103 | $0.0050-$0.0050 | $0.0056-$0.0056 |\n| Optimism | 0.06102 ¬±24.05 gwei | ~$3000 | $0.0630-$24.8828 | $0.0306-$12.0859 | $0.0342-$13.5078 |\n| Base | 0.0535 ¬±24.05 gwei | ~$3000 | $0.0552-$24.8751 | $0.0268-$12.0822 | $0.0300-$13.5036 |\n| Polygon | 30 ¬±108 gwei | ~$0.67 | $0.0070-$0.0324 | $0.0034-$0.0157 | $0.0038-$0.0176 |\n| Avalanche | 29 ¬±4.5 nAVAX | ~$33 | $0.3350-$0.3869 | $0.1627-$0.1879 | $0.1818-$0.2100 |\n| BSC | 4 ¬±0.55 gwei | ~$580 | $0.8120-$0.9236 | $0.3944-$0.4486 | $0.4408-$0.5014 |\n| Ethereum | 3.5 ¬±24 gwei | ~$3000 | $3.6120-$28.3803 | $1.7544-$13.7847 | $1.9608-$15.4064 |\n"
  },
  "aragon/osx": {
    "fetchedAt": "2025-11-12T23:04:33.046Z",
    "content": "![Aragon](https://res.cloudinary.com/dacofvu8m/image/upload/v1677353961/Aragon%20CodeArena/osx_blue_logo_lqrvkr.png)\n\n<p align=\"center\">\n  <a href=\"https://aragon.org/\">Aragon website</a>\n  ‚Ä¢\n  <a href=\"https://devs.aragon.org/\">Developer Portal</a>\n  ‚Ä¢\n  <a href=\"https://aragonproject.typeform.com/to/LngekEhU\">Join our Developer Community</a>\n  ‚Ä¢\n  <a href=\"https://aragonproject.typeform.com/dx-contribution\">Contribute</a>\n</p>\n\n<br/>\n\n# Aragon OSx Protocol\n\nThe Aragon OSx protocol is the foundation layer of the new Aragon stack. It allows users to create, manage, and customize DAOs in a way that is lean, adaptable, and secure.\n\nWithin this monorepo, you will be able to find 3 individual packages:\n\n- [Contracts](https://github.com/aragon/osx/tree/main/packages/contracts): the protocol source code (solidity).\n- [Artifacts](https://github.com/aragon/osx/tree/main/packages/artifacts): the ABI and the contract addresses (per network)\n- [Contract-ethers](https://github.com/aragon/osx/tree/main/packages/contracts-ethers) (deprecated): TypeScript wrappers for use on Ethers.js projects.\n\nEach package is distributed via 3 NPM packages:\n\n- `@aragon/osx`: The source files, including the protocol contracts and interfaces\n- `@aragon/osx-artifacts`: The contracts bytecode and ABI to use the protocol or deploy it\n- `@aragon/osx-ethers` (deprecated): The TypeScript wrappers to use the protocol or deploy it using ethers.js\n\nFor more information on the individual packages, please read the respective `README.md`.\n\n## Audits\n\nOSx smart contracts undergo regular audits.\n\n### v1.4.0\n\n**Halborn**: [audit report](./audits/Halborn_AragonOSx_v1_4_Smart_Contract_Security_Assessment_Report_2025_01_03.pdf)\n\n- Commit ID: [e0ba7b60b08fa1665ecac92dc12ea89e4245e7dc](https://github.com/aragon/osx/commit/e0ba7b60b08fa1665ecac92dc12ea89e4245e7dc)\n- Started: 2024-11-18\n- Finished: 2025-02-13\n\n### v1.3.0\n\n**Code4rena**: [link 1](./audits/Code4rena_AragonOSx_2023-12-12.pdf), [link 2](https://code4rena.com/reports/2023-03-aragon)\n\n- Commit ID: [a2461ae61a8c4cc833a117120b76e306936f5e1c](https://github.com/aragon/osx/commit/a2461ae61a8c4cc833a117120b76e306936f5e1c)\n- Started: 2023-03-03\n- Finished: 2023-03-10\n\n**Halborn**: [link 1](./audits/Halborn_AragonOSx_2023-06-13.pdf), [link 2](https://github.com/HalbornSecurity/PublicReports/blob/b3fe424535dce7ce345f74dc7e6c25e9200e7860/Solidity%20Smart%20Contract%20Audits/Aragon_aragonOS_v1_3_0_Smart_Contract_Security_Assessment_Report_Halborn_Final.pdf)\n\n- Commit ID: [0ad8cad2bb661fbd53086d097d11228304d9b73e](https://github.com/aragon/osx/commit/0ad8cad2bb661fbd53086d097d11228304d9b73e)\n- Started: 2023-05-29\n- Finished: 2023-06-13\n\n### v1.0.0\n\n**Halborn**: [link 1](./audits/Halborn_AragonOSx_2023-02-24.pdf), [link 2](https://github.com/HalbornSecurity/PublicReports/blob/b3fe424535dce7ce345f74dc7e6c25e9200e7860/Solidity%20Smart%20Contract%20Audits/Aragon_aragonOS_Smart_Contract_Security_Audit_Report_Halborn_Final.pdf)\n\n- Commit ID: [cb0621dc5185a73240a6ca33fccc7698f059fdf5](https://github.com/aragon/osx/commit/cb0621dc5185a73240a6ca33fccc7698f059fdf5)\n- Started: 2023-02-07\n- Finished: 2023-02-24\n\n## ABI and artifacts\n\nCheck out the [artifacts folder](./packages/artifacts/README.md) to get the deployed addresses and the contract ABI's.\n\n## Contributing\n\nWe'd love to hear what you think! If you want to build this with us, please find a detailed contribution guide in the `CONTRIBUTION_GUIDE.md` [file here](https://github.com/aragon/osx/blob/main/CONTRIBUTION_GUIDE.md).\n\n## Security\n\nIf you believe you've found a security issue, we encourage you to notify us. We welcome working with you to resolve the issue promptly.\n\nSecurity Contact Email: sirt@aragon.org\n\nPlease do not use the issue tracker for security issues.\n\n## Setup\n\nEnsure you have Node and Yarn installed.\n\nThe latest Node version officially supported by OSx and Hardhat is 16. Node >=19 also works, but is technically unsupported by Hardhat. It's recommended to use a tool such as [nvm](https://github.com/nvm-sh/nvm) to manage different node environments. Please see the relevant documentation for details.\n\nStart by running `yarn --ignore-scripts` in the project root in your terminal.\n\n### Dependencies\n\nSince the repo is set up as yarn workspace, all the linking is done automatically. When contributing, we recommend to `cd` into each package, as this mirrors the workflow of the development team.\n\n## How the Aragon OSx protocol works\n\nTo review the contracts powering the Aragon OSx protocol, feel free to head to `packages/contracts`.\n\nThe Aragon OSx protocol architecture is composed of two key sections:\n\n- **Core contracts**: the primitives the end user will interact with. It is composed of mostly 3 parts:\n  - **DAO contract:** the main contract of our core. It holds a DAO's assets and possible actions.\n  - **Permissions**: govern interactions between the plugins, DAOs, and any other address - allowing them (or not) to execute actions on behalf of and within the DAO.\n  - **Plugins**: base templates of plugins to build upon.\n- **Framework contracts**: in charge of creating and registering each deployed DAO or plugin. It contains:\n  - **DAO and Plugin Repository Factories**: creates DAOs or plugins.\n  - **DAO and Plugin Registries**: registers into our protocol those DAOs or plugins.\n  - **Plugin Setup Processor:** installs and uninstalls plugins into DAOs.\n\nAdditionally to those two sections, we have developed several plugins DAOs can easily install upon creation. These are:\n\n- **Token Voting plugin**: enables token holders to vote yes, no or abstain on incoming DAO proposals\n- **Multisig plugin**: enables DAO governance based on approval from a pre-defined members list.\n- **Addresslist Voting plugin**: enables a pre-defined set of addresses to vote yes, no or abstain in a \"one address, one vote\" mode\n- **Admin plugin**: enables full access to an account needing to perform initial maintenance tasks without unnecessary overhead\n\nLet's dive into more detail on each of these sections.\n\n### Core Contracts\n\nThe _Core Contracts_ describe how every DAO generated by the Aragon OSx protocol will be set up. It is very lean by design and constitutes the most critical aspects of our architecture.\n\nIn a nutshell, each DAO is composed of 3 interconnecting components:\n\n1. **The DAO contract:** The DAO contract is where the **core functionality** of the DAO lies. It is the contract in charge of:\n   - Representing the identity and metadata of the DAO (ENS name, logo, description, other metadata)\n   - Holding and managing the treasury assets\n   - Executing arbitrary actions to:\n     - transfer assets\n     - call its own functions\n     - call functions in external contracts\n   - Providing general technical utilities like callback handling and others\n2. **Permissions:** Permissions are an integral part of any DAO and the center of our protocol architecture. The Permissions manager **manages permissions for the DAO** by specifying which addresses have permission to call distinct functions on contracts associated with your DAO. This Permissions manager lives inside the DAO contract.\n3. **Plugins**: Any custom functionality can be added or removed through plugins, allowing you to **fully customize your DAO**. You'll find some base templates of plugins within the `plugins` folder of the _Core Contracts_. Some examples of plugins that DAOs could install are:\n   - Governance (e.g., token voting, one-address one-vote)\n   - Asset management (e.g., ERC-20 or NFT minting, token streaming, DeFi)\n   - Membership (governing budget allowances, access gating, curating a member list)\n\nThe following graphic shows an exemplary DAO setup:\n\n![A potential DAO setup](./images/dao-plugin.svg)\n\nAn examplary DAO setup showing interactions between the three core contract pieces triggered by different user groups: The `DAO` and `PermissionManager` contract in blue and red, respectively, as well as two `Plugin` contracts in green. Bear in mind,\n\n[... truncated ...]"
  },
  "aragon/app": {
    "fetchedAt": "2025-11-12T23:04:33.379Z",
    "content": "![Aragon](https://res.cloudinary.com/dbktgy3vg/image/upload/v1689668058/aragon-app_hpima1.png)\n\n<p align=\"center\">\n  <a href=\"https://aragon.org/\">Aragon website</a>\n  ‚Ä¢\n  <a href=\"https://devs.aragon.org/\">Developer Portal</a>\n  ‚Ä¢\n  <a href=\"https://aragonproject.typeform.com/to/LngekEhU\">Join our Developer Community</a>\n  ‚Ä¢\n  <a href=\"https://aragonproject.typeform.com/dx-contribution\">Contribute</a>\n</p>\n\n<br/>\n\n# Aragon App - Next\n\nThe Aragon App is an easy-to-use platform that empowers users to create and manage their Decentralized Autonomous\nOrganizations (DAOs). The application interacts with the [Aragon OSx](https://github.com/aragon/osx) through the\nintegration of the [Aragon OSx SDK](https://github.com/aragon/sdk) and the\n[Aragon Governance UI Kit](https://github.com/aragon/gov-ui-kit) library.\n\n## Requirements\n\nBefore setting up the project, ensure you have the following installed:\n\n- Node.js: Version >= 22\n- EditorConfig: Ensure your IDE has EditorConfig support enabled\n\n## Getting Started\n\nFollow these steps to get the app running on your machine:\n\n1. Enable Corepack (one-time setup):\n\n```bash\ncorepack enable\n```\n\n2. Install the required dependencies by running:\n\n```bash\npnpm install\n```\n\n**Note**: pnpm will automatically use the correct Node.js version as configured in the project.\n\n3. Create a `.env` file in the root of the project and populate it with the required environment variables. Use the\n   `.env.example` file as a template:\n\n```bash\ncp .env.example .env\n```\n\n4. Start the development server with:\n\n```bash\npnpm dev\n```\n\n5. Access the Aragon App by navigating to [http://localhost:3000](http://localhost:3000) in your browser.\n\nOther available commands include:\n\n- Lint the code:\n\n```bash\npnpm lint\n```\n\n- Build the project:\n\n```bash\npnpm build\n```\n\n- Run tests:\n\n```bash\npnpm test\n```\n\n## Troubleshooting\n\n### Common Issues\n\n**\"Cannot find module\" errors:**\n\n- pnpm uses strict dependency resolution\n- All imports must be declared in package.json\n- Solution: `pnpm add <package-name>`\n\n**Build script errors:**\n\n- Some packages need approval: `pnpm approve-builds`\n- Check `.npmrc` for `public-hoist-pattern` if needed\n\n**Installation issues:**\n\n- Clear cache: `pnpm store prune`\n- Reinstall: `rm -rf node_modules && pnpm install`\n\n**Node version issues:**\n\n- pnpm automatically manages Node.js versions\n- If issues persist, ensure Corepack is enabled: `corepack enable`\n\n## Environments\n\nThe Aragon App supports various environments, each with its unique URL and deployment trigger. Here are the available\nenvironments:\n\n| Name           | Url                         | Deployment trigger                           | Environment file  |\n| -------------- | --------------------------- | -------------------------------------------- | ----------------- |\n| **Local**      | http://localhost:3000       | -                                            | `.env.local`      |\n| **Preview**    | [Generated by the workflow] | Manual by adding the `Preview` label on PRs  | `.env.preview`    |\n| **Develop**    | https://dev.app.aragon.org  | Automatic on `main` branch push              | `.env.develop`    |\n| **Staging**    | https://stg.app.aragon.org  | Manual through the `Staging` Github workflow | `.env.staging`    |\n| **Production** | https://app.aragon.org      | Manual through the `Release` Github workflow | `.env.production` |\n\n## Documentation\n\nThe Aragon App is built using the following tools to ensure a seamless user experience:\n\n- [ReactJS](https://reactjs.org)\n- [NextJs](https://nextjs.org/)\n- [TypeScript](https://www.typescriptlang.org)\n- [Tailwind CSS](https://tailwindcss.com)\n\nFor more technical information about the Aragon App, please check the [Aragon App Documentation](./docs/index.md).\n\n## Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\nPlease make sure to update tests as appropriate.\n\n## Security\n\nIf you believe you've found a security issue, we encourage you to notify us. We welcome working with you to resolve the\nissue promptly. Security Contact Email: sirt@aragon.org Please do not use the issue tracker for security issues.\n\n## Learn More\n\nFor more information about Aragon and its ecosystem, please visit the [Aragon website](https://aragon.org/) and explore\nour [Developer Portal](https://devs.aragon.org/). Join our\n[Developer Community](https://aragonproject.typeform.com/to/LngekEhU) to stay updated and contribute to the growth of\ndecentralized governance.\n\n## License\n\n[GPL-V3](./LICENSE)\n"
  },
  "etherspot/etherspot-modular-sdk": {
    "fetchedAt": "2025-11-12T23:04:40.894Z",
    "content": "<div align=\"center\">\n  <h1 align=\"center\">Etherspot Modular SDK</h1>\n</div>\n\n<div align=\"center\">\n  <img src=\"https://public.etherspot.io/assets/etherspot.gif\" width=\"200\" height=\"200\">\n  <p>\n    <b>\n      Etherspot Modular SDK \n    </b>\n   </p>\n</div>\n\n--------------\n\n>[!IMPORTANT]\n>This repo/software is under active development.\n>\n>[![npm](https://img.shields.io/npm/v/@etherspot/modular-sdk)](https://www.npmjs.com/package/@etherspot/modular-sdk) \n\n\n## üêû Etherspot Modular\n\nEtherspot Modular is a fully open source SDK which let's dapp developers easily get building with Account Abstraction.\n\nThe SDK makes it incredibly easy to get up and running with Account Abstraction. From social logins to transaction batching, using an Etherspot smart wallet can give your dapp a web2 like interface to ensure the user has a seamless experience.\n\n## ‚öô Get started\n\nYou can either get started by installing the packages yourself here:\n\n```bash\nnpm i @etherspot/modular-sdk\n```\n\nOr follow our introductory guide on our docs [here](https://etherspot.fyi/getting-started) which walk you through \ncloning down an example repo and setting up a dapp in your own environment. \n\nThe testnet bundler API key `etherspot_public_key` is included in the example programs which is a public API key with rate limits, to get higher limits register to https://portal.etherspot.io\n\n### Note: The smart wallet address differs on the `XDC Testnet` compared to other chains.\n\n## üìñ Documentation\n\n- [Quick Start](https://etherspot.fyi/getting-started)\n- [Instantiate the SDK](https://etherspot.fyi/prime-sdk/instantiation)\n- [Running SDK examples](https://etherspot.fyi/examples/intro)\n- [Function List](https://etherspot.fyi/prime-sdk/function)\n- [Batching Transactions](https://etherspot.fyi/prime-sdk/batching-transactions)\n\n## üîó Important Links\n\n- [Skandha Bundler](https://etherspot.fyi/skandha/intro)\n- [Arka Paymaster](https://etherspot.fyi/arka/intro)\n- [SDK Reference](https://sdk.etherspot.io/)\n\n## üèåÔ∏è‚Äç‚ôÇÔ∏è Contributions\n\nPlease feel free to open issues or PRs to this repo.\n\n## üîê Security\n\nTo report security issues please follow [guide](./SECURITY.md)\n\n## üí¨ Contact\n\nIf you have any questions or feedback about Etherspot Modular, please feel free to reach out to us.\n\n- [Follow on Twitter](https://twitter.com/etherspot)\n- [Join our discord](https://discord.etherspot.io/)\n\n## üìÑ License\n\nLicensed under the [MIT License](https://github.com/etherspot/etherspot-modular-sdk/blob/master/LICENSE).\n"
  },
  "etherspot/etherspot-prime-contracts": {
    "fetchedAt": "2025-11-12T23:04:41.222Z",
    "content": "# Etherspot Prime Contracts\n\n[![NPM version][npm-image]][npm-url]\n![MIT licensed][license-image]\n\nSmart contract infrastructure for Etherspot Prime, supporting the ERC4337 implementation.\n\n## Installation & Setup\n\n`npm run setup`\n\n## Contract Deployments\n\n### Prerequisites\n\nSet up your `.env` file following the example found in `.env.example`.\n\n### Etherspot Wallet Factory deployment\n\n`npx hardhat deploy --network <NETWORK_NAME> --tags 'etherspot-wallet-factory'`\n\n### Etherspot Paymaster deployment\n\n`npx hardhat deploy --network <NETWORK_NAME> --tags 'etherspot-paymaster'`\n\n### Etherspot Wallet Factory & Etherspot Paymaster deployment\n\n`npx hardhat deploy --network <NETWORK_NAME> --tags 'required'`\n\n### Test Suite\n\n`npx hardhat test`\n\n### Solidity Usage\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.12;\n\nimport \"@etherspot/prime-contracts/src/etherspot-wallet-v1/wallet/EtherspotWallet.sol\";\n\n// ...\n```\n\n## Documentation\n\n- [ERC4337 Specification](https://eips.ethereum.org/EIPS/eip-4337)\n- [Integration Guide](https://docs.etherspot.dev)\n\n## License\n\nMIT\n\n[npm-image]: https://badge.fury.io/js/%40etherspot%2Flite-contracts.svg\n[npm-url]: https://npmjs.org/package/@etherspot/lite-contracts\n[license-image]: https://img.shields.io/badge/license-MIT-blue.svg\n"
  },
  "framesjs/frames.js": {
    "fetchedAt": "2025-11-12T23:04:48.874Z",
    "content": "# frames.js\n\nframes.js is a TypeScript library and framework for writing and testing Farcaster Frames.\n\n<p align=\"center\"><a href=\"https://framesjs.org\"><img width=\"1000\" title=\"Frames.js\" src='https://framesjs.org/og.png' /></a></p>\n\n## Features\n\n- ‚ö°Ô∏è Local frames debugger\n- ü•≥ Write Frames using React\n- üîã Batteries included framework\n- üå¥ Tree-shakeable & Lightweight\n- üöÄ Library with all the functions\n\n## Documentation\n\n[Look at our documentation](https://framesjs.org) to learn more about frames.js.\n\n## Installation\n\n```bash\nnpm install frames.js\n```\n\n```bash\nyarn add frames.js\n```\n\n## Quick Start\n\n### Clone the frames.js starter template (with local debugger)\n\nRun to clone the starter into a new folder called `framesjs-starter`\n\n```bash\nnpx degit github:framesjs/frames.js/examples/framesjs-starter#main framesjs-starter\n```\n\nor [clone from github](https://github.com/framesjs/frames.js/tree/main/templates/next-starter-with-examples)\n\n## Alternatively, add frames.js to your existing project manually\n\n### 1. Add `frames.js` to your project\n\n```sh\nyarn add frames.js\n```\n\n### 2. Create your Frames app\n\nCreate a `frames` directory in your Next.js app and add the following files:\n\n#### `./app/frames/frames.ts`\n\n```tsx [./app/frames/frames.ts]\nimport { createFrames } from \"frames.js/next\";\n\nexport const frames = createFrames({\n  basePath: \"/frames\",\n});\n```\n\n### 3. Create a Frames route\n\n#### `./app/frames/route.tsx`\n\n```tsx [./app/frames/route.tsx]\n/* eslint-disable react/jsx-key */\nimport { Button } from \"frames.js/next\";\nimport { frames } from \"./frames\";\n\nconst handleRequest = frames(async (ctx) => {\n  return {\n    image: (\n      <span>\n        {ctx.pressedButton\n          ? `I clicked ${ctx.searchParams.value}`\n          : `Click some button`}\n      </span>\n    ),\n    buttons: [\n      <Button action=\"post\" target={{ query: { value: \"Yes\" } }}>\n        Say Yes\n      </Button>,\n      <Button action=\"post\" target={{ query: { value: \"No\" } }}>\n        Say No\n      </Button>,\n    ],\n  };\n});\n\nexport const GET = handleRequest;\nexport const POST = handleRequest;\n```\n\n### 4. Include Frames alongside your existing page's metadata\n\n```tsx [./app/page.tsx]\nimport { fetchMetadata } from \"frames.js/next\";\n\nexport async function generateMetadata() {\n  return {\n    title: \"My Page\",\n    // ...\n    other: {\n      // ...\n      ...(await fetchMetadata(\n        // provide a full URL to your /frames endpoint\n        new URL(\n          \"/frames\",\n          process.env.VERCEL_URL\n            ? `https://${process.env.VERCEL_URL}`\n            : \"http://localhost:3000\"\n        )\n      )),\n    },\n  };\n}\n\nexport default function Page() {\n  return <span>My existing page</span>;\n}\n```\n\n### 5. Done! üéâ\n\n![](/frames/frame2.png)\n\n[Debugging your Frames locally](./docs/pages/guides/debugger.mdx)\n\n## Prefer not to use a Framework?\n\n### You can use frames.js library helper functions instead\n\n```tsx filename=\"./app/page.tsx\"\n// page that renders a frame\n// ./app/page.tsx\n\nimport { Frame, getFrameFlattened } from \"frames.js\";\nimport type { Metadata } from \"next\";\n\n// Declare the frame\nconst initialFrame: Frame = {\n  image: \"https://picsum.photos/seed/frames.js/1146/600\",\n  version: \"vNext\",\n  buttons: [\n    {\n      label: \"Random image\",\n    },\n  ],\n  postUrl: `${process.env.NEXT_PUBLIC_HOST}/frames`,\n};\n\n// Export Next.js metadata\nexport const metadata: Metadata = {\n  title: \"Random Image Frame\",\n  description: \"This is an example of a simple frame using frames.js\",\n  openGraph: {\n    images: [\n      {\n        url: \"https://picsum.photos/seed/frames.js/600\",\n      },\n    ],\n  },\n  other: getFrameFlattened(initialFrame),\n};\n```\n\n```ts filename=\"app/frames/route.ts\"\n// handle frame actions\n// ./app/frames/route.ts\n\nimport { getFrameHtml, validateFrameMessage } from \"frames.js\";\nimport { NextRequest } from \"next/server\";\n\nexport async function POST(request: NextRequest) {\n  const body = await request.json();\n\n  // Parse and validate the frame message\n  const { isValid, message } = await validateFrameMessage(body);\n  if (!isValid || !message) {\n    return new Response(\"Invalid message\", { status: 400 });\n  }\n\n  const randomInt = Math.floor(Math.random() * 100);\n  const imageUrlBase = `https://picsum.photos/seed/${randomInt}`;\n\n  // Use the frame message to build the frame\n  const frame = {\n    version: \"vNext\",\n    image: `${imageUrlBase}/1146/600`,\n    buttons: [\n      {\n        label: `Next (pressed by ${message.data.fid})`,\n      },\n    ],\n    ogImage: `${imageUrlBase}/600`,\n    postUrl: `${process.env.NEXT_PUBLIC_HOST}/frames`,\n  };\n\n  // Return the frame as HTML\n  const html = getFrameHtml(frame);\n\n  return new Response(html, {\n    headers: {\n      \"Content-Type\": \"text/html\",\n    },\n    status: 200,\n  });\n}\n```\n\n## License\n\nDistributed under an MIT License. See [LICENSE](./LICENSE) for more information.\n\n## Community\n\nCheck out the following places for more Frames-related content:\n\n- Join the [/frames-dev](https://warpcast.com/frames-dev) channel on Farcaster to ask questions\n- Follow [Frames.js](https://warpcast.com/frames) & team ([@df](https://warpcast.com/df) and [@stephancill](https://warpcast.com/stephancill)) on Farcaster for updates\n- Star [frames.js](https://github.com/framesjs/frames.js) on GitHub to show your support and keep track of updates\n- Browse the [awesome-frames](https://github.com/davidfurlong/awesome-frames) list of awesome Frames projects and resources\n"
  },
  "AaveChan/aave-proposals-v3": {
    "fetchedAt": "2025-11-12T23:04:56.048Z",
    "content": "# Aave proposals v3\n\nThis repository contains various proposals targeting the Aave governance.\nIn addition to the actual proposals this repository also contains tooling to standardize certain protocol tasks.\nThe tooling documentation is co-located with the relevant smart contracts.\n\n## Tooling\n\n### Config engine\n\nThe AaveV3ConfigEngine ([Docs](https://github.com/bgd-labs/aave-helpers/tree/master/src/v3-config-engine#how-to-use-the-engine)) is a helper smart contract to abstract good practices when doing \"admin\" interactions with the Aave v3 protocol, but built on top, without touching the core contracts.\n\nA less comprehensive version of the engine also exists for [protocol v2](https://github.com/bgd-labs/aave-helpers/tree/master/src/v2-config-engine).\n\n## Development\n\nThis project uses [Foundry](https://getfoundry.sh). See the [book](https://book.getfoundry.sh/getting-started/installation.html) for detailed instructions on how to install and use Foundry.\nThe template ships with sensible default so you can use default `foundry` commands without resorting to `MakeFile`.\n\n### Setup\n\n```sh\ncp .env.example .env\nforge install\nnpm i\n```\n\n### Create an aip\n\nThis repository includes a generator to help you bootstrap the required files for an `AIP`.\nTo generate a proposal you need to run: `npm run generate`\n\nTo get a full list of available commands run `npm run generate -- --help`\n\n```sh\nnpm run generate -- --help\n$ tsx generator/cli --help\nUsage: proposal-generator [options]\n\nCLI to generate aave proposals\n\nOptions:\n  -V, --version              output the version number\n  -f, --force                force creation (might overwrite existing files)\n  -p, --pools <pools...>      (choices: \"AaveV2Ethereum\", \"AaveV2EthereumAMM\", \"AaveV2Polygon\", \"AaveV2Avalanche\",\n                             \"AaveV3Ethereum\", \"AaveV3Polygon\", \"AaveV3Avalanche\", \"AaveV3Optimism\",\n                             \"AaveV3Arbitrum\", \"AaveV3Metis\", \"AaveV3Base\")\n  -t, --title <string>       aip title\n  -a, --author <string>      author\n  -d, --discussion <string>  forum link\n  -s, --snapshot <string>    snapshot link\n  -c, --configFile <string>  path to config file\n  -h, --help                 display help for command\n```\n\nIf you have any feedback regarding the generator (bugs, improvements, features), don't hesitate to create an issue. We'd `<3` to see contributions.\n\n### Test\n\n```sh\n# You can use vanilla forge to customize your test\n# https://book.getfoundry.sh/reference/forge/forge-test\nforge test\n# We also provide a script with sensible defaults to just test a single contract matching a filter\nmake test-contract filter=ENS\n```\n\n### Deploy\n\nThe makefile contains some generic templates for proposal deployments.\nTo deploy a contract you can run `make deploy-ledger contract=pathToContract:Contract chain=chainAlias`.\nThe generator will inline exact instructions on the generated scripts.\n\n## Proposal creation\n\nTo create a proposal you have to do three things:\n\n1. deploy the payload & register it on the payloadsController\n2. create an aip\n3. create the mainnet proposal\n\nWhile the first two steps can be performed in parallel, the final proposal creation relies on (1) and (2).\nEvery step can in theory be performed by a different entity.\n\nThe address creating the mainnet proposal(3) requires 80k AAVE of proposition power.\n\n### 1. Deploy payload\n\nThe payload is always deployed on the chain it affects.\nTherefore you need to adjust the relevant script accordingly.\nThe generated scripts include exact instrauctions on what to execute.\n\n### 2. Create an aip\n\nThe aip can be co-located with the proposal code as a markdown file.\nThis repository will manage the upload to ipfs automatically once a pr is merged to `main`.\n\n### 3. Create proposal\n\nThe proposal requires at least one `payload` and the `encodedHash`.\n\n:tada:\n\n## Troubleshooting Verification\n\nIf for whatever reason verification fails, there's a good chance the error is on the foundry side, not in our tooling.\nTo retry a specific verification you can follow the following steps:\n\n1. copy verify.example.json to verify.json\n2. enter an `ETHERSCAN_API_KEY` in your `.env`\n3. replace the `chain` with the appropriate chainId\n4. replace the `hash` with the transaction hash of the deployment transaction (make sure it's the deployment transaction, not the one registering the payload on the payloadscontroller)\n5. run `FOUNDRY_PROFILE=<chainAlias> forge build --force`\n6. run `FOUNDRY_PROFILE=<chainAlias> npx catapulta-verify -b verify.json`\n"
  }
}